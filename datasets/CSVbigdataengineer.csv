job_id,title,comapany,date,location,place,job_function,employment_type,industries,description
2803917600,Entry Level Big Data Engineer,Comcast,2021-10-28,United States,"West Chester, PA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Internet Publishing, and Telecommunications","Comcast brings together the best in media and technology. We drive innovation to create the worlds best entertainment and online experiences. As a Fortune 50 leader, we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines. We are at the forefront of change and move at an amazing pace, thanks to our remarkable people, who bring cutting-edge products and services to life for millions of customers every day. If you share in our passion for teamwork, our vision to revolutionize industries and our goal to lead the future in media and technology, we want you to fast-forward your career at Comcast.

Job Summary

Responsible for planning and designing new software and web applications. Completes programming and implements, tests and debugs defined software components.

Job Description

Core Responsibilities

Reviews, writes and edits codes. Conducts analysis to determine integration needs.
Researches, writes and edits documentation and technical requirements, including software design evaluation plans, test results and technical manuals.
Monitors and evaluates competitive applications and products. Reviews literature, patents and current practices relevant to the solution of assigned projects.
Works with the Quality Assurance team to determine if applications fit specification and technical requirements.
Applies full use and application of engineering methodologies related to area of engineering specialty.
Displays knowledge of engineering concepts and skills and knowledge of their application in the area of specified engineering specialty.
Displays knowledge of and ability to apply, process design and redesign skills.
Consistent exercise of independent judgment and discretion in matters of significance.
Regular, consistent and punctual attendance. Must be able to work nights and weekends, variable schedule(s) and overtime as necessary.
Other duties and responsibilities as assigned.

Employees At All Levels Are Expected To

Understand our Operating Principles; make them the guidelines for how you do your job.
Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services.
Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences.
Win as a team - make big things happen by working together and being open to new ideas.
Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers.
Drive results and growth.
Respect and promote inclusion & diversity.
Do what's right for each other, our customers, investors and our communities.

Qualifications
Hive
Scala
AWS Cloud Computing
Hadoop Ecosystem
Structured Query Language (SQL)
Spark SQL
Unix
Python

Disclaimer

This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.

Comcast is an EOE/Veterans/Disabled/LGBT employer.

Education

Bachelor's Degree

Relevant Work Experience

0-2 Years

Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details.
Show more Show less"
2785048853,Junior Big Data Engineer,Citi,2021-10-10,United States,"Tampa, FL",Engineering and Information Technology,Full-time,"Banking, Financial Services, and Investment Banking","Job Id: 21360388

The Applications Development Intermediate Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities.

Responsibilities:

Utilize knowledge of applications development procedures and concepts, and basic knowledge of other technical areas to identify and define necessary system enhancements, including using script tools and analyzing/interpreting code
Consult with users, clients, and other technology groups on issues, and recommend programming solutions, install, and support customer exposure systems
Apply fundamental knowledge of programming languages for design specifications.
Analyze applications to identify vulnerabilities and security issues, as well as conduct testing and debugging
Serve as advisor or coach to new or lower level analysts
Identify problems, analyze information, and make evaluative judgements to recommend and implement solutions
Resolve issues by identifying and selecting solutions through the applications of acquired technical experience and guided by precedents
Has the ability to operate with a limited level of direct supervision.
Can exercise independence of judgement and autonomy.
Acts as SME to senior stakeholders and /or other team members.
Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.

Qualifications:

2-5 years of relevant experience in the Financial Service industry
Intermediate level experience in Applications Development role
Consistently demonstrates clear and concise written and verbal communication
Demonstrated problem-solving and decision-making skills
Ability to work under pressure and manage deadlines or unexpected changes in expectations or requirements

Education:

Bachelor’s degree/University degree or equivalent experience

This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.

-------------------------------------------------

Job Family Group:

Technology

-------------------------------------------------

Job Family:

Applications Development

------------------------------------------------------

Time Type:

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting

Effective November 1, 2021, Citi requires that all successful applicants for positions located in the United States or Puerto Rico be fully vaccinated against COVID-19 as a condition of employment and provide proof of such vaccination prior to commencement of employment.


Show more Show less"
2819565442,Big Data Engineer,Braintrust,2021-12-02,United States,"Marina District, CA",Engineering and Information Technology,Full-time,"Online Media, Publishing, and Internet Publishing","JOB TYPE: Freelance, Contract Position - No agencies (See notes below)

LOCATION: Remote (TimeZone: BST, CST, EST)

HOURLY RANGE: Our client is looking to pay $100 - $123 USD / HR

ESTIMATED DURATION: 40Hrs/Week - Long Term, 6-month project

About Us

HIGH-LEVEL QUALIFICATIONS:

Braintrust (usebraintrust.com) is a user-controlled talent network, where you keep 100% of what you earn and actually get to own the platform. We've been onboarding some big clients and specifically need a Big Data Engineer for our client.

About Our Client

We own and develop targeting products. We are responsible for bringing world-class targeting solutions to our advertisers. We succeed only when our customers can reach their intended audience. Our work includes iterating on the architecture, technology, design patterns, and workflows for products that enable our advertisers to target Twitter users.

Come build the next generation of products that empower marketers to tell the most interesting, relevant stories in the world, and make a meaningful contribution to an iconic company.

Who You Are

You are excited to join an incredibly talented and enthusiastic team, which loves to tackle new challenges. You like a dynamic & fun environment, believe in our client's mission in the world, and want to be a core actor in pushing it forward.

If you are an analytical thinker who enjoys complex math problems and algorithm design we would like to talk with you. We look forward to working with people who share our passion for good engineering fundamentals and making decisions grounded in data. We sweat the details.

What You’ll Do

You will take up the task of allowing Twitter’s largest advertisers to plan their campaigns with confidence on one side and will be working with our science team on defining the best audience for our clients. You’ll collaborate with data scientists, digging into massive datasets in order to discover insights that can improve the quality of our forecasts. You’ll develop the algorithms in our online forecasting service, turning those insights into working code. You’ll enhance our data pipelines, marshalling and optimizing the information we need to answer queries. And you’ll own a significant product surface at Twitter, caring about operational quality and the metrics that illustrate that we’re helping our customers be successful.

We’d Like To Talk To You If

3+ years industry experience working with confidence on a massive scale, microservice-based tech stack that (required) Scala, Hadoop, Google Cloud technology, especially dataflow, and Aurora/Mesos.
You have a track record of implementing simple, elegant solutions / great products across complex distributed systems.
You’ve demonstrated an ability to excel in whatever you pursue (whether it's work, school, competitions, open source contributions, personal projects, etc.—you've always stood out and succeeded)
You have experience with a diverse range of frameworks/technologies, whether through work or side projects, with special interest in batch or streaming data processing technologies.

Requirements

You have a sound grasp on OOP concepts, data structures and algorithms.
You have a disciplined approach to writing unit and integration tests.
MUST have working knowledge of Scala
MUST have experience with Dataflow, Hadoop or other MapReduce-based architectures
Experience with Redis, Memcached, MySQL or other key value stores
You easily articulate complex concepts in writing and speech.
BS, MS, or PhD in Computer Science

About The Hiring Process

Qualified candidates will be invited to do a screening interview with the Braintrust staff. We will answer your questions about the project, and our platform. If we determine it is the right fit for both parties, we'll invite you to join the platform and create a profile to apply directly for this project.

C2C Candidates: This role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.

Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.
Show more Show less"
2818898895,Big Data Engineer - Telecommute,Optum,2021-12-03,United States,"Columbia, MD",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Wellness and Fitness Services, and Hospitals and Health Care","Combine two of the fastest-growing fields on the planet with a culture of performance, collaboration and opportunity and this is what you get. Leading edge technology in an industry that's improving the lives of millions. Here, innovation isn't about another gadget, it's about making health care data available wherever and whenever people need it, safely and reliably. There's no room for error. Join us and start doing your life's best work.(sm)

Responsible for Hadoop and Big-Data development, operations and maintenance. Responsible for implementing Hadoop based analytics and reporting solutions including loading from disparate data sets, preprocessing using MapReduce, Hive and Pig or similar technologies. A professional at this position level within Optum has the following responsibilities: Scopes and delivers various Big Data solutions. Designs solutions independently based on high-level architecture. Manages the technical communication between the survey vendor and internal systems. Maintains the production systems (Kafka, Hadoop, MongoDB, and Elasticsearch) while testing changes in the lower environments. Collaborates with other development, analysis and research teams.

A professional at this position level within Optum has the following responsibilities: Scopes and delivers various Big Data solutions. Designs solutions independently based on high-level architecture. Manages the technical communication between the survey vendor and internal systems. Maintains the production systems (Kafka, Hadoop, MongoDB, and Elasticsearch) while testing changes in the lower environments. Collaborates with other development, analysis and research teams.

You’ll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges.

Primary Responsibilities

Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet business requirements
Identify, design and implement internal process improvements, automate manual processes, optimize data delivery, and propose re-designing of infrastructure as appropriate to achieve scalability and cost reduction
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies
Build and/or maintain analytics tools that utilize the data pipeline to provide actionable insights into operational efficiency and other key business performance metrics
Work collaboratively with management, client and stakeholders to assist with data-related technical issues and support their data reporting needs
Ensure that data is maintained and secured keeping in mind the ‘least-privilege’ security principle for teams’ access to it
Support the technical teams to design, develop, test and implement cost-effective strategies for assimilating and reporting of data
Identify risks and form contingency plans as soon as possible
Analyze existing operations and schedule training sessions and meetings to discuss improvements
Support the testing and auditing team members to ensure quality checks involved in reporting of sensitive data
Keep up-to-date with industry trends and developments

You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Required Qualifications

Bachelors or Master’s degree in Computer Science, Engineering, or Math, or equivalent experience
3+ years of experience as a Big Data Engineer or similar role
3+ years of experience programming in a back end language (Spark, Java, J2EE, Kafka, etc.)
2+ Experience with Data Analytics and Reporting
Experience with Spark, or the Hadoop ecosystem and similar frameworks
Advanced working SQL and No-SQL knowledge and experience working with a variety of databases (MySQL, NoSQL, Hadoop, MongoDB, etc.)
Familiarity with various cloud technologies such as AWS (EMR, RDS, Redshift, etc.) and Azure
Full COVID-19 vaccination is an essential requirement of this role. UnitedHealth Group will adhere to all federal, state and local regulations as well as all client requirements and will obtain necessary proof of vaccination prior to employment to ensure compliance

Preferred Qualifications

Experience working with the Health and Human Services (HHS)
Experience working in CMMI Level 3 (or higher) environments
Confident and proactive self-starter, skilled in taking initiative, assessing requirements, coming up with plans, and taking the lead in making plans reality
Demonstrate a high degree of adaptability, comfortable in establishing new directions, managing rapid change, and trying different approaches to deal with uncharted territories
Excellent interpersonal skills to build and maintain positive, productive relationships with colleagues, managers, external stakeholders and client
Excellent written and verbal communication skills to coordinate team work and collaborate with management and stakeholders
Comfortable and experienced operating in an outcome oriented environment
Solid analytic skills related to working with unstructured datasets
Creative and innovative approach to problem-solving and attention to detail

To protect the health and safety of our workforce, patients and communities we serve, UnitedHealth Group and its affiliate companies now require all employees to disclose COVID-19 vaccination status prior to beginning employment. In addition, some roles require full COVID-19 vaccination as an essential job function. UnitedHealth Group adheres to all federal, state and local COVID-19 vaccination regulations as well as all client COVID-19 vaccination requirements and will obtain the necessary information from candidates prior to employment to ensure compliance. Candidates must be able to perform all essential job functions with or without reasonable accommodation. Failure to meet the vaccination requirement may result in rescission of an employment offer or termination of employment.

Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm)

Colorado, Connecticut or Nevada Residents Only: The salary range for Colorado residents is $79,700 to $142,600. The salary range for Connecticut/Nevada residents is $87,900 to $156,900. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you'll find a far-reaching choice of benefits and incentives.

All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy.

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.

Job Keywords: MapReduce, Data Engineer, Backend Engineer, Data Pipeline, Data Architecture, Big Data Engineer, Spark, Apache HBase, Hbase, Scala, Hive, Python, Shell Scripting, big data, Hadoop, backend, Java, J2EE, Kafka, Spark, Data Analytics, No-SQL, SQL, MySQL, MongoDB, AWS, Azure, data pipeline architecture, Maryland, Washington D.C., Virginia, Telecommute, Telecommuting, Telecommuter, Work From Home, Work At Home, Remote
Show more Show less"
2789623674,Big Data Engineer,Zoom,2021-12-03,United States,"New York, NY",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","We’re looking for a Big Data Engineer who can find strategic solutions to tough problems. As a Big Data Engineer, you’ll create and manage our data infrastructure and tools, including collecting, storing, processing and analyzing a range of data and data systems. You know how to work quickly and accurately, using the best solutions to analyze mass data sets, and you know how to get results. You’ll also make this data easily accessible across the company and usable in multiple departments.

Responsibilities

Collect and process raw data at scale for a variety of projects and initiatives.
Design and develop data applications using selected tools and frameworks as required and requested for a variety of teams and projects.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Perform tasks such as writing scripts, web scraping, calling APIs, write SQL queries, etc.
Work closely with the engineering team to integrate your work into our production systems.
Process unstructured data into a form suitable for analysis.
Analyze processed data.
Support business decisions with ad hoc analysis as needed.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Qualifications

2 plus years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
A solid track record of data management showing your flawless execution and attention to detail.
Strong knowledge of and experience with statistics.
Programming experience, ideally in Python, Spark, Kafka or Java, and a willingness to learn new programming languages to meet goals and objectives.
Experience in C, Perl, Javascript or other programming languages is a plus.
Knowledge of data cleaning, wrangling, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience in Cloud Data Warehouse, such as Snowflake or Databricks is a plus.
Deep knowledge of data mining, machine learning, natural language processing, or information retrieval.
Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources.
Experience with machine learning toolkits including, H2O, SparkML or Mahout
A willingness to explore new alternatives or options to solve data mining issues, and utilize a combination of industry best practices, data innovations and your experience to get the job done.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2802991173,Big Data Engineer,Zyreone,2021-11-17,United States,United States,,Contract,,"
Strong in JAVA/SCALA programming
C/Python experience is a plus
Big Data Experience – 4+ years experience.
AWS Experience is a must – EMR, S3, Cloud Watch, Lambda, Step Functions
Good communication skills to work with various stakeholders on operational support work

Show more Show less"
2813395447,Big Data Engineer - MI12186858,Diwo,2021-11-28,United States,"Northville, MI",,Full-time,,"(Work in Northville, MI and various unanticipated locations throughout the U.S.)---Design, develop, test, implement and maintain applications designed to improve data reliability, efficiency and quality; perform data acquisition; develop data set processes; design and construct the architecture of a big data platform; align architecture with business requirements; maintain data pipeline; customize and manage integration tools, databases, warehouses, and analytical systems; manage and structure data; set up data-access tools for data scientists; and use MySQL. Requires Master's or it foreign educational equivalent plus 12 months experience in the job offered or 12 months experience in an alternate occupation. The required experience must include 12 months using MySQL. Travel/relocation to various unanticipated work locations throughout the U.S. required. Mail resume and include job bank number on cover letter or resume to: Diwo, Inc., 22260 Haggerty Road, Suite 250, Northville, MI 48167
Show more Show less"
2810594080,Big Data Engineer,Lorven Technologies Inc,2021-11-23,United States,"San Diego, CA",,Full-time,,"Role: Senior Big Data Engineer

Location: San Diego, CA

Experience: Minimum 8 years of experience

Full Time Position




Job Description:

Technical Keywords: AWS, RedShift, PySpark, Looker, Snowflake, Databricks




Job duties:

Data modeling using LookML.
Analyzing data and creating analytics dashboards using Looker.
Querying and analyzing data from Redshift tables.
Migrating data from AWS Redshift to Snowflake
Data preprocessing using PySpark.
Creating Databricks notebooks to perform data preprocessing.




The candidate will have a good knowledge of Python, AWS essential services, and big data concepts including streaming analytics

Show more Show less"
2789630065,Big Data Engineer,Zoom,2021-12-03,United States,United States,Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","We’re looking for a Big Data Engineer who can find strategic solutions to tough problems. As a Big Data Engineer, you’ll create and manage our data infrastructure and tools, including collecting, storing, processing and analyzing a range of data and data systems. You know how to work quickly and accurately, using the best solutions to analyze mass data sets, and you know how to get results. You’ll also make this data easily accessible across the company and usable in multiple departments.

Responsibilities

Collect and process raw data at scale for a variety of projects and initiatives.
Design and develop data applications using selected tools and frameworks as required and requested for a variety of teams and projects.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Perform tasks such as writing scripts, web scraping, calling APIs, write SQL queries, etc.
Work closely with the engineering team to integrate your work into our production systems.
Process unstructured data into a form suitable for analysis.
Analyze processed data.
Support business decisions with ad hoc analysis as needed.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Qualifications

2 plus years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
A solid track record of data management showing your flawless execution and attention to detail.
Strong knowledge of and experience with statistics.
Programming experience, ideally in Python, Spark, Kafka or Java, and a willingness to learn new programming languages to meet goals and objectives.
Experience in C, Perl, Javascript or other programming languages is a plus.
Knowledge of data cleaning, wrangling, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience in Cloud Data Warehouse, such as Snowflake or Databricks is a plus.
Deep knowledge of data mining, machine learning, natural language processing, or information retrieval.
Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources.
Experience with machine learning toolkits including, H2O, SparkML or Mahout
A willingness to explore new alternatives or options to solve data mining issues, and utilize a combination of industry best practices, data innovations and your experience to get the job done.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2779854723,Big Data Engineer,Adobe,2021-11-05,United States,"San Jose, CA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

The challenge

Adobe Data Science Team is looking for a Big Data Engineer who will help building the web’s next generation of data science products. These products would help businesses understand and manage their customers' full lifecycle, from customer analytics to marketing media optimization. By leveraging big data machine learning techniques, our team is building intelligence products and services that address challenging business problems including real-time online media optimization, marketing mix modeling and planning, media attribution, leads scoring, sales operation analytics, customer conversion scoring and optimization, customer churn scoring and management and social network analysis.

We are looking for a passionate big data engineer who will build advanced data ETL/wrangling pipelines, serve predictive models, and provide data intelligence as a service. Ideal candidates will have a strong knowledge in big data techniques and experience in working with cloud technologies like AWS, Azure.

What you'll do

Build big data pipelines and structures that power predictive models and intelligence services on large-scale datasets with high uptime and production level quality.
Implement and manage large scale ETL jobs on Hadoop/Spark clusters in Amazon AWS / Microsoft Azure
Interface with internal data science, engineering and data consumer teams to understand the data needs
Own data quality throughout all stages of acquisition and processing, including data collection, ETL/wrangling, ground truth generation and normalization

What you need to succeed

Master or Bachelor with equivalent experience in Computer Science or equivalent technical fields
2+ years of experience working with large data sets using open source technologies such as Spark, Hadoop, Kafka on one of the major cloud vendors such as AWS, Azure and Google Cloud
Strong SQL (Postgres, Hive, MySQL, etc) and No-SQL (MongoDB, HBase, etc.) skills, including writing complex queries and performance tuning
Must have good command of Python, Spark / Scala and big data techniques (Hive/Pig, MapReduce, Hadoop streaming, Kafka)
Excellent communication, relationship skills and a strong team player.

Preferred Qualifications

Big plus: experience developing and productizing real-world AI/ML applications such as prediction, personalization, recommendation, content understanding and NLP
Experience with Kafka, Jenkins, docker
Distributed computing principles and experience in big data technologies including performance tuning

Show more Show less"
2721108458,Big Data Software Engineer,Zillow,2021-11-23,United States,"Washington, United States",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Financial Services","About The Team

Zillow is disrupting real estate by empowering people to unlock life's next chapter! The Zillow Data Engineering team supports multiple lines of business and is responsible for implementing, operating and improving data pipelines and creating data sets to empower Zillow Group brands and customers. We achieve this goal by building and deploying highly scalable data pipelines, adhering to software/data engineering best practices, and ensuring the quality of our data to the delight of our consumers.

About The Role

In this role, you will evangelize and build Data Products for customer, property and business-specific data to simplify critical ML and Analytics products, like the Zestimate and pricing of Zillow-owned homes, to enrich the customer experience, simply marketing operations. You will partner with other data engineering teams and platform teams within AI to lead the architecture, implementation, and operations of big data pipelines and tools for building high-quality data marts.

As a Member Of This Team, You Will

Design, build, implement and support data pipelines/products to serve ML and Analytical use cases
Collaborate with Product managers, engineers, data scientists, and analysts on mission-critical property data needs to build world-class datasets
Identify opportunities to evangelize and support existing data processes
Contribute back to common tooling/infrastructure to enable self-service tooling to expedite customer onboarding

This role has been categorized as a Remote position. “Remote” employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.

In Colorado, the standard pay range for this role is $129,400.00 - $206,600.00 Annually. This range is specific to Colorado and may not be applicable to other locations.

Who you are

Must have experience working with Open Source and data engineering technologies ( Spark, Hive, Airflow, Kafka, Flink and AWS technologies etc )
Ability to build end to end data pipelines including CICD, Data Quality, Monitoring & Alerting
Must have thorough knowledge of data structures and algorithms
Experience with Data Modeling
Prior experience building data pipelines or products using Python, Java, Scala
Having SQL knowledge is a plus
Must have prior experience working with customers/stakeholders to understand customer perspective by upholding customer values
Ability to work with large and small teams and able to work independently
Possess strong problem-solving skills, sensible trade-offs and a positive attitude
Here at Zillow - we value the experience and perspective of candidates with non-traditional backgrounds. We encourage you to apply if you have transferable skills or related experiences.

In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location.

Get to know us

Zillow is reimagining real estate to make it easier to unlock life’s next chapter.

As the most-visited real estate website in the United States, Zillow® and its affiliates offer customers an on-demand experience for selling, buying, renting or financing with transparency and nearly seamless end-to-end service. Millions of people visit Zillow and its affiliate sites every month to start their home search, and now they can rely on Zillow to help them finish it — and no matter what job you're in, you will play a critical role in making this vision a reality.

At Zillow, we're powered by our innovative and inclusive work culture, where everyone has the flexibility, support and resources to do the best work of their careers. Our efforts to streamline the real estate transaction is supported by our passion to redefine the employee experience, a deep-rooted culture of innovation, a fundamental commitment to Equity and Belonging, and world-class benefits. But don't just take our word for it. Read our reviews on Glassdoor and recent recognition from multiple organizations, including: Fortune’s 100 Best Companies to Work For® List 2021 Bloomberg Gender-Equality Index 2021, Human Rights Campaign (HRC) Corporate Equity Index and HRC’s Best Place to Work for LGBTQ Equality 2021, Fortune Best Workplaces for Technology 2020, Fortune Best Workplaces for Millennials 2020, Fortune Best Workplaces for Parents 2020, and the Deloitte Technology Fast 500.

Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com.

Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.
Show more Show less"
2826926769,Data Engineer (Remote Optional),Coinme,2021-12-04,United States,"Seattle, WA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","At Coinme, we're large enough to make a difference but small enough for your voice to be heard. This means that we are an organization where every person matters. You are part of the success of our business and that of our customers regardless of where you sit in our organization. A human touch in a digital world.

Digital currency can transform the way we conduct business and brings new benefits to both the corporate world and to consumers globally. Coinme is on a mission to help people everywhere understand and use the power of digital currencies as a delightful medium-of-exchange, and be accessible anywhere in the world, so everyone has a fair chance for financial prosperity.

From analyst to engineers, from marketing to client services experts, we're hiring to support your growth and ours – Together We Rise.

Data Engineer

Coinme is hiring a Data Engineer to support our growing Data & Analytics team. As a Data Engineer, your main responsibility is to remain a step ahead of your fellow Data Scientists and Analysts. You will support them by providing tools and infrastructure needed to deliver deployable solutions to business problems. This is more than just building and maintaining ETL pipelines, this is about using your creativity and skillset to enable the team to drive best in class analytic solutions.

What You'll Be Working On:

Design, develop, and maintain data architecture and pipelines
Develop and deliver scalable unit-tested data assets and products that empowers analysts and drives business workflows
Evaluate and continuously improve existing data products and solutions
Work with engineers and product managers to analyze edge cases and plan for architectural scalability
Manage the deployment of multiple data solutions such as business dashboards and machine learning models
Be a staunch advocate for best in class data development and design
Participate in code reviews with meaningful comments
Participate in the team's Agile process
Be a collaborative, helpful, and curious team member


What We're Looking For:

Bachelor's degree in Engineering, Computer Science or related field
3 Years of experience with ETL, SQL, PowerBI, Tableau, or similar technologies
Understanding of data warehousing technologies and event driven architectures
Experience or desire to work in a fast-paced Agile development environment
Ability to work autonomously while interacting with multiple business teams and stakeholders
Experience delivering solutions on Snowflake
Hands-on experience with Python/R


Not Required, But Nice to Have:

Experience with Java or other backend technologies
Experience in fintech is a strong plus
Passion for cryptocurrency and blockchain technology


Why You'll Want to Work Here:

100% Coinme-paid health insurance options for employees and dependents
100% covered Employee Assistance Program
Paid Parental Leave
Generous time off
401k with up to 4% vested match
Professional development reimbursement
Stock Options
Paid Volunteer Hours
Diverse offering of supplemental insurances
100% Remote Optional


If this sounds exciting, we'd love to hear from you! Not sure if you're a perfect fit? Reach out anyway. We're looking for awesome individuals, not people who perfectly match a job posting.

Coinme employees are the brightest and most talented in our field and are our greatest asset. We strive to create a diverse and inclusive culture where the thoughts and ideas of all Coinme employees are valued, appreciated, and respected. Coinme recognizes that embracing a diverse workforce brings different backgrounds, skills, and perspectives that help our company thrive and grow.

Coinme is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.
Show more Show less"
2768477175,Big Data Engineer,Fannie Mae,2021-11-17,United States,"Reston, VA",Information Technology,Full-time,Financial Services,"Company Description

At Fannie Mae, futures are made. The inspiring work we do makes an affordable home a reality and a difference in the lives of Americans. Every day offers compelling opportunities to modernize the nation's housing finance system while being part of an inclusive team using new, emerging technologies. Here, you will help lead our industry forward, enhance your technical expertise, and make your career.

Job Description

As a valued colleague on our team, you will contribute to developing data infrastructure and pipelines to capture, integrate, organize, and centralize data while testing and ensuring the data is readily accessible and in a usable state, including quality assurance.

THE IMPACT YOU WILL MAKE

Responsibilities

The Enterprise Data - Data Engineering - Senior Associate role will offer you the flexibility to make each day your own, while working alongside people who care so that you can deliver on the following responsibilities

Identify customer needs and intended use of requested data in the development of database requirements and support the planning and engineering of enterprise databases.
Maintain comprehensive knowledge of database technologies, complex coding languages, and computer system skills.
Support the integration of data into readily available formats while maintaining existing structures and govern their use according to business requirements.
Analyze new data sources and monitor the performance, scalability, and security of data.
Create an initial analysis and deliver the user interface (UI) to the customer to enable further analysis.

Qualifications

THE EXPERIENCE YOU BRING TO THE TEAM

Minimum Required Experiences
4 years
Desired Experiences
Bachelor’s degree or equivalent
Skills
The group of skills related to Product Development including designing products, developing product roadmaps, translating design requirements, prototyping, etc.
Skilled in cloud technologies and cloud computing
The group of skills related to Programming including coding, debugging, and using relevant programming languages
Experience in the process of analyzing data to identify trends or relationships to inform conclusions about the data
Determining causes of operating errors and taking corrective action
Ability to frame ideas as systems and analyzing the inputs, outputs, and process
Adept at managing project plans, resources, and people to ensure successful project completion
Working with people with different functional expertise respectfully and cooperatively to work toward a common goal
The group of skills related to Communication including communicating in writing or verbally, copywriting, planning and distributing communication, etc
Tools
Skilled in ETL
Skilled in Java and/or Python
Skilled in JSON
Experience using APIs for developing or programming software
Skilled in SQL
Skilled in Amazon Web Services (AWS) offerings, development, and networking platforms

Additional Information

The future is what you make it to be. Discover compelling opportunities at Fanniemae.com/careers.

Fannie Mae is an Equal Opportunity Employer, which means we are committed to fostering a diverse and inclusive workplace. All qualified applicants will receive consideration for employment without regard to race, religion, national origin, gender, gender identity, sexual orientation, personal appearance, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation in the application process, email us at careers_mailbox@fanniemae.com.

REF6200X
Show more Show less"
2779854721,Big Data Engineer,Adobe,2021-11-05,United States,"San Francisco, CA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

The challenge

Adobe Data Science Team is looking for a Big Data Engineer who will help building the web’s next generation of data science products. These products would help businesses understand and manage their customers' full lifecycle, from customer analytics to marketing media optimization. By leveraging big data machine learning techniques, our team is building intelligence products and services that address challenging business problems including real-time online media optimization, marketing mix modeling and planning, media attribution, leads scoring, sales operation analytics, customer conversion scoring and optimization, customer churn scoring and management and social network analysis.

We are looking for a passionate big data engineer who will build advanced data ETL/wrangling pipelines, serve predictive models, and provide data intelligence as a service. Ideal candidates will have a strong knowledge in big data techniques and experience in working with cloud technologies like AWS, Azure.

What you'll do

Build big data pipelines and structures that power predictive models and intelligence services on large-scale datasets with high uptime and production level quality.
Implement and manage large scale ETL jobs on Hadoop/Spark clusters in Amazon AWS / Microsoft Azure
Interface with internal data science, engineering and data consumer teams to understand the data needs
Own data quality throughout all stages of acquisition and processing, including data collection, ETL/wrangling, ground truth generation and normalization

What you need to succeed

Master or Bachelor with equivalent experience in Computer Science or equivalent technical fields
2+ years of experience working with large data sets using open source technologies such as Spark, Hadoop, Kafka on one of the major cloud vendors such as AWS, Azure and Google Cloud
Strong SQL (Postgres, Hive, MySQL, etc) and No-SQL (MongoDB, HBase, etc.) skills, including writing complex queries and performance tuning
Must have good command of Python, Spark / Scala and big data techniques (Hive/Pig, MapReduce, Hadoop streaming, Kafka)
Excellent communication, relationship skills and a strong team player.

Preferred Qualifications

Big plus: experience developing and productizing real-world AI/ML applications such as prediction, personalization, recommendation, content understanding and NLP
Experience with Kafka, Jenkins, docker
Distributed computing principles and experience in big data technologies including performance tuning

Show more Show less"
2789626320,Big Data Engineer,Zoom,2021-12-03,United States,"Phoenix, AZ",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","We’re looking for a Big Data Engineer who can find strategic solutions to tough problems. As a Big Data Engineer, you’ll create and manage our data infrastructure and tools, including collecting, storing, processing and analyzing a range of data and data systems. You know how to work quickly and accurately, using the best solutions to analyze mass data sets, and you know how to get results. You’ll also make this data easily accessible across the company and usable in multiple departments.

Responsibilities

Collect and process raw data at scale for a variety of projects and initiatives.
Design and develop data applications using selected tools and frameworks as required and requested for a variety of teams and projects.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Perform tasks such as writing scripts, web scraping, calling APIs, write SQL queries, etc.
Work closely with the engineering team to integrate your work into our production systems.
Process unstructured data into a form suitable for analysis.
Analyze processed data.
Support business decisions with ad hoc analysis as needed.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Qualifications

2 plus years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
A solid track record of data management showing your flawless execution and attention to detail.
Strong knowledge of and experience with statistics.
Programming experience, ideally in Python, Spark, Kafka or Java, and a willingness to learn new programming languages to meet goals and objectives.
Experience in C, Perl, Javascript or other programming languages is a plus.
Knowledge of data cleaning, wrangling, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience in Cloud Data Warehouse, such as Snowflake or Databricks is a plus.
Deep knowledge of data mining, machine learning, natural language processing, or information retrieval.
Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources.
Experience with machine learning toolkits including, H2O, SparkML or Mahout
A willingness to explore new alternatives or options to solve data mining issues, and utilize a combination of industry best practices, data innovations and your experience to get the job done.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2820350523,Fully Remote - Hadoop Data Engineer / Developer,Insight Global,2021-12-03,United States,United States,,Full-time,,"Seeking a remote Hadoop Data Engineer/Developer. This person will be responsible for troubleshooting data issues within Hadoop. They will be in charge of leading efforts to quantify and qualify reported data quality issues; develop and report program metrics to demonstrate progress and compliance. This person will also be a key participant in identifying and quantifying data related pain points within the organization and assist in the development of remediation plans.




Show more Show less"
2789626328,Big Data Engineer,Zoom,2021-12-03,United States,"Overland Park, KS",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","We’re looking for a Big Data Engineer who can find strategic solutions to tough problems. As a Big Data Engineer, you’ll create and manage our data infrastructure and tools, including collecting, storing, processing and analyzing a range of data and data systems. You know how to work quickly and accurately, using the best solutions to analyze mass data sets, and you know how to get results. You’ll also make this data easily accessible across the company and usable in multiple departments.

Responsibilities

Collect and process raw data at scale for a variety of projects and initiatives.
Design and develop data applications using selected tools and frameworks as required and requested for a variety of teams and projects.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Perform tasks such as writing scripts, web scraping, calling APIs, write SQL queries, etc.
Work closely with the engineering team to integrate your work into our production systems.
Process unstructured data into a form suitable for analysis.
Analyze processed data.
Support business decisions with ad hoc analysis as needed.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Qualifications

2 plus years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
A solid track record of data management showing your flawless execution and attention to detail.
Strong knowledge of and experience with statistics.
Programming experience, ideally in Python, Spark, Kafka or Java, and a willingness to learn new programming languages to meet goals and objectives.
Experience in C, Perl, Javascript or other programming languages is a plus.
Knowledge of data cleaning, wrangling, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience in Cloud Data Warehouse, such as Snowflake or Databricks is a plus.
Deep knowledge of data mining, machine learning, natural language processing, or information retrieval.
Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources.
Experience with machine learning toolkits including, H2O, SparkML or Mahout
A willingness to explore new alternatives or options to solve data mining issues, and utilize a combination of industry best practices, data innovations and your experience to get the job done.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2818893511,Big Data Engineer,Rakuten Advertising,2021-12-03,United States,"Seattle, WA",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Job Description:

SUMMARY:

The Big Data Engineer is part of the global Rakuten Catalog Platform Department. The Catalog Platform provides services to global business units including an accurate, compelling catalog with millions of products and highly relevant search services. The team uses Big Data technologies, Cloud infrastructure, open source scalable search platform and cutting-edge machine learning/statistical modeling.

The Big Data Engineer will be responsible for participating in design and development of Product Catalog and Search components including storage, search, large data processing, APIs, analytics and web services. Be part of an awesome R&D team where you get inspired by talented people, challenges and mission to change the global e-commerce landscape!

Key Responsibilities

Participate in design & development of Product Catalog & Search
Work on implementing storage integration
Work on developing code and unit testing search index integration
Implement large data processing (stream & batch) solutions
Work on enhancing APIs or implementing new APIs
Implement analytics jobs to process large amount of data

MINIMUM REQUIREMENTS (Knowledge, Skills, Abilities

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Strong knowledge of Java
Strong knowledge of design patterns, OOPS principles and data structures
Strong knowledge of at least some of the following frameworks/technologies – Hibernate, Spring, REST, XML, JSON, ActiveMQ, Kafka
Experience with tools and technologies like Gradle, Maven, Jenkins, git, IntelliJ, Eclipse, Docker to support end to end software development
Experience with Relational databases, queries and RDBMS best practices
Strong troubleshooting and performance tuning skills
Ability to work in a fast-paced Agile and rapid deployment in the Cloud/SaaS environment.
Able to effectively communicate across teams and roles.

Qualification Requirements

BS/MS in Computer Science or a related field
1-5 years of solid Java back-end experience

RAKUTEN SHUGI PRINCIPLES

Our worldwide practices describe specific behaviors that make Rakuten unique and united across the world. We expect Rakuten employees to model these 5 Shugi Principles of Success.

Always improve, always advance. Only be satisfied with complete success - Kaizen.
Be passionately professional. Take an uncompromising approach to your work and be determined to be the best.
Hypothesize - Practice - Validate - Shikumika. Use the Rakuten Cycle to success in unknown territory.
Maximize Customer Satisfaction. The greatest satisfaction for workers in a service industry is to see their customers smile.
Speed!! Speed!! Speed!! Always be conscious of time. Take charge, set clear goals, and engage your team.

Show more Show less"
2818892563,Big Data Engineer,Rakuten Advertising,2021-12-03,United States,"San Mateo, CA",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Job Description:

SUMMARY:

The Big Data Engineer is part of the global Rakuten Catalog Platform Department. The Catalog Platform provides services to global business units including an accurate, compelling catalog with millions of products and highly relevant search services. The team uses Big Data technologies, Cloud infrastructure, open source scalable search platform and cutting-edge machine learning/statistical modeling.

The Big Data Engineer will be responsible for participating in design and development of Product Catalog and Search components including storage, search, large data processing, APIs, analytics and web services. Be part of an awesome R&D team where you get inspired by talented people, challenges and mission to change the global e-commerce landscape!

Key Responsibilities

Participate in design & development of Product Catalog & Search
Work on implementing storage integration
Work on developing code and unit testing search index integration
Implement large data processing (stream & batch) solutions
Work on enhancing APIs or implementing new APIs
Implement analytics jobs to process large amount of data

MINIMUM REQUIREMENTS (Knowledge, Skills, Abilities

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Strong knowledge of Java
Strong knowledge of design patterns, OOPS principles and data structures
Strong knowledge of at least some of the following frameworks/technologies – Hibernate, Spring, REST, XML, JSON, ActiveMQ, Kafka
Experience with tools and technologies like Gradle, Maven, Jenkins, git, IntelliJ, Eclipse, Docker to support end to end software development
Experience with Relational databases, queries and RDBMS best practices
Strong troubleshooting and performance tuning skills
Ability to work in a fast-paced Agile and rapid deployment in the Cloud/SaaS environment.
Able to effectively communicate across teams and roles.

Qualification Requirements

BS/MS in Computer Science or a related field
1-5 years of solid Java back-end experience

RAKUTEN SHUGI PRINCIPLES

Our worldwide practices describe specific behaviors that make Rakuten unique and united across the world. We expect Rakuten employees to model these 5 Shugi Principles of Success.

Always improve, always advance. Only be satisfied with complete success - Kaizen.
Be passionately professional. Take an uncompromising approach to your work and be determined to be the best.
Hypothesize - Practice - Validate - Shikumika. Use the Rakuten Cycle to success in unknown territory.
Maximize Customer Satisfaction. The greatest satisfaction for workers in a service industry is to see their customers smile.
Speed!! Speed!! Speed!! Always be conscious of time. Take charge, set clear goals, and engage your team.

Show more Show less"
2780755376,Big Data Engineer,Experian,2021-11-05,United States,"Costa Mesa, CA",Engineering,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Company Description

Experian is the world’s leading global information services company, unlocking the power of data to create more opportunities for consumers, businesses and society. We are thrilled to share that FORTUNE has named Experian one of the 100 Best Companies to work for. In addition, for the last five years we’ve been named in the 100 “World’s Most Innovative Companies” by Forbes Magazine.

Job Description

Experian’s Consumer Information Services is a leader in providing data and predictive insights to organizations. By leveraging state-of-the-art technology and superior data compilation techniques, we provide market-leading tools that assist small and midsize businesses in making real-time decisions

What You’ll Be Doing

Define technical scope and objectives through research and participation in requirements-gathering and definition of processes
Ingest and Process data from various sources in raw, structured, semi-structured, and unstructured format into Big Data ecosystem
Realtime data feed processing using Big Data ecosystem
Design, review, implement and optimize data transformation processes in Big Data ecosystem
Test and prototype new data integration tools, techniques and methodologies
Participate in overall test planning for the application integrations, functional areas and projects.
Work with cross functional teams in an Agile/Scrum environment to ensure a quality product is delivered

Qualifications

What your background looks like

Technical Skills

10+ years of hands-on experience with enterprise scale applications and systems
5+ Year of expertise in Big Data technologies in Hadoop ecosystem (Spark, Yarn, Kafka, Oozie, HBase, Hive, Spark, HDFS, MapReduce etc.), Hadoop distributions like Cloudera (preferred)
5+ Extensive development experience in Java specifically in Spring Framework and related technologies (Springboot, SpringData, SpringCloud, SpringSecurity etc...)
Experience with Scala is highly desirable
Strong understanding of data analytics and data visualization
Experience with Python and Ruby is a plus
Excellent analytical and problem solving skills
Excellent one-on-one communication and presentation skills, specifically able to convey technical information in a clear and unambiguous manner
Working knowledge of Linux operating system

Qualification

Technically focused Bachelor’s degree in Computer Science, Engineering, Math, etc.
Master Degree is a plus

Perks

Competitive pay and comprehensive benefits package
Flexible work schedule and relaxed dress code

Additional Information

All your information will be kept confidential according to EEO guidelines.

Experian is proud to be an Equal Opportunity and Affirmative Action employer. Our goal is to create a thriving, inclusive and diverse team where people love their work and love working together. We believe that diversity, equity and inclusion is essential to our purpose of creating a better tomorrow. We value the uniqueness of every individual and want you to bring your whole, authentic self to work. For us, this is The Power of YOU and it ensures that we live what we believe.
Show more Show less"
2826745288,Big Data Engineer,Cogent People,2021-12-04,United States,"Columbia, MD",Information Technology,Full-time,Computer Software,"Cogent People Inc is seeking a Big Data Engineer to support Healthcare Marketplace data analytics project at CMS. As a Big Data Engineer, you will extract and integrate data from multiple data systems, design and develop complex ETL pipelines, develop data processing solutions, and create standard reusable design patterns.

Specific Residency Requirement: The candidate must have resided in the US for 3 of the past 5 years and must be legally authorized to work for any employer in the US (Citizen, Permanent Resident, EAD).

Responsibilities

Extract and integrate data from multiple data systems and organize data in a format that can be easily read by human or machine.
Transition of legacy ETLs with Java and Hive queries to Spark ETLs.
Design and develop data processing solutions and custom ETL pipelines for varied data formats like parquet and Avro.
Design, develop, test and release ETL mappings, mapplets, workflows using Streamsets, Java MapReduce, Spark and SQL.
Performance tuning of end-to-end ETL integration processes.
Analyze and recommend optimal approach for obtaining data from diverse source systems.
Work closely with the data architects and interface with business stakeholders to understand requirements and offer solutions.

Preferred Qualifications

BS in Information Technology, Computer Science, Software Engineering or related field.
Understanding of distributed computing principles and hands-on experience in Big Data Analytics and development.
Good knowledge of Hadoop and Spark ecosystems including HDFS, Hive, Spark, Yarn, MapReduce and Sqoop.
4+ years of Big Data development experience.
3+ years of working experience in ETL development and functional programming knowledge preferably with Scala, Spark, Java, Python, R.
3+ years of experience tuning Spark/Java coding, SQL and No SQL.
AWS development using big data technologies preferred.
AWS cloud-certified, Databricks, and Snowflake experience a plus.

Benefits
Selection of health, dental and vision insurance coverage through CareFirst
Company pays 70% of health and dental insurance premiums for the employee and family
Company pays 100% of vision insurance premium for the employee and family
Contributions towards a 401K Plan, with a matching contribution up to 4% of your annual compensation
The company contributions are vested immediately
Life, short-term and long-term disability, and AD&D insurance (company pays 100%)
3 weeks Paid Time Off
10 additional annual holidays aligned with the Federal Holiday schedule
Remote work options

EEO Employer

Cogent People is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, gender, gender identity, sexual orientation, age, status as a protected veteran, among other things, or status as a qualified individual with disability.
Show more Show less"
2789626324,Big Data Engineer,Zoom,2021-12-03,United States,"Pittsburgh, PA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","We’re looking for a Big Data Engineer who can find strategic solutions to tough problems. As a Big Data Engineer, you’ll create and manage our data infrastructure and tools, including collecting, storing, processing and analyzing a range of data and data systems. You know how to work quickly and accurately, using the best solutions to analyze mass data sets, and you know how to get results. You’ll also make this data easily accessible across the company and usable in multiple departments.

Responsibilities

Collect and process raw data at scale for a variety of projects and initiatives.
Design and develop data applications using selected tools and frameworks as required and requested for a variety of teams and projects.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Perform tasks such as writing scripts, web scraping, calling APIs, write SQL queries, etc.
Work closely with the engineering team to integrate your work into our production systems.
Process unstructured data into a form suitable for analysis.
Analyze processed data.
Support business decisions with ad hoc analysis as needed.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Qualifications

2 plus years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
A solid track record of data management showing your flawless execution and attention to detail.
Strong knowledge of and experience with statistics.
Programming experience, ideally in Python, Spark, Kafka or Java, and a willingness to learn new programming languages to meet goals and objectives.
Experience in C, Perl, Javascript or other programming languages is a plus.
Knowledge of data cleaning, wrangling, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience in Cloud Data Warehouse, such as Snowflake or Databricks is a plus.
Deep knowledge of data mining, machine learning, natural language processing, or information retrieval.
Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources.
Experience with machine learning toolkits including, H2O, SparkML or Mahout
A willingness to explore new alternatives or options to solve data mining issues, and utilize a combination of industry best practices, data innovations and your experience to get the job done.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2793259124,Big Data Engineer,Young Gen Technologies LLC.,2021-11-10,United States,United States,,Contract,,"Position: Big Data Enineer
Duration: Long Term Contract
Location: Remote
Duration: Long Term contract
Visa: OPT/CPT/ H1B/ USC/ GC

• Practical experience of Hadoop, Hive.
• Must have java experience.
• Must have Spark experience.
• 3+ years of experience with Apache Spark - this is the most important skill needed

Skills Required:

– Good knowledge of Scala/Java/J2EE & Web Services.
– Designed/ architected and implemented complex projects dealing with the considerable data size (GB/ PB) and with high complexity.
– Should have experience on working with batch processing/ real-time systems using various Open Source technologies like Hadoop, NoSQL DB’s, Spark, Scala, Kafka, etc.
– Capable of providing the design and Architecture for the typical business problems, exposure on Hadoop distribution used in big data solution.
– Excellent ability to grasp business processes and translate them into what is needed to be done technically to implement them.
– Good communication, problem solving & interpersonal skills.
– Working experience on Production Enviornment
– Layered Architecture, clustering
– Deployment of the Architecture, Architecture Trade-offs, Architecture Concepts



Show more Show less"
2818890917,Big Data Engineer,Rakuten Rewards,2021-12-03,United States,"Seattle, WA",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Job Description:

SUMMARY:

The Big Data Engineer is part of the global Rakuten Catalog Platform Department. The Catalog Platform provides services to global business units including an accurate, compelling catalog with millions of products and highly relevant search services. The team uses Big Data technologies, Cloud infrastructure, open source scalable search platform and cutting-edge machine learning/statistical modeling.

The Big Data Engineer will be responsible for participating in design and development of Product Catalog and Search components including storage, search, large data processing, APIs, analytics and web services. Be part of an awesome R&D team where you get inspired by talented people, challenges and mission to change the global e-commerce landscape!

Key Responsibilities

Participate in design & development of Product Catalog & Search
Work on implementing storage integration
Work on developing code and unit testing search index integration
Implement large data processing (stream & batch) solutions
Work on enhancing APIs or implementing new APIs
Implement analytics jobs to process large amount of data

MINIMUM REQUIREMENTS (Knowledge, Skills, Abilities

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Strong knowledge of Java
Strong knowledge of design patterns, OOPS principles and data structures
Strong knowledge of at least some of the following frameworks/technologies – Hibernate, Spring, REST, XML, JSON, ActiveMQ, Kafka
Experience with tools and technologies like Gradle, Maven, Jenkins, git, IntelliJ, Eclipse, Docker to support end to end software development
Experience with Relational databases, queries and RDBMS best practices
Strong troubleshooting and performance tuning skills
Ability to work in a fast-paced Agile and rapid deployment in the Cloud/SaaS environment.
Able to effectively communicate across teams and roles.

Qualification Requirements

BS/MS in Computer Science or a related field
1-5 years of solid Java back-end experience

RAKUTEN SHUGI PRINCIPLES

Our worldwide practices describe specific behaviors that make Rakuten unique and united across the world. We expect Rakuten employees to model these 5 Shugi Principles of Success.

Always improve, always advance. Only be satisfied with complete success - Kaizen.
Be passionately professional. Take an uncompromising approach to your work and be determined to be the best.
Hypothesize - Practice - Validate - Shikumika. Use the Rakuten Cycle to success in unknown territory.
Maximize Customer Satisfaction. The greatest satisfaction for workers in a service industry is to see their customers smile.
Speed!! Speed!! Speed!! Always be conscious of time. Take charge, set clear goals, and engage your team.

Show more Show less"
2721105730,Big Data Software Engineer,Zillow,2021-11-22,United States,United States,Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Financial Services","About The Team

Zillow is disrupting real estate by empowering people to unlock life's next chapter! The Zillow Data Engineering team supports multiple lines of business and is responsible for implementing, operating and improving data pipelines and creating data sets to empower Zillow Group brands and customers. We achieve this goal by building and deploying highly scalable data pipelines, adhering to software/data engineering best practices, and ensuring the quality of our data to the delight of our consumers.

About The Role

In this role, you will evangelize and build Data Products for customer, property and business-specific data to simplify critical ML and Analytics products, like the Zestimate and pricing of Zillow-owned homes, to enrich the customer experience, simply marketing operations. You will partner with other data engineering teams and platform teams within AI to lead the architecture, implementation, and operations of big data pipelines and tools for building high-quality data marts.

As a Member Of This Team, You Will

Design, build, implement and support data pipelines/products to serve ML and Analytical use cases
Collaborate with Product managers, engineers, data scientists, and analysts on mission-critical property data needs to build world-class datasets
Identify opportunities to evangelize and support existing data processes
Contribute back to common tooling/infrastructure to enable self-service tooling to expedite customer onboarding

This role has been categorized as a Remote position. “Remote” employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.

In Colorado, the standard pay range for this role is $129,400.00 - $206,600.00 Annually. This range is specific to Colorado and may not be applicable to other locations.

Who you are

Must have experience working with Open Source and data engineering technologies ( Spark, Hive, Airflow, Kafka, Flink and AWS technologies etc )
Ability to build end to end data pipelines including CICD, Data Quality, Monitoring & Alerting
Must have thorough knowledge of data structures and algorithms
Experience with Data Modeling
Prior experience building data pipelines or products using Python, Java, Scala
Having SQL knowledge is a plus
Must have prior experience working with customers/stakeholders to understand customer perspective by upholding customer values
Ability to work with large and small teams and able to work independently
Possess strong problem-solving skills, sensible trade-offs and a positive attitude
Here at Zillow - we value the experience and perspective of candidates with non-traditional backgrounds. We encourage you to apply if you have transferable skills or related experiences.

In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location.

Get to know us

Zillow is reimagining real estate to make it easier to unlock life’s next chapter.

As the most-visited real estate website in the United States, Zillow® and its affiliates offer customers an on-demand experience for selling, buying, renting or financing with transparency and nearly seamless end-to-end service. Millions of people visit Zillow and its affiliate sites every month to start their home search, and now they can rely on Zillow to help them finish it — and no matter what job you're in, you will play a critical role in making this vision a reality.

At Zillow, we're powered by our innovative and inclusive work culture, where everyone has the flexibility, support and resources to do the best work of their careers. Our efforts to streamline the real estate transaction is supported by our passion to redefine the employee experience, a deep-rooted culture of innovation, a fundamental commitment to Equity and Belonging, and world-class benefits. But don't just take our word for it. Read our reviews on Glassdoor and recent recognition from multiple organizations, including: Fortune’s 100 Best Companies to Work For® List 2021 Bloomberg Gender-Equality Index 2021, Human Rights Campaign (HRC) Corporate Equity Index and HRC’s Best Place to Work for LGBTQ Equality 2021, Fortune Best Workplaces for Technology 2020, Fortune Best Workplaces for Millennials 2020, Fortune Best Workplaces for Parents 2020, and the Deloitte Technology Fast 500.

Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com.

Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.
Show more Show less"
2789676845,"Big Data Engineer, Data Modeling",App Annie,2021-12-03,United States,United States,Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","PLEASE NOTE THAT YOU CAN WORK REMOTELY BUT YOU NEED TO BE LOCATED IN PST/PDT OR MOUNTAIN TIME ZONE TO APPLY FOR THIS ROLE

Something About Us

App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. We are headquartered in San Francisco with 12 offices worldwide. More than 1,200 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business.

Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.

What can you tell your friends when they ask you what you do?

We’re looking for an experienced Big Data engineer who can create innovative new products in the analytics and data space. You will participate in the development that creates the world's #1 app stores analytics service. Together with the team you will build out new product features and applications using agile methodologies and open source technologies. You will work directly with Product Managers, Software Architects, and will be on the front lines of coding new and exciting analytics and data mining products. You should be passionate about what you do and excited to join an entrepreneurial start-­up.

You will be responsible for and take pride in….

As a Big Data Engineer, we will need you to be in charge of model implementation and maintenance, and to build clean, robust and maintainable data processing program that can support these projects on huge amount of data, this includes

Able to design and implement complex product components based on requirements with possible technical solutions.
Write data programs using pyspark with a commitment to maintaining high quality work while being confident in dealing with data mining challenges.
Discover any feasible new technologies lying in the Big Data ecosystem, share them to team with your professional perspectives.
Get up to speed in the machine learning domain, implementing analysis components in a distributed computing environment with instruction from Data Scientists.
Be comfortable conducting detailed discussions with Data Scientists regarding specific questions related to specific data models.
You should be a strong problem solver with proven experience in big data.

You should recognize yourself in the following…

Hands-on experience and deep knowledge of Hadoop ecosystem
Must: PySpark, Mapreduce, HDFS
Plus: Storm, Kafka
Must have 2+ years Linux environment development experience.
Proficient with programming in Python, experience in Pandas, Sklearn or Other data science and data analysis toolset is a big plus.
Having a background of data mining and machine learning domain, familiar with common algorithms and libs is a plus.
Passion for cloud computing (AWS in particular) and distributed systems.
You must be a great problem solver with the ability to dive deeply into complex problems and emerge with clear and pragmatic solutions.
Good communication, and cooperation globally.
Major in Math or Computer Science.

This Is What We Offer…

We provide a $1,000 (country equivalent) WFH allowance to set you up for remote work success.
Internet allowance for stable internet connection, so your video does not freeze on Zoom.
You can work remotely from anywhere as long as you are based in the PST or MST time zone.
90-days global passport. Work remotely from anywhere in the world for 90 days a year!
Flexible working days. We love to meet, but if you need to get your kids behind school-zoom, need to leave early to get to your band repetition or gym classes, do your thing.
Paid leave, so long as you promise to come back!
Health and dental benefits.
An international team of talented and engaged people from different cultural backgrounds and locations.
Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!
Unlimited access to online learning platform Udemy to help you develop your skills.
Virtual initiatives and events to keep you connected with your colleagues.
Generous Employee Referral Program. Up to $10,000 for specific roles.

Yes, I want this job!
Show more Show less"
2826242942,Big Data Engineer,PCR Staffing,2021-12-03,United States,"Huntersville, NC",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Full time / Direct Hire ONLY-

The individual will be passionate about data, software development and analytics with first-hand experience in collecting, storing, processing, and analyzing of huge sets of data. The candidate will have personal experience implementing data lakes, real time and batch data movement, modern data warehousing solutions, master data management, data analytics, advanced analytics, business intelligence, and API development.

Ability to design, build, and maintain the ETL pipeline and data warehouse.
Knowledge of SQL/database(s), Hadoop-based analytics and ability to create & integrate APIs.
Ability to use programming language, scripting, reporting and data visualization.
Demonstrate expertise in data modeling and query performance tuning on SQL Server, Snowflake or similar platforms.
Design, construct, install, test and maintain data management systems
Implement ETL process to analyze and import data from existing data sources
Build data pipelines for ingestion processing, and surfacing of data for large-scale applications
Research new uses for existing data
Use many different scripting languages and tools to connect systems together
Research and Client new methods to acquire data, and new applications for existing data
Work with other members of the data team, including data architects, data analysts, and data scientists
Select and integrate Big Data tools and frameworks required to provide requested capabilities

This is a direct hire role ONLY for a Charlotte NC based client , salary range of $130,000 - $150,000- Prefer candidates within 200 mile radius of Charlotte NC for onsite requirements from time to time, but will consider candidate in the EST and CST time zone.

Main Duties/Required Skills

Very strong in SQL

UNIX/LINUX commands and shell scripting

Previous experience in data engineering including big data and cloud technologies

Strong in Python, API integrations, Data warehousing concepts, ETL design/development

Good knowledge of Big Data querying tools.

Experience with integration of data from multiple data sources

Knowledge of various ETL techniques and frameworks.

Experience with various messaging systems, such as Kafka or RabbitMQ

Experience with building stream-processing systems

Experience with Big Data Client toolkits

Good understanding of GCP Architecture, along with its advantages and drawbacks

Proficient understanding of distributed computing principles

Intellectual curiosity to find new and unusual ways of how to solve data management issues.

Ability to work in a fast-paced environment and manage multiple priorities in parallel.

Nice To Have Skills

Advanced degree in mathematics or data science

Experience In Snowflake, GCP BQ, DBT, Advanced Analytics/Data Science

7-10+ years of relevant experience

Experience with modern cloud-based data pipelines, data modeling, data management and governance, and data architecture is also a plus.

Key Skills

Data Engineer

SQL

Python

ETL

Hadoop

UNIX / LINUX

Bachelor's Degree Requirement: Yes
Show more Show less"
2825556658,Junior Data Engineer,Deloitte,2021-12-03,United States,"Washington, DC","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

Work you'll do

We are looking for experienced Data Engineers to build and deliver innovative, game-changing mission-driven data pipelines. On this project, you will be responsible for leading the architecture and setup of hosted data lakes, as well as the ingestion pipeline and processing for large datasets, working closely with Agile software development team(s). This role includes responsibilities such as creating and managing schedules for data management (migration, integration, etc.) efforts, working with clients to validate migrated data, working with Agile development teams to understand changes and their impacts towards data migration efforts, among other tasks.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Bachelor's degree required
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be able to obtain and maintain the required clearance for this role
2+ years of experience with extract, transform, and load (ETL) methods and tools
2+ years of experience with data modeling, data warehousing, and building ETL pipelines
2+ years of experience with SQL queries and JSON objects
1+ years of experience with both SQL and NoSQL databases, including PostgreSQL and MongoDB

Preferred:

Familiarity with microservice architectures
Interest in event streaming architectures, such as Apache Kafka
Prior professional services or federal consulting experience
Knowledge of data mining, machine learning, data visualization and statistical modeling
Ability to thrive in a fast-paced work environment with multiple stakeholders
Creativity and innovation - desire to learn and apply new technologies, products, and libraries
High-performing team player

How you'll grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
Show more Show less"
2771751503,Big Data Engineer,Barclays,2021-10-02,United States,"Whippany, NJ",Engineering and Information Technology,Full-time,Banking and Financial Services,"RFT Radial Engineer

Whippany, NJ

As a Radial Engineer in our Risk, Finance and Treasury division, you will be a key resource in a Global RADIAL environment management team. RADIAL being the strategic ‘Big Data’ platform within the Risk & Analytics area. This AVP level Engineer’s primary focus will be to onboard RADIAL into the RFT environment function and optimize the environments, processes and support.

Barclays is one of the world's largest and most respected financial institutions, with 329 years of success, quality and innovation behind us. We've helped millions of individuals and businesses thrive, creating financial and digital solutions that the world now takes for granted. An important and growing presence in the USA, we offer careers providing endless opportunity.

What will you be doing?


You will use the Agile process and manage the JIRA stack.
You will own problems and drive solutions.
Work with Development Teams, peers and Project Managers to understand and deliver requirements.
Analyze requirements to find the most appropriate technical solution.
Document designs and communicate them with the team.
Utilize Hadoop and Cloudera.
Ensure adherence to bank technical standards & SDLC.


What We’re Looking For


Experience using Big Data systems including Hadoop
A detailed understanding of server, database and cloud technologies.
Server Performance analysis and capacity planning
Experience with Excel, JIRA, SQL server and SharePoint; RedHat/Linux administration with BASH scripting
Solid Release Management Skills using TeamCity, Perforce or similar technologies


Skills That Will Help You In The Role


Linux or Windows Scripting
Cloudera administration
Exposure to Hadoop ecosystem.
Service Management experience
Project Management experience
Experience deploying high-performance server-side/compute grid distributed risk generation software
Strong architecture and design


Where will you be working?

At Barclays we’re proud to be redefining the future of finance and here in Whippany, we are defining the future of the workplace and the ways we work and live. We are creating a unique community; one of four strategic tech-enabled hubs that will redefine opportunity for everyone that works here. Whatever you do at Barclays, you’ll have every chance to build a world class career in this world class environment.

90290040
Show more Show less"
2825556659,Junior Data Engineer,Deloitte,2021-12-03,United States,"Arlington, VA","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

Work you'll do

We are looking for experienced Data Engineers to build and deliver innovative, game-changing mission-driven data pipelines. On this project, you will be responsible for leading the architecture and setup of hosted data lakes, as well as the ingestion pipeline and processing for large datasets, working closely with Agile software development team(s). This role includes responsibilities such as creating and managing schedules for data management (migration, integration, etc.) efforts, working with clients to validate migrated data, working with Agile development teams to understand changes and their impacts towards data migration efforts, among other tasks.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Bachelor's degree required
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be able to obtain and maintain the required clearance for this role
2+ years of experience with extract, transform, and load (ETL) methods and tools
2+ years of experience with data modeling, data warehousing, and building ETL pipelines
2+ years of experience with SQL queries and JSON objects
1+ years of experience with both SQL and NoSQL databases, including PostgreSQL and MongoDB

Preferred:

Familiarity with microservice architectures
Interest in event streaming architectures, such as Apache Kafka
Prior professional services or federal consulting experience
Knowledge of data mining, machine learning, data visualization and statistical modeling
Ability to thrive in a fast-paced work environment with multiple stakeholders
Creativity and innovation - desire to learn and apply new technologies, products, and libraries
High-performing team player

How you'll grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
Show more Show less"
2818892564,Big Data Engineer,Rakuten Rewards,2021-12-03,United States,"San Mateo, CA",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Job Description:

SUMMARY:

The Big Data Engineer is part of the global Rakuten Catalog Platform Department. The Catalog Platform provides services to global business units including an accurate, compelling catalog with millions of products and highly relevant search services. The team uses Big Data technologies, Cloud infrastructure, open source scalable search platform and cutting-edge machine learning/statistical modeling.

The Big Data Engineer will be responsible for participating in design and development of Product Catalog and Search components including storage, search, large data processing, APIs, analytics and web services. Be part of an awesome R&D team where you get inspired by talented people, challenges and mission to change the global e-commerce landscape!

Key Responsibilities

Participate in design & development of Product Catalog & Search
Work on implementing storage integration
Work on developing code and unit testing search index integration
Implement large data processing (stream & batch) solutions
Work on enhancing APIs or implementing new APIs
Implement analytics jobs to process large amount of data

MINIMUM REQUIREMENTS (Knowledge, Skills, Abilities

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Strong knowledge of Java
Strong knowledge of design patterns, OOPS principles and data structures
Strong knowledge of at least some of the following frameworks/technologies – Hibernate, Spring, REST, XML, JSON, ActiveMQ, Kafka
Experience with tools and technologies like Gradle, Maven, Jenkins, git, IntelliJ, Eclipse, Docker to support end to end software development
Experience with Relational databases, queries and RDBMS best practices
Strong troubleshooting and performance tuning skills
Ability to work in a fast-paced Agile and rapid deployment in the Cloud/SaaS environment.
Able to effectively communicate across teams and roles.

Qualification Requirements

BS/MS in Computer Science or a related field
1-5 years of solid Java back-end experience

RAKUTEN SHUGI PRINCIPLES

Our worldwide practices describe specific behaviors that make Rakuten unique and united across the world. We expect Rakuten employees to model these 5 Shugi Principles of Success.

Always improve, always advance. Only be satisfied with complete success - Kaizen.
Be passionately professional. Take an uncompromising approach to your work and be determined to be the best.
Hypothesize - Practice - Validate - Shikumika. Use the Rakuten Cycle to success in unknown territory.
Maximize Customer Satisfaction. The greatest satisfaction for workers in a service industry is to see their customers smile.
Speed!! Speed!! Speed!! Always be conscious of time. Take charge, set clear goals, and engage your team.

Show more Show less"
2805119353,Big Data Engineer (Remote-US),Dell Technologies,2021-10-29,United States,"Round Rock, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Hardware Manufacturing, and Computer Software","Big Data Engineer

Dell Technologies creates technology solutions for a changing world. Our IT Architecture team translates our customers’ business requirements into total enterprise-wide solutions. It takes deep technical knowledge to create architectural designs that exceed service requirements. We’re skilled in analyzing the customer’s business goals, objectives, needs and general business environment to create technical system solutions. Our expertise includes integrating hardware, processes, methodologies and software into the customer environment.

Join us as a Big Data Engineer on our IT Architecture team to do the best work of your career and make a profound social impact.

What You’ll Achieve

The Dell Enterprise Business Intelligence and Analytics team is looking to invest in modern Data platforms, BI and analytical tools that can scale and meet the explosive growth in data. Looking for an enthusiastic individual to be a key contributor in this area.

Take the first step towards your dream career

Essential Requirements

Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role:

12 + years experience industry experience; must include Big Data experience
Experience with Presto, Dremio, Spark and/or Object storage tools
Automation expertise with hands on experience in Python and shell scripting
Knowledge of Database Management systems and their inner workings (Indexes, Explain Plans, B-Tree, LSM Trees)
Knowledge of Teradata, Hadoop and Greenplum architectures

Desirable Requirements

Experience in OS , storage and Networking concepts

Here’s our story; now tell us yours

Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress.

What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life -- while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more.

We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today.

You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here.

Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Equal Employment Opportunity Policy here.

""LI-Priority""

Job Id: R143638Job Function: Information Technology


Show more Show less"
2754993251,"Big Data Engineer, Experience Data Platform",TikTok,2021-11-15,United States,"Mountain View, CA",Engineering and Information Technology,Full-time,Internet Publishing,"TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.




Our team is responsible for optimizing app performance related experience for TikTok users, including client, video playback, shooting, uploading and network optimization. As a member of us, you will have opportunity to build test infrastructure and data platform to test and monitor performance metrics in a global environment.




Responsibilities:

• Work with product managers to define and develop big data applications;

• Design and implement systems under trillion level data environment;

• Drive cross-team communication to align design and implementation.




Qualifications

• BS or MS in Computer Science, EE, Mathematics or related majors with 3+ years software engineering experience in big data environment;

• Familiar with at least one of apache big data systems such as Hadoop, Spark, Flink, Druid, Impala, etc.;

• Have strong communication and team-collaboration skills;

• Open source committee will be a plus.







TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.




TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at USRC@tiktok.com

Show more Show less"
2826938040,Big Data Hadoop Engineer,infraBIM,2021-12-04,United States,"Pleasanton, CA",Engineering and Information Technology,Full-time,IT Services and IT Consulting,"Seeking a Big Data Hadoop Engineer who meet the following criteria for a long-term contract (W2) role in Pleasanton, CA.

Top 3 Must Haves

Experience with developing Hive QL, UDF’s for analyzing semi structured/structured datasets.
Experience with Java, Spring framework, scala, Pyton Web Services and REST API's.
Experience in the data warehousing and Business Intelligence systems.

Technical Knowledge And Skills

4+ years of hands-on Development, Deployment and production Support experience in Big Data environment.
4-5 years of programming experience in Java, Scala, Python.
Proficient in SQL and relational database design and methods for data retrieval.
Knowledge of NoSQL systems like HBase or Cassandra
Hands-on experience in Cloudera Distribution 6.x
Hands-on experience in creating, indexing Solr collections in Solr Cloud environment.
Hands-on experience building data pipelines using Hadoop components Sqoop, Hive, Solr, MR, Impala, Spark, Spark SQL.
Must have experience with developing Hive QL, UDF’s for analyzing semi structured/structured datasets.
Must have experience with Spring framework, Web Services and REST API's.
Hands-on experience ingesting and processing various file formats like Avro/Parquet/Sequence Files/Text Files etc.
Must have working experience in the data warehousing and Business Intelligence systems.
Expertise in Unix/Linux environment in writing scripts and schedule/execute jobs.
Successful track record of building automation scripts/code using Java, Bash, Python etc. and experience in production support issue resolution process.
Experience in building ML models using MLLib or any ML tools.
Hands-on experience working in Real-Time analytics like Spark/Kafka/Storm
Experience with Graph Databases like Neo4J, Tiger Graph, Orient DB
Agile development methodologies.

Interview process: In-person interview followed by Phone interview.
Show more Show less"
2600614007,Data Developer,Foursquare,2021-11-20,United States,"Los Angeles, CA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","About Foursquare

Foursquare is the leading independent location technology company, powered by our deep understanding of how people move throughout the world. Our solutions help businesses make smarter decisions, developers create more engaging experiences, and brands build more effective marketing strategies.

Foursquare’s platform includes Attribution, Audience, Pinpoint, Proximity, Places, Pilgrim SDK and Visits. As the industry’s first and only accredited company for location data from the Media Rating Council (MRC), this foundation powers all our solutions — those that exist today and those we have yet to build. Over 14 billion consumer-verified place visit confirmations help us keep our map and models fresh and up-to-date, building a phone’s-eye-view of the world with 105 million unique places of interest worldwide.

About The Team

The Places Team is responsible for building and curating Foursquare's Places Database. We combine billions of individual pieces of information into a comprehensive dataset of hundreds of millions of places around the world. The database spans every type of point-of-interest across the world with over a thousand different types of places such as restaurants, stores, parks, hotels, and colleges. In addition to powering our branded products, Places powers customer applications ranging from maps, navigation, analytics and everything in between for tens of thousands developers, including Apple, Microsoft, Uber and many more. Users, including software engineers, data scientists, analysts, and product managers, mix real time precision edits with a git-like branch and merge model for large scale changes.

About The Role

In this role, you will be instrumental in improving the quality of our Places data by researching and acquiring new data sources as well as contributing to our data processing software. You will investigate and solve complex data quality and delivery problems. You will author specifications for new tools and help manage technical projects.

Ideal candidates are independent, hard working individuals who pay strong attention to detail, show great communication and organizational skills, and like to get to the bottom of complicated problems.

Responsibilities Of The Role

Acquire, curate, and maintain point-of-interest data from diverse sources
Collaborate with the Product team to establish long-term, achievable roadmap goals
Build, improve, and utilize data and analysis pipelines to improve the quality, comprehensiveness, and efficiency of Foursquare’s data enrichment and delivery systems
Scale out your contributions using big-data frameworks like Spark, EMR, and Hive
Create and use databases to improve the team’s reporting and analytics

Qualifications

Proficient with Unix commands and comfortable working on the command line
Adept using a scripting language like Python or Ruby to process text files and get things done
Experience exploring and manipulating structured and unstructured datasets
Strong attention to detail and capacity for thorough, self-directed data analysis and troubleshooting.
Excellent written and verbal communication skills. The data issues we deal with are subtle and complex, and being able to distill these problems for stakeholders is one of our most valuable contributions.

Nice To Have

We don't necessarily expect candidates to have prior experience with our specific set of technologies. We care most about finding people with the right mindset toward data quality in general and excitement about location data problems. That said, strong candidates will probably have prior experience with at least one of the following:

Data Querying and manipulation in Spark, Hadoop, and Hive
Regular expressions
Web scraping
Technical project management skills
Experience with relational and non relational databases

Foursquare is proud to foster an inclusive environment that is free from discrimination. We strongly believe in order to build the best products, we need a diversity of perspectives and backgrounds. This leads to a more delightful experience for our users and team members. We value listening to every voice and we encourage everyone to come be a part of building a company and products we love.

Foursquare is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other characteristic protected by law.
Show more Show less"
2826762098,Big Data Engineer,Livemindz,2021-12-03,United States,"California City, CA",Engineering and Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Financial Services","acirceurocent Design, develop, document, and architect Big data applications acirceurocent Develop code using knowledge of SQL, NoSQL, data warehousing, Scala, Spark, Hive

Hadoop acirceurocent Be an expert in newer concepts like Apache Spark and Scala programming. acirceurocent Manage and monitor Hadoop log files acirceurocent Develop MapReduce coding that works seamlessly on Hadoop clusters acirceurocent Seamlessly convert hard-to-grasp technical requirements into outstanding designs acirceurocent Design web services for swift data tracking and query data at high speeds acirceurocent Test software prototypes, propose standards, and smoothly transfer them to operations
Show more Show less"
2825066724,Big Data Engineer,FinTech LLC,2021-12-02,United States,"San Ramon, CA",Engineering and Information Technology,Full-time,"Appliances, Electrical, and Electronics Manufacturing, Manufacturing, and Retail","Title: Big Data Engineer
Location: 100% Remote, Client is based in Beaverton, OR
Duration:Full Time

We are looking for a Senior/Staff Software/Platform Engineer that can design and code critical components for a platform that will interconnect data pipelines in a team of 5-10 engineers. Our customer is one of the world's largest tCPG companies based in Beaverton, Oregon with operations all over the world. The ideal candidate is a proactive, driven, and technology-proficient software engineer with strong data engineering background, experience event messaging system design, and strong coding experience. The candidate will need to quickly design, build and extend services from scratch.

Responsibilities:
Develop and extend a recently started data platform to support big data pipelines in the consumer data space
Drive/remain responsible for development of end-to-end for specific components
Contribute to project discussions, collaborate directly with architect team and present results to key stakeholders
Design, build and continuously enhance the project codebase
Act as an onsite-timezone force multiplier for a distributed team of engineers and managers
Write detailed design documentation, present decisions and motivate these
Work inside a team of industry experts on the cutting edge Big Data technologies to develop solutions for deployment at massive scale
Design data infrastructure with privacy and security being cross-cutting concerns
Set coding and deployment best practices

Requirements:
+6 years’ experience designing and coding platform solutions for Big Data pipelines
+3 years of experience working with event-messaging systems - Kafka is a big plus
+2 years coded and deploying services running on Kubernetes
Python and Spark knowledge is required
Experience working with AWS
Experience with enterprise data warehouse
Strong understanding of the challenges in building end-to-end big data pipelines for a large variety of use-cases at scale
Strong communication skills

What will be a big plus:
Experience with Scala
Experience with EMR
Experience with Snowflake
Understanding Microservices and how to architect/design scalable solutions on Kubernetes
Understanding challenges of working with many disjunct big data technologies
Worked with big data pipelines at terabyte/petabyte scale
Worked with HDFS
Understanding how to run Spark on Kubernetes
Experience working with Big Data scheduling technologies and their APIs - Airflow
Experience with JVM build systems (Gradle, Maven)
Show more Show less"
2822182597,Data Engineer,State of Massachusetts,2021-12-04,United States,"Boston, MA",Information Technology,Full-time,Armed Forces,"About The Executive Office Of Technology Services And Security

The Executive Office of Technology Services and Security (EOTSS) is the state's lead office for information technology. We provide enterprise level information technology services including: network management and security; computer operations; application hosting; desktop provisioning and management; and, modern and responsive digital services to 40,000 internal stakeholders plus the residents, business owners and visitors to the Commonwealth of Massachusetts.

About The Role

The EOTSS Data Team is hiring an experienced Data Engineer. As a data engineer, you will develop and maintain smart, secure data systems and pipelines, while building capacity for innovation in government.

Who We're Looking For

Engineers who develop, construct, test and maintain sound, secure data architectures that meet business needs
Team-oriented specialists who work collaboratively with business leaders, project managers, and analysts to build the right thing
Strategic thinkers who improve the functionality and value of the Commonwealth's data system

What you'll do

Stand up and maintain data infrastructure and data pipelines to process high volumes of complex data
Develop ETL processes and data warehousing efforts
Identify, design, and implement internal process improvements, automate manual processes, optimize data delivery, and re-design infrastructure for greater scalability
Build analytics tools to provide actionable insights into operational efficiency, service delivery, and policy evaluation
Uphold data processing, storage, and documentation standards
Deliver consistent and reliable processes and high-quality output on independent and team

projects

Knowledge, Skills & Abilities

Experience with the Linux stack (bash, git, package management etc.)
Experience with the AWS stack (EC2, lambda, batch, RDS, SQS)
Proficiency with Github and version control systems
Experience processing large quantities of data for analysis
Working, up-to-date knowledge of best practices for keeping data separated and secure
Experience with a team software development process: design, testing, coding, and peer reviews
Experience with continuous integration/continuous development (CI/CD) practices

Distinguished Qualifications

Experience with PostgresSQL and DynamoDB
Experience with current data science tools and methods
Proficiency in mainstream machine learning/deep learning frameworks: sklearn, tensorflow,
keras, etc.
Knowledge of machine learning theory and algorithms: SVM, random forest, gradient boosting methods, graphical models, bayesian methods, etc.

First consideration will be given to those applicants that apply within the first 14 days.

Please See Preferred Qualifications.

Executive Order #595: As a condition of employment, successful applicants will be required to have received COVID-19 vaccination or an approved exemption as of their start date. Details relating to demonstrating compliance with this requirement will be provided to applicants selected for employment. Applicants who receive an offer of employment who can provide documentation that the vaccine is medically contraindicated or who object to vaccination due to a sincerely held religious belief may make a request for exemption.

An Equal Opportunity / Affirmative Action Employer. Females, minorities, veterans, and persons with disabilities are strongly encouraged to apply.
Show more Show less"
2815822815,Data Engineer,Dell Technologies,2021-11-29,United States,"Hopkinton, MA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Hardware Manufacturing, and Computer Software","Dell provides the technology that transforms the way we all work and live. But we are more than a technology company — we are a people company. We inspire, challenge and respect every one of our over 150,000 employees. We also provide them with unparalleled growth and development opportunities.

Join us as a Data Engineer on our global Data Sciences team in Remote , Massachusetts or Remote - USA to do the best work of your career and make a profound social impact.

What You’ll Achieve

The desired candidate will work to enable Dell's Global Business Operations organization with data-driven insights that support our quota planning and business transformation efforts. The ideal candidate will work with a variety of stakeholders including ML engineers, data scientists, software engineers, and peer data engineers to align and execute end-to-end solutions which start with data collection and management, extend through machine learning methodologies, and end with governance of machine learning model performance.

You Will

As a Data Engineer on our team, it will be your responsibility to ensure your fellow team members have clean, reliable data that can be easily consumed into our data science and machine learning procedures.

Take the first step towards your dream career

Essential Requirements

Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role:

Dive into business problems relating to our quota planning and sales compensation efforts
Design and maintain optimal data architecture for our data science products; partner with your peer data engineers to build reliable systems that scale
Build, clean, and maintain data sets that feed our machine learning algorithms and discovery processes (based in PostgreSQL database)
Identify opportunities for process improvements (may results in automating, optimizing, or fully rebuilding workflows)
Work with the greater Decision Sciences team to help with data related issues and analysis needs

Desirable Requirements

Self-learner who is driven to learn new methods and techniques to fulfill business needs
Creative thinker who is success-driven both individually and as a team leader/mentor
Detail-oriented with the ability to effectively prioritize tasks
Experience working in an Agile environment
Expertise in PostgreSQL (experience with GreenPlum a plus)
Expertise with Python, Java, or a similar object-oriented language
Experience building and optimizing data workflows
Experience architecting data pipelines
Experience in root cause analysis
Good written and oral communications skills
Strong project management and organizational skills
1+ year(s) of experience (preferred) in a data engineering capacity, preferably on a data science or advanced analytics team
Bachelors or Masters (preferred) in Computer Science/Engineering or related field

Management Level: Advisor

Advisor, Data Engineering (I7)

Here’s our story; now tell us yours

Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress.

What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life -- while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more.

We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today.

You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here.

Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Employment Opportunity Policy here.

Job Id: R149975
Show more Show less"
2716502149,Big Data Engineer.,Lucid Motors,2021-11-20,United States,"Newark, CA",Engineering and Information Technology,Full-time,"Industrial Automation Machinery, Motor Vehicle Manufacturing, and Industrial Machinery","Leading the future in luxury electric and mobility

At Lucid, we set out to introduce the most captivating, luxury electric vehicles that elevate the human experience and transcend the perceived limitations of space, performance, and intelligence. Vehicles that are intuitive, liberating, and designed for the future of mobility.

We plan to lead in this new era of luxury electric by returning to the fundamentals of great design – where every decision we make is in service of the individual and environment. Because when you are longer bound by convention, you are free to define your own experience.

Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we’re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you.

We are currently seeking a Big Data Engineer who will be streaming pipeline Kafka, Spark, Scala and Python. You will be hands-on to design and develop streaming and IoT data pipelines. Our ideal candidate exhibits a can-do attitude and approaches his or her work with vigor and determination. Candidates will be expected to demonstrate excellence in their respective fields, to possess the ability to learn quickly and to strive for perfection within a fast-paced environment.

The Role

Hands-on design and develop streaming and IoT data pipelines.
Developing streaming pipeline Kafka, Spark, Scala and Python
Python scripting for automation and application development
Design ETL in Apache Airflow and other dependency enforcement and scheduling tools.
Hands-on data modeling and data warehousing
Deploy solution using AWS, S3, Redshift and Docker/Kubernetes
Develop storage and retrieval system using Presto and Parquet/ORC
Scripting with Apache Spark and data frame.

Qualifications

Bachelor or Masters in Software Engineering or Computer Science
3+ years of experience in Data Engineering and Business Intelligence
Excellent coding, scripting and problem solving skills
Experience in tools such as Spark, Kafka, S3, Hive, Data Lake
Experience with AWS, S3, Redshift
Experience with Presto and Parquet/ORC
Proficient with Apache Spark and data frames
Experienced in containerization, including Docker and Kubernetes
Expert in tools such as Apache Spark, Apache Airflow, Presto, and Kubeflow
Expert in design and implement reliable, scalable, and performant distributed systems and data pipelines
Extensive programming and software engineering experience, especially with Scala, Java or Python
Experience with a columnar database such as Redshift or Vertica
Great verbal and written communication skills

At Lucid, we don’t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations.

Notice regarding COVID-19 vaccination requirement as a condition of gainful employment within the United States

At Lucid, we prioritize the health and wellbeing of our employees, families, and friends above all else. In response to the novel Coronavirus, and the increased transmissibility with recent variants, all new Lucid employees, whose job will be based in the United States, must provide original documentation confirming status as having received the prescribed inoculation (doses) based on the manufacturer's guidelines on their first day of employment.

Accommodations due to medical or religious exemptions will be considered. To submit for your medical or religious exemption, please complete our secure form here. Once reviewed, a member of our employee relations team will reach out to you with a determination.

To all recruitment agencies : Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes.
Show more Show less"
2815410553,Big Data Engineer,Mission,2021-12-01,United States,United States,Information Technology and Engineering,Full-time,IT Services and IT Consulting,"As a Big Data Engineer, you will report to the Practice Lead, Data, Analytics & Machine Learning and work with our Big Data Consultants to build data pipelines, data warehouses and dashboards. You will help our customers build modern data solutions on the AWS stack.




This position is 100% remote with up to 50% travel required (post-COVID).




Responsibilities

Under the supervision of Big Data Consultants, work with multiple clients simultaneously to implement enterprise-wide scalable operations on AWS
Validate technical plans and time estimates for customers with Big Data Consultants
Build complex ETL code
Build complex SQL queries using MongoDB, Oracle, SQL Server, MariaDB, MySQL, Redshift, Athena
Develop code using Python, Scala, PySpark
Work with technologies such as Spark, Hadoop, Kafka, etc.
Build complex Data Engineering workflows
Create complex data solutions and build data pipelines
Establish credibility and build impactful relationships with our customers to enable them to be cloud advocates
Capture and share industry best practices amongst the broader community




Requirements

2+ years design & implementation experience with distributed applications
2+ years of experience in database architectures and data pipeline development
Strong experience working with Loading, extracting data from Glue, SQL, DDL, DML commands
Experience handling unstructured, semi-structured data, working in a data lake environment
Data streaming and developing data pipelines driven by events/queues a plus
Demonstrated knowledge of software development tools and methodologies
Presentation skills with a high degree of comfort speaking with IT management, and developers
AWS Big Data Specialty Certification (required within 6 months of hire)




Perks & Benefits

Medical, dental, and vision insurance for employees and their dependents with options for 100% company paid premiums
401(k) plan with company matching
Profit sharing bonuses based on performance
Flexible Spending Accounts (Health and Dependent Care)
Life insurance paid by Mission
Paid time off (Unlimited FlexPTO, parental leave, volunteering time off)
Inclusive work environment with several Employee Resource Groups
Fully distributed team with flexible work hours
Home office furniture & equipment expenses
Flex stipend for use on cell phone, home internet, wellness, etc. It’s up to you!
An internal department dedicated to helping team members on their career path
Show more Show less"
2826695350,Data Engineer,Alto,2021-12-04,United States,Dallas-Fort Worth Metroplex,Information Technology and Engineering,Full-time,"Computer Software, Internet Publishing, and Travel Arrangements","Join the Alto family and be a part of a remarkable ride!




Alto is a destination for innovative, intellectually curious and forward thinking people - our purpose is to disrupt the rideshare industry with an experience that is elevated in every way. Alto operates in Dallas, Houston, Los Angeles, Miami, and Washington DC (coming December 2021).

As a Data Engineer, you will work alongside our engineering, business, marketing, and operations teams to:

Provide ready to consume and analyze data through our warehouses and data platforms
Design and implement new data structures, tools, and products to help our teams as we grow as a company
Help teams make decisions and accomplish goals by providing data-driven perspectives, solutions, and technical analyses across a myriad of internal and third-party platforms that generate data they interact with on a daily basis
Help advance the capabilities and capacity of our Data Experience team and learn new tools, techniques, and skills in a wholly modern cloud-first technology environment




Examples of work you'll do and responsibilities:

Work with teams across Alto to determine data needs, priorities, and develop working plans for implementing data products (ex. warehouses, normalizations, etc.) and data/analytic tooling
Translate data requirements into technical specifications, define implementation plans and designs for ingesting, securing, and controlling access to data for analytic, technical, business, and data science purposes
Participate in project planning identifying milestones, deliverables and resource requirements, and tracks activities and task execution
Generate documentation on data platform design, implementations, and dictionaries for use by other teams to detail and describe data in its original and ""ready to consume"" formats
Develop data pipelines and APIs using a variety of tools and methods to collect, transform, and aggregate data to satisfy requirements of data customers for internal and external customers
Use an analytical, data-driven approach to provide tools and data platforms that help our teams with understanding our business, key metrics, and technical performance among other aspects of our company
Test and validate data ingested and and warehoused to check for successful processing, transformation, and loads to ensure analytics and downstream consumers of data have accurate information
Build ad-hoc, batch, and real-time data pipelines with data processing frameworks and tools on our cloud-based platform (Google Cloud and AWS)
Design and implement tools (ex. dashboards, alerts, monitoring) of technical aspects of our platform and systems to assist Engineering teams with monitoring and tracking the performance and health of our systems




Required Qualifications:

Experience in data engineering with an emphasis on data analytics and reporting
Experience with at least one of the following cloud platforms: Google Cloud Platform (GCP), Amazon Web Services (AWS)
Experience modeling, designing, and implementing data structures for analytics and operational use cases
Experience in modern datastores/databases (SQL and NoSQL), data transformations, statistical analysis, and troubleshooting across more than one database platform (ex. PostgreSQL, BigQuery, BigTable, Cloud Storage, Spanner, RDS, MySQL, Snowflake, etc.)
Experience in the design and build of data ETL processes by writing custom data pipelines
Experience with one or more of the follow scripting languages: Python, SQL, Kafka and/or other
Experience designing and building solutions utilizing various cloud-based data services such as Google Cloud SQL, DataFlow, BigQuery, Amazon RDS




Preferred Qualifications:

Hands-on experience with Google Cloud data tools and platforms
Hands-on experience with modern streaming and API integration-based data ingestions platforms/tools (ex. Stitch, Fivetran, etc.)
Some level of experience/expertise in one or more data-oriented / analytic programming languages/frameworks (ex. Python, JavaScript, etc.)
Experience working with agile development methodologies
Experience with visualization / analytics platforms (ex. Looker, Data Studio, Tableau, etc.)
Experience working with and ingesting data from SaaS platforms such as Firebase Analytics/Crashlytics, Google Analytics, Google Ads, and HubSpot
Academic or Bootcamp background in Data/Analytics systems, MIS, Statistics, or similar data/analytics oriented programs




Bonus Qualifications:

Interest in or experience with engineering and preparing data / rationalizations of data for use in data science and machine learning activities
Interest in or experience with feature engineering/design and implementation of machine learning-ready data views/inputs
Some level of experience/expertise with machine learning tools and platforms such as Google Cloud AI Platform, BigQuery Machine Learning, Jupyter Notebooks, Google Cloud AI APIs (Text-to-speech, Speech-to-text, Natural Language Processing, Vision, Dialogflow, etc.)
Show more Show less"
2816459639,Data Engineer II,Mastercard,2021-11-02,United States,"Arlington, VA",Information Technology,Full-time,"IT Services and IT Consulting, Internet Publishing, and Financial Services","Our Purpose

We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.

Job Title

Data Engineer II

Role Description

The Data Engineer II will participate on data management aspects of client engagements to deliver Test & Learn and other D&S delivery solutions, as well as contribute to and foster a high-performance collaborative workplace. A Data Engineer II will:

Independently execute projects through design, implementation, automation, and maintenance of large-scale enterprise ETL processes for a global client base
Develop repeatable and scalable code that processes client data in an automated and efficient manner to ensure data availability in the platform is as real-time as possible.
Act as an expert data resource within the team
Manage the process of data delivery on teams by overseeing other Data Engineers and Analysts to deliver on-time, accurate, high-value, robust data solutions across multiple clients, solutions, and industry sectors
Build trust-based working relationships with peers and clients across local and global teams
Implement best practices and collaborate in the design of effective streamlined processes for a complex global solutions group
Leverage industry best practices including proper use of source control, code reviews, data validation and testing
Enhance big data pipelines using SQL, SSIS, Powershell and related technologies to address complex technical challenges and seamless communication with several cloud storage technologies
Leverage new SQL Server features such as Columnstore Indexes, In-Memory OLTP, Incremental statistics, Trace Flags, SQL CLR functions, window aggregate functions, and parallel computing algorithms to reduce the processing time of multi-billion row data sets
Contribute to the automation capabilities of the team. Implement techniques to optimize and routinize repeatable tasks for Test & Learn data setup
Comply with and uphold all Mastercard internal policies and external regulations


Minimum Job Requirements

Bachelor's degree in a quantitative field (e.g., Computer Science, Statistics, Econometrics, Engineering, Mathematics, Operations Research). Master's degree preferred
Excellent English quantitative, technical, and communication (oral/written) skills; is an excellent listener
Expertise and hands-on experience with RDBMS technologies, preferably with Microsoft SQL Server, the SSIS Stack and .Net
Proficiency with at least one scripting language (Powershell, Python)
Proven self-motivated leader with experience working in multiple teams spread across several geographies
Demonstrated excellent skills in the ability to innovate, think critically and disaggregate problems. Able to provide oversight, validation and quality control to own and team work product
Skilled at balancing multiple projects and differing project priorities
Flexible to work with global offices across several time zones


Relevant Fields Of Educational Study

Computer Science, Statistics, Econometrics, Engineering, Mathematics, Operations Research

Due to COVID-19, most of our employees are working from home. We’ve implemented a virtual hiring process and continue to interview candidates by phone or video and are onboarding new hires remotely. We value the safety of each member of our community because we know we’re all in this together.

Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.

If you require accommodations or assistance to complete the online application process, please contact reasonable.accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.

Corporate Security Responsibility

All Activities Involving Access To Mastercard Assets, Information, And Networks Comes With An Inherent Risk To The Organization And Therefore, It Is Expected That The Successful Candidate For This Position Must

Every person working for, or on behalf of, Mastercard is responsible for information security.

Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
Show more Show less"
2793181357,Big Data Engineer,Anexinet,2021-11-10,United States,"Blue Bell, PA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Anexinet, based in Blue Bell, PA, specializes in digital business transformation. We empower our clients to grow their customer base and improve workforce efficiency by envisioning, developing, and operating next generation technology solutions. Our core expertise is in digital applications, analytics, and hybrid IT, enabling businesses to rapidly transform. Our clients partner with Anexinet to support the full lifecycle of your next generation digital business. Our people come and stay at Anexinet because we are a technology focused, team-oriented organization with a culture that is second to none as reflected by our 10 consecutive Best Place to Work awards from the Philadelphia Business Journal.

The list below is not comprehensive, but rather intended to provide a general idea of the opportunities available as a Big Data Engineer

Advanced Spark
Advanced Scala
AWS (EMR, S3, Glue, etc)
Spark Tuning
Data modeling
Ability to mentor other developers in these skills
Hands on development not just design/architecture
Show more Show less"
2815573871,Big Data Engineer,Chainlink Labs,2021-11-02,United States,Greater Boston,Engineering and Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Internet Publishing","All roles with Chainlink Labs are globally remote based. We encourage you to apply regardless of your location.

We are looking for a skilled Big Data Engineer to join our rapidly growing team. You will be in charge of processing pipelines and back-end services supporting data science. You can expect to be innovating the infrastructure ecosystem, CI/CD, and product optimization. This job is perfect for someone who can own technical solutions for building the data platform to support the growth of Chainlink Labs & keep optimizing, refactoring and improving the data pipelines in cloud environments. Additionally, you will provide high standard production support for all issues.

Your Impact

Create and implementing scalable and reliable ETL/ELT pipelines and processes to ingest data from different data sources
Assist DevOps personnel to maintain blockchain nodes
Assist in the implementation of best in class CI/CD frameworks
Facilitate near real-time data collection
Own technical solutions for the Data Lake Infrastructure
Collaborate and cooperate with other team members to fulfill the data needs
Requirements

5+ years Python/Scala/Java development experience
Experience of working with RestAPI/JSON-RPC
Big data processing experience like Hadoop, Apache Spark or Apache Flink
Experience building data pipelines using workflow management engines such as Airflow, Luigi, Prefect, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M
3+ years experience of working on cloud or on-prem Big data/MPP platforms(AWS EMR, Azure HDInsight, GCP Dataflow/Dataproc, AWS Redshift, Azure Synapse or BigQuery etc.)
GCP strongly preferred
ElasticSearch preferred
Experience with modern query engines such as Presto/Apache Impala etc.
Desired Qualifications

Excitement for blockchain, Web 3.0, and similar decentralized technologies.
Experience with GitHub Actions and self-hosted runners in particular.
Experience working remotely in a distributed team.
A strong desire to grow and challenge yourself. While this role is mainly focused on maintenance, we would expect you to constantly find ways to improve and automate services under your purview.

Our Principles

At Chainlink Labs, we’re committed to the key operating principles of ownership, focus, and open dialogue. We practice complete ownership, where everyone goes the extra mile to own outcomes into success. We understand that unflinching focus is a superpower and is how we channel our activity into technological achievements for the benefit of our entire ecosystem. We embrace open dialogue and critical feedback to arrive at an accurate and truthful picture of reality that promotes both personal and organizational growth.

About Chainlink Labs

Chainlink is the industry standard oracle network for connecting smart contracts to the real world. With Chainlink, developers can build hybrid smart contracts that combine on-chain code with an extensive collection of secure off-chain services powered by Decentralized Oracle Networks. Managed by a global, decentralized community of hundreds of thousands of people, Chainlink is introducing a fairer model for contracts. Its network currently secures billions of dollars in value for smart contracts across the decentralized finance (DeFi), insurance, and gaming ecosystems, among others. The full vision of the Chainlink Network can be found in the Chainlink 2.0 whitepaper. Chainlink is trusted by hundreds of organizations—from global enterprises to projects at the forefront of the blockchain economy—to deliver definitive truth via secure, reliable data.

This role is location agnostic anywhere in the world, but we ask that you overlap some working hours with Eastern Standard Time (EST).

We are a fully distributed team and have the tools and benefits to support you in your remote work environment.

Chainlink Labs is an Equal Opportunity Employer.


Show more Show less"
2804649738,Data Engineer,Tesla,2021-10-29,United States,"Fremont, CA",Information Technology,Full-time,"Renewable Energy Semiconductor Manufacturing, Motor Vehicle Manufacturing, and Utilities","The Role

Tesla's mission is to accelerate the world's transition to sustainable energy. We are committed to hiring the world's best and brightest people to help make this future a reality. Powertrain group in Tesla is seeking for a Data Engineer to collaborate with the process engineering team to ensure continuous production quality. In this role, you will utilize data to resolve engineering issues throughout the manufacturing process of Telsa’s key technology – battery pack. Additionally, you will be asked to use data-modeling to co-own the design of next generation manufacturing process to optimize the output and yield rate.

Responsibilities

Include but not limited to:

Co-own the manufacturing processes with the process engineering team
Use statistical modeling and machine learning to extract insights on yield and output improvements for the process of battery
Build reliable, fast, and dynamic data tools and pipelines
Develop visualization tools to monitor the manufacturing of the battery, and partner with the process engineering team to develop and enhance the manufacturing tooling and processes
Utilize knowledge of battery chemistry to understand and troubleshoot cell and battery level test yield issues
Create data modeling and partner with the process engineering team to design the manufacturing process for the future product line
Develop monitoring KPI for tracking manufacturing performance

Requirements

Bachelor’s degree in statistics, Mathematics, (Industrial/Mechanical/chemical/electrochemical) Engineering discipline, or equivalent experience
Prior experience in high-volume manufacturing environment is a huge plus with a focus on improving complex processes
Hands-on manufacturing experience is a plus, with strong know-how of SQL queries, Python, and other data analysis tools
Proficient in data visualization techniques and tools using Tableau, Power BI, Superset, Matplotlib, Plotly etc.
A passion and curiosity for data and data-driven decision making
Show more Show less"
2813255050,Data Engineer,Deloitte,2021-10-31,United States,"Arlington, VA","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Bachelor's degree required
2+ years of professional experience designing and developing real time ETL architecture
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be able to obtain and maintain the required clearance for this role

Preferred:

5+ years of professional services and/or government consulting experience
Interest in event streaming architectures, such as Apache Kafka
Creativity and innovation - desire to learn and apply new technologies, products and libraries

How you'll grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
Show more Show less"
2813253125,Data Engineer,Deloitte,2021-10-31,United States,"Arlington, VA","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Bachelor's degree required
2+ years of professional experience designing and developing real time ETL architecture
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be able to obtain and maintain the required clearance for this role

Preferred:

5+ years of professional services and/or government consulting experience
Interest in event streaming architectures, such as Apache Kafka
Creativity and innovation - desire to learn and apply new technologies, products and libraries

How you'll grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
Show more Show less"
2821636126,Big Data Engineer (Work From Home),Highmark Health,2021-11-06,United States,"Home, PA",Engineering and Information Technology,Full-time,Hospitals and Health Care,"Company : Highmark Health Job Description :

'job Summary

The job designs and engineers solutions associated with analytic data for the organization and, working closely with the business, analytic and IT teams, assists with the build and upkeep for these solutions. This includes coding data ingestion, transformation, and delivery programs/locic for analysts to access operational, derived, and external data sets. Expected deliverables will include; coding of delivery frameworks to load and transform raw source data into enhanced analytic assets, being a key resource for analytical and big data efforts, working with architects, analysts and data scientists as needed. The incumbent is responsible for the operation and execution of projects related to Big Data or other analytic platforms. Works in a team to leverage experience in analyzing and delivering large data sets by using a variety of delivery tools to perform tasks. Ability to work in cross-functional teams from different organizations (both technical and non-technical) on projects. Provides guidance and education to Junior level staff. Technologies such as, but not limited to: Hadoop, Hive, NoSQL, Spark, Python, SAS, Teradata, Oracle, Informatica.

Essential Responsibilities

Work closely with IT, architect and engineer solutions that provide views for the Enterprise Data Hub or other analytic ecosystems. This includes working with the appropriate teams, building out the design, and providing upkeep for the solution. Create high performance Big Data (and traditional) systems to be used with analytic applications.
Code, test, process, and maintain data resources for the analytics organizations. This will include working to maintain data sourcing, transformation and delivery, for key analytic platforms throughout the organization. (ETL/ELT)
Work with alternative analytic data systems to incorporate them into the operational data flow for the Analytics Teams. Work with data science teams and strategic partners on capabilities of core platform. This may include products purchased by the organization that must be ingested or modeled/derived data maintained by analytic teams.
Responsible for delivery of assigned projects, this may include providing guidance and Junior contributors within team. Will attend meetings with customers as needed.
Assist with the establishment of standards and patters for high performance data ingestion, transformation, and delivery of data analytic needs. Keep current with Big Data technologies in order to recommend best tools in order to perform current and future work.
Other duties as assigned.


EDUCATION

Required

Bachelor's Degree in Computer Systems Analysis, Computer Engineering, Data Processing, Healthcare Informatics or Management Information Systems


Substitutions

None


Preferred

Master's Degree Management Information Systems, Healthcare Informatics or Computer Engineering


Required

EXPERIENCE

3 - 5 years in Analytics
1 - 3 years in IT Application - Hadoop


Preferred (any Of The Following)

3 - 5 years in Data Warehousing
3 - 5 years in the Healthcare Industry
1 - 3 years in Database Administration


LICENSES AND CERTIFICATIONS

Required

None


Preferred

None


Skills

SQL
Data Warehousing
Problem-Solving
Communication Skills
Analytical Skills


Language (Other Than English)

None

Travel Required

0% - 25%

PHYSICAL, MENTAL DEMANDS and WORKING CONDITIONS

Position Type

Office-Based

Teaches / trains others regularly

Occasionally

Travel regularly from the office to various work sites or from site-to-site

Rarely

Works primarily out-of-the office selling products/services (sales employees)

Never

Physical work site required

Yes

Lifting: up to 10 pounds

Constantly

Lifting: 10 to 25 pounds

Rarely

Lifting: 25 to 50 pounds

Rarely

Disclaimer: The job description has been designed to indicate the general nature and essential duties and responsibilities of work performed by employees within this job title. It may not contain a comprehensive inventory of all duties, responsibilities, and qualifications required of employees to do this job.

Compliance Requirement: This job adheres to the ethical and legal standards and behavioral expectations as set forth in the code of business conduct and company policies.

As a component of job responsibilities, employees may have access to covered information, cardholder data, or other confidential customer information that must be protected at all times. In connection with this, all employees must comply with both the Health Insurance Portability Accountability Act of 1996 (HIPAA) as described in the Notice of Privacy Practices and Privacy Policies and Procedures as well as all data security guidelines established within the Company’s Handbook of Privacy Policies and Practices and Information Security Policy. Furthermore, it is every employee’s responsibility to comply with the company’s Code of Business Conduct. This includes but is not limited to adherence to applicable federal and state laws, rules, and regulations as well as company policies and training requirements.

Highmark Health and its affiliates prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, national origin, sexual orientation/gender identity or any other category protected by applicable federal, state or local law. Highmark Health and its affiliates take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, national origin, sexual orientation/gender identity, protected veteran status or disability.

Highmark Health and its affiliates prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, age, religion, sex, national origin, sexual orientation/gender identity or any other category protected by applicable federal, state or local law. Highmark Health and its affiliates take affirmative action to employ and advance in employment individuals without regard to race, color, age, religion, sex, national origin, sexual orientation/gender identity, protected veteran status or disability.

EEO is The Law

Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled/Sexual Orientation/Gender Identity ( https://www.eeoc.gov/sites/default/files/migrated_files/employers/poster_screen_reader_optimized.pdf )

We endeavor to make this site accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact number below.

For accommodation requests, please contact HR Services Online at HRServices@highmarkhealth.org

California Consumer Privacy Act Employees, Contractors, and Applicants Notice
Show more Show less"
2826043785,Big Data Engineer,LGZ New Media,2021-12-03,United States,"San Ramon, CA",Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Financial Services","Title: Big Data Engineer

Location: 100% Remote, Client is based in Beaverton, OR

Duration:Full Time

We are looking for a Senior/Staff Software/Platform Engineer that can design and code critical components for a platform that will interconnect data pipelines in a team of 5-10 engineers. Our customer is one of the world's largest tCPG companies based in Beaverton, Oregon with operations all over the world. The ideal candidate is a proactive, driven, and technology-proficient software engineer with strong data engineering background, experience event messaging system design, and strong coding experience. The candidate will need to quickly design, build and extend services from scratch.

Responsibilities

Develop and extend a recently started data platform to support big data pipelines in the consumer data space

Drive/remain responsible for development of end-to-end for specific components

Contribute to project discussions, collaborate directly with architect team and present results to key stakeholders

Design, build and continuously enhance the project codebase

Act as an onsite-timezone force multiplier for a distributed team of engineers and managers

Write detailed design documentation, present decisions and motivate these

Work inside a team of industry experts on the cutting edge Big Data technologies to develop solutions for deployment at massive scale

Design data infrastructure with privacy and security being cross-cutting concerns

Set coding and deployment best practices

Requirements

+6 years experience designing and coding platform solutions for Big Data pipelines

+3 years of experience working with event-messaging systems - Kafka is a big plus

+2 years coded and deploying services running on Kubernetes

Python and Spark knowledge is required

Experience working with AWS

Experience with enterprise data warehouse

Strong understanding of the challenges in building end-to-end big data pipelines for a large variety of use-cases at scale

Strong communication skills

What Will Be a Big Plus

Experience with Scala

Experience with EMR

Experience with Snowflake

Understanding Microservices and how to architect/design scalable solutions on Kubernetes

Understanding challenges of working with many disjunct big data technologies

Worked with big data pipelines at terabyte/petabyte scale

Worked with HDFS

Understanding how to run Spark on Kubernetes

Experience working with Big Data scheduling technologies and their APIs - Airflow

Experience with JVM build systems (Gradle, Maven)
Show more Show less"
2818994302,Data Engineer,Deduce,2021-11-29,United States,United States,,Full-time,,"Data Engineer




Who We Are:

Deduce is a fast growing, venture capital backed Cybersecurity startup on the forefront of empowering a more efficient, resilient, and effective cybersecurity industry. We’re building products, big data infrastructure, and APIs that identify fraudulent acc ount activity and compromise - powering businesses and developers to stop fraud in its tracks.

Our leadership team has a history of proven success prior to launching Deduce. They’ve grown, built and gone through 4 acquisitions and recently raised a Series A that will propel us into a hyper stage of growth. If you have a passion for cybersecurity, accessibility, or positive impact – we are your people and now is the time to join us.




About the role:

We are looking to hire a Data Engineer with strong programming skills and big data knowledge to work alongside our cutting edge data scientists, data analysts, and engineering. Your work in this role will help to enhance fraud detection models on our big data platform that protects businesses and customers from unauthorized account access, data leakage, and identity fraud.

This is a limited opportunity to join at this early stage and have an immediate impact on the trajectory and growth of our business as we scale.




Responsibilities:

Become an expert in the Deduce platform, products, and APIs
Work collaboratively with Customers, Product, and Engineering to productionalize
machine learning models, optimize pipelines, and scale AI projects
Develop large scale data structures and pipelines to organize, collect and standardize
data that helps generate insights
Work closely and gather data from the Data Science team and problem solve within our
current tech stack (AWS, Python, Pandas, Postgres, SQL, Kafka, Redis)
Create extract, transform, and load (ETLs) and reporting systems for new data using a
variety of traditional as well as large-scale distributed data systems
Work closely with analysts to productionize various statistical and machine learning
models using data processing pipelines
Collaborate to assist teams through implementation of data feature requests
Enhance and maintain the infrastructure powering our analytics and data products
Experiment with available tools and lends advice on new tools in order to determine
optimal solutions




Requirements:

Degree in Statistics, Data Science, Machine Learning, Computer Science, Applied Mathematics or related field
3+ years of data engineering, data management and/or transformation experience
Experience with ETL, data pipeline creation to load data from multiple data sources
Strong programming skills in Python required; SQL skills also critical
Experience working with scalable real-time systems in a production environment; AWS
experience is an asset
Experience in fraud prevention / cybersecurity in ecommerce, fintech, banking or for a
fraud solution product is a plus
Exposure to scalable real-time systems in a production environment is a plus
Ability to work as an effective, collaborative member within a small team environment –
we all get our hands dirty and are excited about building something for the first time
Proven success as both a self-starter and a considerate team player
Benefits:
Remote-first culture – we’re a distributed team located across the US and Canada
Premium health care benefits – 100% paid for employee and dependents
401K
Stock-options




Deduce is an Equal Opportunity Employer (EOE). We encourage and strongly support workplace diversity and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Show more Show less"
2787281743,Big Data Engineer,App Annie,2021-11-18,United States,"Washington, United States",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","*YOU CAN WORK REMOTELY FROM ANY LOCATION AS LONG AS YOU ARE LOCATED IN PST TIME ZONE




Something about us...

App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. More than 1,300 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business. We are a global company, headquartered in San Francisco but as a “remote” first company, we care about your results and not your location.

Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.




What can you tell your friends when they ask you what you do?




As a Big Data Engineer, I’m a key contributor to the design, implementation and ongoing governance of App Annie’s data products. I’m responsible for expanding and optimizing our large-scale data ingestion flows and our data processing pipelines to create transparency and consistency across the entire Data Science system architecture. I work closely with Product Managers, Data Scientists, Data Analysts and other Big Data and Business Intelligence Engineers to develop and sustain the governance of our data products, including conceiving and building large-scale data integration solutions. I’m passionate about what I do and excited to do it in the context of an entrepreneurial start-­up with a phenomenal team.




You will be responsible for and take pride in….

As a Big Data Engineer, you will be an integral part of a team responsible for large-scale data processing pipelines across our Intelligence Product. You will also help to expand our product governance processes and support the Data Science team in building new product features. This includes:
Ability to work with large, complex data sets that meet function and non-functional business requirements
Working as engineer in building the infrastructure required for optimal extraction, transformation and loading of data from a wide variety of data sources using SQL, Apache Spark, AWS S3, Databricks, Snowflake
Ability to design and optimize queries, scripts and data tools to provide increased visibility into the Data Science system architecture
The ability to communicate well and clearly with teams and team members across multiple time zones and countries.
Designing, building, and supporting large scale, fault-tolerant distributed systems that support App Annie’s data science and analytics teams

You should recognize yourself in the following...

Bachelor’s or Master's degree in Computer Science / Engineering or equivalent experience
At least 2-3 years as a big data engineer with a knowledge of algorithms and data structures
Proficient in data modelling and data warehouse design
Experience in designing architecture is a big plus
Proficient programming experience in SQL
Proficient programming experience in at least one mainstream language, like Python, Scala or Java
Experienced in data processing such as ETL
Flexible mindset and the ability to prototype and change direction rapidly as research evolves
Strong problem solving, analytical and troubleshooting skills
A seasoned engineer with big data ecosystem (Computation: Mapreduce, Spark/Flink, Presto/Hive/Redshift/Snowflake etc.; Storage: Postgresql, Elasticsearch, HDFS, Kafka etc.), experience AWS/Google Cloud/Microsoft Azure is a big plus
An excellent communicator with a knack for concisely explaining problems and solutions to multiple stakeholders, e.g. product managers, senior management, etc.
A strong drive to continue learning and developing
Independently making decisions quickly based on your expertise
Demonstrated ability to produce results as part of a highly distributed team that crosses cultural and country boundaries
Energy and creativity are key characteristics that describe you and the projects you are involved in. You make it happen. Boom!




This is what we offer...

We provide a $1,000 (Country equivalent) reimbursable WFH allowance to set you up for remote work success.
Internet allowance for stable internet connection, so your video does not freeze on Zoom.
Flexible working days. We love to meet, but if you need to get your kids to school/ zoom or need to leave early to get to your band practise or gym classes, do your thing.
Remote working as a standard! 90-days passport next to it, meaning you can work from any country in the world for 90 days a year
Paid leave, so long as you promise to come back!
Health and dental benefits, mental health concierge and financial planning support
Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!
Unlimited access to online learning platform Udemy to help you develop your skills.
An international team of talented and engaged people from different cultural backgrounds and locations.
Ample virtual initiatives and events to keep you connected with your colleagues.

Yes, I want this job!

Show more Show less"
2825280473,Data Engineer,Hitachi Vantara,2021-12-03,United States,"Dallas, TX",Information Technology,Full-time,"IT Services and IT Consulting, Human Resources, and Management Consulting","The Team

At Hitachi Vantara’s Digital Insights practice, we help our clients by building technology solutions that addresses business challenges and improve business outcomes with data-driven insights. As we continue expand our big data team, we are looking for data engineers who are passionate about technology and want to build a career working on the latest technology platforms.

As a Part Of This Team, You Will

Work with our clients to gather requirements and develop scalable data solutions
Use cloud services to integrate different data sources and develop data lakes
Provide recommendations to optimize data pipelines and data warehouse queries

Required Skills

Bachelor’s degree in computer science, MIS related area, or equivalent experience
Ability to work well in a team environment, meet deadlines, demonstrate good time management, and multi-task in a fast-paced project environment
Experience developing data pipelines (EMR/Glue) in AWS cloud
3+ years of experience with Apache Spark (Python or Scala)
Familiarity with basic Linux commands and writing Shell scripts
1+ years of experience working on Snowflake and proficient with SQL”.
Strong understanding of data warehousing concepts and dimensional modeling
Willingness and ability to learn new tools and technologies
Excellent verbal and written communication skills

Preferred Skills

Experience developing stream processing jobs and familiarity with Kafka
NoSQL databases – MongoDB, Cassandra, DynamoDB, HBase, Neo4j, etc.

Our Company

Hitachi Vantara is part of the Global Hitachi family. We balance innovation with an open, friendly culture and the backing of a long-established parent company, known for its ethical reputation. We guide customers from what’s now to what’s next by unlocking the value of their data and applications to solve their digital challenges, achieving outcomes that benefit both business and society.

Our people are our biggest asset, they drive our innovation advantage and we strive to offer a flexible and collaborative workplace where they can thrive. Diversity of thought is welcomed and our employee base is represented by several active Employee Resource Group communities. We offer industry leading benefits packages (flexible working, generous pension and private healthcare) and promote a creative and inclusive culture. If driving real change gives you a sense of pride and you are passionate about powering social good, we’d love to hear from you.

Our Values

We strive to create an inclusive environment for all and are open to considering home working, compressed/flexible hours and flexible arrangements. Get in touch with us to explore how we might be able to accommodate your specific needs.

With Japanese Roots Going Back Over 100 Years, Our Culture Is Founded On The Values Of Our Parent Company Expressed As The Hitachi Spirit

We are proud to say we are an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Wa – Harmony, Trust, Respect

Makoto – Sincerity, Fairness, Honesty, Integrity

Kaitakusha-Seishin – Pioneering Spirit, Challenge
Show more Show less"
2825279522,Data Engineer,Hitachi Vantara,2021-12-03,United States,"Dallas, TX",Information Technology,Full-time,"IT Services and IT Consulting, Human Resources, and Management Consulting","The Team

At Hitachi Vantara’s Digital Insights practice, we help our clients by building technology solutions that addresses business challenges and improve business outcomes with data-driven insights. As we continue expand our big data team, we are looking for data engineers who are passionate about technology and want to build a career working on the latest technology platforms.

As a Part Of This Team, You Will

Work with our clients to gather requirements and develop scalable data solutions
Use cloud services to integrate different data sources and develop data lakes
Provide recommendations to optimize data pipelines and data warehouse queries

Required Skills

Bachelor’s degree in computer science, MIS related area, or equivalent experience
Ability to work well in a team environment, meet deadlines, demonstrate good time management, and multi-task in a fast-paced project environment
Experience developing data pipelines (EMR/Glue) in AWS cloud
3+ years of experience with Apache Spark (Python or Scala)
Familiarity with basic Linux commands and writing Shell scripts
1+ years of experience working on Snowflake and proficient with SQL”.
Strong understanding of data warehousing concepts and dimensional modeling
Willingness and ability to learn new tools and technologies
Excellent verbal and written communication skills

Preferred Skills

Experience developing stream processing jobs and familiarity with Kafka
NoSQL databases – MongoDB, Cassandra, DynamoDB, HBase, Neo4j, etc.

Our Company

Hitachi Vantara is part of the Global Hitachi family. We balance innovation with an open, friendly culture and the backing of a long-established parent company, known for its ethical reputation. We guide customers from what’s now to what’s next by unlocking the value of their data and applications to solve their digital challenges, achieving outcomes that benefit both business and society.

Our people are our biggest asset, they drive our innovation advantage and we strive to offer a flexible and collaborative workplace where they can thrive. Diversity of thought is welcomed and our employee base is represented by several active Employee Resource Group communities. We offer industry leading benefits packages (flexible working, generous pension and private healthcare) and promote a creative and inclusive culture. If driving real change gives you a sense of pride and you are passionate about powering social good, we’d love to hear from you.

Our Values

We strive to create an inclusive environment for all and are open to considering home working, compressed/flexible hours and flexible arrangements. Get in touch with us to explore how we might be able to accommodate your specific needs.

With Japanese Roots Going Back Over 100 Years, Our Culture Is Founded On The Values Of Our Parent Company Expressed As The Hitachi Spirit

We are proud to say we are an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Wa – Harmony, Trust, Respect

Makoto – Sincerity, Fairness, Honesty, Integrity

Kaitakusha-Seishin – Pioneering Spirit, Challenge
Show more Show less"
2787285179,Big Data Engineer,App Annie,2021-11-24,United States,"San Francisco, CA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","*YOU CAN WORK REMOTELY FROM ANY LOCATION AS LONG AS YOU ARE LOCATED IN PST TIME ZONE




Something about us...

App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. More than 1,300 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business. We are a global company, headquartered in San Francisco but as a “remote” first company, we care about your results and not your location.

Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.




What can you tell your friends when they ask you what you do?




As a Big Data Engineer, I’m a key contributor to the design, implementation and ongoing governance of App Annie’s data products. I’m responsible for expanding and optimizing our large-scale data ingestion flows and our data processing pipelines to create transparency and consistency across the entire Data Science system architecture. I work closely with Product Managers, Data Scientists, Data Analysts and other Big Data and Business Intelligence Engineers to develop and sustain the governance of our data products, including conceiving and building large-scale data integration solutions. I’m passionate about what I do and excited to do it in the context of an entrepreneurial start-­up with a phenomenal team.




You will be responsible for and take pride in….

As a Big Data Engineer, you will be an integral part of a team responsible for large-scale data processing pipelines across our Intelligence Product. You will also help to expand our product governance processes and support the Data Science team in building new product features. This includes:
Ability to work with large, complex data sets that meet function and non-functional business requirements
Working as engineer in building the infrastructure required for optimal extraction, transformation and loading of data from a wide variety of data sources using SQL, Apache Spark, AWS S3, Databricks, Snowflake
Ability to design and optimize queries, scripts and data tools to provide increased visibility into the Data Science system architecture
The ability to communicate well and clearly with teams and team members across multiple time zones and countries.
Designing, building, and supporting large scale, fault-tolerant distributed systems that support App Annie’s data science and analytics teams

You should recognize yourself in the following...

Bachelor’s or Master's degree in Computer Science / Engineering or equivalent experience
At least 2-3 years as a big data engineer with a knowledge of algorithms and data structures
Proficient in data modelling and data warehouse design
Experience in designing architecture is a big plus
Proficient programming experience in SQL
Proficient programming experience in at least one mainstream language, like Python, Scala or Java
Experienced in data processing such as ETL
Flexible mindset and the ability to prototype and change direction rapidly as research evolves
Strong problem solving, analytical and troubleshooting skills
A seasoned engineer with big data ecosystem (Computation: Mapreduce, Spark/Flink, Presto/Hive/Redshift/Snowflake etc.; Storage: Postgresql, Elasticsearch, HDFS, Kafka etc.), experience AWS/Google Cloud/Microsoft Azure is a big plus
An excellent communicator with a knack for concisely explaining problems and solutions to multiple stakeholders, e.g. product managers, senior management, etc.
A strong drive to continue learning and developing
Independently making decisions quickly based on your expertise
Demonstrated ability to produce results as part of a highly distributed team that crosses cultural and country boundaries
Energy and creativity are key characteristics that describe you and the projects you are involved in. You make it happen. Boom!




This is what we offer...

We provide a $1,000 (Country equivalent) reimbursable WFH allowance to set you up for remote work success.
Internet allowance for stable internet connection, so your video does not freeze on Zoom.
Flexible working days. We love to meet, but if you need to get your kids to school/ zoom or need to leave early to get to your band practise or gym classes, do your thing.
Remote working as a standard! 90-days passport next to it, meaning you can work from any country in the world for 90 days a year
Paid leave, so long as you promise to come back!
Health and dental benefits, mental health concierge and financial planning support
Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!
Unlimited access to online learning platform Udemy to help you develop your skills.
An international team of talented and engaged people from different cultural backgrounds and locations.
Ample virtual initiatives and events to keep you connected with your colleagues.

Yes, I want this job!

Show more Show less"
2826988272,"Engineer, Data",T Mobile Club,2021-12-04,United States,"Bellevue, WA",Information Technology,Full-time,"IT Services and IT Consulting, Computer and Network Security, and Telecommunications","T-Mobile High-Speed Internet is redefining what it means to be an ISP, standing up for both Consumers and Businesses. We believe that this starts with bringing a world class experience to all customers. T-Mobile is competing in urban areas because we think you deserve a better choice and reaching out to areas that have previously been ignored. The HSI team is a fast-moving team of architects and data engineers; that build, run, and operate back-end and reporting data operations to support customer acquisition and analysis. As a data engineer on this team, you will play a key role in designing and implementing data solutions to meet business needs and ensure our pipelines become more performant, scalable and reliable. This is a fast-growing team, with endless opportunities for learning and growth – you’ll have our support along the way.

At least 18 years of age
Legally authorized to work in the United States
High School Diploma or GED
T-Mobile requires all employees in this position to be fully vaccinated for COVID-19 prior to starting work. The CDC defines ""fully vaccinated"" as two weeks after the second dose for Pfizer and Moderna, and two weeks after the single dose of Johnson & Johnson. T-Mobile will require proof of vaccination and consider requests for exemption from this requirement during the offer phase as a reasonable accommodation for medical reasons or sincerely held religious beliefs where the accommodation would not cause T-Mobile undue hardship or pose a direct threat to the health and safety of others.

BS in Computer Science/Engineering or Engineering or similar degree
At least 2 years of professional experience using an applicable programming language and common data technologies (such as SQL, NoSQL, Spark, Python, Tableau and Power BI)
At least 2 years of experience working with big data processes including ETL/data pipelines, processing, storage, and governance
Experience with AWS big data technologies– Redshift, S3, Lambda, Step Functions, EMR
Excellent problem-solving skills and data engineering habits, including peer-coding, documentation, quality testing, etc
Gather and understand business requirements for data strategy and architecture
Act as a subject matter expert for feature implementations, including pipeline development, management, and delivery across multiple work streams
Develop and implement scalable ETL processes and architecture for critical business systems
Automate and drive scalable solutions, implement data pipelines to support dynamic business needs
Collaborate with other business teams to support data strategy and business roadmaps
Design and optimize validation frameworks and data monitoring to ensure data quality and reliable data systems
Equal Employment Opportunity

We take equal opportunity seriously—by choice.

T-Mobile USA, Inc. is an Equal Opportunity Employer. All decisions concerning the employment relationship will be made without regard to age, race, ethnicity, color, religion, creed, sex, sexual orientation, gender identity or expression, national origin, religious affiliation, marital status, citizenship status, veteran status, the presence of any physical or mental disability, or any other status or characteristic protected by federal, state, or local law. Discrimination, retaliation or harassment based upon any of these factors is wholly inconsistent with how we do business and will not be tolerated.


Show more Show less"
2822726662,Entry Level Data Engineer,Auctis Corporation,2021-12-04,United States,United States,,Full-time,,"Our client is hiring urgently and have extensive training program. They need 5+ Sales Data Analyst on immediate basis.




The ideal candidate will use their passion for sales data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users.




Responsibilities




Understand the day-to-day issues that our business faces, which can be better understood with data

Compile and analyze data related to business' issues

Develop clear visualizations to convey complicated data in a straightforward fashion




Qualifications




Bachelor's degree in Statistics or Applied Mathematics or equivalent experience

1 - 2 years' Data Analysis experience

Proficient in SQL

Show more Show less"
2825284035,Data Engineer,Hitachi Vantara,2021-12-03,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Human Resources, and Management Consulting","The Team

At Hitachi Vantara’s Digital Insights practice, we help our clients by building technology solutions that addresses business challenges and improve business outcomes with data-driven insights. As we continue expand our big data team, we are looking for data engineers who are passionate about technology and want to build a career working on the latest technology platforms.

As a Part Of This Team, You Will

Work with our clients to gather requirements and develop scalable data solutions
Use cloud services to integrate different data sources and develop data lakes
Provide recommendations to optimize data pipelines and data warehouse queries

Required Skills

Bachelor’s degree in computer science, MIS related area, or equivalent experience
Ability to work well in a team environment, meet deadlines, demonstrate good time management, and multi-task in a fast-paced project environment
Experience developing data pipelines (EMR/Glue) in AWS cloud
3+ years of experience with Apache Spark (Python or Scala)
Familiarity with basic Linux commands and writing Shell scripts
1+ years of experience working on Snowflake and proficient with SQL”.
Strong understanding of data warehousing concepts and dimensional modeling
Willingness and ability to learn new tools and technologies
Excellent verbal and written communication skills

Preferred Skills

Experience developing stream processing jobs and familiarity with Kafka
NoSQL databases – MongoDB, Cassandra, DynamoDB, HBase, Neo4j, etc.

Our Company

Hitachi Vantara is part of the Global Hitachi family. We balance innovation with an open, friendly culture and the backing of a long-established parent company, known for its ethical reputation. We guide customers from what’s now to what’s next by unlocking the value of their data and applications to solve their digital challenges, achieving outcomes that benefit both business and society.

Our people are our biggest asset, they drive our innovation advantage and we strive to offer a flexible and collaborative workplace where they can thrive. Diversity of thought is welcomed and our employee base is represented by several active Employee Resource Group communities. We offer industry leading benefits packages (flexible working, generous pension and private healthcare) and promote a creative and inclusive culture. If driving real change gives you a sense of pride and you are passionate about powering social good, we’d love to hear from you.

Our Values

We strive to create an inclusive environment for all and are open to considering home working, compressed/flexible hours and flexible arrangements. Get in touch with us to explore how we might be able to accommodate your specific needs.

With Japanese Roots Going Back Over 100 Years, Our Culture Is Founded On The Values Of Our Parent Company Expressed As The Hitachi Spirit

We are proud to say we are an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Wa – Harmony, Trust, Respect

Makoto – Sincerity, Fairness, Honesty, Integrity

Kaitakusha-Seishin – Pioneering Spirit, Challenge
Show more Show less"
2813250591,Data Engineer,Deloitte,2021-10-31,United States,"Alexandria, VA","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Bachelor's degree required
2+ years of professional experience designing and developing real time ETL architecture
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be able to obtain and maintain the required clearance for this role

Preferred:

5+ years of professional services and/or government consulting experience
Interest in event streaming architectures, such as Apache Kafka
Creativity and innovation - desire to learn and apply new technologies, products and libraries

How you'll grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
Show more Show less"
2804617482,Data Engineer,Aurora Payments,2021-11-23,United States,Greater Phoenix Area ,,Full-time,,"*We respect the work of recruiters, but we request candidates only (no recruiters) for this role*




Location Disclaimer - **Note that while this role is able to be fully remote, the employee must be available and working during a mainland US time zone (Eastern, Central, Mountain, or Pacific). During month-end close and commission processing times, later evening hours (Pacific time) may be required to interface with our finance team.




With that said, if you love working nights and want to live 12 hours opposite our office, go for it! Only you know your strengths and tolerance for time zone adaptation here. We're human, and we accept that human things happen, but a time zone difference can't be the reason why deliverables are missed or you aren't available for questions.




We do have three corporate office locations and would be thrilled to have you in any of them, if you are local to Tempe, AZ, Westlake Village, CA, or Mentor (Cleveland), OH. **




Now, with that out of the way, moving forward:




Who we are:

Aurora is a payment processor. We're the company that moves money from the coffee shop customer's credit card to the coffee shop owner's bank account. We provide our services directly to merchants (small businesses) as well as to our sales partners who themselves sell services to merchants.




We support over 23,000 merchants on multiple sponsor banks and transaction processing platforms. We specialize in niche vertical markets, association partnerships, and also ""Main Street America"".




At the risk of sounding cliche, we function like a well-established startup. There is a great deal of functional overlap. Very seldom will someone tell you ""that's not in my job description"". We encourage cross-training and learning throughout all business areas.




What we need:

With over $10 Billion in transaction processing volume annually, we accumulate a lot of data. We also have a large number of sales partners who need to be paid, fairly and transparently, for the opportunities with which they entrust us. This means properly processing, analyzing, and presenting data.




We need a confident analyst who understands data and thrives on learning the business. You should love SQL, and be prepared to answer most questions with SQL, but we don't expect you to know every dialect out of the box. On a typical day, and there is no typical day, you might be asked to present a 36 month view of the risk/profitability ratio of accounts within a specific sales partner or vertical market. Right after that, you might field a question from a colleague in operations about a specific partner's payout. During partner payout processing time, there will likely be a lot of heads-down work with our custom-engineered systems and validating input/output to ensure that we pay our partners properly.




Specific skills that will help you to excel in this job:

A SQL oriented mind. If you think in queries, you're going to kill it.

Specific dialects that we work with:

PostgreSQL - all of our net-new development is Postgres or Postgres compatible (Cockroach, Spanner's Postgres interface, etc)

BigQuery standard SQL - We've built our data warehouse platform on BigQuery and interacting with it will be a huge part of your daySQL Server - We still have legacy data in Microsoft SQL Server. Ideally, part of this job will be properly modifying data structures so that it can be ELT into BigQuery, but in absence of that, you will need to query it.

mySQL/MariaDB - Less critical, but nice to have for two of our legacy platforms.

Understanding of how data pipelines work and when they're used. We're a Fivetran shop, but we use other connectors as well.

Understanding of columnar-store data warehouses and when they are appropriate to use.

Tableau and PowerBI - we use Tableau for visualizations and are in the process of rolling out PowerBI for our business-users to self-service query.

Excel. It's not glamorous, but we'd expect that you are extremely proficient in advanced spreadsheet work.




Non-technical attributes:




Fluent to native-level English communication, in writing and verbal communication. You will be interacting with our business users and some of our external partners, so English is part of the job.




A strong ability to make data understandable for non-technical business users. Can you take the complex and make it seem simple?




A mind for efficiency. Are you a person who is always looking for more efficient ways to run the same process?




Payment processing or FinTech experience - not a hard requirement, but this will accelerate your integration into the company.




Acceptance of the fact that sometimes, work and personal time blend together. We run a critical business and occasionally need to deal with issues outside of core-US hours.




We’re an organization driven by a passion for helping our clients and partners succeed. You should also be passionate about what you do and take pride in the process as well as the output of your work.

Show more Show less"
2780748794,Big Data Engineer,Experian,2021-11-05,United States,"Costa Mesa, CA",Engineering,Full-time,IT Services and IT Consulting,"Experian’s Consumer Information Services is a leader in providing data and predictive insights to organizations. By leveraging state-of-the-art technology and superior data compilation techniques, we provide market-leading tools that assist small and midsize businesses in making real-time decisions



What you’ll be doing



Define technical scope and objectives through research and participation in requirements-gathering and definition of processes
Ingest and Process data from various sources in raw, structured, semi-structured, and unstructured format into Big Data ecosystem
Realtime data feed processing using Big Data ecosystem
Design, review, implement and optimize data transformation processes in Big Data ecosystem
Test and prototype new data integration tools, techniques and methodologies
Participate in overall test planning for the application integrations, functional areas and projects.
Work with cross functional teams in an Agile/Scrum environment to ensure a quality product is delivered


Qualifications



What your background looks like



Technical Skills:



10+ years of hands-on experience with enterprise scale applications and systems
5+ Year of expertise in Big Data technologies in Hadoop ecosystem (Spark, Yarn, Kafka, Oozie, HBase, Hive, Spark, HDFS, MapReduce etc.), Hadoop distributions like Cloudera (preferred)
5+ Extensive development experience in Java specifically in Spring Framework and related technologies (Springboot, SpringData, SpringCloud, SpringSecurity etc...)
Experience with Scala is highly desirable
Strong understanding of data analytics and data visualization
Experience with Python and Ruby is a plus
Excellent analytical and problem solving skills
Excellent one-on-one communication and presentation skills, specifically able to convey technical information in a clear and unambiguous manner
Working knowledge of Linux operating system

Qualification:



Technically focused Bachelor’s degree in Computer Science, Engineering, Math, etc.
Master Degree is a plus

Perks



Competitive pay and comprehensive benefits package
Flexible work schedule and relaxed dress code


Additional Information



All your information will be kept confidential according to EEO guidelines.



Experian is proud to be an Equal Opportunity and Affirmative Action employer. Our goal is to create a thriving, inclusive and diverse team where people love their work and love working together. We believe that diversity, equity and inclusion is essential to our purpose of creating a better tomorrow. We value the uniqueness of every individual and want you to bring your whole, authentic self to work. For us, this is The Power of YOU and it ensures that we live what we believe.



Show more Show less"
2791725487,Remote Big Data Engineer,Toyota North America,2021-12-01,United States,"Dallas, TX",Engineering and Information Technology,Full-time,"Appliances, Electrical, and Electronics Manufacturing, Motor Vehicle Manufacturing, and Industrial Machinery","Who We Are

Collaborative. Respectful. A place to dream and do. These are just a few words that describe what life is like at Toyota. As one of the world’s most admired brands, Toyota is growing and leading the future of mobility through innovative, high-quality solutions designed to enhance lives and delight those we serve. We’re looking for diverse, talented team members who want to grow and challenge what’s possible with us.

Who We’re Looking For

Toyota Data and Analytics practice is looking for an experienced and highly motivated Big Data Engineer with a deep passion for solving complex & large-scale data problems as a core competency thereby enabling data-driven decision making in our journey towards creating mobility for all.

Big Data Engineer will be responsible for engineering best-in-class enterprise Data platforms with cutting edge technologies guided by principles of Agility, DevSecOps, Infrastructure as a code, and continuous innovation.

This is an Individual Contributor role that requires working with cross-functional teams across the company to ensure the platform is built for adoption with high standards of performance, and scalability while optimizing the cost and using emerging technologies in the Data universe.

What You’ll Be Doing

Design and develop highly scalable and state of the art Big data solutions in AWS and GCP to enable advanced analytics in the company.
Design and Build scalable data infrastructures required for optimal extraction, transformation, and loading (ELT, ETL) of data from a wide variety of data sources using Big Data and Integration technologies.
Implement automation of infrastructure, security components, and Continuous Integration & Continuous delivery for optimal execution of data pipelines.
Design and deliver advanced tooling/frameworks to promote Low-Code/No-Code and improve developer productivity.
Perform design, feature, and code reviews to drive excellence in engineering and ensure high quality & maintainability.
Apply DevSecOps & Agile approaches to deliver holistic and integrated solutions in iterative increments.
Implement and enforce security features and standards to protect platform access and the most critical asset of the organization - data.
Support the build of analytics tools that utilize the data pipeline to provide actionable insights for business stakeholders, including data preparation for predictive and prescriptive modeling.
Be current on the latest industry developments and trends to help lead the development of system/process improvements.
Ensure consistency of process and usage, and champion best practices in data management.
Work with both business and technical stakeholders on data issue resolution.
Adopt new methodologies that provide the business with increased flexibility and agility and work with product vendors to request new features.
Keep up with the latest features and capabilities, understand the competitive edge compared to similar product stacks, technology ideas, patterns, and methodologies.
Drive the creation of roadmaps, maintain product portfolio components.
Collaborate with Product owners, Enterprise architects, Business SMEs as well as different sub-groups within the Data organization to effectively lead data and analytics solutions.

What You Bring

Bachelor’s degree in Information Systems, Computer Science, or related discipline or equivalent work experience.
Progressive years of demonstrated experience in developing Big data solutions that support business analytics and data science teams.
Progressive more years of proficient experience developing data platforms, data warehouses, ETL/ELT pipelines, and programming in SQL, Python, Java, Scala-Spark, Bash, and other scripting languages.
Strong knowledge and hands-on experience in Big Data technologies in Cloud such as AWS EMR, Apache Spark, Databricks, AWS Redshift, Snowflake, and S3.
Competent with various batches & real-time streaming ingestion patterns with Sqoop, Kafka, and Kinesis.
Proven leadership in cloud administration with an emphasis on infrastructure automation (Terraform, Cloud Formation) and provisioning Lambda, SNS, EC2, Airflow, Elastic Cache, Redis, RESTful APIs in AWS.
Knowledge of DevOps methodology and automation experience with Jenkins, Ansible, Chef, XL Release, and XL Deploy.
Ability to research the latest trends and propose advanced tooling/solutions for data virtualization & digital twin concepts.
Good understanding of AI/ML platforms Sagemaker, TensorFlow, Vertex AI and other AI/ML capabilities in AWS and GCP clouds.
Experience leading data solutions for effective integration with BI reporting tools (i.e. Tableau, Power BI, Looker, etc.).
Experience working with agile methodologies (Scrum, Kanban) and Meta Scrum with cross-functional teams (Product Owners, Scrum Master, Architects, and data SMEs).
Excellent written, oral communication, and presentation skills to present architecture, features, and solution recommendations to senior management and C-level executives.
Proven success in building strong relationships and managing stakeholder expectations.

Additional Bonus If You Have

Master’s degree in Computer Science or related discipline.
AWS/GCP cloud certifications.
AWS/GCP Data Engineering certifications.
Experience with Automobile and/or Manufacturing organizations.
Experience with GCP Big Query, Google Cloud Storage, Google Data Proc, and GCP Pub/Sub.

What We’ll Bring

During your interview process, our team can fill you in on all the details of our industry-leading benefits and career development opportunities. A few highlights include:

A work environment built on teamwork, flexibility, and respect.
Professional growth and development programs to help advance your career, as well as tuition reimbursement.
Vehicle purchase & lease programs.
Comprehensive health care and wellness plans for your entire family.
Flextime and virtual work options (if applicable).
Toyota 401(k) Savings Plan featuring a company match, as well as an annual retirement contribution from Toyota regardless of whether you contribute.
Paid holidays and paid time off.
Referral services related to prenatal services, adoption, childcare, schools, and more.
Flexible spending accounts.
Relocation assistance (if applicable).

Belonging At Toyota

Our success begins and ends with our people. We embrace diverse perspectives and value unique human experiences. Respect for all is our North Star. Toyota is proud to have 10+ different Business Partnering Groups across 100 different North American chapter locations that support team members’ efforts to dream, do and grow without questioning that they belong. As a company that has been one of DiversityInc’s Top 50 Companies for Diversity and a member of The Billion Dollar Roundtable supporting minority and woman-owned suppliers for over 10 years, we are proud to be an equal opportunity employer that celebrates the diversity of the communities where we live and do business.

Applicants for our positions are considered without regard to race, ethnicity, national origin, sex, sexual orientation, gender identity or expression, age, disability, religion, military or veteran status, or any other characteristics.

Have a question or need assistance with your application? Check out the How to Apply section of our careers page on Toyota.com.
Show more Show less"
2808818081,Big Data Software Engineer,AT&T,2021-11-22,United States,United States,"Engineering, Analyst, and Information Technology",Full-time,IT Services and IT Consulting and Telecommunications,"Join AT&T and reimagine the communications and technologies that connect the world. We’re committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won’t just imagine the future – you’ll create it.




As a Big Data Software Engineer, you'll be responsible for the development of high performance, distributed computing tasks using Big Data technologies such as Hadoop, NoSQL, text mining and other distributed environment technologies within the Chief Data Office. You’ll oversee Big Data platform administration from installation, configuration and networking to troubleshooting and monitoring. You’ll also perform Linux operating system administration like bare-metal installation, configuration, networking, troubleshooting, monitoring and security.




Key Roles and Responsibilities:

• Virtual OS Platform administration (i.e. Azure) and Guest OS deployment, tuning and maintenance

• Administration in Java-based application and environment, including tuning, troubleshooting, and deployment ; Administration in Tomcat-based Web Services; Administration in the following Linux-based services: LDAP, DNS, NTP, and SCP

• Gathering and analysis of performance metrics such as memory, processor and network utilization on servers for the purpose of fine-tuning and improving resource utilization and anticipating capacity issues and bottlenecks

• System security – controlling access to systems, system files and networked resources via password and permissions restrictions as well as hardening and securing servers




Skills & Qualifications:

3-5 + years of recent Linux Operating System Administration experience required
Azure/HDI Platform administration and metric collection tools such as Nagios and Ganglia
Azure Administration
Certificate Administration (SSL, PKI)




A career with us, a global leader in communications and technology, comes with big rewards. As part of our team, you’ll lead transformation surrounded by trailblazing industry leaders like you. You’ll be empowered to go above and beyond – making a difference through company-sponsored initiatives or connecting and networking through one of our many employee groups. And regardless of where you’re at in your career trajectory, you’ll be rewarded by the impact that comes with making a difference in the lives of millions. With AT&T, you’ll be a part of something greater, do incredible things and be rewarded with a chance to change the world.




This is a remote work from home position that can be located anywhere in the United States however may require occasional travel. #virtualwork #virtualjob

#ChiefDataOffice

Show more Show less"
2813256025,Data Engineer,Deloitte,2021-10-31,United States,"Washington, DC","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Bachelor's degree required
2+ years of professional experience designing and developing real time ETL architecture
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be able to obtain and maintain the required clearance for this role

Preferred:

5+ years of professional services and/or government consulting experience
Interest in event streaming architectures, such as Apache Kafka
Creativity and innovation - desire to learn and apply new technologies, products and libraries

How you'll grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
Show more Show less"
2827321890,Data Science Engineer,Ulta Beauty,2021-12-04,United States,"Bolingbrook, IL",Information Technology,Full-time,"Personal Care Product Manufacturing, Consumer Services, and Retail","Overview

Discover the possibilities of our progressive, omnichannel approach to beauty retail. At Ulta Beauty, our E-Commerce and Digital associates sit at the cutting edge of our efforts to reimagine the future of retail. Through a full suite of new and emerging technologies, this team is creating an enhanced buying experience for guests who crave simplicity, choice, personal insights and the joy of discovery. With greater interactivity. Inspired applications of big data, AI and UI/UX. And creative that persuades and delights. All of this, with the opportunity to experience smart ideas come to life.

At Ulta Beauty, we’re forever imagining. Forever striving. Forever investing in next-gen—with deep and rich opportunities for ongoing learning, growth and advancement. We encourage you to take control of your career and set your own ceiling. For curious and big-picture thinkers who can flex to the need and who want to stretch themselves through courage and conviction, Ulta Beauty provides an environment perfectly suited to your ambitions. Let’s build brilliant together.

POSITION SUMMARY:

This Data Science Engineer is an integral part of the Ulta Beauty Analytics team that utilizes the power of data, analytics, and automation to address the diverse business questions and challenges facing Ulta Beauty Leadership. Our team’s mission is to provide Ulta Beauty a distinct competitive advantage by mining our rich data assets to inform strategic and tactical business decisions. As a Data Science Engineer, you will succeed by translating business needs to technical solutions, distilling large datasets into automated deliverables, and implementing large scale data infrastructure systems in a fast-paced, data-focused retail environment. The Data Science Engineer will also act as a subject matter expert, communicating the value and tackling the application of scalable infrastructure for various use cases with multiple stakeholders across Ulta Beauty.

CORE JOB RESPONSIBILITIES:

Transform complex analytical models into scalable, production-ready solutions on top of a robust analytical data layer
Identify, extract, assess, and transform internal and external data assets from multiple sources and build pipelines to support new and existing analytic solutions
Develop reusable building blocks for quantitative models, leveraging highly parallel, distributed machine learning and advanced data analysis techniques (e.g., feature engineering, model type DAGs, etc.)
Efficiently manage our infrastructure through working with Analytics, IT, and Innovation partners to design, develop, maintain, and optimize our data management and advanced analytics architecture
Ensure data integrity and quality by leveraging proven methodologies, code reviews, and testing to ensure software and process quality is high and requirements are met
Leverage a modern data engineering toolkit to test ecosystems and prepare them for data scientists to execute predictive and prescriptive models
Collaborate with both internal Ulta Beauty and external teams to design new algorithms, drive optimization, and continuously improve our analytical capabilities
Explain and present complex analytical and engineering approaches in a concise manner to drive alignment and outcomes from business partners
Continue driving a data driven culture across Ulta Beauty and mentoring less experienced team members on MLOps and deployment techniques


ESSENTIALS FOR SUCCESS:

3+ years of professional experience in software engineering or analytical functions
Advanced degree preferred in a highly quantitative field such as Computer Science, Engineering, Mathematics, Statistics, etc.
Experience in designing and developing data pipelines for data ingestion or transformation using Java or Scala or Python
Fluency in Python and scientific related frameworks (e.g., scikit-learn, numpy, scipy etc.)
Advanced experience working with SQL and related data access and analysis tools
Hands-on experience with cloud computing platforms, preferably Google Cloud Platform
Strong understanding in model inferencing lifecycle, monitoring, feedback loop and data capture in real time at scale
Demonstrated ability to work effectively both in a team environment and independently by handling multiple projects, meeting deadlines, prioritizing appropriately, and responding to issues quickly and creatively with an open and positive attitude
Energetic and self-motivated with a strong sense of curiosity - must be extremely organized and detail oriented with an ability to make proactive recommendations
View the “big picture” and drive towards business results
Comfort working in a dynamic, research-oriented team


PREFERRED QUALIFICATIONS:

Experience in retailer and e-commerce industries
Google’s Certified Professional-Data-Engineer certification, or other Professional certifications
Experience with big data tools (e.g., Apache Spark) and data pipeline and workflow management tools (e.g., Airflow)
Practical experience with CI/CD and MLOps best practices and tools (Git, Airflow, Jenkins, Bamboo, etc.)
Experience with or knowledge of Agile, Lean, Six Sigma and/or demonstrated process improvement methodologies
Knowledge of software development principles and architectures
Hands-on experience with designing, deploying, and maintaining machine learning pipelines
Basic understanding of advanced analytics and machine learning techniques


About

At Ulta Beauty (NASDAQ: ULTA), the possibilities are beautiful. Ulta Beauty is the largest North American beauty retailer and the premier beauty destination for cosmetics, fragrance, skin care products, hair care products and salon services. We bring possibilities to life through the power of beauty each and every day in our stores and online with more than 25,000 products from approximately 500 well-established and emerging beauty brands across all categories and price points, including Ulta Beauty’s own private label. Ulta Beauty also offers a full-service salon in every store featuring—hair, skin, brow, and make-up services.

We will consider for employment all qualified applicants, including those with arrest records, conviction records, or other criminal histories, in a manner consistent with the requirements of any applicable state and local laws, including the City of Los Angeles’ Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, and the New York City Fair Chance Act.
Show more Show less"
2825282440,Data Engineer,Hitachi Vantara,2021-12-03,United States,"Atlanta, GA",Information Technology,Full-time,"IT Services and IT Consulting, Human Resources, and Management Consulting","The Team

At Hitachi Vantara’s Digital Insights practice, we help our clients by building technology solutions that addresses business challenges and improve business outcomes with data-driven insights. As we continue expand our big data team, we are looking for data engineers who are passionate about technology and want to build a career working on the latest technology platforms.

As a Part Of This Team, You Will

Work with our clients to gather requirements and develop scalable data solutions
Use cloud services to integrate different data sources and develop data lakes
Provide recommendations to optimize data pipelines and data warehouse queries

Required Skills

Bachelor’s degree in computer science, MIS related area, or equivalent experience
Ability to work well in a team environment, meet deadlines, demonstrate good time management, and multi-task in a fast-paced project environment
Experience developing data pipelines (EMR/Glue) in AWS cloud
3+ years of experience with Apache Spark (Python or Scala)
Familiarity with basic Linux commands and writing Shell scripts
1+ years of experience working on Snowflake and proficient with SQL”.
Strong understanding of data warehousing concepts and dimensional modeling
Willingness and ability to learn new tools and technologies
Excellent verbal and written communication skills

Preferred Skills

Experience developing stream processing jobs and familiarity with Kafka
NoSQL databases – MongoDB, Cassandra, DynamoDB, HBase, Neo4j, etc.

Our Company

Hitachi Vantara is part of the Global Hitachi family. We balance innovation with an open, friendly culture and the backing of a long-established parent company, known for its ethical reputation. We guide customers from what’s now to what’s next by unlocking the value of their data and applications to solve their digital challenges, achieving outcomes that benefit both business and society.

Our people are our biggest asset, they drive our innovation advantage and we strive to offer a flexible and collaborative workplace where they can thrive. Diversity of thought is welcomed and our employee base is represented by several active Employee Resource Group communities. We offer industry leading benefits packages (flexible working, generous pension and private healthcare) and promote a creative and inclusive culture. If driving real change gives you a sense of pride and you are passionate about powering social good, we’d love to hear from you.

Our Values

We strive to create an inclusive environment for all and are open to considering home working, compressed/flexible hours and flexible arrangements. Get in touch with us to explore how we might be able to accommodate your specific needs.

With Japanese Roots Going Back Over 100 Years, Our Culture Is Founded On The Values Of Our Parent Company Expressed As The Hitachi Spirit

We are proud to say we are an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Wa – Harmony, Trust, Respect

Makoto – Sincerity, Fairness, Honesty, Integrity

Kaitakusha-Seishin – Pioneering Spirit, Challenge
Show more Show less"
2826952397,Hadoop Developer,American Recruiting & Consulting Group,2021-12-04,United States,"Jacksonville, FL",Engineering and Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Financial Services","ARC Group has an immediate opportunity for a Hadoop Developer for a Jacksonville, Florida-based Direct client. This is starting out as a 12 month contract position with strong potential to extend or possibly convert to FTE. This is a fantastic opportunity to join a well-respected organization that offers tremendous career growth potential.

This is a 100 % remote position working East Coast hours.

Any Visa Who Can Work On Our W2

There is a chance for this opportunity to convert to full-time employment. As such, you must work directly on W2 without current or future sponsorship or transfer of visas. This position is not eligible for C2C and no employers.

Role: Sr Hadoop Developer

Job Reference # 7759-1

Required Skills:

Hadoop EcoSystems with Spark/ Scala
Kafka, spark streaming/ Batch/ real-time processing
Hive, Hbase
Sqoop, NiFi
MongoDB, Postgres DB
Shell scripts


Preferred Skillsets:

Java, JavaScript
SQL


What will the project focus on?

Design, coding and testing of ETL jobs for Project Initiatives
Enhancement to existing ETLs and services
Debug and resolve production data and code issues


What has prompted the opening of this role?

Skills requirement for projects and production support.


Specific Tools/Languages Required:

HADOOP

Spark

Experience With Agile Methodology

Required Education:

Related Bachelor's degree in an IT related field or relevant work experience

Powered by JazzHR

45iaIpVzI2
Show more Show less"
2805436279,"Software Engineer, Autopilot Data",Tesla,2021-10-30,United States,"Palo Alto, CA",Engineering and Information Technology,Full-time,"Renewable Energy Semiconductor Manufacturing, Motor Vehicle Manufacturing, and Utilities","The Role

Data is deeply embedded in the engineering culture at Tesla. We rely on data – lots of it – to improve Autopilot functionality, design new self-driving features, and educate the world on the possibilities of our industry-defining technology.

As an Autopilot Software Engineer you will be responsible for collecting high quality data from our fleet of cars and presenting that data to key decision makers both inside and outside of the company. You will act as a champion to promote best practices in data integrity, metric design, feature validation, and documentation. You will use existing data and distinguish signal from noise, as well as design new metrics and collection methods when existing data is insufficient. Your work will affect millions of cars, as well as support the initiatives of many internal Tesla teams. We believe an autonomous future is a safer future, so success means shipping excellent, well validated features with a sense of urgency.

You Will

Build and own data frameworks and pipelines that support measuring fleetwide performance, safety statistics, and feature development
Design and implement new metrics and signals for evaluating Autopilot performance
Use data that you collect to build comprehensive, accurate reports of Autopilot feature performance and present your findings to both internal and external stakeholders
Work with stakeholders to take a vague problem statement, identify where data can be useful, and use the results to drive informed decisions
Productionize dashboards to be used across the entire team
Provide ad-hoc support in creating visualizations to help engineers make informed decisions

We Are Looking For Candidates With

BS or higher in computer science, computer engineering, electrical engineering or equivalent practical engineering experience
Proven track record of exceptional ability (i.e., you personally solved difficult problems that moved the needle on meaningful projects)
Strong proficiency in Python, SQL
Strong foundation in statistics
Experience with building data infrastructure (e.g., designing architecture, setting up databases, building data pipelines, implementing scalable monitoring) and implementing reporting solutions
Experience with data science tools such as Pandas, Numpy, R, etc.
Experience building data visualizations
Experience writing software in a production environment
Strong problem solving, critical thinking, and communication skills (both verbal and written)
Show more Show less"
2825177424,Senior-Big Data Engineer,AT&T,2021-12-02,United States,"El Segundo, CA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Wireless Services, and Telecommunications","Join AT&T and reimagine the communications and technologies that connect the world. We’re committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won’t just imagine the future – you’ll create it.

The Big Data Engineer will be responsible for interpreting the requirements of various Big Data Analytic Use Cases and Scenarios, and driving the design and implementation of specific data models to ultimately help drive better business decisions through insights from a combination of external and AT&Ts data assets. This is someone who is also motivated by their ongoing learning and willingness to pursue and complete professional .certifications on a continuing basis – and can use time management skills to balance learning with project related needs.

Key Roles and Responsibilities

Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the Big Data Environment.
Support the standardization, customization and ad-hoc data analysis, and will develop the mechanisms to ingest, analyze, validate, normalize and clean data.
Implements statistical data quality procedures on new data sources, and by applying rigorous iterative data analytics, supports Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value.
Will work with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data.
Develop and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods and techniques.

Qualifications

Preferred Bachelors of Science in Computer Science, Math or Scientific Computing preferred.
Typically requires 5-8 years experience.
Python, Azure or AWS, Data wrangling and Data pipeline design required
The ideal candidate will have fluency in programming, but also analytical skills since they will be working and exchanging ideas with data scientists

Ready to join our team? Apply today!

#ChiefDataOffice

JobCategory:Technology
Show more Show less"
2766260349,Big Data Engineer,American Express,2021-12-02,United States,"Phoenix, AZ",Engineering and Information Technology,Full-time,Financial Services,"“You Lead the Way. We’ve Got Your Back.

At American Express, we know that with the right backing, people and businesses have the power to progress in incredible ways. Whether we’re supporting our customers’ financial confidence to move ahead, taking commerce to new heights, or encouraging people to explore the world, our colleagues are constantly redefining what’s possible - and we’re proud to back each other every step of the way. When you join #TeamAmex, you become part of a diverse community of over 60,000 colleagues, all with a common goal to deliver an exceptional customer experience every day.”

Our Software Engineers not only understand how technology works, but how that technology intersects with the people who count on it every day. Today, innovative ideas, insight and new perspectives are at the core of how we create a more powerful, personal and fulfilling experience for all our customers. So if you’re interested in a career creating breakthrough software and making an impact on an audience of millions, look no further.

You won’t just keep up, you’ll break new ground.

At American Express, the Enterprise Platform team was established to reimagine the platform solution-delivery model to dramatically improve our strategic agility, speed to market, effectiveness of delivery and transparency. Enterprise Platform O2 team build solutions to acquire new clients and expand existing customers and integrated across Salesforce ecosystem.

Qualifications

BS degree or higher in computer science or related discipline
4+ years of recent hands-on experience on an agile development team of building big data capabilities with Apache Spark, HIVE on Java/Python
Demonstrated experience in Agile development, application design, software development, and testing.
Strong Hands-on Apache Spark Data frame and Datasets, Map Reduce, Hive Query Language, HDFS, Hive, PySpark.
Experience Java, Python, Scala languages
Good understanding of CI/CD processes leveraging Jenkins, SBT, XLR and Maven.
Knowledge/ experience in Elastic Cache and NoSQL databases.
Ability to implement scalable, high performing, secure, highly available solutions
Self-Starter, Problem solver, Highly collaborative and adaptive
Excellent communication skills, enthusiasm and ability ask questions, understand business value.
Enterprise Scale Engineering experience (Industry standard build/test/deploy tools)
Any knowledge of Salesforce ecosystem is a plus.


Employment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions.

BS degree or higher in computer science or related discipline
4+ years of recent hands-on experience on an agile development team of building big data capabilities with Apache Spark, HIVE on Java/Python
Demonstrated experience in Agile development, application design, software development, and testing.
Strong Hands-on Apache Spark Data frame and Datasets, Map Reduce, Hive Query Language, HDFS, Hive, PySpark.
Experience Java, Python, Scala languages
Good understanding of CI/CD processes leveraging Jenkins, SBT, XLR and Maven.
Knowledge/ experience in Elastic Cache and NoSQL databases.
Ability to implement scalable, high performing, secure, highly available solutions
Self-Starter, Problem solver, Highly collaborative and adaptive
Excellent communication skills, enthusiasm and ability ask questions, understand business value.
Enterprise Scale Engineering experience (Industry standard build/test/deploy tools)
Any knowledge of Salesforce ecosystem is a plus.


American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, age, or any other status protected by law.
Show more Show less"
2825278579,Data Engineer,Hitachi Vantara,2021-12-03,United States,"Santa Clara, CA",Information Technology,Full-time,"IT Services and IT Consulting, Human Resources, and Management Consulting","The Team

At Hitachi Vantara’s Digital Insights practice, we help our clients by building technology solutions that addresses business challenges and improve business outcomes with data-driven insights. As we continue expand our big data team, we are looking for data engineers who are passionate about technology and want to build a career working on the latest technology platforms.

As a Part Of This Team, You Will

Work with our clients to gather requirements and develop scalable data solutions
Use cloud services to integrate different data sources and develop data lakes
Provide recommendations to optimize data pipelines and data warehouse queries

Required Skills

Bachelor’s degree in computer science, MIS related area, or equivalent experience
Ability to work well in a team environment, meet deadlines, demonstrate good time management, and multi-task in a fast-paced project environment
Experience developing data pipelines (EMR/Glue) in AWS cloud
3+ years of experience with Apache Spark (Python or Scala)
Familiarity with basic Linux commands and writing Shell scripts
1+ years of experience working on Snowflake and proficient with SQL”.
Strong understanding of data warehousing concepts and dimensional modeling
Willingness and ability to learn new tools and technologies
Excellent verbal and written communication skills

Preferred Skills

Experience developing stream processing jobs and familiarity with Kafka
NoSQL databases – MongoDB, Cassandra, DynamoDB, HBase, Neo4j, etc.

Our Company

Hitachi Vantara is part of the Global Hitachi family. We balance innovation with an open, friendly culture and the backing of a long-established parent company, known for its ethical reputation. We guide customers from what’s now to what’s next by unlocking the value of their data and applications to solve their digital challenges, achieving outcomes that benefit both business and society.

Our people are our biggest asset, they drive our innovation advantage and we strive to offer a flexible and collaborative workplace where they can thrive. Diversity of thought is welcomed and our employee base is represented by several active Employee Resource Group communities. We offer industry leading benefits packages (flexible working, generous pension and private healthcare) and promote a creative and inclusive culture. If driving real change gives you a sense of pride and you are passionate about powering social good, we’d love to hear from you.

Our Values

We strive to create an inclusive environment for all and are open to considering home working, compressed/flexible hours and flexible arrangements. Get in touch with us to explore how we might be able to accommodate your specific needs.

With Japanese Roots Going Back Over 100 Years, Our Culture Is Founded On The Values Of Our Parent Company Expressed As The Hitachi Spirit

We are proud to say we are an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Wa – Harmony, Trust, Respect

Makoto – Sincerity, Fairness, Honesty, Integrity

Kaitakusha-Seishin – Pioneering Spirit, Challenge
Show more Show less"
2819245984,Big Data Engineer,MedPage Today,2021-11-30,United States,"New York, NY",Engineering and Information Technology,Full-time,Wellness and Fitness Services,"Description

Position at Everyday Health - Professional

Everyday Health Group (EHG) is a recognized leader in patient, and provider education with services attracting an engaged audience of over 60 million health consumers and over one million U.S. healthcare providers. Our mission is to drive better clinical and health outcomes through decision-making informed by highly relevant information, data, and analytics. We empower healthcare professionals and consumers with trusted content and services delivered through Everyday Health Group’s world-class brands.

The Opportunity

Everyday Health Group is looking for a Big Data Engineer to join our Data Analytics and Business Intelligence team immediately. In this role, they will take the lead in developing database tools, managing ETL, storage, optimization of AWS, Databricks, and providing analysis of database performances. This is a critical role to ensure that our data pipelines are properly created, stored, and maintained.

Key Responsibilities

Big Data Engineer will manage and analyze big data sources and report their performances

They will extract data from various sources, such as Google Analytics, Salesforce, and multiple email services providers with established protocols (see Tools section, bellow).
They will use tools, such as APIs, and Python, PySpark or other programs to fetch or stream data into storage.
They will create and modify these tools for new requirements.
Engineer will analyze data feeds performance and provide insights, they will detect, analyze problems, and provide solutions for data extractions and storage and retrievals, including
Identifying errors,
Creating rules to alert users of the reports of abnormal performance of data, or events,
Providing root cause analysis,
Proposing and implementing solutions,
Designing monitoring programs for performance and data accuracy.
They will adopt tools and reports to new business needs by
Using existing data to support insights and analytics,
Identifying new sources to support and create insights,

Job Qualifications

To successfully complete the tasks, Engineer is expected to have

At least three years in big data and database engineering, ETL, Storage optimization; or equivalent training or certification,
Experience in using PySpark,
High level familiarity with big data concepts,
Knowledge of root cause analysis, or appropriate diagnostic framework,
Worked on digital traffic modelling, such as email opens, clicks, visits, and other KPIs,
Designed measurement programs for digital media, including videos, texts, contents, and
An education in statistics, mathematics, computer science, or quantitative studies

The following tools are basic requirements to complete the tasks:

SQL, including MySQL, MSSQL
Google Analytics
Python, PySpark, or other big data management tools
Modern data technology platforms, Redshifts, PostgreSQL, HIVE, Databricks

Others

Familiarity with PowerBI, or other dashboard tools
Examples of a career of learning and creativity
Techniques that show high focus, organization, communication and presentation skills

Our Culture and Values

We love collaboration, always desire to understand the business problem we’re solving, push decisions down as low as possible, and want to further our culture of innovation and experimentation. We created our values together, to embody both our audience goals and our workplace aspirations: to promote diversity and create opportunities; to be authentic; to enable wellness; to ignite passion and reimagine possibilities; to be results driven with a bias toward action; and to inspire connectedness.

About Everyday Health

At Everyday Health Group, a division of Ziff Davis, we work in a culture of collaboration and welcome those who desire to join our growing global community. We believe in careers versus jobs and people versus employees. We seek enthusiastic individuals with an entrepreneurial spirit looking for an environment that rewards your best work.

Everyday Health offers competitive salaries in addition to robust health and wellness focused benefits including medical, dental, vision, life and disability benefits; Flexible Spending accounts, 401(k) with company match, an Employee Stock Purchase Plan, Pregnancy and Parental leave, Family Planning Support via Maven, Flexible Time Off, Volunteer Time Off, Fitness Reimbursement as well as employee-focused engagement and education programs, including Employee Resource Groups and company-sponsored events. If you’re seeking a dynamic work environment where you can see the direct impact of your performance, then Everyday Health is the place for you.

Everyday Health Group is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive and equitable environment for all employees. This is a remote/office-based position which may be performed anywhere in the United States except within Colorado.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

#MedpageToday


Show more Show less"
2826041247,Data Engineer,Synersys Technologies inc,2021-12-03,United States,"Santa Clara, CA",,Full-time,,"Task:

·        Data preparation, and data pipeline development using Pandas for enterprise data science projects.

 

Technical Skills:

·        Python

·        Pandas

·        SQL

Show more Show less"
2821840818,Big Data Engineer,Redjack,2021-12-01,United States,"Silver Spring, MD",Information Technology,Full-time,Computer Software,"Big Data Engineer


We are looking for people who share our core values of heroism, audacity, curiosity, and excellence to join our team. We are a tight-knit group of engineers, analysts, and business professionals who have organically built a company that monitors more than 8% of the Internets public IP space and 40 trillion business communications per year. We've had a huge impact on the Fortune-50 and Government sectors over the past year, so we're looking to grow rapidly while maintaining our culture and diversity.






As a cyber resilience company, we solve security, continuity, regulatory, and efficiency problems for our customers. Youll help protect the jobs and security of millions of people while working on and advancing novel techniques in computer science. Youll be connected to everything thats happening; every developer on the team is responsible for our products quality, everyone ships production code, and everyone directly supports the mission.






As a Big Data Engineer at Redjack, youll be responsible for data analysis solutions to automate the understanding and protection of the worlds largest digital enterprises. Your data science skills will be translated into opportunities for customers through the use of algorithmic, statistical, machine learning, and visualization techniques. You will demonstrate initiative and creativity by proposing ways to address problems often with large or incomplete data sets and validate findings using an experimental and iterative approach.




Your job


Your job will be to develop software to store and analyze massive amounts of customer enterprise data to reduce threat surface, increase cyber resilience, and facilitate digital transformations of some of the worlds largest enterprises. Specifically, you will:







Leverage cloud-based data stores and write software using exciting, modern approaches to manage information on massive cyber environments.


Collaborate with members of the engineering team to increase their big data engineering IQ and understand the needs of our customers.


Design, develop and implement novel detectors and classifiers of critical systems and activity through machine learning and other modern approaches.



What you should have accomplished


Well assess your skills and ensure your impact will scale with your ability. What were looking for to start:







Bachelors degree or higher in mathematics, statistics, engineering, or computer science.


3+ years experience with modern data science and machine learning approaches, big data analytics, and software development skills.


Knowledge and ability to explain both the code and the underlying statistical or analysis approac


hes used by modern data science algorithms/models.


Analytical and problem-solving skills.


Communication skills, critical thinking, and strategic thinking skills above and beyond the technical knowledge and implementation experience.





PM20




Show more Show less"
2798599288,Big Data Engineer,Amazon,2021-11-18,United States,"Bellevue, WA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Amazon Last Mile tech is seeking an extraordinary Big Data Engineer to join the DSP Big data analytics team.

At Amazon, we are working to be the most customer-centric company on earth -- including how we fulfill and deliver customer orders. The goal of Amazon’s Service Partner (DSP) Management Team is to exceed the expectations of our customers by ensuring that their orders, no matter how large or small, are delivered as quickly, accurately, and cost effectively as possible. To meet this goal, Amazon is continually striving to innovate and provide best in class experience through the introduction of pioneering new products and services in the last mile space.

The NA DSP team is seeking an exceptional Big data engineer to join the team. This person will play a key role in providing the end-to-end data engineering solutions to support key business initiatives. If you are passionate about Big data technologies, strongly biased to go deep to find insights and build scalable real time analytical platform, relentless in ensuring data quality and reliability, and feel comfortable communicating with different levels of leadership, you are the candidate we are looking for!

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build ETL to ingest the data into the data lake. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

As a Big Data Engineer, you will develop new data engineering patterns that leverage new cloud architectures, and will extend or migrate existing data pipelines to the architectures as needed. You will be responsible for designing and implementing the complex ETL pipelines in Big data platform and other BI solutions to support the rapidly growing and dynamic business demand for data, and use it to deliver the data as service which will have an immediate influence on day-to-day decision making at Amazon.com


Basic Qualifications

Ability to work in a team environment that promotes collaboration
Degree in Computer Science, Engineering, Mathematics, or a related field and 4+ years industry experience

Must have three year of experience in the following skill(s):

Developing and operating large-scale data structures for business intelligence using: ETL/ELT processes; OLAP technologies; data modeling; SQL;Python
Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQL
Experience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark or Hadoop based big data solution
Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)

Preferred Qualifications

Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.
Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
Experience building data products incrementally and integrating and managing datasets from multiple sources
Query performance tuning skills using Unix profiling tools and SQL
Experience building large-scale data warehouse projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies
Proven ability to drive adoption of data engineering best practices in a team of engineers, and ability to mentor junior team members
Linux/UNIX including to process large data sets.
Experience with AWS
Ability to work on a diverse team or with a diverse range of coworkers

Inclusive Team Culture

Here at Amazon, we embrace our differences. We are committed to furthering our culture of inclusion. We have 12 affinity groups (employee resource groups) with more than 87,000 employees across hundreds of chapters around the world. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which reminds team members to seek diverse perspectives, learn and be curious, and earn trust.

Flexibility

It isn’t about which hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We offer flexibility and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

We care about your career growth too. Whether your goals are to explore new technologies, take on bigger opportunities, or get to the next level, we'll help you get there. Our business is growing fast and our people will grow with it.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us


Company - Amazon.com Services LLC

Job ID: A1419330
Show more Show less"
2825174532,Senior-Big Data Engineer,AT&T,2021-12-02,United States,"Austin, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Wireless Services, and Telecommunications","Join AT&T and reimagine the communications and technologies that connect the world. We’re committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won’t just imagine the future – you’ll create it.

The Big Data Engineer will be responsible for interpreting the requirements of various Big Data Analytic Use Cases and Scenarios, and driving the design and implementation of specific data models to ultimately help drive better business decisions through insights from a combination of external and AT&Ts data assets. This is someone who is also motivated by their ongoing learning and willingness to pursue and complete professional .certifications on a continuing basis – and can use time management skills to balance learning with project related needs.

Key Roles and Responsibilities

Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the Big Data Environment.
Support the standardization, customization and ad-hoc data analysis, and will develop the mechanisms to ingest, analyze, validate, normalize and clean data.
Implements statistical data quality procedures on new data sources, and by applying rigorous iterative data analytics, supports Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value.
Will work with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data.
Develop and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods and techniques.

Qualifications

Preferred Bachelors of Science in Computer Science, Math or Scientific Computing preferred.
Typically requires 5-8 years experience.
Python, Azure or AWS, Data wrangling and Data pipeline design required
The ideal candidate will have fluency in programming, but also analytical skills since they will be working and exchanging ideas with data scientists

Ready to join our team? Apply today!

#ChiefDataOffice

JobCategory:Technology
Show more Show less"
2818858745,Analytics Engineer,Skimmia,2021-12-03,United States,United States,,Full-time,,"Summary
We’re seeking a motivated and talented Analytics Engineer to join our
Data Engineering Team remotely. This role, reporting to the Data Team,
will be responsible for understanding business analytics needs and
requirements and then turning those requirements into datasets used
throughout the business. The role will focus on expanding our data
warehouse and data pipelines through use of our ELT stack. To be
successful in this role, applicants must be comfortable working with a
variety of stakeholders and learning on the job. Analytics development
experience and strong communication skills are a must. In this role, you
will be exposed to a wide variety of cloud-based best-of-breed
technologies and help accelerate the growth of analytics at a leading
brand in the outdoor industry.

Essential Skills

• Self-starter with outstanding attention to detail and problem-
solving ability

• Strong oral and written communication skills
• Highly organized, ability to stay on track and meet deadlines in a
fast-paced work environment
• 2 years ELT/ETL experience
• Experience with enterprise level RDMS, SQL fluency
• Programming/Scripting (Python, R, Scala)
• Data analytics experience
Show more Show less"
2819645835,Data Engineer,Giig,2021-12-03,United States,United States,,Full-time,,"Our client is a global commerce leader that connects millions of buyers and sellers in more than 190 markets around the world. They exist to enable economic opportunity for individuals, entrepreneurs, businesses and organisations of all sizes.




They create inspiring ecommerce experiences for our buyers, sellers and developers. Embracing innovation has been a cornerstone of their growth and customer loyalty over the past 25 years – encompassing technologies such as AI, computer vision, natural language processing and machine translation.




Must have skills: Python, SQL, Hadoop, GCP (Google Cloud Provider), Bash (Gnu Bash)




Nice to have skills: Keras, Java, Scala, Docker, API




Location Constraints: Remote - Global




Please apply here for immediate consideration.

Show more Show less"
2764354838,Big Data Engineer,Inmar Intelligence,2021-12-03,United States,"Boston, MA",Engineering and Information Technology,Full-time,IT Services and IT Consulting and Information Services,"About You

You are passionate about data… big data. You are familiar with techniques for streaming and moving data between applications. You have developed applications that efficiently and effectively move and transform data as needed.. You want to drive the accuracy, timeliness and completeness of data for all products. You want to improve processes and outcomes for data for client consumption.

Primary Accountabilities

Technical (100%)

Create and maintain optimal data pipeline architectures in a hybrid cloud environment
Assemble large and complex data sets that meet both functional and non-functional business needs
Identify, design and implement internal process improvements such as automating manual data processes, optimizing data delivery and scalability
Build and maintain the infrastructure that is required to transfer and hold data from a wide variety of data sources
Create analytics tools that utilize the data pipeline to provide actionable insights, operational efficiencies and other key performance metrics/indicators (KPM/KPI)
Keep Inmar’s data secure throughout the pipeline in our hybrid cloud environment
Create data tools for analytics and data science team members that will assist them in building and optimizing Inmar’s product portfolio
Work with stakeholders on data-related technical issues and their data needs

Required Qualifications

Experience building and optimizing big data pipelines architectures and data sets.
Working knowledge of message queuing, stream processing and highly scalable big data data stores
You have built processes that support data transformation, data structures, metadata, dependency and workload management
A successful history of manipulation, processing and extracting value from data sets
Familiarity with Agile methodologies and development processes.
You have performed root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Experience supporting and working with cross-functional teams in a dynamic environment
Experience with big data tools such as Hadoop, Spark, Kafka, etc.
Experience with public cloud technologies in Google, AWS and Azure
Experience with relational and NoSQL databases such as SQL Server, Postgres, Cassandra, etc.
Experience with data pipeline and workflow management tools such as Airflow
Experience with object oriented/object function scripting languages such as Python, Java, Scala

Individual Competencies

Integrity: Gains the trust of others by taking responsibility for own actions and telling the truth.
Teamwork: Builds relationships and works cooperatively with others, inside and outside the organization, to accomplish objectives to build and maintain mutually-beneficial partnerships, leverage information and achieve results.
Adaptable: Responds to change with a willingness to learn new ways to accomplish work objectives with a positive attitude.
Innovative: Ability to develop, sponsor, or support the introduction of new and improved methods, products, procedures or technologies.
Curious: A desire to inquire and learn, to seek new knowledge and wisdom, and to listen to the contributions of others with a genuine interest to better self, the team, and the organization.
Analytical and Critical Thinking: Ability to tackle a problem by using a logical, systematic, sequential approach.
Problem Solving: Gathers and analyzes information to generate and evaluate potential solutions to problems, issues and challenges while weighing the accuracy and relevance of the facts, data and information.

The physical demands described here are representative of those that must be met by an associate to successfully perform the major job responsibilities (essential functions) of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the major job responsibilities. This job description is not intended to be an exhaustive list of all duties, responsibilities, or qualifications associated with the job.

While performing the duties of this job, the associate is:

Regularly required to use hands to finger, handle or feel objects, tools or controls, and reach with hands or arms.
Regularly required to talk or hear and read instructions on a computer monitor and/or printed on paper.
Occasionally required to stand, kneel or stoop, and lift and/or move up to 25 pounds.
Regularly required to view items at an extremely close range and must be able to adjust and readjust focus.

Safety

Support a safe work environment by following safety rules and regulations and reporting all safety hazards.

As An Inmar Associate, You

Put clients first and consistently display a positive attitude and behaviors that demonstrate an awareness and willingness to listen and respond to clients in order to meet their short-term and long-term needs, requirements and exceed their expectations.
Treat clients and teammates with courtesy, consideration and tact; you also have the ability to perceive the needs of internal and external clients and communicate effectively with the objective of delighting and retaining the client.
Build collaborative relationships and work cooperatively with others, inside and outside the organization, to accomplish objectives, develop and maintain mutually-beneficial partnerships, leverage information and achieve results.
Set and attain achievable, yet aggressive, goals with a sense of urgency and accountability.
Understand that results are important and focus on turning mission into action to achieve results following the principles of Flawless Execution while consistently complying with quality, service and productivity standards to meet deadlines and exceed expectations by giving our clients the best possible outcome.
Show more Show less"
2825080119,Data Engineer,Bull IT Services,2021-12-02,United States,"Texas, United States",,Full-time,,"Drive Architectural plans and implementation for future data storage, reporting and analytics solutions

Align architecture with business requirements

Direct the data acquisition from different sources

Develop, maintain and improve data set processes

Use one or several programming languages and cloud technologies to maintain data Warehouse Database Systems

Identify ways to Improve data readability, quality and efficiency

Conduct research to answer business/industry questions and necessities

Prepare data for consumption

Prepare data for predictive and prescriptive modeling

Find hidden patterns using data

 

Use data to discover tasks that can be automated

 

Interact with Stakeholders for Requirement definitions provide updates and recommendations

 

Work collaboratively with other data positions, to identify opportunities or problems

 

Monitor and Troubleshoot operational data issues in data pipelines

 

This is 100% remote position

Show more Show less"
2813249707,Data Engineer,Deloitte,2021-10-31,United States,"Falls Church, VA","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Bachelor's degree required
2+ years of professional experience designing and developing real time ETL architecture
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be able to obtain and maintain the required clearance for this role

Preferred:

5+ years of professional services and/or government consulting experience
Interest in event streaming architectures, such as Apache Kafka
Creativity and innovation - desire to learn and apply new technologies, products and libraries

How you'll grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
Show more Show less"
2787828411,Big Data Engineer (Data Modeling),App Annie,2021-11-18,United States,"Washington, United States",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","*YOU CAN WORK REMOTELY FROM ANY LOCATION AS LONG AS YOU ARE LOCATED IN PST TIME ZONE




Something about us

App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. More than 1,300 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business. We are a global company, headquartered in San Francisco but as a “remote” first company, we care about your results and not your location.

Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.




What can you tell your friends when they ask you what you do?




I am an experienced Big Data engineer who can create innovative new products in the analytics and data space. I participate in the development that creates the world's #1 app stores analytics service. Together with my team I build out new product features and applications using agile methodologies and open source technologies. I work directly with Product Managers, Software Architects, and I am on the front lines of coding new and exciting analytics and data mining products. I love what I do and excited to join an entrepreneurial company with a start-­up culture!




You will be responsible for and take pride in….

As a Big Data Engineer, you will be in charge of our data analysis projects and to build clean, robust and maintainable data processing program that can support these projects on huge amount of data, this includes:

Able to design and implement complex product components based on requirements with possible technical solutions.
Write data analysis and statistics programs using Pyspark with a commitment to maintaining high quality work while being confident in dealing with data mining challenges.
Discover any feasible new technologies lying in the Big Data ecosystem, share them to team with your professional perspectives.
Get up to speed in the machine learning domain, implementing analysis components in a distributed computing environment with instruction from Data Scientists.
Be comfortable conducting detailed discussions with Data Scientists regarding specific questions related to specific data models.
You should be a strong problem solver with proven experience in big data.

You should recognize yourself in the following…

Master's degree in Math or Computer Science and at least 2+ years of experience in Big Data Engineering.
Hands-on experience and deep knowledge of Hadoop ecosystem.
Knowledge and experience with PySpark, Mapreduce, HDFS, Linux, Storm, Kafka.
Proficient with programming in Python, experience in Pandas, Sklearn or Other data science and data analysis toolset is a big plus.
Having a background of data mining and machine learning domain, familiar with common algorithms and libs is a plus.
Passion for cloud computing (AWS in particular) and distributed systems.
You must be a great problem solver with the ability to dive deeply into complex problems and emerge with clear and pragmatic solutions.
Good communication, and cooperation globally.




This is what we offer…

We provide a $1,000 (country equivalent) WFH allowance to set you up for remote work success.
Remote working from anywhere in PST time zone! We are not office centric anymore and never will be.
90-days global passport. Work from anywhere in the world for 90 days a year!
Internet allowance for stable internet connection, so your video does not freeze on Zoom.
Flexible working days. We love to meet, but if you need to get your kids behind school-zoom, need to leave early to get to your band repetition or gym classes, do your thing.
Paid leave, so long as you promise to come back!
Health and dental benefits.
An international team of talented and engaged people from different cultural backgrounds and locations.
Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!
Unlimited access to online learning platform Udemy to help you develop your skills.
Virtual initiatives and events to keep you connected with your colleagues.
Generous Employee Referral Program. Up to $10,000 for specific roles.




Yes, I want this job!

Show more Show less"
2826787192,Data Engineer - Remote,TechFetch.com - On Demand Tech Workforce hiring platform,2021-12-04,United States,"Houston, TX",Information Technology,Part-time,IT Services and IT Consulting,"""ALL our jobs are US based and candidates must be in the US with valid US Work Authorization. Please apply on our website directly."" UnitedHealthcare is a company that's on the rise. We're expanding in multiple directions, across borders and, most of all, in the way we think. Here, innovation isn't about another gadget, it's about transforming the health care industry. Ready to make a difference? Make yourself at home with us and start doing your life's best worksm) Come join the Business Insights division or the UHC Operations Analytics team whose mission is simple and audacious ? make the healthcare system better for everyone by driving action with data and analytics. In our team, we are guided by the desire to mature our solutions to be more descriptive, predictive, and prescriptive in nature, while at the same time build the relationships needed to be a trusted advisor, working hand in hand with our business partners. Within this team you will be focused on Provider Data solutions ? making sure we provider accurate and timely reporting and analytics suite to serve our provider operations teams.Functions may include database architecture, engineering, design, optimization, security, and administration; as well as data modeling, big data development, Extract, Transform, and Load (ETL) development, storage engineering, data warehousing, data provisioning and other similar roles. Responsibilities may include Platform-as-a-Service and Cloud solution with a focus on data stores and associated eco systems. Duties may include management of design services, providing sizing and configuration assistance, ensuring strict data quality, and performing needs assessments. Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging data storage and retrieval system capabilities. Manages relationships with software and hardware vendors to understand the potential architectural impact of different vendor strategies and data acquisition. May design schemas, write SQL or other data markup scripting and helps to support development of Analytics and Applications that build on top of data. Selects, develops and evaluates personnel to ensure the efficient operation of the function. You?ll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges. Primary ResponsibilitiesUse your operational analytical skills to design/develop, program, maintain and publish reportsMake solid recommendations based on the analysis and provide explanations for reporting results for both internal operations and our customersSelf-directed and creative as you will deal with some very interesting and complex issuesDemonstrate an understanding of data modeling (relationships, data types, tables, etc and analytics concepts (queries, reporting, association of data sources)Interpret requirements and translate them into data requirements (interfaces, data transformation, etc for complex projectsCollect and interpret data from various internal and external sources; prepares and compiles dataDemonstrate familiarity in using modeling and reporting tools and how to use them during the analysis process (e.g. SQL and/or Business Objects tools)Design and/or develop specific databases for collection, tracking, and reporting to facilitate analysisDesign and develop network accessibility reports in Quest Analytics software packages.Data mapping (e.g. between source and target databases; mapping screen fields to database columns)Assist business and systems analysts with business rule and data integrationYou?ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. You?ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.Required QualificationsBachelor?s Degree or equivalent experience1+ year of customer Facing Experience (Including status updates, strategy discussions and managing complex/sensitive scenarios)1+ year of experience Capturing Requirements, Documenting System/Process Changes, and/or Design/Thinking Experience2+ years of experience Leading/Participating in a Project Delivery Environment3+ years of Report Development & Analysis Experience2+ years of experience with BI Tools (Tableau, Power Bi or Equivalent)3+ years of Data Technology Experience (SQL Server, Salesforce, etc), or equivalent experience working with data3+ years of ETL and Data Modeling Experience1+ year of Experience working with Big Data/Cloud Technologies (Hadoop, MAPR Hive, Spark/Snowflake)2+ years of experience with Productivity Suite (Excel, PowerPoint, Work) Preferred Qualifications3+ year of Healthcare Industry ExperienceHealth Insurance Experience UnitedHealth Group requires all new hires and employees to report their COVID-19 vaccination status. Careers with UnitedHealthcare. Let's talk about opportunity. Start with a Fortune 6 organization that's serving more than 85 million people already and building the industry's singular reputation for bold ideas and impeccable execution. Now, add your energy, your passion for excellence, your near-obsession with driving change for the better. Get the picture? UnitedHealthcare is serving employers and individuals, states and communities, military families and veterans where ever they're found across the globe. We bring them the resources of an industry leader and a commitment to improve their lives that?s second to none. This is no small opportunity. It's where you can do your life's best worksm) *All Telecommuters will be required to adhere to UnitedHealth Group?s Telecommuter Policy. Colorado Residents Only: The salary range for Colorado residents is $64,800 to $116,000 Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements No matter where or when you begin a career with UnitedHealth Group, you?ll find a far-reaching choice of benefits and incentives

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity / Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.

Job Keywords: Data Engineer, Remote, Telecommute, SQL, Data, Hiring Immediately, #RPO, work from home, work at home, WFH, WAH
Show more Show less"
2779807009,Big Data Engineer,Bloom Energy,2021-11-26,United States,"San Jose, CA",Engineering and Information Technology,Full-time,"Appliances, Electrical, and Electronics Manufacturing, Computer Software, and Oil and Gas","Job Description:

Big Data Engineer

Bloom Energy is the leading force in transforming the way energy is generated and delivered. We are driving toward the parallel goals of growing a dynamic and forward-thinking company while creating a positive impact on our environment. Our company is filled with smart and innovative thinkers and doers, and we never stop striving to improve our technology, to expand and improve our company performance, and to develop and support the many talented employees that serve our mission.

We are looking for a Big Data Engineer to join our team in one of today’s most exciting technologies. This role will report to Senior Staff Controls Engineer and will be ideally based in San Jose, CA, however, Remote work will be considered.

**FLEXIBILITY WITH LOCATION**

Role -


Assist in analyzing diverse sets of imperfect data and finding common patterns, theme and trends by using Big Data tools and machine learning
Design and delivery of scalable data-driven applications in real-time platforms
Full development cycle from conceptualizing, coding, testing, deployment to iterating for continuous improvement
Work closely with engineering, operations, and business teams to measure, analyze, and understand Bloom Energy’s complex and growing data and help them make real time decisions.
Develop/maintain services, exposed through clean REST API, that would store process data, run analytics, generate KPIs and take automated control actions.
Automation first thinking !


Requirement -
Knowledgeable in machine learning and statistics concepts including regression analysis, linear/non-linear models, classification, clustering, anomaly detection etc.
Proficient with programming in Python/Java/Scala or similar language
Demonstrated experience with NoSQL databases like MongoDB, Hadoop and REST APIs
Experience with algorithm development and design pattern
Strong analytical and problem solving skills & comfortable working in teams
Work experience in the process industry is a plus but is not required.
Graduate Education in:
Chemical, Mechanical, Electrical Engineering, Computer or Data Sciences
M.S. degree candidates preferred



About Bloom Energy:

At Bloom Energy, we strive toward a 100% renewable future. Our Energy Servers are adaptable to new and innovative fuels while already acting as a cleaner and far more resilient source of power than existing solutions. We see hydrogen as a significant game-changer in the world’s energy usage, and Bloom Energy fuel cells and electrolyzers will be the industry standard for clean, efficient, and reliable energy production. We anticipate being able to work in concert with other renewable energy technologies to create a comprehensive system that will change the way energy in the world is produced, stored, transmitted, and used. For more information visit: www.bloomenergy.com.

Bloom Energy is an equal opportunity employer and makes employment decisions on the basis of merit. We are committed to compliance with all applicable laws providing equal employment opportunities. All qualified applicants, will receive consideration for employment without regard to race, sex, color, religion, national origin, protected veteran status, or on the basis of disability. Bloom Energy makes reasonable accommodations, consistent with applicable laws, for the known physical or mental limitations of an otherwise qualified applicant or employee with a disability, who can perform the essential job functions, unless undue hardship would result.


Show more Show less"
2816918950,Big Data Engineer,Capgemini Engineering,2021-11-30,United States,"San Jose, CA",Engineering and Information Technology,Full-time,IT Services and IT Consulting,"Capgemini Engineering combines, under one brand, a unique set of strengths from across the Capgemini Group: the world leading engineering and R&D services of Altran – acquired by Capgemini in 2020 – and Capgemini’s digital manufacturing expertise. With broad industry knowledge and cutting-edge technologies in digital and software, Capgemini Engineering supports the convergence of the physical and digital worlds. Combined with the capabilities of the rest of the Group, it helps clients to accelerate their journey towards Intelligent Industry. Capgemini Engineering has more than 52,000 engineer and scientist team members in over 30 countries across sectors including aeronautics, automotive, railways, communications, energy, life sciences, semiconductors, software & internet, space & defence, and consumer products.










Job Title: Big Data Engineer

Type: FTE

Location: San Jose, CA

Job Description:

Qualifications -

Extensive Linux Knowledge

Programming language: Java

Data analysis knowledge such as Apache Spark, Kudu and Flink

Desired Skills/Qualifications/System Experience requirements:

Nice to have Qualifications

1. In depth knowledge of HDFS and its eco-system

2. Relational Database knowledge

Setting up :

Data analysis knowledge such as Apache Spark, Kudu and Flink

Linux Sysadmin

In depth knowledge of HDFS and its eco-system




Software Engineers perform requirements analysis.

They then design, develop or maintain the physical application (components) or the application environment, based on the Software Architecture (models and principles).

Activities include coding, integrating, implementing, installing or changing frameworks and standard components, or technical and functional application management.

A Software Engineer also develops languages, methods, frameworks and tools, and/or undertakes activities in support of server-based databases in development, test and production environments.




Required Skills and Experience:

You have mastered several Software Engineering areas, applications or database environments. You act as a Software Engineering stream leader with technical delivery ownership within a (limited) number of technology areas. You contribute to bids or client proposals based on your technological expertise. You also act as a team leader with delivery ownership, and guide individuals and groups towards desired outcomes. You actively participate in at least one community and contribute to community discussions.




• Qualification: 6-8 years (2 years min relevant experience in the role) experience, Bachelor’s Degree.

• Certification: Should have SE Level 1 and seeking level 2.

• Should be proficient in Business Analysis, Business Knowledge, Software Engineering, Testing, Data Management, Architecture Knowledge and Technical Solution Design.

Candidates should be flexible / willing to work across this delivery landscape which includes and not limited to Agile Applications Development, Support and Deployment.













This company is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.

Show more Show less"
2814731769,Data Engineer,VITA Tech,2021-12-01,United States,"Dallas, TX",,Full-time,,"Job description:

• Python
• SQL
• Azure Data factory
• Synapse
• Databricks,
• Restful
Show more Show less"
2825279521,Data Engineer,Hitachi Vantara,2021-12-03,United States,"San Francisco, CA",Information Technology,Full-time,"IT Services and IT Consulting, Human Resources, and Management Consulting","The Team

At Hitachi Vantara’s Digital Insights practice, we help our clients by building technology solutions that addresses business challenges and improve business outcomes with data-driven insights. As we continue expand our big data team, we are looking for data engineers who are passionate about technology and want to build a career working on the latest technology platforms.

As a Part Of This Team, You Will

Work with our clients to gather requirements and develop scalable data solutions
Use cloud services to integrate different data sources and develop data lakes
Provide recommendations to optimize data pipelines and data warehouse queries

Required Skills

Bachelor’s degree in computer science, MIS related area, or equivalent experience
Ability to work well in a team environment, meet deadlines, demonstrate good time management, and multi-task in a fast-paced project environment
Experience developing data pipelines (EMR/Glue) in AWS cloud
3+ years of experience with Apache Spark (Python or Scala)
Familiarity with basic Linux commands and writing Shell scripts
1+ years of experience working on Snowflake and proficient with SQL”.
Strong understanding of data warehousing concepts and dimensional modeling
Willingness and ability to learn new tools and technologies
Excellent verbal and written communication skills

Preferred Skills

Experience developing stream processing jobs and familiarity with Kafka
NoSQL databases – MongoDB, Cassandra, DynamoDB, HBase, Neo4j, etc.

Our Company

Hitachi Vantara is part of the Global Hitachi family. We balance innovation with an open, friendly culture and the backing of a long-established parent company, known for its ethical reputation. We guide customers from what’s now to what’s next by unlocking the value of their data and applications to solve their digital challenges, achieving outcomes that benefit both business and society.

Our people are our biggest asset, they drive our innovation advantage and we strive to offer a flexible and collaborative workplace where they can thrive. Diversity of thought is welcomed and our employee base is represented by several active Employee Resource Group communities. We offer industry leading benefits packages (flexible working, generous pension and private healthcare) and promote a creative and inclusive culture. If driving real change gives you a sense of pride and you are passionate about powering social good, we’d love to hear from you.

Our Values

We strive to create an inclusive environment for all and are open to considering home working, compressed/flexible hours and flexible arrangements. Get in touch with us to explore how we might be able to accommodate your specific needs.

With Japanese Roots Going Back Over 100 Years, Our Culture Is Founded On The Values Of Our Parent Company Expressed As The Hitachi Spirit

We are proud to say we are an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Wa – Harmony, Trust, Respect

Makoto – Sincerity, Fairness, Honesty, Integrity

Kaitakusha-Seishin – Pioneering Spirit, Challenge
Show more Show less"
2813250592,Data Engineer,Deloitte,2021-10-31,United States,"McLean, VA","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Bachelor's degree required
2+ years of professional experience designing and developing real time ETL architecture
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be able to obtain and maintain the required clearance for this role

Preferred:

5+ years of professional services and/or government consulting experience
Interest in event streaming architectures, such as Apache Kafka
Creativity and innovation - desire to learn and apply new technologies, products and libraries

How you'll grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
Show more Show less"
2805703599,Big Data Engineer,SHEIN Technology LLC,2021-11-19,United States,Los Angeles Metropolitan Area,Information Technology,Full-time,Internet Publishing,"Job Title: Big Data Engineer

Reports to: Head of Big Data

Location: Los Angeles, CA - Remote (must be a CA resident to come into the office as needed)

(Remote California till Q4’22)




About SHEIN Technology

SHEIN Technology is a U.S. technology company. Founded in 2012, SHEIN is a leading global online retailer with operations in Guangzhou, Los Angeles, and Singapore, along with other key markets. SHEIN reaches consumers across more than 150 countries and regions around the world. We place a premium on choice, delivering more than 6,000 new fashion, beauty, and lifestyle products daily with more than 600,000 items available. Our mission is to help people express their individuality through the latest trends that are accessible and affordable. To learn more about SHEIN, follow us at shein.com, instagram.com/sheinofficial and youtube.com/shein.




Position Summary:

SHEIN is the largest online-only fashion company in the world! The Big Data team has the unique opportunity to own the US-based Big Data operations, refactor and redesign, while partnering with an established global organization. We are looking for an experienced Big Data Engineer to support operations, solve complex issues, and drive growth. We achieve this goal by building and deploying highly scalable data pipelines, adhering to software/data engineering best practices, and ensuring the security and quality of our data to the delight of our consumers.




Responsibilities:

Responsible for design, development, implementation, operations, and support of the Big Data platforms and tools for securing, processing, and querying data at scale
Create best-in-class data analytical solutions with strong referenceable documentation for implementing, executing, and delivering data insights
Partner in a cross-functional global organization across data, security, infrastructure, and business teams to build trust and ensure successful delivery of top-quality data solutions
Follow approved life cycle methodologies and DevOps / DataOps procedures, creates design documents and documentation, perform program coding and testing
Lead projects or project steps within a broader project and / or solve project objectives while working independently with minimal guidance and direction




Skills and Qualifications:

Bachelor’s degree or higher in the field of engineering, computer science or equivalent advance technology field of study
A minimum of 5 years of hands-on experience in developing Big Data applications using Hadoop ecosystem, streaming platforms, RDBMS, and NoSQL database technologies. Including experience in similar data technologies, data pipelines, and associated architecture patterns on public cloud (AWS, Azure, or GCP)
Demonstrated ability to write complex SQL, and high degree of competency programing in Python, Java, and Scala
High level of personal integrity, with the ability to professionally handle confidential matters and exudes the appropriate level of judgment and maturity
Must be a strong communicator with exceptional verbal and written communication skills to translate the vision and strategy into clear priorities and direction, both internally and externally.




SHEIN Technology is an equal opportunity employer committed to a diverse workplace environment.

Show more Show less"
2806055926,Big Data Engineer (Remote),Orange Quarter,2021-10-26,United States,United States,Engineering and Information Technology,Full-time,Staffing and Recruiting,"Backed by one of the most well-respected private equity firms in the world, this company has pioneered brand establishment and research technologies for IP and brand professionals. Being the first to market and a continuous focus on research, innovation and collaboration has solidified their stronghold on the industry as they now plan for another stage of growth following a large acquisition.

Serving more than 5000 clients from around the globe, the goal is to empower them with the ability to easily monitor and protect brand assets from anywhere in the world. Now, they’re looking for an ambitious Big Data Engineer to join their diverse team-based anywhere in the world.

Industry

OQ-industries Internet

What To Expect

You’ll be working with an advanced software solution that allows analysts to easily detect infringements that could have a detrimental effect on their client’s businesses. Working with data on the tera-scale, the goal is to spot those infringements and co-ordinate investigation activities with advanced data-streaming and data-classification techniques. You’ll have the opportunity to work with machine learning, image recognition, risk analysis and fraud detection algorithms in parallel with the grand goal of tidying up the internet (no biggie).

Perks

Full time remote working environment
Laptop provided
The opportunity to work on challenging project with a supportive and equally talented team
25 vacation days per year

Requirements

5+ years of experience in Big Data Engineering
Experience with Java or Python and solid experience in SQL and related RDBMS (MySQL, PostgreSQL)
Hands-on experience with the big-data eco-system - Hadoop, Spark, Kafka, Flink or Airflow
Familiar with NoSQL Databases (ElasticSearch, MongoDB, DynamoDB)
Experience building large scale Data Warehouses or Data Lakes on production environments
You have built several ETL pipelines and familiar with the ETL optimization techniques
Familiar with Amazon Web Services and related big data cloud services
Experience in developing enterprise multi-tenant SaaS
Experience with Linux/Unix a plus
Fluent communication skills in English;

Sounds good? Apply now
Show more Show less"
2817853028,Data Engineer,IBM,2021-11-29,United States,"Houston, TX",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

tTtThe IBM Client Innovation Center in Baton Rouge is expanding and has immediate opportunities for experienced forward-thinking Data Engineer with a passion for growth and innovation. The success of IBM is in your hands as you transform vital business needs into innovation solutions to drive growth for our clients. Our clients are some of the world’s leading companies and you will be part of challenging projects to build and support technical solutions for their needs You will have access to the latest education, tools and technology, and a limitless career path with the world’s technology leader. Come to IBM and make a global impact!

The position of the Data Engineer plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. The Data Engineer defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business. Develops applications on Big Data and Cognitive technologies including API development. Expected to have traditional Application Development background along with knowledge of Analytics libraries, open-source Natural Language Processing, statistical and big data computing libraries. Strong technical abilities to understand, design, write and debug complex code.

The role of the Data Engineer is to work directly with the client using Pyspark,Scala, Hadoop, Hive and Postgre SQL. The Data Analyst must possess an understanding of the relational databases. The Data Engineer must also possess the skills to effectively collaborate with the client Subject Matter Experts (SMEs) to provide necessary solutions.

The successful candidates for this position will become members of our Client Innovation Team. You will work closely across the CIC network to delight our customers with leading edge solutions with a keen focus on quality and client satisfaction. In addition to strong collaboration across the team, you will be virtually integrated into our deep learning and knowledge program as well as employee engagement across NA. All resources in our CIC network may be requested to travel depending on specific client project needs. US Travel is typically related to knowledge transfer and client relationship building at the client site, as well as subsequent travel for key milestones or project initiatives. Travel is generally no more than 50% of the time. Preferred Locations: Lake Charles & New Orleans LA; Mobile AL; Pensacola FL; Gulfport, Hattiesburg, Jackson & Oxford MS; Beaumont & Galveston TX.

This position requires relocation to Louisiana within 30 days of the office reopening. This position requires up to 50% travel. This is not a permanent work from home position.

sprgg21

Required Technical and Professional Expertise

Minimum 3 Years Relevant Experience

Should have a strong knowledge on Pyspark, Scala, Hadoop,Hive and/or Postgre SQL

Preferred Technical And Professional Expertise

Unless specified as a Required Skill, the following are additionally preferred but not required:


Experience with big data solutions such as Hadoop, MapReduce, Hive, Pig, Kafka, Storm etc. is a major plus.


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2812586672,Senior Big Data Engineer,Mastercard,2021-10-31,United States,"San Francisco, CA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Internet Publishing, and Financial Services","Our Purpose

We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.

Job Title

Senior Big Data Engineer

Have you ever wondered how do you see offers on your credit card based on your past purchase? If you wanted to find the answer do join our team.

We are looking for a Data Engineer to not only build data pipelines but also extend the next generation of our data tools. As a Data Engineer, you will develop a clear sense of connection with our platform - as Data Engineering is the eyes through which they see the product.

Data Engineer Responsibilities

Lead day to day system development and maintenance activities of the team to meet service level agreements and create solutions with high level of innovation, cost effectiveness, high quality and faster time to market.

Support code versioning, and code deployments for Data Pipelines.

Ensure test coverage for unit testing and support integration and performance testing.

Contribute ideas to help ensure that required standards and processes are in place.

Research and evaluate current and upcoming technologies and frameworks.

Build data expertise and own data quality for your areas.

Minimum Qualifications

Extensive Java/Scala development experience.

Extensive experience with SQL.

Strong experience with Spark Processing engine.

Strong experience with Big data tools / technologies (Hive, Impala, OOZIE, Airflow, NIFI)

Strong experience with Data Modeling.

Experience in Kafka and PCF (Pivotal Cloud Foundry)

Experience analyzing data to discover opportunities and address gaps.

Experience working with cloud or on-prem Big Data platform(i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).

Due to COVID-19, most of our employees are working from home. We’ve implemented a virtual hiring process and continue to interview candidates by phone or video and are onboarding new hires remotely. We value the safety of each member of our community because we know we’re all in this together.

Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.

If you require accommodations or assistance to complete the online application process, please contact reasonable.accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.

Corporate Security Responsibility

All Activities Involving Access To Mastercard Assets, Information, And Networks Comes With An Inherent Risk To The Organization And Therefore, It Is Expected That The Successful Candidate For This Position Must

Every person working for, or on behalf of, Mastercard is responsible for information security.

Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
Show more Show less"
2803947675,Senior Big Data Engineer,Nike,2021-11-23,United States,"Beaverton, OR",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Nike, Inc., Beaverton, OR. Develops, codes/configures, tests programs/systems and solutions problems in order to meet defined digital product specifications and direction. Assesses a well-defined problem and leads the development of a technical solution that meets the needs of the business and aligns with architectural standards. Responsible for building highly scalable and fault tolerant data pipelines, including performance-tuning extraction and transformation and load processes using latest optimization techniques. Capable of executing projects in highly agile environment with focus on quality deliverables in a process oriented manner. Manages small- to moderate-sized solutions, or plays a key role on larger teams, working within the parameters of two to three sprints. Provides direction to team members and/or vendors. Advises product owners on discrete technology-related business problems. Formulates options, including assessing their relative merits and risks. Works with product owners to determine the best solution. Interprets customer needs, assesses requirements and identifies solutions to non-standard requests. Impacts a range of standard and non-standard customer, operational, process, project or service activities. Monitors and controls costs of own work and may manage costs for small projects or programs. Performs work in support of brand plans. Demonstrates link between daily work and company mission. Participates in initiatives, programs or products with moderate visibility.

Applicant must have a Master’s degree in Computer Science, Computer Information Systems, or Engineering and 2 years of experience in the job offered or a related occupation. Experience must include:

Python;
SQL;
Big Data Analytics;
AWS;
Data Modeling;
Data Architectrue;
Snowflake;
Github/Bitbucket;
Airflow;
Spark framework;
Building ETL Pipelines;
NoSQL;
AWS or equivalent cloud experience, such as GCP/Azure;
Scala;
Big Data/Real Time Analytics; and
Automated Testing
Show more Show less"
2824515232,Data Engineer,Reveal Mobile,2021-12-02,United States,"Raleigh, NC",Engineering,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Reveal Mobile is a venture-backed startup pioneering the use of mobile location data to improve how companies better reach and serve their customers. Our clients leverage our tools and APIs to build dynamic audiences based on real-world location data.

To support our growth we are adding a Data Engineer to the team. This critical role requires strong technical skills to help build our products, as well as leadership and communication skills to help us shape our processes and team culture as we grow. We have great benefits that include competitive pay, stock options and great PTO policies.

You will be joining a talented and fun team, leveraging the latest technologies to write and automate tests for our data pipeline and SaaS products. As a member of the engineering team, you will be responsible for promoting quality and playing an active role in product development, while bringing in great ideas for ways to innovate and improve our platform. Our office environment is casual but the pace is fast!

As a software company committed to creating a diverse and inclusive community, we are an equal opportunity employer and do not discriminate. Join us as we build a great company that solves challenging problems and takes great care of its employees.

We’re looking for a growth trajectory over experience. We value intellectual ability, love of learning, and enthusiasm for team environments over years of experience.

Requirements

Our ideal candidate:

You use a combination of persistence, research, problem-solving skills, and experience to overcome obstacles
You take pride in your work. You are attentive to detail, but also flexible.
You are available for and responsive to questions. You are professional and collegial in your communications.
You like being the person that others rely on.
You quickly learn new technologies as needed and recognize that you are engaged in timely, business-critical tasks.
You are transparent in what you do. You discuss, document, and commit your work as needed
You enjoy working in an Agile environment and welcome constructive feedback
You approach problems with a product development mindset


Technical Skills:

3+ years of experience with Apache Spark
3+ years of experience with Scala/Java and Python
2+ years building data pipelines
2+ years working with stream processing technologies such as Apache Kafka and Apache Storm
2+ years working in AWS or Google Cloud
Experience with or desire to learn a functional programming language
Experience with Git and continuous integration systems
Excellent verbal and written communication skills


Bonus Skills:

Familiarity with event-driven systems
Experience working with NoSQL data stores like ElasticSearch or MongoDB
Experience working with geospatial data
Experience with Kubernetes
Experience with machine learning
Experience working in ad tech


Benefits

Competitive salary
401k matching
Health, dental, life and disability insurance plans
Unlimited PTO
Flexible work schedule
Show more Show less"
2817131316,Data Engineer,AllianceBernstein,2021-12-02,United States,"Nashville, TN",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Company Description

As a leading global investment management firm, AB fosters diverse perspectives and embraces innovation to help our clients navigate the uncertainty of capital markets. Through high-quality research and diversified investment services, we serve institutions, individuals and private wealth clients in major markets worldwide. Our ambition is simple: to be our clients’ most valued asset-management partner.

With over 4,400 employees across 51 locations in 25 countries, our people are our advantage. We foster a culture of intellectual curiosity and collaboration to create an environment where everyone can thrive and do their best work. Whether you're producing thought-provoking research, identifying compelling investment opportunities, infusing new technologies into our business or providing thoughtful advice to clients, we’re looking for unique voices to help lead us forward. If you’re ready to challenge your limits and build your future, join us.

IT Group Description

The Equity Investment Management Technology (“EIMT”) team creates software to support the research, portfolio management, and trading activities for our institutional and private client equity products. This role is within the EIMT – Research team which supports an established business team of buy side equity quantitative and research analysts. Members of this team are focused on solutions surrounding market data and investment models used for managing equity products.

IT Job Description

We are seeking a Nashville based Data Engineer to join our Equity Investment Management Technology Research team.

Describe The Role

The EIMT Research Data Engineer is a key role for our firm providing focused on enhancing the equity data architecture to provide rapid data onboarding, quality control, accessibility, and business insights.

Describe the applications and business or enterprise functions the role supports:

This role will focus on building out infrastructure and frameworks using cloud-based distributed compute and storage technologies, continuous integration and deployment tools, data pipeline orchestration, non-SQL and traditional data warehousing (RDMS) technology.

The key job responsibilities include, but are not limited to:

Automation of data ingestion supporting various sources and formats both external and internal.
Implementing a quality control framework for ensuring data consistency.
Cataloging new data sets to facilitate data discovery, lineage, and self-service.
Building business intelligence dashboards to provide data insights.
Assist with ad-hoc data and research requests from the investment team.
Provide support for overnight jobs.

What makes this role unique or interesting?

This role provides the opportunity to experience the full lifecycle of building investment decisions from onboarding data to evaluating factor performance while applying modern processing concepts using cloud based solutions.

What is the professional development value of this role, i.e. what learning and professional growth does the role offer the candidate?

This Role Provides Opportunity In The Following Areas

Learning the equity investment business and engaging directly with investment professionals
Automating complex data loads and pipelines
Onboard alternative datasets including learning how to web scrape
Best practices managing large data sets
Building technical skills including SQL, Python, and PowerBI
Working with cloud-based technologies including data lakes, data pipelines, and data warehouses

Qualifications, Experience, Education

BS in Computer Science/Engineering, Finance, Mathematics/Statistics or a related major
5+ years programming in SQL with experience in relational schema designs and optimizing query performance
2+ years using Python or another object oriented language (C#, Java)
Experience building both Data and ETL Pipelines
Experience with cloud data warehouses such as Snowflake, Azure Synapse, Amazon Redshift or Google BigQuery.
Building visualizations using PowerBI, Tableau, or Qlik, is a strong plus

Skills

Solid analytical and technical skills
Candidate must be willing to take ownership of projects and show strong client commitment
Must demonstrate good communication skills and be comfortable working closely with business users
Self starter as well as a good team player
A strong desire to document and share work done to aid in long term support

Special Knowledge (Nice To Have But Not Necessary)

Experience working in the financial industry or knowledge of basic financial statement concepts
Experience using Airflow

People of color, women, and those who identify as LGBTQ people are encouraged to apply. AB does not discriminate against any employee or applicant for employment on the basis of race, color, religion, creed, ancestry, national origin, sex, age, disability, marital status, citizenship status, sexual orientation, gender identity, military or veteran status or any other basis that is prohibited by applicable law. AB’s policies, as well as practices, seek to ensure that employment opportunities are available

Nashville, Tennessee
Show more Show less"
2805272868,Data Engineer,Courier Network,2021-12-01,United States,United States,,Full-time,,"Your Role:

Our quickly growing small business specializes in expedited air courier services, from anywhere to everywhere in the world. We are looking for a BI specialist who is passionate about data, analytics, and true reporting. 

 

Our data analytics BI warehouse and pipeline/engines are built on Sisense, TMS (Transportation Management System), and Priority ERP Accounting. You will help us see more of our business, teach others in the company about analytics, and improve the use and reporting of our data. 

 

You will become an integral part of providing data-driven insights that inform significant company decisions, and that can also be safely and reliably shared with customers.

 

Your Responsibilities:

Monitor and corrections of all data platforms.
 Build Elasticubes and Dashboards using Sisense.
Improve and develop new TMS and Priority ERP Accounting data models.
Generate efficient end-to-end reporting solutions (from data ingestion to customers).
Work with key business managers to define key metrics and reporting requirements.
Maintain and improve our data ecosystem (ETL, DB technology, data optimizations).
Drive the adoption and effective use of our software tool within every team.

 

You are a good fit if you:

Have a solid understanding of data warehouse, ETL, Pipeline tools, and BI tools.
Have deep experience with Sisense or other advanced BI tools.
Know query optimization, indexing, SQL query optimization, and analysis.
Familiar with Priority Accounting or a similar ERP.
Familiar with an advanced global TMS platform (Transportation Management System).
Are very proficient in JavaScript, Python, API, Frameworks & EDI.
Are familiar with the AWS ecosystem, have solid scripting skills and write clean code.
Can communicate clearly and directly.

 

Your Education and Experience:

BA/BS in a quantitative field.
3-5+ years of work experience as a data engineer, or in a highly analytical role.
Experience writing SQL queries and using Sisense and a TMS.
Experience with programmatic scripting using JavaScript and Python.
Strong grasp of statistics and experience conducting rigorous data analyses.
Experience developing models and visualizations, including Excel.

 

Useful for you to have:

The capacity to juggle multiple priorities effectively within a fast-paced environment (critical).
Be a highly motivated self-starter with the ability to execute plans independently (important).
Be able to learn new data-related tools and technologies to maintain and improve the overall data management and BI strategy.
Be passionate about spreading the value of data throughout the company.
Communicate insights to a broad audience with varying levels of technical expertise.

 

Why work at CNW Global?

We are a fast-moving, fun-loving, passionate group of people who really care about solving expedited air logistics emergencies for our customers. We work for them! We empower our employees to drive our business and to suggest changes when we don't get it right. These are our values:

Exceed Customer Expectations: we provide an exceptional experience on each and every challenge.
Take Ownership: we are trusted to make decisions that are in the best interests of our customers. We think and act like owners. We care and are agile, and that makes all the difference in the world.
Be Curious: We are curious, ask questions, seek to understand and try new things.
Do the Right Thing: We earn trust by being transparent, respectful, and honest with each person with whom we interact.
Get Results: Results fuel our excitement, and we know how our personal accomplishments tie to the success of the company.

 

Our benefits:

CNW offers its employees a generous Employee Benefits Package including:

Competitive Wages.
Fully paid medical insurance for you and your family.
We provide a 401k Plan with a generous contribution.
Discretionary bonuses.
And, much more!

.

All benefits offered are subject to eligibility requirements, terms, and provisions set forth in the respective policies and plan documents, which you may request from Human Resources.

CNW is committed to providing equal employment opportunities to all employees and applicants. CNW does not tolerate discrimination against job applicants or employees because of race, color, creed, sex, religion, age, national origin, disability, marital status, genetic predisposition or carrier status, sexual orientation, and military status or any other protected class recognized under federal, state, or local law. This commitment extends to all aspects of the company's employment practices including, but not limited to, recruiting, hiring, promoting, transferring, compensation, benefits, training, leaves of absence, termination, and other terms and conditions of employment.

Show more Show less"
2819655911,Data Science Engineer,VertexBlue,2021-12-03,United States,"Plano, TX",,Full-time,,"Job Description:

To build systems that collect, manage, and convert raw data into usable information for data scientists and business analysts to interpret.
 Their goal is to make data accessible so that organizations can use it to evaluate and optimize their performance.

Roles and responsibilities:

Freshers would also work.
Analyze and organize raw data, build data systems and pipelines.
Evaluate business needs and objectives. Interpret trends and patterns.
Conduct complex data analysis and report on results.
Prepare data for prescriptive and predictive modeling.
Build algorithms and prototypes.

Requirements:

  Previous experience as a data engineer or in a similar role
  Technical expertise with data models, data mining, and segmentation techniques
Knowledge of programming languages (e.g., Java and Python)
  Hands-on experience with SQL database design
  Great numerical and analytical skills
  Degree in Computer Science, IT, or similar field; a master's is a plus.
Show more Show less"
2827224623,Data Engineer,APPIC Solutions LLC,2021-12-04,United States,"Greenwood Village, CO",Information Technology,Full-time,IT Services and IT Consulting,"JOB Description: Data Engineer

Advertising location: Englewood, CO 80112

What you’ll be doing: This role will be responsible for expanding our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler, who enjoys optimizing data systems and building them from the ground up. This position will support our software developers, database architects, data analysts, and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.

The successful candidate will:

Create and maintain optimal data pipeline architecture;
Assemble large, complex data sets that meet both functional and non-functional business requirements;
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.;
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies;
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics;
Collaborate with stakeholders including the executive, product, data and design teams to assist with data-related technical issues and support their data infrastructure needs;
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader;
Work with data and analytics experts to strive for greater functionality in our data systems.

A successful Data Engineer will have:

A Bachelor’s degree in Computer Science Engineering, Data Analytics, or a related technical degree. Technical requirements:
Five+ years of experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Kafka, Flink etc) for building efficient, large-scale ‘big data’ pipelines;
Strong Software Engineering experience with proficiency in at least one of the following programming languages: Java, Golang, Python, Scala or equivalent;
Implement data ingestion pipelines both real-time and batch using best practices;
Experience with building stream-processing applications using Apache Flink, Kafka Streams, or others;
Experience with Cloud Computing platforms like Amazon AWS, Google Cloud, etc.;
Experience supporting and working with cross-functional teams in a dynamic environment;
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with ELK stack.
Ability to work in a Linux environment. Ideal qualifications:
Experience in building distributed, high-volume data services;
Experience with big data processing and analytics stack in AWS: EMR, S3, EC2, Athena, Kinesis, Lambda, Quicksight etc.;
Knowledge of data science tools and their integration with data lakes;
Experience in container technologies like Docker/Kubernetes
Show more Show less"
2826772212,Big data Engineer,Nuvento Inc,2021-12-02,United States,"Rockville, MD",Engineering and Information Technology,Contract,IT Services and IT Consulting,"Job Functions

Analyze system requirements and design responsive algorithms and solutions

Use big data and cloud technologies to produce production quality code

Engage in performance tuning and scalability engineering

Work with team, peers and management to identify objectives and set priorities

Perform related SDLC engineering activities like sprint planning and estimation

Work effectively in small agile teams

Provide creative solutions to problems

Identify opportunities for improvement and execute

Essential Skills

Experience with cloud based Big Data technologies

Proficiency in Hive

Spark SQL

Experience with Spark

Experience with one or more programming languages like Scala, Python, andor Java

Ability to push the frontier of technology and independently pursue better alternatives
Show more Show less"
2826257109,Data Engineer,Insight Global,2021-12-03,United States,United States,,Full-time,,"-3+ years of software programming experience

-Knowledge of professional software engineering and best practices (ie: coding standards, code reviews, testing, operations, etc.)

- Proven experience building data pipelines using variety of tools including but not limited to Python, Shell script, Data Lake, PySpark

-Experience working within a cloud-based environment (AWS, google cloud or Azure)

- Excellent communication, analytical problem solving skills and the ability to collaborate







Plusses

-Experience working within an Agile environment







Day-to-Day *

A global chemical manufacturing company located in Wilmington, DE is seeking a well-rounded Data Engineer to join for a long term contract opportunity. This individual will be joining the enterprise Digital Innovation organization specialized in data engineering, business intelligence, advanced analytics, data science, and machine learning. They will be responsible for front and back end programming for data-driven solutions delivery for a large, ongoing pipeline of work. Technically speaking, the ideal candidate should be experienced in programming (python, javascript, R, java) and have experience/ exposure to cloud based environments. Additionally, this person must have previous credible project experience (whether in school or otherwise), be an analytical thinker and problem solver and must be able to work collaboratively and efficiently.




Additional Responsibilities:

- Design, develop, and launch extremely efficient and reliable data pipelines using Python frameworks to move data and to provide intuitive analytics to our partner teams.

- Develop within existing designs of various solutions in Microsoft Azure environment to help the business get valuable insights

- Collaborate with other engineers and Data Scientists to discover the best solutions.

- Diagnose and solve issues in our existing data pipelines and envision and build their successors.

Show more Show less"
2818889703,Data Engineer,Hyatt Hotels Corporation,2021-12-03,United States,Greater Chicago Area,Information Technology,Full-time,Hospitality,"This is not a remote position

This is a hybrid position in Chicago

We will relocate you to Chicago




At Hyatt, we’re working to Advance Care through data-driven decisions and automation. This mission serves as the foundation for every decision as we create the future of travel. We can’t do that without the best talent – talent that is innovative, curious, and driven to create exceptional experiences for our guests, customers, owners and colleagues.




Hyatt seeks an experienced Data Engineer who will be an exceptional addition to our growing engineering team. The Data Engineer will work closely with engineering, product managers and data science teams to meet data requirements of various initiatives in Hyatt.




As a Data Engineer, you will take on big data challenges in an agile way. In this role, you will build data pipelines that enable engineers, analysts and other stakeholders across the organization. You will build data models to deliver insightful analytics while ensuring the highest standard in data integrity. You will integrate different data sources, improve the efficiency, reliability, and latency of our data system, help automate data pipelines, and improve our data model and overall architecture.




You will be part of a highly visible, collaborative and passionate data engineering team and will be working on all the aspects of design, development and implementation of scalable and reliable data products and pipelines.




Applying the latest techniques and approaches across the domains of data engineering, and machine learning engineering isn’t just a nice to have, it’s a must.




This candidate builds fantastic relationships across all levels of the organization and is recognized as a problem solver who looks to elevate the work of everyone around them.




Collaborate with product managers, data scientists, engineering, and program management teams to define product features, business deliverables and strategies for data products
Collaborate with business partners, operations, senior management, etc on day-to-day operational support
Support operational reporting, self-service data engineering efforts, production data pipelines, and business intelligence suite
Interface with multiple diverse stakeholders and gather/understand business requirements, assess feasibility and impact, and deliver on time with high quality
Design appropriate solutions and recommend alternative approaches when necessary
Work with high volumes of data, fine tuning database queries and able to solve complex technical problems
Contribute to multiple projects/demands simultaneously
Work in a fast paced, collaborative and iterative environment
Exercise independent judgment in methods and techniques for obtaining results
Work in an agile/scrum environment
Use state of the art technologies to acquire, ingest and transform big datasets

The ideal candidate demonstrates a commitment to Hyatt core values: respect, integrity, humility, empathy, creativity, and fun.




Qualifications

1 to 5 years of experience within the field of data engineering or related technical work including business intelligence, analytics
Experience and comfort solving problems in an ambiguous environment where there is constant change. Have the tenacity to thrive in a dynamic and fast-paced environment, inspire change, and collaborate with a variety of individuals and organizational partners
Experience designing and building scalable and robust data pipelines to enable data-driven decisions for the business
Very good understanding of the full software development life cycle
Very good understanding of Data warehousing concepts and approaches
Experience in building Data pipelines and ETL approaches
Experience in building Data warehouse and Business intelligence projects
Experience in data cleansing, data validation and data wrangling
Hands-on experience in AWS cloud and AWS native technologies such as Glue, Lambda, Kinesis, Lake Formation, S3, Redshift
Experience using Spark EMR, RDS, EC2, Athena, API capabilities, CloudWatch, CloudTrail is a plus
Experience with Business Intelligence tools like Tableau, Cognos, ThoughtSpot, etc is a plus
Hands-on experience building complex business logics and ETL workflows using Informatica PowerCenter is preferred
Experience in one of the scripting languages: Python or Unix Scripting
Proficient in SQL, PL/SQL, relational databases (RDBMS), database concepts and dimensional modeling
Strong verbal and written communication skills
Demonstrate integrity and maturity, and a constructive approach to challenges
Demonstrate analytical and problem-solving skills, particularly those that apply to Data Warehouse and Big Data environments
Open minded, solution oriented and a very good team player
Passionate about programming and learning new technologies; focused on helping yourself and the team improve skills
Effective problem solving and analytical skills.
Ability to manage multiple projects and report simultaneously across different stakeholders
Rigorous attention to detail and accuracy
Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance, or a related quantitative field
The position responsibilities outlined above are in no way to be construed as all encompassing. Other duties, responsibilities, and qualifications may be required and/or assigned as necessary.

Show more Show less"
2827141706,Data Engineer (Remote),Varis,2021-12-04,United States,United States,Engineering and Information Technology,Full-time,Computer Software and Internet Publishing,"Data Engineer

Product & Technology

Role is 100% REMOTE! You can work from anywhere within the US!

Varis is a well-funded and fast-growing technology startup. Our incredible team includes top industry leaders with decades of experience. We are innovation driven, customer centric, and ready to transform Business-to-Business (B2B) Procurement with insights gleaned from data. Our culture is focused on bold vision, launching the simplest (yet still valuable) initial solution to learn, then either failing or scaling fast. We seek teammates who drive value creation, are great problem solvers, have strong interpersonal savvy, and can successfully learn on the fly! Joining us now is a ground-floor opportunity to shape our limitless future. On our team you will: see and feel the direct impact of your work; be surrounded by passionate people; learn how to be an entrepreneur; and be at the center of a highly dynamic business model with tremendous individual and collective potential.

#A2b2l5# The Data Engineer is accountable for implementing methods to improve data reliability and quality. They combine raw information from different sources to create consistent and machine-readable formats. They also develop and test architectures that enable data extraction and transformation for predictive or prescriptive modeling.

He/she must conduct the analysis of raw data, developing and maintain datasets, improving data quality and efficiency around the data pipeline.

We are looking for an experienced data engineer to join our team. You will use various methods to transform raw data into useful data systems. For example, you’ll create algorithms and conduct statistical analysis to provide important insights to foster product and technical adoption within and outside of Varis. Overall, you’ll strive for efficiency by aligning data systems with business goals.

To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources. Data engineer skills also include familiarity with several programming languages and knowledge of learning machine methods.

If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you.

Primary Responsibilities:

1. Analyze and organize raw data

2. Build data systems and pipelines

3. Evaluate business needs and objectives

4. Interpret trends and patterns

5. Conduct complex data analysis and report on results

6. Prepare data for prescriptive and predictive modeling

7. Build algorithms and prototypes

8. Combine raw information from different sources

9. Explore ways to enhance data quality and reliability

10. Identify opportunities for data acquisition

11. Develop analytical tools and programs

12. Collaborate with data/research scientists and ontologists on several initiatives

Education & Experience

Level of Formal Education: Bachelor’s or Master’s degree or equivalent experience

Area of Study: Data Science and or Computer Science

Years of Experience: Minimum 2 -3 years’ experience in related field

Type of Experience:

· Modeling large data sets and data repositories

· Experience in eCommerce, B2B, Sourcing, or Procurement environment is a plus.

Language Skills:

· Excellent verbal and written communication skills

Technical Competencies:

· Previous experience as a data engineer or in a similar role

· Technical expertise with data models, data mining, and segmentation techniques

· Knowledge of programming languages (e.g. Java and Python)

· Hands-on experience with database design (e.g., SQL, Key-Value, and Document based, etc.)

· Data engineering certification (e.g IBM Certified Data Engineer) is a plus

Skills and Ability:

· Knowledge of planning, designing, and implementing a data pipelines, architecting and designing through scientific method the use of machine learning techniques, to ensure that the data science management best practices are planning, designed and implemented.

· Strong background in research and analysis, including the ability to evaluate source authority

· Solid problem solving and conceptual thinking abilities

· Great numerical and analytical skills

· Ability to work in a collaborative, fast-paced environment

· Comfortable in technical environments and eager to learn new systems as needed

· Ability to context switch between systems-level thinking and attention to minute details

· Time management skills, demonstrated success in handling multiple, sometimes conflicting priorities

· Capable of balancing quick decision-making with attention to quality and accuracy

Personal Attributes:

· Interpersonal and leadership skills

· Executive level presence

· Maintains a positive attitude, high energy, and strong sense of urgency

· Ability to learn quickly and think creatively

· Resident expert on cutting-edge customer experience

Other/Preferred:

· Knowledge of various eCommerce and Internet technologies

The above statements are intended to describe the general nature and level of work being performed by associates assigned to this classification and are not intended to be a complete list of all required responsibilities and skills. Other duties and special projects may be assigned per business needs. Job descriptions are subject to change at any time with or without notice. Varis is wholly owned by The ODP Corporation, which is the legal employer of Varis associates. ODP is an Equal Opportunity Employer.

Show more Show less"
2790859291,Data Engineer,Tesla,2021-10-19,United States,"Fremont, CA",Information Technology,Full-time,"Renewable Energy Semiconductor Manufacturing, Motor Vehicle Manufacturing, and Utilities","The Role

For our Energy products Reliability and Test team, we are looking for an extraordinary Data Engineer who is proficient in database development and data management to create and manage large-scale data pipelines as well as data management-centered applications (database, back-end, and front-end user interface). As a successful candidate, you will utilize your data analysis and programming expertise to collect, integrate, analyze, and report the test and field data that ultimately drives key decisions related to Tesla’s solar and other sustainable energy products. This is a cross-functional position in which you will work with reliability, quality, design, process and manufacturing teams.

Responsibilities

Access and process large amounts of lab and field data through developing customized code and scripting in Python or other programming languages.
Own projects ranging from data structure design to extraction / transformation / loading (ETL), as well as building dashboards for analysis to provide varying levels of visualizations tailored for each audience.
Develop and maintain databases and applications to automate real-time monitoring as well as the collection and analysis of reliability data from laboratory tests and field evaluations.
Interface with engineering, design and product management to understand data needs and provide customized solutions.
Develop programming and technical tools that leverage artificial intelligence and machine learning and to pave the way for smarter and faster data-driven decisions and predictions.

Requirements

Degree in Computer Science, Electrical Engineering, Mechanical Engineering, Applied physics, or Mathematics with 2+ years’ work experience in data science, ETL development, and data warehousing.
Excellent knowledge of SQL working with large data sets, as well as creating and maintaining databases.
Outstanding programming skills (Python, and HTML are preferred, Java, JavaScript and cyclone can also be considered).
Demonstrated experience creating automated, reproducible data pipelines and working with complex, large data sets.
Skills in building dashboards using Tableau, Power BI, or similar visualization software,
Excellent teamwork/interpersonal skills, willing to gain and share new knowledge and the ability to communicate effectively.
Remain engaged, proactive and positive in tough circumstances. Own assignments and take full accountability for their success.
Positive attitude, eager to learn and ability to change direction quickly.

Preferred Qualifications

Hands-on experience in statistical analysis, machine learning and data driven forecasting.
Previous course work and understanding in power electronics and/or solar energy is a plus.
Show more Show less"
2787360200,Data Engineer,GreatVines Beverage Sales Execution Platform,2021-11-05,United States,United States,,Full-time,," Looking for a highly motivated Big Data Engineer with a passion for data, to build and implement data pipelines in cloud technologies, specifically SnapLogic. Work from home in a highly flexible environment using a blend of open source and industry leading technology and working with data in the beverage alcohol space. Must be able to work in US without Sponsorship.

Show more Show less"
2790638013,Data Engineer,Qloo,2021-11-11,United States,"New York, NY",,Full-time,,"WHAT WE DO




Qloo is the Cultural AI, connecting and predicting consumer taste across domains including media, entertainment, consumer products, fashion, and travel. We offer an API to clients and maintain consumer-facing projects. We are funded by institutional investors like AXA, AI Ventures, and individuals ranging from Sir Elton John and Leonardo DiCaprio to Barry Sternlicht and Pierre Lagrange.




Few more links on us -




*Inc. just released the Inc.5000, and Qloo placed in the top 200 of the fastest growing companies in America and in the top 5 in NYC.




Programmableweb has named Qloo one of the top APIs for AI (alongside IBM Watson and Amazon Alexa).




POSITION

As a Data Engineer at Qloo, you will be tasked with contributing and improving on Qloo’s data ingestion pipeline and knowledge graph. The ingestion pipeline services Qloo’s AI/Machine Learning models so you will collaborate closely with the machine learning team in order to ensure data quality, automation, and testing is aligned with Qloo’s and our clients’ standards. A Data Analyst with experience in processing and qualitatively evaluating large sets of data would be necessary for this role.




WHAT YOU’LL DO

Contribute to designing, building, evaluating, shipping, and refining data pipelines used for ML models and various other tools.
Assist with architecting data solutions for incoming client projects.
Assist expanding and enriching Qloo’s knowledge graph by integrating large datasets
Help drive optimization, testing, and tooling to improve quality of our data.




WHAT YOU NEED TO KNOW

Python, Pandas, and NumPy libraries
PySpark or Hadoop technologies
AWS or other cloud computing platforms
Experience working with and processing large datasets




AND IT WOULD BE NICE IF YOU KNEW

Familiar with ML frameworks like TensorFlow or PyTorch
SQL or familiar with other RDMS
Experience working with data visualization tools like Tableau
Familiar with knowledge graph structures and processing




MORE ABOUT US




A small, growing team with high output, all of us are passionate about creating. In normal times we're in a sunny, dog friendly office in SoHo, Manhattan, and fully flexible about remote work. Compensation is competitive and hours are flexible.

Show more Show less"
2794635010,Big Data (Spark) Engineer,TEEMA,2021-11-16,United States,United States,Information Technology,Contract,Financial Services,"Working with Big Data tech (Spark) with Kafka and Python (PySpark) and Hadoop (or Hive); also needed HTML, CSS, XML and Javascript. W-2 only.

Show more Show less"
2826785439,Data Engineer - Remote,TechFetch.com - On Demand Tech Workforce hiring platform,2021-12-04,United States,"Minnetonka, MN",Information Technology,Part-time,IT Services and IT Consulting,"""ALL our jobs are US based and candidates must be in the US with valid US Work Authorization. Please apply on our website directly."" UnitedHealthcare is a company that's on the rise. We're expanding in multiple directions, across borders and, most of all, in the way we think. Here, innovation isn't about another gadget, it's about transforming the health care industry. Ready to make a difference? Make yourself at home with us and start doing your life's best worksm)Positions in this function are responsible for the management and manipulation of mostly structured data, with a focus on building business intelligence tools, conducting analysis, performing normalization operations, and assuring data quality.

This customer facing position will work directly with executive level stakeholders within our Broker & Employer teams to develop advanced UI reporting solutions.

This position provides visibility, analytical, ad hoc and development capabilities leveraging data from different functional areas across the Broker and Employer landscape.You'll enjoy the flexibility to telecommute* as you take on some tough challenges.Primary Responsibilities:Works in a matrix environment by partnering with other partners in the Broker & Employer Operations/Services area and the Appeals and Escalations area to deliver reporting needs to support service operations.Works in an Agile framework within a matrix environment working in sprints and utilizing agile tools (e.g., Swift KanbanInstills an Agile framework within the team and across the matrix environment to operate as applicable and fully utilizing KanBan tools.Builds / maintains and/or adheres to a structured data governance process to be used across all datasets with a focus on quality and accuracy.Works closely with in Business Insights and across partner areas like ARA, DAS3 and others within UnitedHealthcare Operations EnablementParticipates in data readiness specifically in support of United Strategic Platform (USP) migrationsIdentifies and participates in the resolution of data integrity issues and organizational problemsFunctional Responsibilities:Demonstrates and applies understanding of UnitedHealth Group's business (e.g., specific business capabilities, functions, processes, and business cycles) and knowledge of operations, goals, and policies and procedures of internal business partners (e.g., information contacts) to provide effective support to internal and/or external customers.Manages and protects data, adhering to applicable legal/regulatory requirements (e.g., HIPAA, PHI, PII, DOI, state and federal regulationsProposes and/or defines long-term strategies for implementing process and/or data and reporting improvements.Reviews competitive intelligence (e.g., report formats; aggregation levels) to identify trends and opportunities for new reporting solutions and data strategy. Identifies and/or provides opportunities for additional training and learning to support process and report improvements.Creates and/or updates presentation documents and materials to summarize results (e.g., written reports; PowerPoint deck; Tableau; graphs and/or chartsReviews and/or identifies appropriate data infrastructure to use based on customers' needs in alignment with PADU.Develops business context diagrams (e.g., business data flows, process flows) to analyze/confirm the definition of project requirements.Demonstrates understanding of the difference between business requirements and technical solutions and defines approach for storing and updating business requirements.Collaborates with business and technical stakeholders (e.g., business owners, process owners, domain experts) to identify specific business requirements.

Performs reviews with all stakeholders to obtain approval/signoff of project requirements documents (e.g., walkthroughsUpdates progress to project schedule to track/measure progress one?s progress fulfilling aligned tasks.

In addition to supporting ongoing monitoring by keeping project documentation or applications updated (e.g., Swift KanBanYou?ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.Required Qualifications:3+ years of Data Technology Experience (SQL Server, SQL/TSQL, Snowflake, Hadoop/HIVE, etc, or equivalent experience working with data1+ years of experience with BI Tools (Tableau, Power Bi or Equivalent), data analysis and report development1+ years of ETL, Modeling, Report Development & Analysis Experience2+ years of experience Capturing Requirements, Documenting System/Process Changes, and/or Design/Thinking Experience2+ years of experience with reporting databases/data warehousesAdvanced proficiency in Microsoft Excel, Word, Power Point and VisioBachelor?s degree or- equivalent work experienceCareers with UnitedHealthcare. Let's talk about opportunity. Start with a Fortune 5 organization that's serving more than 85 million people already and building the industry's singular reputation for bold ideas and impeccable execution. Now, add your energy, your passion for excellence, your near-obsession with driving change for the better. Get the picture? UnitedHealthcare is serving employers and individuals, states and communities, military families and veterans where ever they're found across the globe. We bring them the resources of an industry leader and a commitment to improve their lives that?s second to none. This is no small opportunity. It's where you can do your life's best worksm)UnitedHealth Group requires all new hires and employees to report their COVID-19 vaccination statusAll Telecommuters will be required to adhere to UnitedHealth Group?s Telecommuter Policy.Colorado, Connecticut or Nevada Residents Only: The salary range for Colorado residents is $64,800 to $116,000. The salary range for Connecticut / Nevada residents is $71,400 to $127,400. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements No matter where or when you begin a career with UnitedHealth Group, you?ll find a far-reaching choice of benefits and incentives. Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity / Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.UnitedHealth Group is a drug ? free workplace. Candidates are required to pass a drug test before beginning employment. Keywords: Data Engineer, Agile, WFH, Nationwide Telecommute, Remote, Data, Analysis, ETL, SQL, Snowflake, Reporting, UHG, UnitedHealth, Optum, Hiring Immediately, Hadoop, HIVE, #RPO
Show more Show less"
2797248753,Data Engineer,Nike,2021-10-24,United States,"Beaverton, OR",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Who are we looking for

We need an experienced Data Engineer to join our team. You are a natural born leader with a history of developing complex data solutions and experience working on end-to-end solution design. You are a passionate, data evangelist who loves finding relationships between disparate data sets and clarity in a muddied data environment and are continually learning as well as finding opportunities to share knowledge with others.

What will you work on

As a senior-level Data Engineer, you will design and build reusable components, frameworks, and libraries at scale to support analytics products. You’ll identify and solve issues concerning data management to improve data quality, and clean, prepare and optimize data for ingestion and consumption. You also will build continuous integration, test-driven development, and production deployment frameworks.

Who will you work with

You will work with your Data Engineering teammates to review design, code, and test plans to increase knowledge and application of key methodologies. You’ll also collaborate with business and Technology partners to build well-defined components that support the implementation of product features.

What you bring to nike

Pursuing a master’s degree in computer science, engineering, information sciences or related field with a graduation date of December 2021 or Spring/Summer 2022
3+ years of relevant experience
Deep understanding of data structures and algorithms
Deep understanding of solution and technical design
Strong problem-solving and analytical skills
Ability to quickly pick up new programming languages, technologies, and frameworks


Please submit your resume as a PDF!

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

#NikeUniversityRelations
Show more Show less"
2818834992,Data Engineer,Nebosys,2021-12-03,United States,"Dallas, TX",,Contract,,"Responsibilities:




Develops innovation strategies, processes, and best practices.




Drives the execution of multiple business plans and projects.




Supports and ensures business objectives being met.




Leads the discovery phase of medium to large projects to come up with high level design.




Leads the work of other small group of 3 to 4 engineers for assigned Engineering projects




Leads and participates in end to end service implementations, data feeds ingestion, and orchestration.




Environment:




Project tech stack is varied, a lot of micro services and pipelines running in the background. A lot running in Java and Big Data. A few years of experience in Java would be secondary/helpful.




Hadoop ecosystem - HDFS, Spark, Spark Streaming, Kafka, Hive-- If they have GCP, it is a big plus.




Top Skills Details




1. Coding in either Scala or Java (Java is preferred)




2. Hadoop & Kafka




3. Spark Streaming, SQL




Additional Skills & Qualifications




1 big challenge they had with hiring - knowledge level and experience in building real time pipelines. 100% remote during contract duration, will need to relocate to Dallas, Sunnyvale . communication is important to the teams




 Interview Information




1 - 1 hr interview with a technical lead

Show more Show less"
2826746606,Big Data Engineer,"Donato Technologies, Inc.",2021-12-03,United States,"San Francisco, CA",Engineering and Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Staffing and Recruiting","Hi, Greetings from Donato Technologies Inc.!!! We have an immediate opening with my direct client. If you are looking for a new project and if you are available please send me a copy of your updated resume ASAP. Job Role Big Data Engineer Location Bay Area, CA (Day One Onsite) Duration 12+ months Job Description

9+ years of IT experience Big Data Engineer Design, develop, document, and architect Big data applications Develop code using knowledge of SQL, NoSQL, data warehousing, Scala, Spark, Hive

Hadoop Be an expert in newer concepts like Apache Spark and Scala programming. Manage and monitor Hadoop log files Develop MapReduce coding that works seamlessly on Hadoop clusters Seamlessly convert hard-to-grasp technical requirements into outstanding designs Design web services for swift data tracking and query data at high speeds Test software protot

DONATO TECHNOLOGIES, INC 12100 Ford Rd, 306, Dallas, TX 75234
Show more Show less"
2821505254,Data Engineer,Sia Partners,2021-12-03,United States,"Charlotte, NC",Consulting,Full-time,Management Consulting,"Sia Partners is looking for a talented Data Engineer to support our activities within the Data Science Business Unit. You will be working alongside with our Data Science consultants and our clients on Data Engineering topics, including creating relevant data models, developing powerful data pipelines, exposing them through various mechanisms including APIs, and using data visualization tools to efficiently present data.



You will also contribute to internal Data Science projects posted on Heka, our internal accelerator for Data Science projects. As part of the global Data Science team you will contribute to the development of various solutions designed to address our clients' needs.



Key Responsibilities 



Partner with our client’s leadership teams, engineers, program managers and data analysts to understand data needs.
Design, build and launch efficient and reliable data pipelines transforming data into useful report ready datasets.
Communicate at scale, through multiple mediums: presentations, dashboards, client-wide datasets, bots and more.
Use your data and analytics experience to ‘see what’s missing,’ identifying and addressing data gaps, build monitors to detect data quality issues and partner to establish a self-serve environment.
Broad range of partners equates to a broad range of projects and deliverables, including ML Models, datasets, measurements, services, tools and process.
Leverage data and business principles to automate data flow, detect business exceptions, build diagnostic capabilities, and improve both business and data knowledge base.
Build data expertise and own data quality for your areas.


Qualifications


At least 4+ years' of advanced SQL experience (including at least one SQL DBMS and one noSQL).
4+ years' of Python development experience.
3+ years' of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).
3+ years' experience with Data Modeling.
Experience analyzing data to discover opportunities and address gaps.
4+ years' experience in custom ETL design, implementation and maintenance.
Experience working with cloud or on-prem Big Data/MPP analytics platform (i.e. SnowFlake, Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).
BSc/BA in Data Science, Computer Science, Engineering.

Preferred Experience with:



Experience with more than one coding language.
Knowledge of Docker, CI/CD pipelines, and Kubernetes.
Experience in designing and implementing real-time pipelines.
Experience with data quality and validation.
Experience with SQL performance tuning and e2e process optimization.
Experience with anomaly/outlier detection.
Experience with notebook-based Data Science workflow.
Experience querying massive datasets, using Spark, Presto, Hive, Impala, etc.


Additional Information



This is an opportunity to join a rapidly growing team that serves some of the most exciting and highly respected companies in the world. You will have the opportunity to provide clients with original thinking and customized solutions and you’ll often have the satisfaction of seeing the impact of your work on their business. We are committed to a healthy work-life integration. 



Benefits



Generous PTO, including Parental leave
Healthcare that includes dental and vision, life insurance and 401K matching                                        
Career advocacy program that supports achieving personal development goals through coaching, collaboration and real-time feedback
Robust learning and development platform through the Sia Institute, 360 Learning App, Sia Blend App, working groups, US Training Sessions, and reimbursement for continuing education and certifications
Women at Sia Club
Annual Seminar/a value add experience to network with your colleagues across North America and other regions
Opportunities for geographic mobility if desired
Work directly with clients

Still Interested? Tell Us About Your…  



Academic successes
Consulting / Agency experience
Data supported success stories
Growth from failure
Tools and training
Cross-functional experience
Extracurriculars

Diversity, equity, inclusion, and belonging (DEIB) are part of Sia Partners’ DNA. Thanks to our expertise in several sectors and our international growth, our teams include a variety of experiences and cultures. We’re confident that promoting DEIB creates an environment in which everyone can reach their full potential. 



Our global network, DEIB@Sia Partners, brings together our people worldwide to facilitate local and global progress, focused on the following areas:



Gender equality (global Gender Equality Index score of 91/100 for FY19-20)
LGBTQ+
Race & Ethnicity
Working Parents 
Disabilities

We are an equal opportunity employer that values collective diversity, equity, inclusion and belonging. Our goal is to develop a work environment where everyone feels safe to be their authentic self and valued as part of the Sia Village.



All your information will be kept confidential according to EEO guidelines.



Sia Partners is an equal opportunity employer. All aspects of employment, including hiring, promotion, remuneration, or discipline, are based solely on performance, competence, conduct, or business needs. 



Show more Show less"
2817741670,Big Data Engineer ** REMOTE - U.S. **,Varian,2021-11-06,United States,United States,Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Hospitals and Health Care","Together, we can beat cancer.

At Varian, we bring together the world's best talent to realize our vision of a world without fear of cancer. Together, we work passionately to develop and deliver easy-to-use, efficient oncology solutions. If you want to be part of this important mission, we want to hear from you.

As a Data Engineer you would be part of our growing Data Analytics team, working closely with domain experts in defining well thought and thorough solutions. You would be involved in all phases of development like project scoping, team building, working with business leads and project managers, organizing sprints, managing deadlines, understanding, and articulating priorities, architecting solutions, coding and delivering high quality results.

This position reports to the Engineering Manager and has high level of visibility to functional managers worldwide.

What You Will Do

Work in capacity of a software engineer as part of Analytics team to design Business Intelligence product
Gather a
d understanding of requirement and help other team members to translate it into technology solution
Deliver development supporting artifacts like Use Case diagrams, Class diagrams and Sequence diagrams based on requirement analysis and design
Provide consulting to development teams when required
Document the technical implementations and evangelize with development teams
Participate in cross-functional technical discussions local and remote groups
Follow process and produce quality deliverables supporting the process
Participate in software design and review activities
Develop / innovate solutions to complex problems
Participate in sprints and component backlogs refinement
Participate in troubleshooting complex issues in production and resolving defects
Production of high quality code
Formulates and recommends standards for achieving maximum performance and efficiency of the DW Ecosystem
Develop and demonstrate high quality prototypes / modules and finished applications that meet the desired goals, quality and are well documented
Stay in touch with latest and upcoming BI open source technologies
Mentoring team members to get up to the speed on technology

What You Will Have

Education: Bachelor’s in technology, MSc, MCA or equivalent degree in Computer Science
Minimum of 5 years relevant experience
Technology: SQL Server, Hadoop, Spark, Python
Languages: Java, Python
ETL Technology: SSIS, Azure Data Factory
Experience with large database interactions (Postgres is desired)
Cloud knowledge – Azure cloud
Strong Data warehousing skills
Proven software development background with a very good systems perspective
Experience in end to end phases of development lifecycle
Hands on experience in low level design skills

What Will Set You Apart

Technologies: Hadoop, Kafka, NoSql
Languages: .Net, J2EE, Scala
ETL Technology: SSIS, Talend
Cloud knowledge – Exposure to AWS, GCP
BI Technology: SSRS, SSAS, Tableau
Time series analysis, clustering, decision trees and neural networks
Experience with Agile development methodologies
Leadership qualities and the ability to take initiative

Fighting cancer calls for big ideas.

We envision a world without fear of cancer. Achieving this vision takes dedication and commitment from all of us, every single day. That's why we celebrate and value the distinctly beautiful and intersectional identities of each of our employees. We are a mirror of our patient-base, which allows us to innovate. Big ideas come from everywhere, and the best ideas are fostered by our unique individual experiences. At Varian, we encourage you to bring your whole self to work and believe your bold and authentic perspective will help to power more victories over cancer.

#TogetherWeFight

Privacy Statement
Show more Show less"
2825179041,Senior-Big Data Engineer,AT&T,2021-12-02,United States,"Alpharetta, GA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Wireless Services, and Telecommunications","Join AT&T and reimagine the communications and technologies that connect the world. We’re committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won’t just imagine the future – you’ll create it.

The Big Data Engineer will be responsible for interpreting the requirements of various Big Data Analytic Use Cases and Scenarios, and driving the design and implementation of specific data models to ultimately help drive better business decisions through insights from a combination of external and AT&Ts data assets. This is someone who is also motivated by their ongoing learning and willingness to pursue and complete professional .certifications on a continuing basis – and can use time management skills to balance learning with project related needs.

Key Roles and Responsibilities

Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the Big Data Environment.
Support the standardization, customization and ad-hoc data analysis, and will develop the mechanisms to ingest, analyze, validate, normalize and clean data.
Implements statistical data quality procedures on new data sources, and by applying rigorous iterative data analytics, supports Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value.
Will work with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data.
Develop and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods and techniques.

Qualifications

Preferred Bachelors of Science in Computer Science, Math or Scientific Computing preferred.
Typically requires 5-8 years experience.
Python, Azure or AWS, Data wrangling and Data pipeline design required
The ideal candidate will have fluency in programming, but also analytical skills since they will be working and exchanging ideas with data scientists

Ready to join our team? Apply today!

#ChiefDataOffice

JobCategory:Technology
Show more Show less"
2789398881,Data Engineer,WeWork,2021-10-16,United States,"New York, NY","Information Technology, Product Management, and Engineering",Full-time,"Computer Software, Computer Networking Products, and Computer and Network Security","About Us

At WeWork, we provide inspiring and flexible workplace solutions to help businesses - small, medium or large - thrive in more than 150 cities globally. The future of work is happening right now, and we are leading this moment. United by a common purpose, here we will empower tomorrow’s world at work. Join us on our journey as we give our members the freedom and support to push boundaries in their industries, and work to redefine our own.

About The Opportunity

At WeWork, data sits in the center of our business, providing insights into the effectiveness of our physical and digital product & features. We believe data brings everything together and it is the only way we make decisions.

Data Engineering is a team constantly striving to create an amazing experience for our customers and internal teams. We regard culture and trust highly and believe you will have a positive influence in your own way as a data engineer.

Who You Are

You're a data engineer with extensive experience designing, implementing data solutions for various business challenges, and leading database and data warehousing initiatives.


You’re excited to solve data challenges that combines digital and physical aspects, across multiple business verticals like Real Estate, Finance, Sales & Marketing, Social Media, and regions
You're motivated to enable and collaborate with engineering, analytics and product teams to tackle the most challenging business needs


What You Will Do

As a Data Engineer at WeWork, You will be a part of a central team and work with passionate leaders on highly impactful business challenges.


Leverage data expertise to help build and evolve data models in various components of the data stack
Work on architecting, building, and launching highly scalable and reliable data pipelines to support WeWork
Collaborate closely with data engineers, analysts,data scientists, ML Engineers, as well as cross-functional teams, to leverage huge amounts of WeWork data, for data-driven business and user behavior insights
Collaborate on improving efficiency and quality of internal data processes as well as stakeholder engagement, including implementation of system and model quality tracking
Develop centralized source of truth data sets to encourage a democratized, data-driven culture
Develop tools supporting self-service data pipeline management (ETL)


Requirements


Strong communication skills, empathy and initiative
2+ years of experience in data engineering
Strong background in data warehouse concept and design
Proficient in at least one of the SQL dialects (Snowflake, MySQL, PostgreSQL, SqlServer, Oracle)
Good understanding of SQL Engine and able to conduct advanced performance tuning
Familiar with at least one scripting language (Python, Ruby, Perl, Bash)
Experience with Git and the pull request workflow
Experience working closely with Analytics/Data Science teams
Experience with modern BI tools (Looker, Tableau, etc)
Experience working with Salesforce data (extra points for experience with Revenue Cloud)


Life At WeWork

Being a WeWorker is more than just a job. We believe the magic of work is sparked by the passion you bring, the places you go, the people you meet and the purpose you follow. And it starts here. Here you will brush shoulders with those who dare to dream and do. Here you will be welcomed by a diverse community that embraces and inspires you—because together we can achieve more. Here we challenge ideas, and explore new ways of getting things done. Whether you are part of our Employee Community Groups, or part of a global project, we ask you to bring your open-minded attitude and collaborative spirit. In return, you will be part of a team where your unique perspectives are celebrated.

WeWork is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon gender, sexual orientation, marital or civil status, pregnancy (or pregnancy-related conditions), gender identity or expression, transgender status or gender reassignment, race, color, national origin or ancestry, citizenship, religion or religious beliefs, age, physical or mental disability, genetic information (including genetic testing and characteristics), military or veteran status, or any other grounds or characteristic that is protected under the law.

As part of our commitment to health and safety, WeWork -- like a growing number of employers -- is requiring all U.S. employees to be fully vaccinated for COVID-19 as a condition of employment, absent a legal exception for reasonable accommodation. We provide unvaccinated new hires a 45-day grace period after their start date to get fully vaccinated or, if eligible, obtain a reasonable accommodation. If you believe that a legal exception may apply to you, please still apply for any role(s) you are interested in and, if you are hired, you will receive instructions on how to request a reasonable accommodation after your start date. Please note that roles that require in-person work -- currently, within our Community (excluding Member Experience), Facilities Management (including Security), Sales (excluding Sales Ops), and Member Technology teams -- will not be eligible for work-from-home as an accommodation because it poses an undue hardship on our business.
Show more Show less"
2813573681,"Engineer, Data",T-Mobile,2021-11-05,United States,"Bellevue, WA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Job Description

T-Mobile High-Speed Internet is redefining what it means to be an ISP, standing up for both Consumers and Businesses. We believe that this starts with bringing a world class experience to all customers. T-Mobile is competing in urban areas because we think you deserve a better choice and reaching out to areas that have previously been ignored. The HSI team is a fast-moving team of architects and data engineers; that build, run, and operate back-end and reporting data operations to support customer acquisition and analysis. As a data engineer on this team, you will play a key role in designing and implementing data solutions to meet business needs and ensure our pipelines become more performant, scalable and reliable. This is a fast-growing team, with endless opportunities for learning and growth – you’ll have our support along the way.


Functional Group

Emerging Products


Location

WA108-WA-Bellevue Building 12 Office


Location Address

3076 160th Ave SE


City

Bellevue


State

Washington


Zip

98006


Travel Required?

No


Responsibilities


Gather and understand business requirements for data strategy and architecture
Act as a subject matter expert for feature implementations, including pipeline development, management, and delivery across multiple work streams
Develop and implement scalable ETL processes and architecture for critical business systems
Automate and drive scalable solutions, implement data pipelines to support dynamic business needs
Collaborate with other business teams to support data strategy and business roadmaps
Design and optimize validation frameworks and data monitoring to ensure data quality and reliable data systems


Qualifications


BS in Computer Science/Engineering or Engineering or similar degree
At least 2 years of professional experience using an applicable programming language and common data technologies (such as SQL, NoSQL, Spark, Python, Tableau and Power BI)
At least 2 years of experience working with big data processes including ETL/data pipelines, processing, storage, and governance
Experience with AWS big data technologies– Redshift, S3, Lambda, Step Functions, EMR
Excellent problem-solving skills and data engineering habits, including peer-coding, documentation, quality testing, etc


Minimum Qualifications


At least 18 years of age
Legally authorized to work in the United States
High School Diploma or GED
T-Mobile requires all employees in this position to be fully vaccinated for COVID-19 prior to starting work. The CDC defines ""fully vaccinated"" as two weeks after the second dose for Pfizer and Moderna, and two weeks after the single dose of Johnson & Johnson. T-Mobile will require proof of vaccination and consider requests for exemption from this requirement during the offer phase as a reasonable accommodation for medical reasons or sincerely held religious beliefs where the accommodation would not cause T-Mobile undue hardship or pose a direct threat to the health and safety of others.


Company Profile

T-Mobile U.S. Inc. (NASDAQ: TMUS) is America’s supercharged Un-carrier, delivering an advanced 4G LTE and transformative nationwide 5G network that will offer reliable connectivity for all. T-Mobile’s customers benefit from its unmatched combination of value and quality, unwavering obsession with offering them the best possible service experience and undisputable drive for disruption that creates competition and innovation in wireless and beyond. Based in Bellevue, Wash., T-Mobile provides services through its subsidiaries and operates its flagship brands, T-Mobile, Metro by T-Mobile and Sprint. For more information please visit: http://www.t-mobile.com

Applicant Privacy Policy

We are committed to maintaining your trust by respecting and protecting your privacy. For more information about how T-Mobile processes the personal data of job applicants, please visit Applicant Privacy Policy .


EOE Statement


Equal Employment Opportunity

We take equal opportunity seriously—by choice.

T-Mobile USA, Inc. is an Equal Opportunity Employer. All decisions concerning the employment relationship will be made without regard to age, race, ethnicity, color, religion, creed, sex, sexual orientation, gender identity or expression, national origin, religious affiliation, marital status, citizenship status, veteran status, the presence of any physical or mental disability, or any other status or characteristic protected by federal, state, or local law. Discrimination, retaliation or harassment based upon any of these factors is wholly inconsistent with how we do business and will not be tolerated.


Positions Remaining

1


Brand

T-Mobile


Schedule

Full Time


Show more Show less"
2815527968,Data Engineer,Massachusetts Institute of Technology,2021-11-02,United States,"Cambridge, MA",Information Technology,Full-time,"Non-profit Organizations, Internet Publishing, and Insurance","Working at MIT offers opportunities, an environment, a culture – and benefits – that just aren’t found together anywhere else. If you’re curious, motivated, want to be part of a unique community, and help shape the future – then take a look at this opportunity.

Information on MIT’s COVID-19 vaccination requirement can be found at the bottom of this posting.
Show more Show less"
2825177420,Senior-Big Data Engineer,AT&T,2021-12-02,United States,"New Jersey, United States",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Wireless Services, and Telecommunications","Join AT&T and reimagine the communications and technologies that connect the world. We’re committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won’t just imagine the future – you’ll create it.

The Big Data Engineer will be responsible for interpreting the requirements of various Big Data Analytic Use Cases and Scenarios, and driving the design and implementation of specific data models to ultimately help drive better business decisions through insights from a combination of external and AT&Ts data assets. This is someone who is also motivated by their ongoing learning and willingness to pursue and complete professional .certifications on a continuing basis – and can use time management skills to balance learning with project related needs.

Key Roles and Responsibilities

Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the Big Data Environment.
Support the standardization, customization and ad-hoc data analysis, and will develop the mechanisms to ingest, analyze, validate, normalize and clean data.
Implements statistical data quality procedures on new data sources, and by applying rigorous iterative data analytics, supports Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value.
Will work with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data.
Develop and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods and techniques.

Qualifications

Preferred Bachelors of Science in Computer Science, Math or Scientific Computing preferred.
Typically requires 5-8 years experience.
Python, Azure or AWS, Data wrangling and Data pipeline design required
The ideal candidate will have fluency in programming, but also analytical skills since they will be working and exchanging ideas with data scientists

Ready to join our team? Apply today!

#ChiefDataOffice

JobCategory:Technology
Show more Show less"
2794618164,Big Data Engineer,Mindtree,2021-11-16,United States,"Las Vegas, NV",Engineering and Information Technology,Full-time,IT Services and IT Consulting,"Mindtree is looking for Data Engineer for its project in Las Vegas Area, Who is expert in Hadoop, Querying NoSQL Database, Data Insight




This role is an experienced Development Data Engineer that will assist in designing developing and deploying data driven solutions as part of a strategic data transformation effort The candidate will join a team of Data Architects and Engineers who will be responsible for optimizing and transforming our data architecture infrastructure operations and related functions This team will work with developers architects business data analysts and data scientists on data initiatives and will ensure optimal data solutions Summary Essential Job Functions Leverage modern data management toolsets and coding methods to design build implement and optimize data solutions of all types including support for OLTP and API Microservices data warehouses data lakes ODS streaming data analytic and BI visualizations etc Transform legacy data structures and processes to modern capable and secure solutions in a hybrid cloud setup Position Requirements 3 years of experience in data engineering development and operations roles including experience with transformational efforts Strong Database skills with RDBMS E g Oracle SQL as well as modern relational and unstruct ured data sources like NoSQL including cloud services AWS GCP Azure Hands on experience using tools is strongly preferred Experience with Tools or similar such as Hadoop Stack Airflow Kafka NiFi PostgreSQL Oracle SQL Server ElasticSe arch ELK JSON Parquet Avro and other Data Storage formats Tableau Superset and other Visualization Tools Apache Atlas and other Data centric Apache Packages Knowledge of Design Patterns for Software and Data Engineering Experience Codingwi th Java Javascript Nodejs Python GO Rust and similar Experience in on prem and hybrid cloud infrastructure including service and cost optimization Experience with production and analytics data batch and real time streaming etc .




Job Requirements: Hadoop, Querying NoSQL Database, Data Insight

Show more Show less"
2822347079,Big Data Engineer,Robert Half,2021-12-01,United States,"Chicago, IL ",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Description

Data Engineer

Robert Half Technology is looking for a data engineer who actively looks to find the creative solution to a problem.

What you get to do every single day

Leads, grows and develops a team of data engineers that writes, deploys and maintains software to build, integrate, manage, maintain, and quality-assure data at bp.
Creates positive engagement and drives an inclusive work environment with team and partners through the quality of interactions and collaboration across multiple business entities.
Effectively works with cross-disciplinary collaborators and partners across multiple business entities.
Architects and designs reliable and scalable data infrastructure.
Advocates for and ensures their team adheres to software engineering standard methodologies (e.g. technical design, technical design review, unit testing, monitoring & alerting, checking in code, code review, documentation),
Responsible for deploying secure and well-tested software that meets privacy and compliance requirements.
Responsible for service reliability and following site-reliability engineering standard methodologies: on-call rotations for services they oversee, responsible for defining and maintaining SLAs.
Actively contributes to improve developer velocity.
Actively mentors others.

What you bring to the role

Experience (typically 2+ years) leading, growing and developing a data engineering team of around 7-30 people
Deep and hands-on experience (typically 5+ years) designing, planning, productionizing, maintaining and documenting reliable and scalable data infrastructure and data products in complex environments
Development experience in one or more object-oriented programming languages (e.g. Python, Go, Java, C++)

About Robert Half Technology

Technology doesn't change the world. People do.

As a technology staffing firm, we can't think of a more fitting mantra. We're extreme believers in technology and the incredible things it can do. But we know that behind every smart piece of software, every powerful processor, and every brilliant line of code is an even more brilliant person.

Leader among IT staffing agencies

The intersection of technology and people — it's where we live. Backed by more than 65 years of experience, Robert Half Technology is a leader among IT staffing agencies. Whether you're looking to hire experienced technology talent or find the best technology jobs, we are your IT expert to call.

We understand not only the art of matching people, but also the science of technology. We use a proprietary matching tool that helps our staffing professionals connect just the right person to just the right job. And our network of industry connections and strategic partners remains unmatched.

It's a simple but powerful truth. Innovation starts with people, and people start with us.

© 2019 Robert Half Technology. An Equal Opportunity Employer M/F/Disability/Veterans.

Requirements

Python, Amazon Web Services (AWS), API Development

Technology Doesn't Change the World, People Do.®

Robert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.

Robert Half puts you in the best position to succeed by advocating on your behalf and promoting you to employers. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity – even on the go. Download the Robert Half app and get 1-tap apply, instant notifications for AI-matched jobs, and more.

Questions? Call your local office at 1.888.490.4429. All applicants applying for U.S. job openings must be legally authorized to work in the United States. Benefits are available to contract/temporary professionals. Visit

© 2021 Robert Half. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to
Show more Show less"
2796272380,Big Data Engineer,Braintrust,2021-10-21,United States,"San Francisco, CA",Engineering and Information Technology,Full-time,Internet Publishing,"JOB TYPE: Freelance, Contract Position - No agencies (See notes below)


LOCATION: Remote (TimeZone: BST, CST, EST)


HOURLY RANGE: Our client is looking to pay $100 - $123 USD / HR


ESTIMATED DURATION: 40Hrs/Week - Long Term, 6-month project


HIGH-LEVEL QUALIFICATIONS:


•


ABOUT US:


Braintrust (usebraintrust.com) is a user-controlled talent network, where you keep 100% of what you earn and actually get to own the platform. We've been onboarding some big clients and specifically need a Big Data Engineer for our client.


About our client:


We own and develop targeting products. We are responsible for bringing world-class targeting solutions to our advertisers. We succeed only when our customers can reach their intended audience. Our work includes iterating on the architecture, technology, design patterns, and workflows for products that enable our advertisers to target Twitter users.


Come build the next generation of products that empower marketers to tell the most interesting, relevant stories in the world, and make a meaningful contribution to an iconic company.


Who You Are:


You are excited to join an incredibly talented and enthusiastic team, which loves to tackle new challenges. You like a dynamic & fun environment, believe in our client's mission in the world, and want to be a core actor in pushing it forward.


If you are an analytical thinker who enjoys complex math problems and algorithm design we would like to talk with you. We look forward to working with people who share our passion for good engineering fundamentals and making decisions grounded in data. We sweat the details.


What You’ll Do:


You will take up the task of allowing Twitter’s largest advertisers to plan their campaigns with confidence on one side and will be working with our science team on defining the best audience for our clients. You’ll collaborate with data scientists, digging into massive datasets in order to discover insights that can improve the quality of our forecasts. You’ll develop the algorithms in our online forecasting service, turning those insights into working code. You’ll enhance our data pipelines, marshalling and optimizing the information we need to answer queries. And you’ll own a significant product surface at Twitter, caring about operational quality and the metrics that illustrate that we’re helping our customers be successful.


We’d like to talk to you if:


• 3+ years industry experience working with confidence on a massive scale, microservice-based tech stack that (required) Scala, Hadoop, Google Cloud technology, especially dataflow, and Aurora/Mesos.

• You have a track record of implementing simple, elegant solutions / great products across complex distributed systems.

• You’ve demonstrated an ability to excel in whatever you pursue (whether it's work, school, competitions, open source contributions, personal projects, etc.—you've always stood out and succeeded)

• You have experience with a diverse range of frameworks/technologies, whether through work or side projects, with special interest in batch or streaming data processing technologies.


Requirements:


• You have a sound grasp on OOP concepts, data structures and algorithms.

• You have a disciplined approach to writing unit and integration tests.

• MUST have working knowledge of Scala

• MUST have experience with Dataflow, Hadoop or other MapReduce-based architectures

• Experience with Redis, Memcached, MySQL or other key value stores

• You easily articulate complex concepts in writing and speech.

• BS, MS, or PhD in Computer Science


ABOUT THE HIRING PROCESS:


Qualified candidates will be invited to do a screening interview with the Braintrust staff. We will answer your questions about the project, and our platform. If we determine it is the right fit for both parties, we'll invite you to join the platform and create a profile to apply directly for this project.


C2C Candidates: This role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.


Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.
Show more Show less"
2825316375,Data Engineer,Bill.com,2021-12-03,United States,"San Jose, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","About Bill.com

Bill.com , together with its wholly owned subsidiaries Divvy and Invoice2go, is focused on being the one stop shop that simplifies, digitizes, and automates complex financial operations for small and midsize businesses. Customers use the platform to manage end-to-end financial workflows and to process payments. The AI-enabled, financial software platform creates connections between businesses and their suppliers and clients. It helps manage cash inflows and outflow. The company partners with several of the largest U.S. financial institutions, the majority of the top 100 U.S. accounting firms, and popular accounting software providers. Bill.com has its headquarters in San Jose, California with offices in Houston, Texas, Draper, Utah, and Sydney, Australia.

Mission

Our team’s mission is to build a world-class platform for data analytics and machine learning to fuel existing and new business critical initiatives. As a member of our team you would be designing and scaling our platform, tackling big data challenges and working closely with other teams in deriving insights from data. Come and join our team to take our company’s data architecture to the next level.

Responsibilities

Collaborate with architects, data scientists, analysts and product managers to understand their data requirements and translate them into design.
Build scalable frameworks required to support data science, analytics, streaming pipelines.
Own the data quality, efficiency and automation of data pipelines.
Partner with different teams within the company to drive data driven business goals.

Professional Experience/Background To Be Successful In This Role

Bachelor’s degree in Computer Science, Engineering or related discipline.
2+ years of industry experience working with distributed data technologies (e.g. Apache Spark, Flink, Kinesis, Kafka etc.).
Proficiency in SQL and one high-level programming language (Python, Scala, Java or equivalent) is required.
Experience developing batch and real time data processing frameworks is required.
Experience in AWS is highly preferred.
Experience in Redshift, Snowflake, Airflow, DBT etc. is a plus.

Competencies (Attributes Needed To Be Successful In This Role)

Problem Solving - Seek out challenging problems to solve.
Values - Be honest, fun, dedicated, passionate and authentic.
Quick Learner - Be curious and have an appetite for learning.
Communication - Excellent verbal and written communication skills.
Team Player - Collaborate with and help other team members.

Expected Outcomes In 12 Months

Learn the Bill.com product, business domain and data platform technology stack within Bill.com
Bring in industry standard best practices and evolve our technology footprint.
Develop the data ingestion & processing pipelines for Data Science, Analytics and Machine Learning teams.
Improve existing framework, research newer technology stacks and architecture.
Own and improve the data quality of pipelines.

Bill.com is committed to a policy of equal employment opportunity. We recruit, employ, train, compensate, and promote without regard to race, color, age, sex, ancestry, marital status, religion, national origin, disability, sexual orientation, veteran status, present or past history of mental disability, genetic information or any other classification protected by state or federal law.

Bill.com Culture

Humble – No ego
Fun – Celebrate the moments
Authentic – We are who we are
Passionate – Love what you do
Dedicated – To each other and the customer

Our Applicant Privacy Notice describes how Bill.com treats the personal information it receives from applicants.
Show more Show less"
2822801857,Big Data Engineer,Cognizant,2021-12-02,United States,"Foster City, CA",Engineering and Information Technology,Full-time,IT Services and IT Consulting,"Role: BigData Engineer

Cognizant (NASDAQ: CTSH) is a leading provider of information technology, consulting, and business process outsourcing services, dedicated to helping the world's leading companies build stronger businesses. Headquartered in Teaneck, New Jersey (U.S.). Cognizant is a member of the NASDAQ-100, the S&P 500, the Forbes Global 1000, and the Fortune 500 and we are among the top performing and fastest growing companies in the world.

*Please note, this role is not able to offer visa transfer or sponsorship now or in the future*

Practice - AIA - Artificial Intelligence and Analytics

About AI & Analytics: Artificial intelligence (AI) and the data it collects and analyzes will soon sit at the core of all intelligent, human-centric businesses. By decoding customer needs, preferences, and behaviors, our clients can understand exactly what services, products, and experiences their consumers need. Within AI & Analytics, we work to design the future—a future in which trial-and-error business decisions have been replaced by informed choices and data-supported strategies.

By applying AI and data science, we help leading companies to prototype, refine, validate, and scale their AI and analytics products and delivery models. Cognizant’s AIA practice takes insights that are buried in data, and provides businesses a clear way to transform how they source, interpret and consume their information. Our clients need flexible data structures and a streamlined data architecture that quickly turns data resources into informative, meaningful intelligence.

Responsibilities :

Essential Functions Person will be responsible to Perform Big Data Platform Administration and Engineering activities on multiple Hadoop, Kafka, Hbase and Spark clusters
Work on Performance Tuning and Increase Operational efficiency on a continuous basis
Monitor health of the platforms and Generate Performance Reports and Monitor and provide continuous improvements
Working closely with development, engineering and operation teams, jointly work on key deliverables ensuring production scalability and stability
Develop and enhance platform best practices
Ensure the Hadoop platform can effectively meet performance & SLA requirements
Responsible for Big Data Production environment which includes Hadoop (HDFS and YARN), Hive, Spark, Livy, SOLR, Oozie, Kafka, Airflow,Nifi, Hbase etc
Perform optimization, debugging and capacity planning of a Big Data cluster
Perform security remediation, automation and self heal as per the requirement
Basic Qualifications
2 years of work experience with a Bachelor’s Degree or an Advanced Degree
Hands-on Experience in Hadoop Admin, Hive, Spark, Kafka is must.
Preferred Qualifications
Minimum 3 years of work experience in maintaining, optimization, issue resolution of Big Data large scale clusters, supporting Business users and Batch process.
Hands-on Experience
No SQL Databases HBASE is plus
Prior Experience in Linux / Unix OS Services, Administration, Shell, awk scripting is a plus
Excellent oral and written communication and presentation skills, analytical skills, and problem-solving skills
Self-driven, Ability to work independently and as part of a team with proven track record
Experience on Hortonworks distribution or Open Source preferred

EDUCATION, CERTIFICATION, TRAINING: Minimum bachelor’s degree or equivalent to bachelor’s in computer science | required




Cognizant is an Equal Opportunity Employer M/F/D/V. Cognizant is committed to ensuring that all current and prospective associates are afforded equal opportunities and treatment and a work environment free of harassment.

Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.

Show more Show less"
2806955924,Big Data Engineer,Peterson Technology Partners,2021-11-24,United States,United States,Information Technology,Full-time,Staffing and Recruiting,"Fantastic opportunity for a Big Data Engineer!




Our Chicago-based client is seeking a Big Data Engineer to join a close-knit, passionate team that collaborates in an agile environment to develop great technology.




Please submit your resume with the link to your LinkedIn Profile.




Must have qualifications:

Scala, Spark, Hive, Hadoop & spark Architecture and its components such as HDFS, Job Tracker, Task Tracker, executor cores and memory params.
Hadoop development, SPARK, SCALA and Database exposure
Spark and Spark Streaming creating RDD’s, applying operations -Transformation and Actions.
Code optimize to fine tune the applications.
Develop Shell scripts to orchestrate execution of all other scripts and move the data files within and outside of HDFS.
Develop scripts for doing transformations using Scala.
Configure Spark Streaming to receive real time data from the Apache Kafka and store the stream data to HDFS using Spark-Scala.
Analyze large amounts of data set to determine optimal way to aggregate and report on it.
Strong database, SQL, ETL and data analysis skills.
Integration with Hadoop/HDFS, Real-Time Systems, Data Warehouses, and Analytics solutions. Experience in Data Warehousing and ETL processes.
Experienced with streaming work flow operations.
Experience with developing large-scale distributed applications and developing solutions to analyze large data sets efficiently




Good to have (Knowledge)

Experience with GIT, Jenkins, test frameworks is good to have
Good understanding of Agile development methodology.
Create the required technical tasks in backlog and update status regularly.
Using Kafka on publish-subscribe messaging as a distributed commit log, have experienced in its fast, scalable and durability.




Peterson Technology Partners (PTP) is an Equal Opportunity Employer that is committed to diversity and inclusion in the workforce.




About the Company:

Peterson Technology Partners (PTP) has been Chicago's premier Information Technology (IT) staffing, consulting, and recruiting firm for over 23+ years. Named after Chicago's historic Peterson Avenue, PTP has built its reputation by developing lasting relationships, leading digital transformation, and inspiring technical innovation throughout Chicagoland.




Based in Park Ridge, IL, PTP's 250+ employees have a narrow focus on a single market (Chicago) and expertise in 4 innovative technical areas;

· Cybersecurity

· Artificial Intelligence

· Data Science

· Cloud & DevOps




PTP exists to ensure that all of our partners (clients and candidates alike) make the best hiring and career decisions.

Show more Show less"
2821502627,Data Engineer,Sia Partners,2021-12-03,United States,"Palo Alto, CA",Consulting,Full-time,Management Consulting,"Sia Partners is looking for a talented Data Engineer to support our activities within the Data Science Business Unit. You will be working alongside with our Data Science consultants and our clients on Data Engineering topics, including creating relevant data models, developing powerful data pipelines, exposing them through various mechanisms including APIs, and using data visualization tools to efficiently present data.



You will also contribute to internal Data Science projects posted on Heka, our internal accelerator for Data Science projects. As part of the global Data Science team you will contribute to the development of various solutions designed to address our clients' needs.



Key Responsibilities 



Partner with our client’s leadership teams, engineers, program managers and data analysts to understand data needs.
Design, build and launch efficient and reliable data pipelines transforming data into useful report ready datasets.
Communicate at scale, through multiple mediums: presentations, dashboards, client-wide datasets, bots and more.
Use your data and analytics experience to ‘see what’s missing,’ identifying and addressing data gaps, build monitors to detect data quality issues and partner to establish a self-serve environment.
Broad range of partners equates to a broad range of projects and deliverables, including ML Models, datasets, measurements, services, tools and process.
Leverage data and business principles to automate data flow, detect business exceptions, build diagnostic capabilities, and improve both business and data knowledge base.
Build data expertise and own data quality for your areas.


Qualifications


At least 4+ years' of advanced SQL experience (including at least one SQL DBMS and one noSQL).
4+ years' of Python development experience.
3+ years' of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).
3+ years' experience with Data Modeling.
Experience analyzing data to discover opportunities and address gaps.
4+ years' experience in custom ETL design, implementation and maintenance.
Experience working with cloud or on-prem Big Data/MPP analytics platform (i.e. SnowFlake, Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).
BSc/BA in Data Science, Computer Science, Engineering.

Preferred Experience with:



Experience with more than one coding language.
Knowledge of Docker, CI/CD pipelines, and Kubernetes.
Experience in designing and implementing real-time pipelines.
Experience with data quality and validation.
Experience with SQL performance tuning and e2e process optimization.
Experience with anomaly/outlier detection.
Experience with notebook-based Data Science workflow.
Experience querying massive datasets, using Spark, Presto, Hive, Impala, etc.

This is an opportunity to join a rapidly growing team that serves some of the most exciting and highly respected companies in the world. You will have the opportunity to provide clients with original thinking and customized solutions and you’ll often have the satisfaction of seeing the impact of your work on their business. We are committed to a healthy work-life integration. 



Benefits



Generous PTO, including Parental leave
Healthcare that includes dental and vision, life insurance and 401K matching                                        
Career advocacy program that supports achieving personal development goals through coaching, collaboration and real-time feedback
Robust learning and development platform through the Sia Institute, 360 Learning App, Sia Blend App, working groups, US Training Sessions, and reimbursement for continuing education and certifications
Women at Sia Club
Annual Seminar/a value add experience to network with your colleagues across North America and other regions
Opportunities for geographic mobility if desired
Work directly with clients

Still Interested? Tell Us About Your…  



Academic successes
Consulting / Agency experience
Data supported success stories
Growth from failure
Tools and training
Cross-functional experience
Extracurriculars

Please note that Sia Partners requires all individuals in this position to be fully vaccinated against COVID-19.  “Fully vaccinated” means that the individual can provide acceptable proof that the individual has received, at least fourteen (14) days prior to the individual’s start date, either the second dose of a two-dose COVID-19 vaccine, or one dose of a single-dose COVID-19 vaccine.  Vaccines must be authorized and/or approved by the FDA.  Individuals needing an exemption to this requirement due to medical, disability-related, or religious reasons may request an exemption.  The Company will engage in an interactive process to determine if an exemption to this requirement as a reasonable accommodation is appropriate.





Additional Information



Diversity, equity, inclusion, and belonging (DEIB) are part of Sia Partners’ DNA. Thanks to our expertise in several sectors and our international growth, our teams include a variety of experiences and cultures. We’re confident that promoting DEIB creates an environment in which everyone can reach their full potential. 



Our global network, DEIB@Sia Partners, brings together our people worldwide to facilitate local and global progress, focused on the following areas:



Gender equality (global Gender Equality Index score of 91/100 for FY19-20)
LGBTQ+
Race & Ethnicity
Working Parents 
Disabilities

We are an equal opportunity employer that values collective diversity, equity, inclusion and belonging. Our goal is to develop a work environment where everyone feels safe to be their authentic self and valued as part of the Sia Village.



All your information will be kept confidential according to EEO guidelines.



*Candidates must be located within commute distance of one of our three West Coast offices, San Francisco, Seattle and Denver. 



Sia Partners is an equal opportunity employer. All aspects of employment, including hiring, promotion, remuneration, or discipline, are based solely on performance, competence, conduct, or business needs. 



Show more Show less"
2790223797,Data Engineer,BallerTV,2021-10-14,United States,"Los Angeles, CA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Job Title: Data Engineer

Classification: Exempt

Reports to: CTO

Location: Remote work available

Our Story

BallerTV is a venture-backed startup building the world's largest sports network from the ground up. In 2021, BallerTV live streamed over 300,000 youth basketball, volleyball, soccer and lacrosse games, powered by groundbreaking autonomous video capture and logistics technology. Similar to the early days of ESPN, BallerTV is rapidly expanding the spectrum of sports coverage and changing the landscape of sports broadcasting.

Why BallerTV?

Competitive Salary
Generous Equity stock options
Medical, Dental, and Vision Insurance
401k Plan
Unlimited Vacation
Immediate impact on the growth of the business


Job Summary

This position will take the data infrastructure that powers our autonomous technology to the next level. BallerTV is building the world’s largest content platform for sports, and within that, our team solves problems enabling automated capture & statistics for basketball, volleyball & soccer. We’re rapidly adding capture and analytics capabilities for new sports as we continue to dominate the youth sports landscape and we need a robust data infrastructure that powers it all.

Essential Functions

Designing, building and maintaining our data infrastructure
Improve the quality and reliability of our data pipelines through monitoring, version control & validation
Automate manual processes and create a platform in favor of self-service data consumption


Basic Qualifications

Qualifications include:

B.S. / B.A. in marketing, or other related field
5+ years of experience in data engineering or other related field
Experience with ML Ops & Data Engineering at some scale
Experience with Distributed Data Processing, Modeling & Warehousing
Experience with Python & SQL


Supervisory Responsibility

This position has no supervisory responsibilities

Working Conditions

This position spends most of her/his time sitting or standing in an office or facility


Travel Requirements

This position requires no travel


Other Duties

Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.

Work Authorization/Security Clearance

There is no visa or H-1B sponsorship.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.

Powered by JazzHR

3UT0MEjMqQ
Show more Show less"
2817654653,Entry Level Big Data Software Engineer,John Deere,2021-11-03,United States,"Chicago, IL",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Staffing and Recruiting, and Human Resources","At John Deere, we run so life can leap forward. This powerful purpose is our promise to humankind that we will dream, design and deliver breakthrough products that sustain our world for generations to come. The world is counting on us to feed billions of people and build vital infrastructures in villages, towns, and megacities. We live up to the legacy our founder forged in a one-room blacksmith's shop nearly two centuries ago by creating a culture that brings out the best in all of us. A culture where great ideas thrive because every voice is heard.

Primary Location: United States (US) - Illinois - Chicago

Function: Information Technology

Title: Entry Level Big Data Software Engineer - 78590

Onsite/Remote: Onsite Position

Your Responsibilities

As an Entry Level Big Data Software Engineer , for John Deere in either Chicago, IL, or Moline, IL., you will provide tangible expertise on big data and streaming technologies in the cloud, and how to leverage these to create a Scalable Data & Analytics solutions. You will work with very large data sets including data from internal sources as well as IoT streams from connected vehicles. In addition, you will:

Develop new functionality/code for high-volume data processes; e .g. a machine learning pipeline for preventative maintenance.
Monitor and support day to day ETL processes loading & transforming large data volumes
Participate in discussions/decisions regarding future engineering direction; as well as evaluation, prioritization and elimination of technical debt
Provide input to business and IT for existing and future solutions in support of Deere's Data & Analytics programs
Develop and enhance data quality for large scale analytic data environments
Provide expertise to resolve critical, complex technical issues around Big Data and Analytic technology
Act as an escalation point and resolution provider for defects/outages as well as design/engineering issues
Develop and maintain strategic relationships with existing source data teams, Data and Analytic platform teams, business analytics teams

What Skills You Need

Poven technical skills and experiences with data engineering and warehousing
1-2+ years of experience in Data Engineering, ETL, Data Warehousing or other data movement applications
1-2+ years of experience in the design, development, testing and integration of high complex software utilizing Java, Scala, Node, or Python
1 or more years of proven experience in an Agile/Scrum team environment
1 or more years of technical experience in multiple Data Warehouse systems or Data Lake technology, with demonstrated success in managing and administering Big Data Technologies such as Hadoop, SPARK, HANA, Redshift, AWS S3

What Makes You Stand Out

1 or more years of experience in cloud development with platforms like AWS or Azure
Experience with CAN, Agronomic, or Telematics Data.
Experience working with streaming or micro batching large datasets from IOT devices.
Advanced Technical Degree/Masters in CS and/or Data Analytics

Education

Ideally you will have a degree or equivalent related work experience in the following:

Bachelor's degree in IT, Computer Science, Computer Engineering, or equivalent experience in a related career field

What You'll Get

At John Deere, you are empowered to create a career that will take you to where you want to go. Here, you'll enjoy the freedom to explore new projects, the support to think outside the box and the advanced tools and technology that foster innovation and achievement. We offer comprehensive relocation and reward packages to help you get started on your new career path. Click here to find out more about our Total Rewards Package.

The information contained herein is not intended to be an exhaustive list of all responsibilities and qualifications required of individuals performing the job. The qualifications detailed in this job description are not considered the minimum requirements necessary to perform the job, but rather as guidelines.

An Equal Opportunity Employer, John Deere requires a diversity of people, perspectives and ideas to address the complex challenges of its global business. John Deere is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to, among other things, race, religion, color, national origin, sex, age, sexual orientation, gender identity, status as a protected veteran, or status as a qualified individual with disability.
Show more Show less"
2791843381,Data Engineer,IBM,2021-11-12,United States,"Austin, TX",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2817787577,Remote Big Data Engineer (Redshift & Databricks),Asurion,2021-12-01,United States,"Nashville, TN",Information Technology,Full-time,IT Services and IT Consulting,"Do you have a passion for driving business results through technology enabled solutions? Do you possess the magical ability to speak both tech and operations? Are you passionate about data and software engineering? If so, we should talk!




We are technology experts who build and deliver high-quality and innovative solutions that help our clients to be successful and change the way people interact with Asurion data. Your job will be to build analytical capabilities through data management principles to drive growth, efficiencies, and automation. Your passion for technology, attention to detail, and love of data will keep those initiatives on track and ensure that the systems are accurate and stable. Your drive to broaden your own exposure to other functions and influence thinking will be key to your success. This position works with key stakeholders to help drive improvements throughout Enterprise Data Services in partnership with other product, business, and analytics teams.




Primary Responsibilities:

Utilize technical and industry knowledge to drive multiple data projects across different analytics platforms & data domains
Identify, analyze, evaluate, and develop data products
Design and build the data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of sources using SQL and AWS ‘big data’ technologies
Collaborate with cross-functional teams and leadership to identify and evaluate opportunities, issues, and trends to drive results throughout the organization
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Create data tools for analytics and data scientist team members to help drive decisions across business
Partner with analysts leveraging engineering skill and data knowledge to provide input on feasibility of requirements
Responsible for the accuracy, completeness, timeliness, and validity of all data
Formulates, implements, and enforces proper data collection policies and procedures
Assists with troubleshooting and driving quality and stability of our production solutions
Acts as a mentor to lead peers in a project and present outcomes to management




Requirements:

Strong sense of drive, ability to solve problems, and think analytically
Strong attention to detail with through knowledge of SDLC concepts and overall software engineering process.
Strong organizational skills, self-motivated, able to multi-task, and meet deadlines
Strong understanding of SQL concepts such as stored procedures, query optimization, performance tuning, execution plans, etc.
Able to design, model, and deliver data products to meet business need
Strong understanding of Big Data core concepts and how to manipulate data on a cloud infrastructure (e.g. AWS, Azure)
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Ability to maintain high quality technical documentation and partner with team to develop standards
Able to establish and maintain effective working relationships with the business community, vendors, customers, and team members
Must maintain a high sense of ownership and be able to work with a direction instead of being task oriented
Familiarity with reporting and visualization tools is a plus.




Experience:

• 3+ years of experience in a Data Engineer role

Experience with the following tools preferred:

Relational SQL and NoSQL databases, including Redshift, Aurora, and DynamoDB
Object-oriented/object function scripting languages: Python, Go, Java, C++, Scala, etc.
Big data tools: Hadoop, Spark, Kafka, Presto etc.
AWS cloud services: EC2, EMR, RDS
Jenkins, Bamboo, or other CI tools




Education:

• Bachelor’s degree in Computer Science, Information Systems, Engineering, Mathematics, or related field
Show more Show less"
2785700089,*Big Data Engineer,Citi,2021-10-10,United States,"Irving, TX",Engineering and Information Technology,Full-time,"Banking, Financial Services, and Investment Banking","Job Id: 20229194

The Data Analytics Senior Analyst is a seasoned professional role. Applies in-depth disciplinary knowledge, contributing to the development of new techniques and the improvement of processes and work-flow for the area or function. Integrates subject matter and industry expertise within a defined area. Requires in-depth understanding of how areas collectively integrate within the sub-function as well as coordinate and contribute to the objectives of the function and overall business. Evaluates moderately complex and variable issues with substantial potential impact, where development of an approach/taking of an action involves weighing various alternatives and balancing potentially conflicting situations using multiple sources of information. Requires good analytical skills in order to filter, prioritize and validate potentially complex and dynamic material from multiple sources. Strong communication and diplomacy skills are required. Regularly assumes informal/formal leadership role within teams. Involved in coaching and training of new recruits. Significant impact in terms of project size, geography, etc. by influencing decisions through advice, counsel and/or facilitating services to others in area of specialization. Work and performance of all teams in the area are directly affected by the performance of the individual.

Responsibilities:

Applies in-depth disciplinary knowledge, contributing to the development of new techniques and the improvement of processes and work-flows.
Coordinates and contribute to the objectives of data science initiatives and overall business through leveraging in-depth understanding of how areas collectively integrate within the sub-function.
Assumes informal/formal leadership role through coaching and training of new recruits.
Significantly influences decisions, work, and performance of all teams through advice, counsel and/or facilitating services to others in the business.
Conducts strategic data analysis, identifies insights and implications and make strategic recommendations, develops data displays that clearly communicate complex analysis.
Mines and analyzes data from various banking platforms to drive optimization and improve data quality.
Delivers analytics initiatives to address business problems with the ability to identify data required, assess time & effort required and establish a project plan.
Consults with business clients to identify system functional specifications. Applies comprehensive understanding of how multiple areas collectively integrate to contribute towards achieving business goals.
Consults with users and clients to solve complex system issues/problems through in-depth evaluation of business processes, systems and industry standards; recommends solutions.
Leads system change process from requirements through implementation; provides user and operational support of application to business users
Formulate and define systems scope and objectives for complex projects through research and fact-finding combined with an understanding of applicable business systems and industry standards.
Impacts the business directly by ensuring the quality of work provided by self and others; impacts own team and closely related work teams.
Considers the business implications of the application of technology to the current business environment; identifies and communicates risks and impacts.
Drives communication between business leaders and IT; exhibits sound and comprehensive communication and diplomacy skills to exchange complex information.
Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.
Required Skills
5+ years of experience with Hadoop (Cloudera) or Cloud Technologies Expert level building pipelines using Apache Beam or Spark Familiarity with core provider services from AWS, Azure or GCP, preferably having supported deployments on one or more of these platforms
Advanced knowledge of the Hadoop ecosystem and Big Data technologies Hands-on experience with the Hadoop eco-system (HDFS, MapReduce, Hive, Pig, Impala, Spark, Kafka, Kudu, Solr)
Proficient in programming in Java or Python with prior Apache Beam/Spark experience a plus.
Experience with all aspects of DevOps (source control, continuous integration, deployments, etc.)
Experience with containerization and related technologies (e.g. Docker, Kubernetes)
Experience in other open-sources like Druid, Elastic Search, Logstash etc is a plus
Knowledge of agile(scrum) development methodology is a plus
Strong development/automation skills
System level understanding - Data structures, algorithms, distributed storage & compute
Can-do attitude on solving complex business problems, good interpersonal and teamwork skills
Preferred Skills:

Angular.JS 4 Development and React.JS Development expertise in a up to date Java Development Environment with Cloud Technologies

Qualifications:

5-8 years experience using tools for statistical modeling of large data sets
Ability to effectively use complex analytical, interpretive and problem solving techniques
Demonstrated interpersonal, verbal and written communication skills

Education:

Bachelor’s/University degree or equivalent experience

This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.

-------------------------------------------------

Job Family Group:

Technology

-------------------------------------------------

Job Family:

Data Analytics

------------------------------------------------------

Time Type:

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting

Effective November 1, 2021, Citi requires that all successful applicants must be fully vaccinated against COVID-19 as a condition of employment and provide proof of such vaccination prior to commencement of employment.


Show more Show less"
2826687350,Data Engineer I,Arbella Insurance Group,2021-12-04,United States,"Quincy, MA",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","The Data Engineer I provides support development in the field of big data and analytics and is responsible for working with and understanding various elements of data both internal and external to Arbella. Understands how to read and follow architectural mapping to create data models. Follows best practices used across organization. Prepares data for use in predictive and prescriptive modeling. Employ a variety of languages and tools (e.g. scripting languages) to marry systems together. Develops meaningful business reports through various presentation and BI tools like Business Objects.

Candidates must have willingness to learn new and legacy technologies, learn various relevant platforms and environments, and be familiar with business process, functions and data to provide innovative, insightful, and secure data and analytic solutions. Candidates must have a passion for learning new emerging technologies.

They must be excited and motivated to work in a data centric environment. They have sound organizational skills. They look to build collaborative relationships across all levels of the business and the IT organization. They possess analytic and problem-solving skills and have the ability to analyze the datasets. Able to communicate technical results to both technical and non-technical users using effective story telling techniques and visualizations. Demonstrated ability to perform high quality work both independently and collaboratively.

Key Responsibilities

Demonstrates expertise synthesizing and analyzing data sets of different sizes and complexities that can be both structured and unstructured as well as augmenting data from internal sources with appropriate external data.
Demonstrates the application of sound data modeling principles.
Assists team in the development and maintenance of best practices, methodologies, standards and frameworks.
Continually seeks ways to improve processes, workflows and/or operations.

Show more Show less"
2804693748,Mid-level Data Engineer,Vector Space Biosciences,2021-12-03,United States,United States,,Full-time,,"As a mid-level Data Engineer you will be responsible for improving the architecture of a general-purpose data pipeline used to do ETL of various data sources: crawled web pages, various APIs, PDFs, text files, etc.




You will build, maintain, scale and support existing data pipelines and deploy them on the cloud. You will ensure the proper storing of the raw and processed data.




You will set up monitoring for this pipeline, re-run on failure and update the pipeline with improvements without disrupting ongoing operations.




You will integrate this pipeline to feed data to our machine learning / language models and archive the model’s artifacts (weights, hyperparameters, model training code versions) at each run, as well as load these artifacts into an API server. You will have the opportunity to learn more about NLP / NLU language models and how to train and evaluate them.




You are expected to share knowledge with the team and mentor junior data engineers.




Nice to haves

Experience with a data orchestration tool
Dagster
Airflow
Experience in CI/CD, DevOps
Experience in API engineering
Experience mentoring junior engineers
Basic experience with training of machine learning models and archiving of artifacts 
Side projects
Technical blog




Show more Show less"
2777441673,Jr Big Data Engineer - Hybrid(Remote/Office),"DataDelivers, LLC.",2021-10-28,United States,"Schaumburg, IL ",,Full-time,,"The Big Data Engineer II primary responsibilities are to create, implement, and maintain various automated data solutions within DataDelivers big data ecosystem. The Engineer will work closely with other teammates to design optimum solutions using best practices. The Engineer is responsible to monitor and measure the data ecosystem’s performance, troubleshoot as needed, and report on status and metrics.

The Big Data Engineer also collaborates with DataDelivers data scientists and account team to creates ETL, batch, and automated processes to best suite DataDelivers and its client’s needs.

They proactively follow and contribute to the teams coding and programming standards and offer suggestions to how better improve them. They have a high standard for the quality of code and documentation they themselves produce.

Qualifications:

(5 years of relevant experience) or (2 years of relevant experience and an advanced degree in Computer Science/IT or related field)
Good understanding of distributed computing principles.
Proficiency with Big Data frameworks such as Hadoop, Spark, MapReduce, HDFS.
Proven experience ingesting data from multiple data sources such as REST API, SFTP flat files, Streaming data etc.
Proven experience with Big Data querying tools such as Athena/Presto, Pig, Hive, and Impala.
Proven experience with NoSQL databases, such as HBase, Cassandra, Redshift, DynamoDB.
Proven experience with various ETL techniques and frameworks, such as Flume, Glue Jobs, Step Functions.
Proven experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O
Proven experience with AWS Lambda and leveraging it in various solutions such as Glue, Step Functions, CloudWatch, S3 Events, etc.
Strong experience with using Python scripts & libraries.
Experience desired with Database Warehousing Design Concepts; Dimensional.
Modeling, Star/Snowflake Schemas, ETL/ELT, Data Marts, Analytic Playgrounds, Reporting techniques.
Experience working with Agile software development methodologies, namely Scrum.
Proven experience with team collaboration, release management, system and performance monitoring.
Ability to work well with people from many different disciplines and varying degrees of technical experience.
Excellent analytical, problem resolution, organization and time management skills.
Ability to handle multiple tasks at a time.

Required Experience:




Work closely with SMEs, make solution recommendations, and implement agreed upon solutions using best practices.
Select and integrate any Big Data tools and frameworks required to provide requested capabilities.
Design and implement ETL and automated processes.
Monitor performance and advise of any necessary improvements and changes.
Management of EMR clusters, Glue Jobs, Athena Tables, S3 data lakes; with all included services.
Provide technical support to members of TS and SA team, as well as project support across client engagements.
Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value.
Stays current with relevant technology in order to maintain and/or improve functionality for authored applications.
Assume other responsibilities as requested/required.
Acts as a subject matter expert for systems worked on. Ensures DataDelivers data solutions are using the latest versions and code base.
Actively listen to and work with end users to gather feedback and input, and make suggestions and solutions based on said feedback.

Benefits:

We constantly strive to achieve a strong work/life balance; we are an employee-centric culture, with room for flexibility in work location and hours where possible
We provide excellent benefits, including 401K, medical, dental, vision, disability, and life insurance, and generous compensated time off policy
We offer a competitive compensation package with opportunities for performance rewards based on company success

Show more Show less"
2820644865,Data Engineer,"AppFolio, Inc.",2021-11-18,United States,"Seattle, WA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Human Resources","Hi, We’re AppFolio.

We’re innovators, changemakers, and collaborators. We’re more than just a software company — we’re a cloud-based Software company that creates products to make our customers’ lives easier. We’re revolutionizing the way people do business, and we want your ideas, your enthusiasm, and your passion to help us keep on innovating.

We love where we work, and you can, too.

Whom We Are Looking For

We are hiring a Data Engineer to contribute to our growing Data Operations team. We work collaboratively to set the technical direction for our Data Platform, developing easy-to-use solutions for our customers. You’ll get the opportunity to work to develop, design, and operate all aspects of the Data Platform infrastructure.

This is an ideal opportunity for someone who has a passion for building a leading-edge data platform and is driven to work as an individual contributor and a great team player. We foster an environment that empowers small teams to collaboratively set the technical direction of our solutions.

Responsibilities

Design, build, deploy, and operate next-generation data infrastructure.
Develop and promote Apache Kafka best practices in the Data platform.
Collaborate with engineers and analysts to ensure that our data infrastructure meets the needs of our most data-intensive customers
Develop techniques for monitoring the correctness and reliability of our data infrastructure
Leverage agile practices, encourage collaboration, prioritization, and urgency to develop at a rapid pace
Research, share, and recommend new technologies and trends

You know you’re the right fit if…

You've worked with Apache Kafka in production
You have excellent SQL skills and have worked with change data capture systems in production
You have experience working with Infrastructure as Code, configuration management, and monitoring tools. Our team uses Terraform, Ansible, and Datadog.
You have some experience working with languages like Python or Ruby.
You care about work-life balance and want your company to care about it too; you'll put in the extra hour when needed but won't let it become a habit.
You want to work with a high degree of autonomy, while at the same time working on initiatives of high importance to the company.

Additional Skills And Knowledge

Experience with Confluent, Kafka Connect, Kafka Streams, or KSQLDB is desirable
Experience with CDC (change data capture) systems in general, or Debezium in particular, is highly desirable.
Experience with clickstream tracking technology in general, or Snowplow in particular, is desirable.
Experience with data warehouse technology is desirable, particularly with Snowflake.
Experience in visualization tools like tableau
Experience with containers and container orchestration tools. Docker and Kubernetes experience, in particular, is desirable.
Light data science skills for analyzing data and communicating with ML engineers are a plus.

Nice To Have

Bachelors in Computer Science or other quantitative fields.
Experience working across all levels of the development stack
Experience with AWS

If you are interested in creating exceptional SaaS products, and contributing to a successful company, apply today!

Our Story

AppFolio (NASDAQ: APPF) was founded in 2006 with the mission to revolutionize vertical industry businesses by providing great software and service. Our easy-to-use, cloud-based software helps our customers more effectively market, manage, and grow their businesses. Our software solutions exist in the real estate vertical, including AppFolio Property Manager and AppFolio Investment Management.

To find out more about what AppFolio has to offer, check out appfolioinc.com/careers.
Show more Show less"
2795131448,Data Engineer II,Grubhub,2021-11-11,United States,"New York County, NY",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","About The Opportunity

Grubhub is all about connecting hungry diners with our network of over 300,000 restaurants nationwide. Innovative technology, user-friendly platforms and streamlined delivery capabilities set us apart and make us an industry leader in the world of online food ordering. When you join our team, you become part of a community that works together to innovate, solve problems, grow, work hard and have a ton of fun in the process!

Why Work For Us

Grubhub is a place where authentically fun culture meets innovation and teamwork. We believe in empowering people and opening doors for new opportunities. If you’re looking for a place that values strong relationships, embraces diverse ideas–all while having fun together–Grubhub is the place for you!

More About The Role

We are looking for data engineers to help us expand and improve our big data and machine learning pipelines powering Grubhub’s restaurant supply growth. You will work with smart, humble, and committed colleagues to create innovative, robust, automated solutions for Grubhub’s three-way marketplace. This is an unbeatable opportunity for data engineers who hope to work on and deliver world-class data products in a friendly and fun environment.

The Impact You Will Make

Work with high volumes of data and distributed systems using technologies such as Amazon Redshift, AWS S3, Azkaban, Presto etc.
Create and maintain the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Comfortable in occasional client discussions that may benefit from their presence
Actively contribute to the adoption of strong data engineering architecture, development practices, and new technologies.
Maintain up-to-date technical documentation while continuously delivering technical solutions and business impacts.

What You Bring To The Table

Bachelor’s Degree in Computer Science, or Engineering related field or equivalent experience
Excellent knowledge of SQL, data modeling, and patterns.
3+ years experience with Python or similar programming language
Experience architecting and building data pipelines and optimizing them for speed (of imports, exports, and queries) and reliability.
Strong project management and organizational skills
Experience working for a fast-paced, product-development team

Got These? Even Better

Excellent communication skills to collaborate and share data insights with different stakeholders.
Rigorous attention to detail and accuracy
Exposure to Amazon AWS or another cloud provider
Growth mindset
Be passionate about continuous learning and knowledge sharing
Familiarity with Agile software development methodologies
You will work with your team to monitor and ensure the health of the platform, which includes a 24/7 hour on-call rotation, to ensure a great customer experience.

And Of Course, Perks!

Flexible PTO/PTO. Grubhub employees enjoy a generous amount of time to recharge.
Health and Wellness. Excellent medical benefits, employee network groups and paid parental leave are just a few of our programs to support your overall well-being.
Competitive Pay. You’ll receive a competitive base salary with eligibility for generous incentives, bonuses, commission or RSUs (role-specific).
Learning and Career Growth. Your personal and professional development is a priority at Grubhub. We empower you to be a leader and grow your career through training, coaching and mentorship opportunities.
MealPerks. Get meals on us! Our employees get a weekly Grubhub credit to enjoy and support local restaurants.
Fun. Every Grubhub office has an employee-led Culture Crew that connects people through fun, meaningful events and initiatives like Wellness Wednesdays, Slack competitions and virtual happy hours!
Social Impact. At Grubhub we believe in giving back through programs like the Grubhub Community Relief Fund and donating $1 million to the Equal Justice Initiative in 2020. Employees are also given paid time off each year to support the causes that are important to them.

Vaccination Requirement: In the event the role you are applying for requires you to report to an office, you must be able to provide proof of full Covid-19 vaccination prior to starting employment. Fully vaccinated is defined as: “2 weeks have passed since your second dose in a 2-dose series, such as the Pfizer or Moderna vaccines, or 2 weeks after a single-dose vaccine, such as Johnson & Johnson’s vaccine.

Grubhub is an equal opportunity employer. We welcome diversity and encourage a workplace that is just as diverse as the customers we serve. We evaluate qualified applicants without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics. If you’re applying for a job in the U.S. and need a reasonable accommodation for any part of the employment process, please send an email to TalentAcquisition@grubhub.com and let us know the nature of your request and contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address.
Show more Show less"
2821516155,Data Engineer,Coca-Cola Beverages Florida,2021-11-20,United States,"Tampa, FL",Information Technology,Full-time,IT Services and IT Consulting,"Tampa, FL, USA Req #6759 Monday, November 15, 2021 Coca-Cola Beverages Florida, LLC (Coke Florida) is a family-owned independent Coca-Cola bottler that is the third largest privately-held and the sixth largest independent Coca-Cola bottler in the United States. Coke Florida's exclusive territory covers over 18 million consumers across 47 Florida counties, and includes the major metropolitan markets of Jacksonville, Miami, Orlando and Tampa. Coke Florida sells, markets, manufactures and distributes over 600 products of The Coca-Cola Company and other partner companies including Monster Beverage Corporation and BODYARMOR. In 2017, Coke Florida generated over $1.2 billion in revenue and the company currently has approximately 4,800 employees. As one of the first US greenfield independent Coca-Cola bottlers in nearly sixty years, Coke Florida is at an exciting stage in its transformational journey to become a leading-edge beverage company, the best bottler in the Coca-Cola System, and one of the best companies to work for in Florida. The Data Engineer is a key member of the Coke Florida Information Governance Organization responsible for supporting, managing, and optimizing data pipelines to support business/data analysts, data scientists or any persona that needs curated data for data and analytics use cases across the enterprise. Role Responsibilities + Build platforms and pipeline to enables teams to clearly analyze data, build models and drive business decisions + Create, maintain, and optimize data pipelines within the Coke Florida system + Assist with driving automation through effective metadata management, assist with renovating data management infrastructure to drive automation in data integration and management + Become a Subject Matter Expert (SME) on data within Coke Florida, how it flows through which systems and how it can interact with other systems + Participate in ensuring data governance during data use + Work with various APIs to integrate with internal data models Role Requirements + Bachelor's or Master's degree in computer science, statistics, data management or equivalent work experience + 3+ years work experience in data management disciplines including data integration, modeling, optimization, and data quality, and/or other areas directly to data engineering responsibilities and tasks + 3+ years experience working in cross-functional teams and collaborating with key stakeholders + Experience with ETL, data replication, API design is highly desired + Experience with SAP Snowflake and Neilson Data highly desired + Experience with cloud tools, such as Azure highly desired + Previous experience with data management architectures such as Data Warehouse, Data Lake, Data Hub and the supporting processes like Data Integration, Governance + Metadata Management This job description is not an exhaustive list of all functions that the employee may be required to perform, and the employee may be required to perform additional functions. Coke Florida reserves the right to revise the job description at any time. Employment with Coke Florida is at-will. The employee must be able to perform the essential functions of the position satisfactorily and, if requested, reasonable accommodations may be made to enable employees with disabilities to perform essential functions of their job, absent undue hardship. Coca-Cola Beverages Florida is an Equal Opportunity Employer and does not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class. **Other details** + Job Family Technology/Transformation + Job Function Information Governance + Pay Type Salary Apply Now + Tampa, FL, USA
Show more Show less"
2739430286,"Big Data Engineer, Data Modeling",App Annie,2021-11-23,United States,United States,Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","PLEASE NOTE THAT YOU CAN WORK REMOTELY BUT YOU NEED TO BE LOCATED IN PST/PDT OR MOUNTAIN TIME ZONE TO APPLY FOR THIS ROLE

Something About Us

App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. More than 1,300 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business. We are a global company, headquartered in San Francisco but as a “remote” first company, we care about your results and not your location.

Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.

What can you tell your friends when they ask you what you do?

We’re looking for an experienced Big Data engineer who can create innovative new products in the analytics and data space. You will participate in the development that creates the world's #1 app stores analytics service. Together with the team you will build out new product features and applications using agile methodologies and open source technologies. You will work directly with Product Managers, Software Architects, and will be on the front lines of coding new and exciting analytics and data mining products. You should be passionate about what you do and excited to join an entrepreneurial start-­up.

You will be responsible for and take pride in….

As a Big Data Engineer, We Will Need You To Be In Charge Of Our Data Analysis Projects And To Build Clean, Robust And Maintainable Data Processing Program That Can Support These Projects On Huge Amount Of Data, This Includes

Able to design and implement complex product components based on requirements with possible technical solutions.
Write data analysis and statistics programs using pyspark with a commitment to maintaining high quality work while being confident in dealing with data mining challenges.
Discover any feasible new technologies lying in the Big Data ecosystem, share them to team with your professional perspectives.
Get up to speed in the machine learning domain, implementing analysis components in a distributed computing environment with instruction from Data Scientists.
Be comfortable conducting detailed discussions with Data Scientists regarding specific questions related to specific data models.
You should be a strong problem solver with proven experience in big data.

You should recognize yourself in the following…

Hands-on experience and deep knowledge of Hadoop ecosystem
Must: Spark, Mapreduce, HDFS
Plus: Storm, Kafka
Must have 2+ years Linux environment development experience.
Proficient with programming in Python, experience in Pandas, Sklearn or Other data science and data analysis toolset is a big plus.
Having a background of data mining and machine learning domain, familiar with common algorithms and libs is a plus.
Passion for cloud computing (AWS in particular) and distributed systems.
You must be a great problem solver with the ability to dive deeply into complex problems and emerge with clear and pragmatic solutions.
Good communication, and cooperation globally.
Major in Math or Computer Science.

This Is What We Offer…

We provide a $1,000 (country equivalent) WFH allowance to set you up for remote work success.
Internet allowance for stable internet connection, so your video does not freeze on Zoom.
Flexible working days. We love to meet, but if you need to get your kids behind school-zoom, need to leave early to get to your band repetition or gym classes, do your thing.
Paid leave, so long as you promise to come back!
Health and dental benefits.
An international team of talented and engaged people from different cultural backgrounds and locations.
Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!
Unlimited access to online learning platform Udemy to help you develop your skills.
Virtual initiatives and events to keep you connected with your colleagues.
Generous Employee Referral Program. Up to $10,000 for specific roles.

Yes, I want this job!


Show more Show less"
2810592288,Data Engineer,FTS(Failure To Success),2021-11-23,United States,"New Jersey, United States",,Full-time,,"Role : Data Engineer

Location : Bedminster, NJ

Employment Type : W2

 




Job Responsibilities:

· Design and support the database and table schemas for new and evolving sources of data being brought into the data warehouse

· Create and support the Analysis Services

· Monitor and troubleshoot performance issues

· Define and promote the team’s design principles and best practices

· Work with business teams to be able to define requirements for real time reporting

 

Skills and Experience Required:

Required:

· Very Strong in SQL (2012 or better):  stored procedures, functions, views, joins, import/export data, and the ability to develop queries from SQL

· Broad Knowledge of BIDS (Business Intelligence Development Studio) with heavy concentration in SSIS

· Experience in Tableau and Power BI

· Expertise in Excel and advance excel skills, must be able to: connect to various data sources, conditional formatting, pivot tables & pivot reporting, functions & formulas, and sorting & filtering

· Have the ability to identify data anomalies in a timely manner.

· Previous Healthcare experience

· Previous Fintech experience (banking, banking integrations, treasury, payments)

Desired:

· Visual Studio .NET




Show more Show less"
2794619156,Big Data Engineer,Mindtree,2021-11-16,United States,"New York, United States",Engineering and Information Technology,Full-time,IT Services and IT Consulting,"Mindtree is looking for Data Engineer for its project in NYC, Who is expert in Hadoop, Querying NoSQL Database, Data Insight




This role is an experienced Development Data Engineer that will assist in designing developing and deploying data driven solutions as part of a strategic data transformation effort The candidate will join a team of Data Architects and Engineers who will be responsible for optimizing and transforming our data architecture infrastructure operations and related functions This team will work with developers architects business data analysts and data scientists on data initiatives and will ensure optimal data solutions Summary Essential Job Functions Leverage modern data management toolsets and coding methods to design build implement and optimize data solutions of all types including support for OLTP and API Microservices data warehouses data lakes ODS streaming data analytic and BI visualizations etc Transform legacy data structures and processes to modern capable and secure solutions in a hybrid cloud setup Position Requirements 3 years of experience in data engineering development and operations roles including experience with transformational efforts Strong Database skills with RDBMS E g Oracle SQL as well as modern relational and unstruct ured data sources like NoSQL including cloud services AWS GCP Azure Hands on experience using tools is strongly preferred Experience with Tools or similar such as Hadoop Stack Airflow Kafka NiFi PostgreSQL Oracle SQL Server ElasticSe arch ELK JSON Parquet Avro and other Data Storage formats Tableau Superset and other Visualization Tools Apache Atlas and other Data centric Apache Packages Knowledge of Design Patterns for Software and Data Engineering Experience Codingwi th Java Javascript Nodejs Python GO Rust and similar Experience in on prem and hybrid cloud infrastructure including service and cost optimization Experience with production and analytics data batch and real time streaming etc .




Job Requirements: Hadoop, Querying NoSQL Database, Data Insight

Show more Show less"
2604286577,Big Data Engineer,FinTech LLC,2021-06-23,United States,"Raleigh, NC",Engineering and Information Technology,Contract,"Appliances, Electrical, and Electronics Manufacturing, Manufacturing, and Retail","Big Data / Data Engineering - Contract
Raleigh, NC
8+ Years of experience in Big Data / Data Engineering.
Experienced in Hadoop/Bigdata technologies: HDFS, Map Reduce, Spark, Python, Scala, Impala, Hive, HBase, Sqoop, Zookeeper, Oozie, Storm, Kafka, Flume, Splunk.
Experienced with Devops tools like Chef, Puppet, Ansible, Jenkins, Jira, Docker and Splunk.
Experience working with Amazon AWS.
Knowledge of MySQL, SQL Server.
Knowledge of Cloudera Manager, Hue, Shell scripting, JSON, HTML scripting.
Knowledge of complete Software Design lifecycle including design, development, testing and implementation of moderate to advanced complex systems.
Strong analytical, troubleshooting, and problem-solving skills - experience in analyzing and understanding business/technology system architectures.
Excellent communication skills.
Working in fast-paced environment, both independently and in collaborative team environments.
Experienced in Agile and Waterfall methodologies.
Preferable from Banking / Finance sector.
Show more Show less"
2750808095,AWS Big Data Analytics Engineer,Vanguard,2021-09-14,United States,"Malvern, PA",Information Technology,Full-time,Financial Services,"As An AWS/Big Data Analytics Engineer You Will

Vanguard is shifting our development to leaner, faster and more innovative solutions. Business and technical teams are partnering together to investigate and solve business problems using AWS as the platform.

Contribute to design, development & testing to ingest and transform/build the data lake for driving business outcomes.
Must be forward thinking and be able to find innovative solutions to drive faster outcomes.
Contribute to frequent deployments using CI/CD pipeline and improve the Team’s DevOps measures
Team player with good collaborative skills to work with cross-functional teams
Can-do attitude when working with ambiguity and demonstrate learning agility.

Preferred Experience In

Experience in AWS technologies such as EC2, Cloud formation, EMR, AWS S3, AWS Analytics.
Big data related AWS technologies like HIVE, Presto, Hadoop.
Experience with CI/CD pipeline tools like Bamboo, Jenkins
AWS certification is preferable: AWS Developer/Architect/DevOps/Big Data
UNIX scripting/Linux configuration.
Functional knowledge of Python, Scala, SQL.
Problem-solver and a team player.

Vanguard is not offering sponsorship for this position.

About Vanguard

We are Vanguard. Together, we’re changing the way the world invests.

For us, investing doesn’t just end in value. It starts with values. Because when you invest with courage, when you invest with clarity, and when you invest with care, you can get so much more in return. We invest with purpose – and that’s how we’ve become a global market leader. Here, we grow by doing the right thing for the people we serve. And so can you.

We want to make success accessible to everyone. This is our opportunity. Let’s make it count.

Inclusion Statement

Vanguard’s continued commitment to diversity and inclusion is firmly rooted in our culture. Every decision we make to best serve our clients, crew (internally employees are referred to as crew), and communities is guided by one simple statement: “Do the right thing.”

We believe that a critical aspect of doing the right thing requires building diverse, inclusive, and highly effective teams of individuals who are as unique as the clients they serve. We empower our crew to contribute their distinct strengths to achieving Vanguard’s core purpose through our values.

When all crew members feel valued and included, our ability to collaborate and innovate is amplified, and we are united in delivering on Vanguard's core purpose.

Our core purpose: To take a stand for all investors, to treat them fairly, and to give them the best chance for investment success.
Show more Show less"
2824688684,Data Engineer,Credit Suisse,2021-12-02,United States,"Raleigh, NC",Information Technology,Contract,Banking,"airisDATA has several ongoing projects with Credit Suisse in Raleigh and I’m searching for a Big Data Engineer to join our team of passionate Data Scientists and Data Engineers. This position does requier relocation to Raleigh NC. The team is working 2 days a week onsite and 3 days remote.

The ideal candidate will have hands on experience with Scala as well as Python or Java. Experience with the Cloudera Stack, Spark, Hive, Sqoop etc, Pipeline, Kafka. and Cloud experience will be a plus

This position can be either our W2 or Corp to Corp. Our Company, airisDATA is a strategic partner with Credit Suisse, we specializes in cloud and data analytic solutions. Feel free to review our web site

www.airisDATA.com

I’d be happy to discuss the position and compensation further. Please let me know if you have an interest. Feel free to share your resume my email is: frank.petrone@airisdata.com or submit it to this posting. I look forward to your response.

Stay safe, Frank

Show more Show less"
2801609730,Data Engineer,"Aruba, a Hewlett Packard Enterprise company",2021-10-26,United States,"San Jose, CA",Information Technology,Full-time,IT Services and IT Consulting,"Hewlett Packard Enterprise advances the way people live and work. We bring together the brightest minds to create breakthrough technology solutions, helping our customers make their mark on the world.

Aruba is redefining the ""Intelligent Edge"" Aruba is creating new customer experiences by building intelligent spaces and digital workspaces - leading next-generation network access solutions for the mobile enterprise. We are focused on campus, branch, mobility, and the IoT to transform businesses with the combined power of computing, context, control, and secure connectivity. We help some of the largest and most exciting companies globally to modernize their networks to meet the demands of a digital future.

What You'll Do

Research, propose, design, implement, operate and maintain software platforms for big data exploration and visualization, in support of a team of data scientists
Implement, monitor and maintain pipelines for processing big data in streaming and batch mode
Deploy implemented machine learning solutions in public and private cloud environments
Deploy and maintain orchestration and monitoring systems for big data processing

Our Minimum Requirements For This Role Are

B.S. degree in Computer Science or related field
3 years of industry experience as data engineer and/or devops engineer
Expert Python coder
Proficiency in big data computing infrastructure (especially Spark on Kubernetes)
Excellent familiarity with the landscape of big data exploration, visualization, and prototyping platform
Great at communication and team work

Additional Preferred Skills

Familiarity with statistical and machine learning techniques
Familiarity with wireless and wired networking protocols

Join us and make your mark!

We Offer

A competitive salary and extensive social benefits
Diverse and dynamic work environment
Work-life balance and support for career development
An amazing life inside the element! Want to know more about it?

Then let’s stay connected!

https://www.facebook.com/HPECareers

https://twitter.com/HPE_Careers

HPE is an Equal Employment Opportunity/ Veterans/Disabled/LGBT and Affirmative Action employer. We are committed to diversity and building a team that represents a variety of backgrounds, perspectives, and skills. We do not discriminate and all decisions we make are made on the basis of qualifications, merit, and business need. Our goal is to be one global diverse team that is representative of our customers, in an inclusive environment where we can continue to innovate and grow together.

#Aruba #ArubaUS #Diversity

1094663

This role has been designated as ‘Edge’, which means you will primarily work outside of an HPE office

HPE is an equal opportunity employer/Female/Minority/Individual with Disabilities/Protected Veteran Status
Show more Show less"
2814404078,Data Engineer,Capio,2021-11-30,United States,"Dallas, TX",,Full-time,,"JOB SUMMARY:

 

Capio, a well-established and expanding healthcare receivables management company based out of Sherman, TX, seeks a Data Engineer. Capio has an increasing number of data integration needs which must be fulfilled by our Information Technology department. As our organization continues to grow, our need to organize, integrate, share, and act upon findings revealed by our data also expands.

 

In this role, you will be responsible for Capio’s data engineering functions. You will create and maintain ETL, modeling, and data distribution applications. You will facilitate organization-wide data literacy and create a robust data warehouse, empowering our staff with self-service abilities within their BI and decision science toolsets.

 

Responsibilities




·        Extract, analyze, and store data from a variety of sources across the organization in a structured, secure, and efficient manner.

·        Create and maintain a new data warehouse using MS SQL server and SSIS.

·        Empower our business intelligence, decision science, and other enterprise applications with business-ready datasets.

·        Provide administrative technical support for our reporting servers, databases, business intelligence tools, and report delivery portals.

·        Maintain permissions, security, and license assignment within our data warehouse and business intelligence environments.

·        Create, monitor, and maintain ETL jobs using the JAMS enterprise job scheduler, responding to issues in a timely manner.

·        Champion Capio’s data literacy culture, from training our non-technical staff on basic data warehouse utilization to publishing official data diagrams.

·        Protect sensitive personal and financial data, adhering to HIPAA and PCI guidelines.

·        Other technical duties, as assigned.




Qualifications




·        Bachelor’s degree in business intelligence, data analytics, computer science, software engineering, or related field, or 4+ years of relevant experience required.

·        2+ years of experience with SSIS packages and complex SQL queries is required.

·        Strong design and presentation skills required.

·        Experience in QlikView, Qlik Sense, Tableau, Power BI, or another enterprise-level BI application is highly desired.

·        Experience within the receivables management or healthcare industries a strong plus.

·        Object oriented programming experience is desired. Preferred languages include C#, Java, Python, and PowerShell.

·        Fluency in written and verbal English is required.

 

Personal Characteristics

·        Accurate and thorough; strong attention to detail.

·        Self-sufficient, monitors own work to ensure quality.

·        Ability to translate business needs into solutions.

·        Collaborative, flexible, and responsive.

·        Strong analytical, numerical, and reasoning abilities.

·        Well-developed, mature interpersonal skills with diverse personalities.

·        Results-oriented.

·        Lifetime learner with an eager and open mind, an ever-expanding skillset, and a desire to share knowledge with others.

Show more Show less"
2804693205,Data Engineer,SKIMS,2021-11-23,United States,"Los Angeles, CA",Information Technology,Full-time,Apparel and Fashion,"Data Engineer

SKIMS is a solutions-oriented brand creating the future of underwear, shapewear and loungewear.

We’re disrupting the industry with our game-changing product and culturally driven creative, and are looking for a Data Engineer to join us in building the next generation of intimates.

You should have a passion for developing new ideas, challenging assumptions and be equal parts creative and analytical.







The Role

We are looking for a Data Engineer to be a founding member of our Data and Analytics team. In this role you will be responsible for building the foundational data analytics, reporting, and data pipelines platforms that power data-driven decision making across the entire company. This role is also critical in building data products and dashboards to empower data-driven decision making across the organization.




Primary Responsibilities




Create and maintain optimal data and analytics architecture, including visualization tools like Domo
Assemble large and complex data sets that meet functional and non-functional business requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Support the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and ‘big data’ technologies
Build tools for analytics team members that enable them to build and optimize reports and dashboards for the entire company




Qualifications




3-5 years experience in a data engineering role, preferably working in a direct-to-consumer business
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases and statistical programming languages (Python, R, etc.)
Experience building and optimizing cloud based big data data pipelines, architectures and data sets leveraging a combination of SaaS and custom build solutions
Successful history of manipulating, processing and extracting value from large disconnected datasets
Strong project management and organizational skills
Direct experience supporting data visualization tools like Looker (highly desired), Tableau, or PowerBI
Demonstrated success working in a fast-paced, swiftly-changing startup environment
BA/BS in Computer Science, Statistics, Informatics, Information Systems or other quantitative field highly desirable

Show more Show less"
2791841448,Data Engineer,IBM,2021-11-12,United States,"Washington, DC",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2825176580,Senior-Big Data Engineer,AT&T,2021-12-02,United States,"Dallas, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Wireless Services, and Telecommunications","Join AT&T and reimagine the communications and technologies that connect the world. We’re committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won’t just imagine the future – you’ll create it.

The Big Data Engineer will be responsible for interpreting the requirements of various Big Data Analytic Use Cases and Scenarios, and driving the design and implementation of specific data models to ultimately help drive better business decisions through insights from a combination of external and AT&Ts data assets. This is someone who is also motivated by their ongoing learning and willingness to pursue and complete professional .certifications on a continuing basis – and can use time management skills to balance learning with project related needs.

Key Roles and Responsibilities

Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the Big Data Environment.
Support the standardization, customization and ad-hoc data analysis, and will develop the mechanisms to ingest, analyze, validate, normalize and clean data.
Implements statistical data quality procedures on new data sources, and by applying rigorous iterative data analytics, supports Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value.
Will work with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data.
Develop and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods and techniques.

Qualifications

Preferred Bachelors of Science in Computer Science, Math or Scientific Computing preferred.
Typically requires 5-8 years experience.
Python, Azure or AWS, Data wrangling and Data pipeline design required
The ideal candidate will have fluency in programming, but also analytical skills since they will be working and exchanging ideas with data scientists

Ready to join our team? Apply today!

#ChiefDataOffice

JobCategory:Technology
Show more Show less"
2742761533,Data Engineer - Personalization,Spotify,2021-11-18,United States,"Boston, MA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","The Personalization team makes deciding what to play next easier and more enjoyable for every listener. From Daily Mix to Discover Weekly, we’re behind some of Spotify’s most-loved features. We built them by understanding the world of music and podcasts better than anyone else. Join us and you’ll keep millions of users listening by making great recommendations to each and every one of them. We ask that our team members be physically located in Central European time or Eastern Standard/Daylight time zones for the purposes of our collaboration hours.

Spotify is looking for a Data Engineer to join the team! You will build data driven solutions to bring music and digital media experiences to hundreds of millions of active users and millions of creators by matching fans with creators in a personal and relevant way. You will take on complex data-related problems using some of the most diverse datasets available — user behaviors, acoustical analysis, revenue streams, cultural and contextual data, and other signals across our broad range of mobile and connected platforms. Above all, your work will impact the way the world experiences art.

What You'll Do

Build large-scale batch and real-time data pipelines with data processing frameworks like Scalding, Scio, Storm, Spark and the Google Cloud Platform.
Use best practices in continuous integration and delivery.
Help drive optimization, testing and tooling to improve data quality.
Collaborate with other software engineers, ML experts and stakeholders, taking learning and leadership opportunities that will arise every single day.
Work in multi-functional agile teams to continuously experiment, iterate and deliver on new product objectives!

Who You Are

You know how to work with high volume heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, and Cassandra.
You know how to write distributed, high-volume services in Java or Scala.
You are knowledgeable about data modeling, data access, and data storage techniques.
You appreciate agile software processes, data-driven development, reliability, and responsible experimentation.
You understand the value of partnership within teams.
We are proud to foster a workplace free from discrimination. We strongly believe that diversity of experience, perspectives, and background will lead to a better environment for our employees and a better product for our users and our creators. This is something we value deeply and we encourage everyone to come be a part of changing the way the world listens to music.

Where You'll Be

We are a distributed workforce enabling our band members to find a work mode that is best for them!
Where in the world? For this role, it can be within the Americas region in which we have a work location and is within working hours.
Working hours? We operate within the Eastern Standard time zone for collaboration and ask that all be located that time zone.
Prefer an office to work from home instead? Not a problem! We have plenty of options for your working preferences. Find more information about our Work From Anywhere options here .

Spotify is an equal opportunity employer. You are welcome at Spotify for who you are, no matter where you come from, what you look like, or what’s playing in your headphones. Our platform is for everyone, and so is our workplace. The more voices we have represented and amplified in our business, the more we will all thrive, contribute, and be forward-thinking! So bring us your personal experience, your perspectives, and your background. It’s in our differences that we will find the power to keep revolutionizing the way the world listens.

Spotify transformed music listening forever when we launched in 2008. Our mission is to unlock the potential of human creativity by giving a million creative artists the opportunity to live off their art and billions of fans the chance to enjoy and be passionate about these creators. Everything we do is driven by our love for music and podcasting. Today, we are the world’s most popular audio streaming subscription service with a community of more than 381 million users.
Show more Show less"
2820799826,Data Engineer,Sia Partners,2021-12-03,United States,"Chicago, IL",Consulting,Full-time,Management Consulting,"Sia Partners is looking for a talented Data Engineer to support our activities within the Data Science Business Unit. You will be working alongside with our Data Science consultants and our clients on Data Engineering topics, including creating relevant data models, developing powerful data pipelines, exposing them through various mechanisms including APIs, and using data visualization tools to efficiently present data.



You will also contribute to internal Data Science projects posted on Heka, our internal accelerator for Data Science projects. As part of the global Data Science team you will contribute to the development of various solutions designed to address our clients' needs.



Key Responsibilities 



Partner with our client’s leadership teams, engineers, program managers and data analysts to understand data needs.
Design, build and launch efficient and reliable data pipelines transforming data into useful report ready datasets.
Communicate at scale, through multiple mediums: presentations, dashboards, client-wide datasets, bots and more.
Use your data and analytics experience to ‘see what’s missing,’ identifying and addressing data gaps, build monitors to detect data quality issues and partner to establish a self-serve environment.
Broad range of partners equates to a broad range of projects and deliverables, including ML Models, datasets, measurements, services, tools and process.
Leverage data and business principles to automate data flow, detect business exceptions, build diagnostic capabilities, and improve both business and data knowledge base.
Build data expertise and own data quality for your areas.


Qualifications


At least 4+ years' of advanced SQL experience (including at least one SQL DBMS and one noSQL).
4+ years' of Python development experience.
3+ years' of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).
3+ years' experience with Data Modeling.
Experience analyzing data to discover opportunities and address gaps.
4+ years' experience in custom ETL design, implementation and maintenance.
Experience working with cloud or on-prem Big Data/MPP analytics platform (i.e. SnowFlake, Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).
BSc/BA in Data Science, Computer Science, Engineering.

Preferred Experience with:



Experience with more than one coding language.
Knowledge of Docker, CI/CD pipelines, and Kubernetes.
Experience in designing and implementing real-time pipelines.
Experience with data quality and validation.
Experience with SQL performance tuning and e2e process optimization.
Experience with anomaly/outlier detection.
Experience with notebook-based Data Science workflow.
Experience querying massive datasets, using Spark, Presto, Hive, Impala, etc.


Additional Information



This is an opportunity to join a rapidly growing team that serves some of the most exciting and highly respected companies in the world. You will have the opportunity to provide clients with original thinking and customized solutions and you’ll often have the satisfaction of seeing the impact of your work on their business. We are committed to a healthy work-life integration. 



Benefits



Generous PTO, including Parental leave
Healthcare that includes dental and vision, life insurance and 401K matching                                        
Career advocacy program that supports achieving personal development goals through coaching, collaboration and real-time feedback
Robust learning and development platform through the Sia Institute, 360 Learning App, Sia Blend App, working groups, US Training Sessions, and reimbursement for continuing education and certifications
Women at Sia Club
Annual Seminar/a value add experience to network with your colleagues across North America and other regions
Opportunities for geographic mobility if desired
Work directly with clients

Still Interested? Tell Us About Your…  



Academic successes
Consulting / Agency experience
Data supported success stories
Growth from failure
Tools and training
Cross-functional experience
Extracurriculars

Diversity, equity, inclusion, and belonging (DEIB) are part of Sia Partners’ DNA. Thanks to our expertise in several sectors and our international growth, our teams include a variety of experiences and cultures. We’re confident that promoting DEIB creates an environment in which everyone can reach their full potential. 



Our global network, DEIB@Sia Partners, brings together our people worldwide to facilitate local and global progress, focused on the following areas:



Gender equality (global Gender Equality Index score of 91/100 for FY19-20)
LGBTQ+
Race & Ethnicity
Working Parents 
Disabilities

We are an equal opportunity employer that values collective diversity, equity, inclusion and belonging. Our goal is to develop a work environment where everyone feels safe to be their authentic self and valued as part of the Sia Village.



All your information will be kept confidential according to EEO guidelines.



Sia Partners is an equal opportunity employer. All aspects of employment, including hiring, promotion, remuneration, or discipline, are based solely on performance, competence, conduct, or business needs. 



Show more Show less"
2789622807,Big Data Engineer,Rakuten Americas,2021-12-03,United States,"San Mateo, CA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Job Description:

SUMMARY:

The Big Data Engineer is part of the global Rakuten Catalog Platform Department. The Catalog Platform provides services to global business units including an accurate, compelling catalog with millions of products and highly relevant search services. The team uses Big Data technologies, Cloud infrastructure, open source scalable search platform and cutting-edge machine learning/statistical modeling.

The Big Data Engineer will be responsible for participating in design and development of Product Catalog and Search components including storage, search, large data processing, APIs, analytics and web services. Be part of an awesome R&D team where you get inspired by talented people, challenges and mission to change the global e-commerce landscape!

Key Responsibilities

Participate in design & development of Product Catalog & Search
Work on implementing storage integration
Work on developing code and unit testing search index integration
Implement large data processing (stream & batch) solutions
Work on enhancing APIs or implementing new APIs
Implement analytics jobs to process large amount of data

MINIMUM REQUIREMENTS (Knowledge, Skills, Abilities

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Strong knowledge of Java
Strong knowledge of design patterns, OOPS principles and data structures
Strong knowledge of at least some of the following frameworks/technologies – Hibernate, Spring, REST, XML, JSON, ActiveMQ, Kafka
Experience with tools and technologies like Gradle, Maven, Jenkins, git, IntelliJ, Eclipse, Docker to support end to end software development
Experience with Relational databases, queries and RDBMS best practices
Strong troubleshooting and performance tuning skills
Ability to work in a fast-paced Agile and rapid deployment in the Cloud/SaaS environment.
Able to effectively communicate across teams and roles.

Qualification Requirements

BS/MS in Computer Science or a related field
1-5 years of solid Java back-end experience

RAKUTEN SHUGI PRINCIPLES

Our worldwide practices describe specific behaviors that make Rakuten unique and united across the world. We expect Rakuten employees to model these 5 Shugi Principles of Success.

Always improve, always advance. Only be satisfied with complete success - Kaizen.
Be passionately professional. Take an uncompromising approach to your work and be determined to be the best.
Hypothesize - Practice - Validate - Shikumika. Use the Rakuten Cycle to success in unknown territory.
Maximize Customer Satisfaction. The greatest satisfaction for workers in a service industry is to see their customers smile.
Speed!! Speed!! Speed!! Always be conscious of time. Take charge, set clear goals, and engage your team.

Show more Show less"
2770783646,Data Engineer,BuzzClan,2021-11-30,United States,Dallas-Fort Worth Metroplex,,Full-time,,"JTitle - SQL Server Data Engineer

Location - USA-TX-Dallas

Duration – Long Term

Description -

The Data Engineer shall apply specialized knowledge to conceptualize, design, develop, unit-test, configure, and implement data engineering solution that moves, cleans, and loads data to differing systems within client. The person will interact with our clients and differing roles within IT to gain understanding of the business environment, technical context, and strategic direction.  This person will also be responsible for generating documentation as needed; conform to security and quality standards; and stay current on emerging trends. Teams supported include: Application Engineering, Data Engineering, Decision Science, and Business Analytics

 For a successful candidate for this position, you must -

·       Have experience in creating robust and automated pipelines to ingest and process structured and unstructured data sources into analytical platforms using batch and streaming mechanisms leveraging cloud native toolset

·       Be able to develop high performance data queries, stored procedures and/or functional code for data related batch jobs, application support and ETL needs

·       Leverage the right tools for the right job to deliver testable, maintainable, and modern data solutions

·       Be comfortable with researching data questions, identify root causes, and interact closely with business users and technical resources on various data related decisions

·       Understand how to profile code, queries, programming objects and optimize performance

·       Aspire to be efficient, thorough and proactive

 Responsibilities and Duties

·       Develops data pipelines to ingest, move, transform, and integrate data in a secure and performant manner while ensuring and enforcing general data governance principals.

·       Explores new technologies and data processing methods to increase efficiency, performance, flexibility, and usefulness to the Enterprise’s data.

·       Document requirements and translate into proper system requirements specifications using high-maturity methods, processes and tools.

·       Execute and coordinate requirements management and change management processes. Participates as a member of and leads development teams.

·       Designs, prepares and executes unit tests.

·       Completes development to implement complex components.

·       Participates in cross-functional teams.

·       Designs, prepares and executes unit tests.

·       Represents team to clients.

·       Demonstrates technical leadership and exerts influence outside of immediate team.

·       Develops innovative team solutions to complex problems.

·       Contributes to strategic direction for teams.

·       Applies in-depth or broad technical knowledge to provide maintenance solutions across one or more technology areas (e.g. Power BI and Power App development).

·       Integrates technical expertise and business understanding to create superior solutions for clients.

·       Consults with team members and other organizations, clients and vendors on complex issues.

·       Special projects as requested

·       Performs other duties as assigned

Qualifications

·       Bachelor’s degree in IT preferred. Equivalent combination of education and experience may be substituted in lieu of degree.

·       3+ years of Microsoft SSIS package development experience including experience with Microsoft Visual Studio

·       3+ years of experience contributing and working with enterprise data warehouses

·       6+ years of experience in SQL and be able to write complex logic using SQL as part of ETL, and use SQL effectively to perform complex data analysis and discovery

·       2+ years of experience building reports with SSRS.

·       1+ years of Microsoft Power BI report development experience.

·       Exposure to Azure and Azure Data Factory

·       Exposure to an Enterprise Data Lake

·       Demonstrate strong organization skills and detail-oriented

·       Experience with CMD shell and PowerShell

·       Experience with large-scale, complex data environments

·       Ability to self-motivate and meet deadlines

·       Intense desire to learn

·       Ability to express complex technical concepts effectively, both verbally and in writing

·       Ability to multi-task in a fast-paced, changing environment

·       Ability to maintain confidentiality

Show more Show less"
2814278052,Data Engineer,Incubit,2021-11-30,United States,"Bentonville, AR",,Contract,,"We need a data engineer that have experience with GCP (Google Cloud Platform).




The following technologies are a plus: dataprok, scala, python airflow.

Show more Show less"
2821503519,Data Engineer,Sia Partners,2021-12-03,United States,"New York, NY",Consulting,Full-time,Management Consulting,"Sia Partners is looking for a talented Data Engineer to support our activities within the Data Science Business Unit. You will be working alongside with our Data Science consultants and our clients on Data Engineering topics, including creating relevant data models, developing powerful data pipelines, exposing them through various mechanisms including APIs, and using data visualization tools to efficiently present data.



You will also contribute to internal Data Science projects posted on Heka, our internal accelerator for Data Science projects. As part of the global Data Science team you will contribute to the development of various solutions designed to address our clients' needs.



Key Responsibilities 



Partner with our client’s leadership teams, engineers, program managers and data analysts to understand data needs.
Design, build and launch efficient and reliable data pipelines transforming data into useful report ready datasets.
Communicate at scale, through multiple mediums: presentations, dashboards, client-wide datasets, bots and more.
Use your data and analytics experience to ‘see what’s missing,’ identifying and addressing data gaps, build monitors to detect data quality issues and partner to establish a self-serve environment.
Broad range of partners equates to a broad range of projects and deliverables, including ML Models, datasets, measurements, services, tools and process.
Leverage data and business principles to automate data flow, detect business exceptions, build diagnostic capabilities, and improve both business and data knowledge base.
Build data expertise and own data quality for your areas.


Qualifications


At least 4+ years' of advanced SQL experience (including at least one SQL DBMS and one noSQL).
4+ years' of Python development experience.
3+ years' of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).
3+ years' experience with Data Modeling.
Experience analyzing data to discover opportunities and address gaps.
4+ years' experience in custom ETL design, implementation and maintenance.
Experience working with cloud or on-prem Big Data/MPP analytics platform (i.e. SnowFlake, Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).
BSc/BA in Data Science, Computer Science, Engineering.

Preferred Experience with:



Experience with more than one coding language.
Knowledge of Docker, CI/CD pipelines, and Kubernetes.
Experience in designing and implementing real-time pipelines.
Experience with data quality and validation.
Experience with SQL performance tuning and e2e process optimization.
Experience with anomaly/outlier detection.
Experience with notebook-based Data Science workflow.
Experience querying massive datasets, using Spark, Presto, Hive, Impala, etc.


Additional Information



This is an opportunity to join a rapidly growing team that serves some of the most exciting and highly respected companies in the world. You will have the opportunity to provide clients with original thinking and customized solutions and you’ll often have the satisfaction of seeing the impact of your work on their business. We are committed to a healthy work-life integration. 



Benefits



Generous PTO, including Parental leave
Healthcare that includes dental and vision, life insurance and 401K matching                                        
Career advocacy program that supports achieving personal development goals through coaching, collaboration and real-time feedback
Robust learning and development platform through the Sia Institute, 360 Learning App, Sia Blend App, working groups, US Training Sessions, and reimbursement for continuing education and certifications
Women at Sia Club
Annual Seminar/a value add experience to network with your colleagues across North America and other regions
Opportunities for geographic mobility if desired
Work directly with clients

Still Interested? Tell Us About Your…  



Academic successes
Consulting / Agency experience
Data supported success stories
Growth from failure
Tools and training
Cross-functional experience
Extracurriculars

Diversity, equity, inclusion, and belonging (DEIB) are part of Sia Partners’ DNA. Thanks to our expertise in several sectors and our international growth, our teams include a variety of experiences and cultures. We’re confident that promoting DEIB creates an environment in which everyone can reach their full potential. 



Our global network, DEIB@Sia Partners, brings together our people worldwide to facilitate local and global progress, focused on the following areas:



Gender equality (global Gender Equality Index score of 91/100 for FY19-20)
LGBTQ+
Race & Ethnicity
Working Parents 
Disabilities

We are an equal opportunity employer that values collective diversity, equity, inclusion and belonging. Our goal is to develop a work environment where everyone feels safe to be their authentic self and valued as part of the Sia Village.



All your information will be kept confidential according to EEO guidelines.



Sia Partners is an equal opportunity employer. All aspects of employment, including hiring, promotion, remuneration, or discipline, are based solely on performance, competence, conduct, or business needs. 



Show more Show less"
2824225125,Crypto Big Data Engineer (US-Remote),Token Metrics,2021-11-07,United States,"New York, NY",Engineering and Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","Token Metrics is seeking a multi-talented Big Data Engineer to facilitate the operations of our Data Scientists and Engineering team. The Big Data Engineer will be responsible to employ various tools and techniques to construct frameworks that prepare information using SQL, Python, R, Java and C++. The Big Data Engineer will be responsible for employing machine learning techniques to create and sustain structures that allow for the analysis of data while remaining familiar with dominant programming and deployment strategies in the field. During various aspects of this process, you should collaborate with coworkers to ensure that your approach meets the needs of each project.

Responsibilities

Liaising with coworkers and clients to elucidate the requirements for each task.
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Building a data pipeline from different data sources using different data types like API, CSV, JSON, etc.
Preparing raw data for manipulation by Data Scientists.
Implementing proper data validation and data reconciliation methodologies.
Ensuring that your work remains backed up and readily accessible to relevant coworkers.
Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.
Requirements

Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field.
A Master's degree in a relevant field is an added advantage.
3+ years of Python, Java or any programming language development experience
3+ years of SQL & No-SQL experience (Snowflake Cloud DW & MongoDB experience is a plus)
3+ years of experience with schema design and dimensional data modeling
Expert proficiency in SQL, NoSQL, Python, C++, Java, R.
Expert with building Data Lake, Data Warehouse or suitable equivalent.
Expert in AWS Cloud.
Excellent analytical and problem-solving skills.
A knack for independence and group work.
Capacity to successfully manage a pipeline of duties with minimal supervision.
About Token Metrics

Token Metrics helps crypto investors build profitable portfolios using artificial intelligence-based crypto indices, rankings, and price predictions.

Token Metrics has a diverse set of customers, from retail investors and traders to crypto fund managers, in more than 50 countries.
Show more Show less"
2813231529,Data Engineer,Deloitte,2021-10-31,United States,"Arlington, VA","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

Work you'll do

A Data Engineer will be responsible for leading the setup of an AWS hosted data lake as well as the ingestion pipeline and processing for 100+ datasets, working closely with Agile software development team(s). This role includes responsibilities such as creating and managing schedules for data management (migration, integration, etc.) efforts, working with clients to validate migrated data, working with Agile development teams to understand changes and their impacts towards data migration efforts, among other tasks.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Bachelor's degree required
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be able to obtain and maintain the required clearance for this role
Travel up to 10%
3 + years data engineering, data management and transformation experience
2+ years experience with Big Data tools such as Kubernetes, MongoDB
3+ years experience with Extract, Transform, Load (ETL)

Preferred:

Professional Amazon Cloud Architecture certification
Ability to thrive in a fast-paced work environment with multiple stakeholders
Knowledge of data mining, machine learning, data visualization and statistical modeling
Prior professional services or federal consulting experience

How You'll Grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
Show more Show less"
2813229668,Data Engineer,Deloitte,2021-10-31,United States,"Arlington, VA","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

Work you'll do

A Data Engineer will be responsible for leading the setup of an AWS hosted data lake as well as the ingestion pipeline and processing for 100+ datasets, working closely with Agile software development team(s). This role includes responsibilities such as creating and managing schedules for data management (migration, integration, etc.) efforts, working with clients to validate migrated data, working with Agile development teams to understand changes and their impacts towards data migration efforts, among other tasks.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Bachelor's degree required
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be able to obtain and maintain the required clearance for this role
Travel up to 10%
3 + years data engineering, data management and transformation experience
2+ years experience with Big Data tools such as Kubernetes, MongoDB
3+ years experience with Extract, Transform, Load (ETL)

Preferred:

Professional Amazon Cloud Architecture certification
Ability to thrive in a fast-paced work environment with multiple stakeholders
Knowledge of data mining, machine learning, data visualization and statistical modeling
Prior professional services or federal consulting experience

How You'll Grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
Show more Show less"
2800714477,Data Engineer,Dell Technologies,2021-10-24,United States,"Round Rock, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Hardware Manufacturing, and Computer Software","Advisor – Data Engineer

Join us as a Data Engineer on our EBI team in Round Rock,Tx, Hopkinton, MA or remote to do the best work of your career and make a profound social impact.

What You’ll Achieve

At Dell Technologies we are enabling the next data decade for our businesses and customers. With some of the biggest data implementations in the industry, the Dell Digital Data team is constantly reimagining and innovating the way data is consumed and enabled.

In this role we are looking for individuals who are passionate about data and the possibilities of leveraging it to power intelligent, insightful and impactful outcomes. You will be working with some of the best minds and talents in the data space including business stakeholders, architects, application teams, privacy, security, governance etc. We believe in empowering our teams and leaders to take end to end ownership of the outcomes with the highest focus on quality, stability, security and customer satisfaction.

Design and develop analytical design for business problem statement and progress the solution from design though the software development lifecycle to implementation using various analytics tools and techniques.

You Will

Analyzes business needs and creates software and hardware solution blueprints.
Work closely with Data Product Managers and Solution Architects to define use cases and measurable business metrics
Works with engineering teams to check the feasibility of the solution, build stories and architects the solution for the Projects. Drives use cases through complete lifecycle.
Prepares flow charts, systems diagrams and design documentation to assist in problem analysis.
Designs, codes, tests and debugs software according to Dell’s standards, policies and procedures.
Mentoring junior team members on technical and functional skills. Should be a great team player. Functional knowledge of business processes is required.

Take the first step towards your dream career

Essential Requirements

Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role:

3-5 years of relevant IT experience in Data-Warehousing Technologies with excellent communication and Analytical skills
Possesses and applies a broad knowledge of application programming processes and procedures to the completion of complex assignments.
Competent to analyze diverse and complex problems.
Advanced ability to effectively troubleshoot program errors.
Build high reliability, high quality, high volume data pipelines
Setup batch, micro batch, streaming pipelines needed for data ingestion, transformation, processing
Automated tests and tie outs, self-healing data jobs
Ability to communicate complex insights in a precise and actionable manner
Mindset to think differently; alignment to Industry standards; awareness of emerging technologies and industry trends
Experience in working in Agile (SCRUM) Methodology

Desirable Requirements

Bachelor of Engineering or Master of Computer Applications
Experience in handling Data Security and Governance
Prior experience in delivering full stack Applications, APIs

Benefits

We offer highly competitive salaries, bonus programs, world-class benefits, and unparalleled growth and development opportunities — all to create a compelling and rewarding work environment.

Our EVP

Our Culture Code unites us and makes us a great family of companies and a great place to work. It’s how we run the business, go to market, work together and provide inspirational leadership. Our culture code is defined by our values and are made real every day by defining expectations for how we work and how we lead.

Here’s our story; now tell us yours

Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress.

What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life -- while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more.

We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today.

You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here.

Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Employment Opportunity Policy here.

Job Id: R142535
Show more Show less"
2801703886,Data Developer,TEKsystems,2021-11-16,United States,United States,,Contract,,"I am currently supporting a fully remote, long-term contract position with a large healthcare client who is looking for candidates with data profiling experience who would work within their highly innovative, dynamic team, consistently implementing and evaluating new technologies, and managing data governance from an IT perspective for the entire enterprise. This individual must possess a great deal of initiative and work well with autonomy. They are flexible on the specific profiling tool (IBM Information Analyzer, Delphix, Informatica BDQ, etc.)
Show more Show less"
2799440037,Data Engineer,MyDataProduct,2021-11-19,United States,United States,,Contract,,"MyDataProduct is a custom data product development company with a focus on high-performance data engineering.




As a Data Engineer, you will leverage Python, SQL, Amazon Web Services (AWS), and other technologies to solve mission-critical business problems for MyDataProduct clients and their stakeholders.




This opportunity may be a good fit if

• You excel at independent execution of complex data engineering projects

• You are comfortable working 100% remotely as part of a distributed team

• You enjoy the flexibility of setting your own hours and work cadence

• You do not have a PhD in Computer Science and 10+ year of work experience—but you do have the necessary skills, aptitude, and mindset to get the job done




Responsibilities

• Use Python to develop new data platform features

• Engineer and manage production-grade data pipelines

• Deploy, maintain, and support Docker-based solutions

• Create and maintain documentation to enable solution modularity, reproducibility, portability, collaboration, performance, and knowledge sharing

• Collaborate with teammates using Slack, GitHub, Google Meet, and other cloud-based tools




Qualifications

• 2+ years of Airflow experience

• 2+ years of SQL experience

• 2+ years of Amazon Web Services (AWS) experience

• Proficiency in writing functional and object-oriented Python

• Demonstrated ability to write production-grade data integrations

• Experience using Git-based version control in a team setting

• Practical understanding of software engineering principles, design patterns, and best practices

• Effective modular thinking skills evidenced by the ability to break down large, intricate undertakings into a series of smaller self-contained tasks

• Excellent written and verbal communication skills

• Emotional intelligence and coachability




How to stand out from other applicants

Preference will be given to applicants who share and demo and end-to-end data engineering project.

Show more Show less"
2826009882,Data Engineer,Revcontent,2021-12-03,United States,"Sarasota, FL",,Full-time,,"Revcontent is looking for an experienced and skilled Data Engineer to join our growing Data Analytics department. The Data Engineer will be responsible for a range of duties including:




Develop creative solutions to internal and external challenges that illustrate a thorough understanding of the platform and business goals
Assist and actively contribute to data modeling efforts between business stakeholders and tech teams
Demonstrate expertise on table joins as well as other advanced LookML options to develop BI reports and dashboards that highlight KPIs and/or identify notable patterns
Work with software and solutions engineers to define and improve upon report performance
Establish processes to ensure as well as maintain data integrity and reliability
Recognize when to pass along complex, deep-rooted issues to the tech development team to ensure their time is utilized effectively
Dissect large datasets, drawing from them impactful insights and big-picture narratives
Spearhead improvements to data organization and workflows that are intuitive, establish continuity, and increase efficiency
Understand the current landscape of enterprise data collection and expand data frameworks where needed to meet business objectives
Build compelling data visualizations that are accurate and well-represented
Analyze and interpret product performance results to influence optimization strategies
Support external calls by presenting data in an easily digestible way that translates meaningfully to the client’s unique business initiatives
Play a key role in mitigating potential financial risk by identifying statistical anomalies and providing perspective on deterrent
Strengthen the effectiveness of meetings by contributing key take-aways and drawing useful parallels that help facilitate info share on industry trends in data science and analytics
Other duties and responsibilities may be assigned




Required Skills & Qualities:




Strong ability to communicate and present data to both technical and non-technical audiences equally
Advanced skill in data programming language(s) (SAS, R, Python and/or SQL)
Well-versed building data visualizations as well as optimizing data retrieval within Looker or similar BI tools (Tableau, Qlik, Mode, DataStudios, etc.)
Proficient in Microsoft Excel, including advanced functions
Meticulously detail-oriented, organized, and through prioritization has the ability to meet assigned deadlines
Flexible, creative, and able to operate independently with minimal daily direction from manager to accomplish objectives
Business acumen and sound decision making
Show more Show less"
2794491949,Data Engineer,Vanguard,2021-11-11,United States,"Malvern, PA",Research and Analyst,Full-time,Financial Services,"Opportunity to join an industry leader in the institutional retirement space. As a Data Engineer, you will provide advanced data solutions by using software to process, store, and serve data to others. Tests data quality and optimizes data availability. Ensures that data pipelines are scalable, repeatable, and secure. Utilizes a deep dive analytical skillset on a variety of internal and external data.

Core Responsibilities

Writes ETL (Extract / Transform / Load) processes, designs database systems, and develops tools for real-time and offline analytic processing.
Troubleshoots software and processes for data consistency and integrity. Integrates large scale data from a variety of sources for business partners to generate insight and make decisions.
Translates business specifications into design specifications and code. Responsible for writing complex programs, ad hoc queries, and reports. Ensures that all code is well structured, includes sufficient documentation, and is easy to maintain and reuse.
Partners with internal clients to gain an enhanced understanding of business functions and informational needs. Gains expertise in tools, technologies, and applications/databases in specific business areas and company-wide systems.
Leads all phases of solution development. Explains technical considerations at related meetings, including those with internal clients and less experienced team members.
Tests code thoroughly for accuracy of intended purpose. Reviews end product with the client to ensure adequate understanding. Provides data analysis guidance as required.
Designs and conducts training sessions on tools and data sources used by the team and self provisioners. Provides job aids to team members and business users.
Tests and implements new software releases through regression testing. Identifies issues and engages with vendors to resolve and elevate software into production.
Participates in special projects and performs other duties as assigned.

Qualifications

Minimum of five years data analytics, programming, database administration, or data management experience.
Undergraduate degree or equivalent combination of training and experience.

Additional Helpful Skills

Experience with AWS services like EMR, Glue ETL, S3 and IAM
Experience in writing Hive QL queries using Hue
Experience with Control-M scheduling and Splunk Monitoring.

About Vanguard

We are Vanguard. Together, we’re changing the way the world invests.

For us, investing doesn’t just end in value. It starts with values. Because when you invest with courage, when you invest with clarity, and when you invest with care, you can get so much more in return. We invest with purpose – and that’s how we’ve become a global market leader. Here, we grow by doing the right thing for the people we serve. And so can you.

We want to make success accessible to everyone. This is our opportunity. Let’s make it count.

Inclusion Statement

Vanguard’s continued commitment to diversity and inclusion is firmly rooted in our culture. Every decision we make to best serve our clients, crew (internally employees are referred to as crew), and communities is guided by one simple statement: “Do the right thing.”

We believe that a critical aspect of doing the right thing requires building diverse, inclusive, and highly effective teams of individuals who are as unique as the clients they serve. We empower our crew to contribute their distinct strengths to achieving Vanguard’s core purpose through our values.

When all crew members feel valued and included, our ability to collaborate and innovate is amplified, and we are united in delivering on Vanguard's core purpose.

Our core purpose: To take a stand for all investors, to treat them fairly, and to give them the best chance for investment success.
Show more Show less"
2805472132,Big Data Engineer,Global Payments Inc.,2021-10-30,United States,"Alpharetta, GA",Engineering and Information Technology,Full-time,IT Services and IT Consulting and Financial Services,"Every day, Global Payments makes it possible for millions of people to move money between buyers and sellers using our payments solutions for credit, debit, prepaid and merchant services. Our worldwide team helps over 3 million companies, more than 1,300 financial institutions and over 600 million cardholders grow with confidence and achieve amazing results. We are driven by our passion for success and we are proud to deliver best-in-class payment technology and software solutions. Join our dynamic team and make your mark on the payments technology landscape of tomorrow.

Summary Of This Role

We are looking for a Big Data Engineer to play a key role in building their industry leading Customer Information Analytics Platform. Are you passionate about Big Data and highly scalable data platforms? Do you enjoy building end to end Analytics solutions to help drive business decisions? And if you have experience in building and maintaining highly scalable data warehouses and data pipelines with high transaction volumes then we need you!!!

The full stack Data Engineer will design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for analytics and deep learning. Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes leveraging AWS technologies and Big data tools. logical abstraction layer against large, multi-dimensional datasets and multiple sources. Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture. Produce comprehensive, usable dataset documentation and metadata. Provides input and recommendations on technical issues to the project manager.

Preferred Basic Qualifications

5+ years of experience with detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools.

5+ years of work experience with very large data warehousing environment

3+ years of experience data modeling concepts

3+ years of Python development experience

2+ years’ experience in Big Data stack environments (EMR, Hadoop, Glue, Hive)

Experience with Kafka, Flume and AWS tool stack such as Redshift and Kinesis are preferred.

Experience in writing Spark ETL jobs

Experience using software version control tools (Git, Jenkins, Apache Subversion)

Demonstrated strength in architecting data warehouse solutions and integrating technical components

Good analytical skills with excellent knowledge of SQL.

Excellent communication skills, both written and verbal

Preferred Qualifications

Experience working with CDC solutions like Golden Gate, Syncsort, Attunity

Java Development Experience Is Preferred

Experience in gathering requirements and formulating business metrics for reporting.

Experience with Kafka, Flume and AWS tool stack such as Glue ETL, Redshift and Kinesis are preferred.

Experience building on AWS using S3, EC2, Redshift, DynamoDB, Lambda, QuickSight, etc.

AWS certifications or other related professional technical certifications

Experience with cloud or on-premise middleware and other enterprise integration technologies

Minimum Qualifications

Bachelor's Degree

Relevant Experience or Degree in: Computer Science, Management Information Systems, Business or related field

Typically Minimum 6+ Years Relevant Exp

Four-year college degree and 4 or more years, and/or a high school diploma with 6 or more years professional experience in full life cycle design and development to include IT architecture, banking industry experience, and understanding client requirements

Global Payments Inc. is an equal opportunity employer.

Global Payments provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex (including pregnancy), national origin, ancestry, age, marital status, sexual orientation, gender identity or expression, disability, veteran status, genetic information or any other basis protected by law. Those applicants requiring reasonable accommodation to the application and/or interview process should notify a representative of the Human Resources Department.
Show more Show less"
2798002456,Data Engineer required 2no,Zen & Art,2021-11-18,United States,New York City Metropolitan Area,,Contract,,"Python, Athena/Glue ,Dataframe , Redshift.
Show more Show less"
2819501981,(1356156)Data Engineer,Cisco,2021-12-03,United States,"Portland, OR",Information Technology,Full-time,"Computer Hardware Manufacturing, Computer Software, and Computer Networking Products","Who We Are

Today’s challenging business environment is more than that – it’s a period of disruption between the pandemic, global business change, and internal process complexity. For us to focus on simplicity and the best customer experience, we need great talent and the right skillsets to be successful. This is now a mantra for our Cisco leadership team and for us.

The Digital Enterprise Solutions team is changing the way we run Cisco’s operations by maximizing the power of technology, the best of business processes and superior data insights. Together, we will Reimagine the Cisco experience. Show the world how to Reinvent applications and leverage the future of the Internet to Showcase the power of Cisco our people, products, processes, systems, and data. Please join us and make this journey together!

What You'll Do



We have an outstanding opportunity for a Data Engineer that wants to develop their technical skills by crafting and building innovative cloud data pipelines between Anaplan, Oracle, Snowflake, and other data sources for our partners in the Sales and Finance organizations. You would play a critical role in the team guiding the tactical design and execution of our development teams. Responsibilities would include

Partnering with business architects, operational teams, and domain specialists to build, improve, test, deploy, document, and support existing data pipelines.
Automating and innovating on existing data flows to enable Data Science, Data Analytics, and Data Services that are essential for business transformation.
Managing a cloud-based data framework used in auditing millions of transactions daily to find compensation anomalies for Sellers.
Modernize legacy data pipelines to build configurable, reliable, and secure data transportation to critical Sales systems.
Follow agile development methodologies to delivery solutions and product features following industry standards.
Identifying and resolving issues raised by users.
Discerning impacts to downstream systems and working multi-functionally to explore solutions.


Who You'll Work With

As part of the Digital Enterprise Solutions team, you will be in a team focused on delivering capabilities and features for Sales Territory/Account Planning, and Financial Goaling. You will work with the Data & Analytics, Sales, Finance, and internal program teams to develop the strategy for new data features. You will partner with architects, leads, and project managers to implement innovative technical solutions. Through these collaborations you will drive exceptional experiences to showcase our technical capabilities through secure and scalable enterprise solutions.

Who You Are



A hardworking and experienced professional who enjoys digging into complicated problems and exploring details of technical solutions. Someone who has a clear passion for technology and thrives in bringing clarity to ambiguous situations. A standout colleague capable of influencing within and outside of the team, as well as being an agent for change and transformation. Someone with an ability to take the lead in developing business solutions and clearly communicate complex concepts.

Our Minimum Requirements Are As Follows

7+ years of professional experience as a Data Engineer or other technical role working closely with data.
Experience with AWS cloud based tools like Glue, SC3, and Lambda.
Expertise with databases like MongoDB, Oracle, and Snowflake, as well as data languages like SQL, Spark, Java, and Python.
Strong experience with source control systems such as GIT, and Jenkins for build deployments.
Proven experience in automating data pipelines and resolving complex data integration problems.
Familiarity with data visualization tools like PowerBI and Tableau.
Understanding of machine learning principles and algorithms.
Superb communication and collaboration skills.
Experienced in Agile and Waterfall development methodologies.
Understanding of software development lifecycles and tools, including design and operations.
Highly dedicated and execution-focused, with a willingness to deliver results.
Lead and maintain an agile partnership between business, operations, and IT.
Experienced in facilitating estimation sessions and value driven decision making.


Why Cisco

#WeAreCisco, where each person is unique, but we bring our talents to work as a team and make a difference powering an expansive future for all.

We adopt digital, and help our customers implement change in their digital businesses. Some may think we’re “old” (36 years strong) and only about hardware, but we’re also a software company. And a security company. We even invented an intuitive network that adapts, predicts, learns and protects. No other company can do what we do – you can’t put us in a box!

But “Digital Transformation” is an empty buzz phrase without a culture that allows for innovation, creativity, and yes, even failure (if you learn from it.)

Day to day, we focus on the give and take. We give our best, give our egos a break, and give of ourselves (because giving back is built into our DNA.) We take accountability, bold steps, and take difference to heart. Because without diversity of thought and a dedication to equality for all, there is no moving forward.

So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture geek? Many of us are. Passion for technology and world changing? Be you, with us!
Show more Show less"
2817388409,Data Engineer II,Rolls-Royce,2021-12-01,United States,"Indianapolis, IN",Information Technology,Full-time,"IT Services and IT Consulting, Machinery Manufacturing, and Staffing and Recruiting","Job Description

Data Engineer II

Indianapolis, IN

Please note, there is a change in our requirements regarding the Covid-19 vaccine. A detailed statement can be found below in the basic requirement section of the posting.

The Data Engineer II will collaborate with Data Solutions & Insights Team members, data owners, consumers and key Stakeholders to develop databases, develop data extraction-transformation-loading (ETL) applications, and create meaningful visualizations that allow the business to evaluate our data and to make informed decisions.

At Rolls-Royce, innovation is in our DNA. We pioneer integrated power and propulsion solutions across multiple markets. We embrace the power of data and technology and we aim to be Digital First in everything we do.

To ensure we continue to be pioneers of our industry, Rolls-Royce has a team of over 16,500 engineers around the globe. They include everyone from world experts in their field to those who manage hundreds of people and millions of pounds worth of investments. We recruit engineers at all levels and in a range of disciplines. And while we encourage specialization, we also offer freedom to cross-specialize and develop skills across a number of different areas.

Key Accountabilities

Delivering allocated projects in accordance with the project plan
Ensuring customer requirements are fully understood and adequately captured
Database development
Data preparation- Extract, Transform, Load (ETL)
Visualization design and implementation
Carrying out controlled definition, design, build, test, verification, and documentation

Rolls-Royce is a Military Friendly Employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or any other protected characteristic.

Basic Requirements

An Associate’s degree with 3+ years of experience in Computer Engineering, Data Engineering, Data Science or Informatics, or
A Bachelor’s degree with 1+years of experience in Computer Engineering, Data Engineering, Data Science or Informatics, or
A Master’s degree with 0+ years of experience in Computer Engineering, Data Engineering, Data Science or Informatics, or
A JD/PhD with 0+ years of experience in Computer Engineering, Data Engineering, Data Science or Informatics
In order to be considered for this opportunity, you must be a US Citizen
Intermediate level database development skills
Intermediate knowledge of Structured Query Language

In accordance with Executive Order 14042, its implementing guidelines, and our internal policies, candidates should be aware that after an offer is accepted, proof of vaccination against COVID-19 will be required for this position during the pre-employment screening. Individuals may apply for an exemption from the COVID-19 vaccination requirements due to a medical condition or religious belief. Please note, federal, state, customer or company policy COVID-19 requirements may change before or after the start date.

Preferred Requirements

Business Intelligence domain knowledge
Experience with BI tools such as Power BI, Tableau or Cognos Analytics
Experience with manipulation of data using Python
SQL Server development experience

Beyond tomorrow

We are an equal opportunities employer. We’re committed to developing a diverse workforce and an inclusive working environment. We believe that people from different backgrounds and cultures give us different perspectives. And the more perspectives we have, the more successful we’ll be. By building a culture of respect and appreciation, we give everyone who works here the opportunity to realize their full potential.

You can learn more about our global Diversity and Inclusion strategy here .

At Rolls-Royce we also support requests for flexible working arrangements wherever possible.

Due to the COVID-19 pandemic we are keeping our people safe by offering the option to work from home where possible and necessary. If you’re successful for this role, you’ll be expected to work from home on a temporary basis. When Rolls-Royce updates the safety protocols related to COVID-19, you may be required to work in multiple spaces (home, office, alternate locations, etc.) as needed across the work week. These may vary dependent on required tasks, the needs of the team, and the focus of the organization.

Closing date: December 14, 2021

Job CategorySystems Engineering & DevelopmentPosting Date30 Nov 2021; 00:11
Show more Show less"
2822662994,Data Engineer,Robin Healthcare,2021-12-01,United States,"Austin, TX",Information Technology,Full-time,"Computer Software, Financial Services, and Hospitals and Health Care","Robin Healthcare is a tech-healthcare startup with a mission to transform our healthcare system from its very core: the doctor-patient encounter. We marry medical scribing with the Robin Assistant™, our proprietary smart device, to help streamline documentation, coding, and other administrative tasks in the background of natural patient care.

Why:

The purpose of this role in the short term is to prototype and build out the data sets, reports, KPIs and dashboards to operate Robin's business on the new Assist platform, with an explicit goal to democratize Robin's most widely-used data for teams outside the Data Science & Analytics group to consume. In the longer-term, this role will be responsible for analysis, insights, reports, and actionable recommendations for the most challenging business problems at Robin. This role will also provide strong technical guidance to other data analysts in the Data Science & Analytics group.

Experience needed:

General Purpose language like Python, R, Scala, 3 years experience in the industry.
Must have worked with deployed data.
Familiarity writing production ETL using data technologies that allow analysis of large amounts of data (Spark, Hadoop, Hive, Presto, etc)


What You'll Be Doing:

Use data, logic, and intuition to improve business outcomes through analysis, insights, reports, and actionable recommendations
Develop democratized dashboards, data sets, and KPIs that empower less technical owners and operators across the business to make data-driven business decisions
Design durable and forward-looking data models and data sets for the Data Science & Analytics group to develop on and provide technical direction to other analysts
Partner with Product Management, Engineering, and Creative to condense feedback from users & customers, explore & experiment to (in)validate hypotheses, and measure the outcomes of product initiatives
Partner with Client Success and account managers to build creative tools and insights to increase provider and practice satisfaction, grow revenue, and communicate performance to our customers
Partner with Operations, Talent Acquisition, and Content to create diagnostic metrics and reveal opportunities to increase the satisfaction, efficiency, and performance of our scribe population


What You'll Bring:

Adept at distilling complicated analytical concepts to broad audiences and influencing decision making through compelling data narratives
Experience building clean visualizations and performant dashboards using Jupyter, Tableau, Looker, or similar software
Experience writing performant code in BigQuery SQL
Expert programming skills in one or more general purpose languages (Python, R, Scala, etc.)
Experience with statistical and machine learning methods to build descriptive and predictive models
Familiarity writing production ETL using data technologies that allow analysis of large amounts of data (Spark, Hadoop, Hive, Presto, etc)
Familiarity with a variety of business domains and their common data and analytics needs


Graduate-level degree or equivalent proven experience in a quantitative field such as mathematics, statistics, engineering or natural sciences

What We Offer

Amazing Mission - Break new ground in a stable, well-funded company and fix a broken healthcare system
Barrier Free Culture- No Micro-Management!! We Remove Bureaucracy and Empower Our People
Decide How and When You Work
100% Remote Work Environment OR WeWork Space Of Your Choice
Your Choice of Laptop (PC or Mac) and Home Office Setup Stipend
Flexible Schedule- Build Your Work Around Your Life
Generous Stock Options
Unlimited Vacation Time (Must Take At Least 2 Weeks and Shut Off Your Phone)
Great Benefits - Medical, Dental, Vision, Life, Disability, 401k, etc.
Paid Family Leave (Up To 16 Weeks)
Investment Into Your Career With Resourcing For Education And Development
Close, Fun, And Engaging Community
Work With Brilliant, Hard-Working, Caring People Daily
Netflix Watch Parties, Pilates/Yoga classes, Clubs & Social Events


Equal Opportunity Employer: Successful applicants must be eligible to work in the US (visa sponsorship is not provided at this time) and must be able to pass a pre-employment background test. Robin Healthcare is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

To request reasonable accommodation or if you need assistance to complete the job application, contact hiring@robinhealthcare.com
Show more Show less"
2818871827,Data Engineer,CYR3CON,2021-12-03,United States,"Tempe, AZ",,Full-time,,"CYR3CON is looking for a driven data engineer with profound coding skills for its database operations to ensure high integrity and availability of data collected from natural, uncurated data sources. Maintain and monitor data pipeline components to normalize and process data to support AI-models producing meaningful results and enabling optimal UX.




Minimum requirements:

Outstanding Python 3.x programming skills
Attention to detail
Fast autonomous learner with exceptional deductive reasoning skills
Experience in MongoDB queries
Previous work experience in (Big) Data analyses
Have a strong grip on the foundational material of computer science

Preferred qualifications:

Contributions to open source projects 
Understanding of internal working of NoSQL databases
Work experience on AWS

Qualifications for Advanced Considerations:

Strong experience designing scalable solutions with distributed, Big Data technologies  like Spark and Hadoop
Master degree with focus in Big Data or Databases
AWS certification
Excellent working knowledge of MongoDB management
Experience with DevOps and automation
A great Github profile
Experience with Text search engines like ElasticSearch




This position requires meticulous attention to detail, deductive reasoning and autonomous fast learning as we are looking for profound and exhaustive solutions that ensure data integrity, reliability, and fault tolerance. The ideal candidate’s most towering objective will always be to provide quality data to our customers in a timely manner. Exceptional organizational and project management skills (Agile) are a must.

Show more Show less"
2783717201,Software Engineer / Data Transformation (Spark / Splunk),Tesla,2021-10-13,United States,"Palo Alto, CA",Engineering and Information Technology,Full-time,"Renewable Energy Semiconductor Manufacturing, Motor Vehicle Manufacturing, and Utilities","The Role

As a member of the Infotainment Software team, you will utilize existing data pipelines, and establish new ones, to bring meaningful insights to Infotainment software performance and usage in our rapidly expanding global customer fleet.

The ideal candidate in this position will be passionate about big-data analytics and a quick-learner with extensive experience in transforming raw data into meaningful visualizations and tools for others. This will involve building, maintaining, and improving Splunk, Spark, and Python based Kubernetes tools and applications to understand and improve customer experience with the Tesla Infotainment System with data driven insights.

Responsibilities

Perform complex data analysis from raw data to meaningful insights using Splunk, Spark, and Python
Develop, maintain, and improve CI/CD pipelines to support Extract, Transform, and Load (ETL) applications
Support application level development, monitoring, support, and debugging

Requirements

BS or higher in computer science/engineering, software engineering, physics, math, electrical engineering or proof of exceptional skills in related fields, with practical engineering experience
3+ years of experience working with advanced data analysis tools
1+ years of experience with Python, Splunk, Spark, and SQL; advanced Spark API experience preferred
Experience with Kubernetes, Docker, and CI/CD methods
Strong aptitude to collaborate with different internal stakeholders to understand requirements and developing systems and tools to meet them
Excellent oral and written communication skills
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
A passion and curiosity for data and data-driven decision making

Employee Benefits

As a full time Tesla employee you will receive full benefits from day 1 for you and your dependents.
Kaiser and UnitedHealthcare PPO and HSA plans (including infertility coverage)
3 medical plan choices with $0 paycheck contribution
Vision & dental plans (including orthodontic coverage)
Company paid Life, AD&D, short-term and long-term disability
401(k), Employee Stock Purchase Plans, and other financial benefits
Employee Assistance Program, Paid Time Off, and Paid Holidays
Back-up childcare and employee discounts
Show more Show less"
2812798388,Data Engineer,"Georgia IT, Inc.",2021-11-29,United States,"Bedminster, NJ",,Contract,,"Data Engineer

Location: Bedminster, NJ

Duration: Contract

Rate: DOE

Required:

Very Strong in SQL (2012 or better):  stored procedures, functions, views, joins, import/export data, and the ability to develop queries from SQL
Broad Knowledge of BIDS (Business Intelligence Development Studio) with heavy concentration in SSIS
Experience in Tableau and Power BI
Expertise in Excel and advance excel skills, must be able to: connect to various data sources, conditional formatting, pivot tables & pivot reporting, functions & formulas, and sorting & filtering
Have the ability to identify data anomalies in a timely manner.
Previous Healthcare experience
Previous Fintech experience (banking, banking integrations, treasury, payments)




Desired:

Visual Studio .NET




What You Will Do

Design and support the database and table schemas for new and evolving sources of data being brought into the data warehouse
Create and support the Analysis Services
Monitor and troubleshoot performance issues
Define and promote the team’s design principles and best practices
Work with business teams to be able to define requirements for real time reporting
Show more Show less"
2789622812,Big Data Engineer,Rakuten Americas,2021-12-03,United States,"Seattle, WA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Job Description:

SUMMARY:

The Big Data Engineer is part of the global Rakuten Catalog Platform Department. The Catalog Platform provides services to global business units including an accurate, compelling catalog with millions of products and highly relevant search services. The team uses Big Data technologies, Cloud infrastructure, open source scalable search platform and cutting-edge machine learning/statistical modeling.

The Big Data Engineer will be responsible for participating in design and development of Product Catalog and Search components including storage, search, large data processing, APIs, analytics and web services. Be part of an awesome R&D team where you get inspired by talented people, challenges and mission to change the global e-commerce landscape!

Key Responsibilities

Participate in design & development of Product Catalog & Search
Work on implementing storage integration
Work on developing code and unit testing search index integration
Implement large data processing (stream & batch) solutions
Work on enhancing APIs or implementing new APIs
Implement analytics jobs to process large amount of data

MINIMUM REQUIREMENTS (Knowledge, Skills, Abilities

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Strong knowledge of Java
Strong knowledge of design patterns, OOPS principles and data structures
Strong knowledge of at least some of the following frameworks/technologies – Hibernate, Spring, REST, XML, JSON, ActiveMQ, Kafka
Experience with tools and technologies like Gradle, Maven, Jenkins, git, IntelliJ, Eclipse, Docker to support end to end software development
Experience with Relational databases, queries and RDBMS best practices
Strong troubleshooting and performance tuning skills
Ability to work in a fast-paced Agile and rapid deployment in the Cloud/SaaS environment.
Able to effectively communicate across teams and roles.

Qualification Requirements

BS/MS in Computer Science or a related field
1-5 years of solid Java back-end experience

RAKUTEN SHUGI PRINCIPLES

Our worldwide practices describe specific behaviors that make Rakuten unique and united across the world. We expect Rakuten employees to model these 5 Shugi Principles of Success.

Always improve, always advance. Only be satisfied with complete success - Kaizen.
Be passionately professional. Take an uncompromising approach to your work and be determined to be the best.
Hypothesize - Practice - Validate - Shikumika. Use the Rakuten Cycle to success in unknown territory.
Maximize Customer Satisfaction. The greatest satisfaction for workers in a service industry is to see their customers smile.
Speed!! Speed!! Speed!! Always be conscious of time. Take charge, set clear goals, and engage your team.

Show more Show less"
2815489158,Data Engineer,Pave,2021-12-01,United States,"San Francisco, CA",Information Technology,Full-time,Computer Software,"About Pave

Here at Pave, you’ll be joining a world class team with tremendous growth potential. We’re a Series B start-up backed by top Silicon Valley investors Andreessen Horowitz (a16z), Y Combinator Continuity, and Bessemer Venture Partners.

The world of compensation is broken today. Pave is here to fix it. Today, teams cobble together hundreds of messy spreadsheets and outdated surveys to determine how to compensate their workforce. Covid and remote work have made the situation far more difficult, and the notion of “market compensation” is now confusing to everyone.

At Pave, you will reinvent the world of compensation and help build a more transparent future of work.

Pave allows companies to benchmark compensation to leaders in their industry, analyze internal compensation data and make the right adjustments, then visually communicate compensation to their employees. We’re building the world’s largest real-time compensation data platform to accomplish this goal, and are acquiring amazing customers like Credit Karma, Discord, and Allbirds at an unbelievable pace. Come join our team on this mission!

Our Team

Do you want to work on meaningful data science projects that truly make the world a better place? Are you interested in working with the world’s largest and most complete real-time compensation dataset? Would you rather spend more time delivering value than cleaning data? Do you want to be a force multiplier who works with a variety of tools, domains, and stakeholders?

At Pave, we have one of the world’s most interesting datasets (seriously, this is every data scientist’s dream). We have almost every characteristic you could want, from compensation characteristics to demographic characteristics to location data to, well, anything you could want analyze. Oh, did we mention it was clean? If you said yes to the above, come help us make a more fair and transparent world at Pave.

Your Primary Focus

At Pave you'll be working with data scientists and other engineers to

understand their needs and
make data easily and quickly accessible by building pipelines around production and non-production processes in effort to make data quickly and easily available throughout Pave.

This means you'll be:

Creating and maintaining pipelines to support analytics, reporting, machine learning, and product feature
D esigning and maintaining relational database architectures
Creating analytic dashboards in Looker to support engineering, customer, or data science objectives

About You


2-3+ years of building pipelines to support machine learning and/or products at a large scale
2-3+ years of working with stakeholders to define and deliver successful outcomes
Expert knowledge of SQL and Python
SQLAirflow experience is a nice-to-have!
Looker experience is a nice-to-have!

Life at Pave

Pave is growing incredibly fast, and we have high ambition. We've complemented our ambitious goals with a world-class culture and a variety of early startup benefits. As an early hire, you’ll play a key role in shaping what this looks like, but some of the benefits that we already offer include:

Compensation: Competitive salary and startup equity (it's in our DNA)

Wellness: Top tier health insurance along with exercise & wellness benefits

Food: All meals while working, plus snacks. We take our snacking seriously

Tech: Choose your laptop and accessories of choice

Team: Retreats, happy hours, and events for our team, friends, and family

Flexible Time Off: Take the time you need

WFH Wednesday: A dedicated work from home day each week

Location: Our company is based in San Francisco's SoMA district with a high energy in-person culture

And much more... we want all Pave employees to define the best benefits based on our combined interests.

Pave is committed to a diverse and inclusive workforce. We are an equal opportunity employer and do not discriminate on the basis of race, ethnicity, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please email recruiting@pave.com.
Show more Show less"
2826739984,Big Data Engineer,"Pinnacle Group, Inc.",2021-11-09,United States,"Houston, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Must be open to work on W2

Job Title: Big Data Engineer

Location: Houston, TX & Wilmington, DE

Duration: 12 Months Contract

Description

Build spark python based solutions for implementing ML models on Hadoop and AWS platforms
Identify and develop opportunities to improve firm processes and tools for automation.
Work with other members of scrum team to create solutions to improve business efficiency.

Regards,

Abdul Waseem

Recruiter

Abdul.Waseem@pinnacle1.com
Show more Show less"
2827281503,Data Engineer,HealthVerity,2021-12-04,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","How you will help

You will support the engineering team’s data endeavors, diving in to fix issues, optimize processes, and automate what you do more than once. You’ll use the best tools for the job, whether modern and revolutionary or time tested and proven, to deliver elegant, scalable solutions that meet business and technical needs.

What you will do

Work with internal stakeholders to load data into HealthVerity's data warehouse
Troubleshoot and resolve issues relating to data integrity
Help establish procedures and best practices for transforming and storing dataLead requirements gathering around data pipeline automation improvements
Work with some of the most exciting open-source tools like Spark, Hadoop, Docker, Airflow, Zeppelin
Leverage distributed computing and serverless architecture such as AWS EMR & AWS Lambda, to develop pipelines for transforming data
Enjoy the peace that comes with working in a mature software development environment
Marvel at the speed with which your creation makes it into production
Research and implement new technologies with a team of developers to execute strategies and implement solutions
Produce peer reviewed quality software
Solve complex problems related to the real-time discovery of large data


About You

Experienced in writing scalable applications on distributed architectures
Data driven, testing and measuring as much as you can
Eager to both review peer code and have your code reviewed
Comfortable on the command line and consider it an essential tool
Confident in SQL, you know it, write smart queries, it’s no big deal


Required Skills And Experience

5+ years of work experience
3+ years of experience with Python and Scala
3+ years of experience with PySpark and Spark-SQL (writing, testing, debugging spark routines)
1+ years of experience with AWS EMR, AWS S3 service.
Comfortable using AWS CLI and boto3
Comfortable working in remote environmentsComfortable using *nix command line (shell scripting, AWK, SED)
Experience with MySQL and Postgres

Bonus experience

Experience with Apache Airflow
Experience with Apache Zeppelin
Experience with healthcare data


About HealthVerity

Pharmaceutical manufacturers, payers and government organizations have partnered with HealthVerity to solve some of their most complicated use cases through transformative technologies and real-world data infrastructure. The HealthVerity IPGE platform, based on the foundational elements of Identity, Privacy, Governance and Exchange, enables the discovery of RWD across the broadest healthcare data ecosystem, the building of more complete and accurate patient journeys and the ability to power best-in-class analytics and applications with flexibility and ease. Together with our partners, HealthVerity has built the modern way to data for the health insights economy. To learn more about the HealthVerity IPGE platform, visit www.healthverity.com.

Our company challenges

Empowering clients with highly rewarding data discovery and licensing tools
Ingesting and managing billions of healthcare records from a wide variety of partners
Standardizing on common data models across data types
Orchestrating an industry-leading HIPAA privacy layer
Innovating our proprietary de-identification and data science algorithms
Building a culture that supports rapid iteration and new possibilities

We have big plans

The infrastructure and culture we are building will provide an environment that cultivates innovation. We want to move fast knowing we can fix anything we break along the way. If a new need arises, we want to turn around a solution quickly. We want to solve our challenges in ways that create even more possibilities. We’ve created a platform that will scale to support an ever-growing array of data providers and innovative products and services. You must be able to think big while still delivering on near-term requirements.

HealthVerity is an equal opportunity employer devoted to inclusion in the workplace. We believe incorporating different ideas, perspectives and backgrounds make us stronger and encourages an environment where ageism, racism, sexism, ableism, homophobia, transphobia or any other form of discrimination are not tolerated. At HealthVerity, we’re working towards an innovative and connected future for healthcare data and believe the future is better together. We can only do that if everyone has a seat at the table. Read our Equity Inclusion and Diversity Statement.

If you require a reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to careers@healthverity.com

HealthVerity offers in-office and remote options, so you can work from anywhere within the US!


Show more Show less"
2791842413,Data Engineer,IBM,2021-11-12,United States,"Los Angeles, CA",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2790600824,Big Data Engineer,Motion Recruitment,2021-11-11,United States,"Bethesda, MD ",Engineering and Information Technology,Contract,Staffing and Recruiting,"A large consulting company is looking to hire a Big Data Engineer, to work on a 3 month contract-to-hire basis. Based in Bethesda, Maryland, this company needs someone with ideally 4+ years of professional experience, and who has experience with ETL/Big Data tools, experience w/ Azure and Snowflake, and CI/CD pipeline experience.




Required Skills

3+ years of experience
Azure
Snowflake
ETL

Show more Show less"
2819142416,Data Engineer,CloudIngest,2021-12-03,United States,Atlanta Metropolitan Area,,Contract,,"We are looking for a Data Engineer for the below skills. Please revert back if you would be interested on this role.

 

Location: Remote

 

4 + years of experience in data processing

The developer must have sound knowledge in Apache Spark and Python programming.

Deep experience in developing data processing tasks using pySpark such as reading data from external sources, merge data, perform data enrichment and load in to target data destinations.

Experience in deployment and operationalizing the code is added advantage

Databricks in Azure is a must

 

Show more Show less"
2767577055,"Engineer, Data",Chainalysis Inc.,2021-12-02,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Chainalysis has become known as the leader in blockchain investigation and compliance software. Our products have built trust in blockchains by taking down terrorist financing campaigns, disrupting major ransomware operations, identifying the Twitter hackers, and more.

Now, we are building the blockchain data platform for cryptocurrency. Data engineers will be critical to that mission by building and scaling the ETL pipelines, data stores, and services our customers rely on every day to stop crime, understand risk, and strategize about their business. Working alongside infrastructure and security-focused engineers, they obsess over making our services highly available and safe for our customers to use for their most sensitive and real-time blockchain workflows. They deeply understand what is possible with cloud-native technologies and use those insights to enable our customers to push the boundaries of the cryptocurrency landscape.

In one year you’ll know you were successful if…

You have created efficient data pipelines, leveraging the most relevant services from AWS, and have made data consumable for downstream systems and services.
You’ve improved data quality and have made new datasets available to our product suite that detect activities for market manipulation, fraud, behavioral patterning, and more.
You have built cloud-native data ingestion and aggregation processes that intake gigabytes of data per day.
You have helped modernize our stack to a streaming architecture.
Your team’s services are easy to set up locally and their health in production is simple to understand.
You have debugged production issues and participated in a blameless post-mortem process to make our systems stronger.

A Background Like This Helps

Designed and implemented microservices-based systems in a major cloud provider like AWS or GCP.
Experience with object-oriented programming languages. We mostly use Java but appreciate a variety of languages!
Working SQL knowledge
Experience with Python
Experience in using event-streaming platforms such as Kafka
Knowledge of workflow orchestration tools such as Airflow
A bias to ship and iterate alongside product management and design partners
You have regularly participated in code and architecture reviews with your team
Exposure to or interest in the cryptocurrency technology ecosystem
Experience with Terraform and Kubernetes is a plus!
1-4 years of experience

At Chainalysis, we help government agencies, cryptocurrency businesses, and financial institutions track and investigate illicit activity on the blockchain, allowing them to engage confidently with cryptocurrency. We take care of our people with great benefits, professional development opportunities, and fun.

You belong here.

At Chainalysis, we believe that diversity of experience and thought makes us stronger. With both customers and employees around the world, we are committed to ensuring our team reflects the unique communities around us. Some of the ways we’re ensuring we keep learning are an internal Diversity Committee, Days of Reflection throughout the year including International Women’s Day, Juneteenth, Harvey Milk Day, and International Migrant’s Day, and a commitment to continue revisiting and reevaluating our diversity culture.

We encourage applicants across any race, ethnicity, gender/gender expression, age, spirituality, ability, experience and more. Additionally, if you need any accommodations to make our interview process more accessible to you due to a disability, don't hesitate to let us know. You can learn more here. We can’t wait to meet you.

Applying from the EU? Please review our Candidate GDPR Notice.

By submitting this application, I consent to and authorize Chainalysis to contact my former employers, and any and all other persons and organizations for information bearing upon my qualifications for employment. I further authorize the listed employers, schools and personal references to give Chainalysis (without further notice to me) any and all information about my previous employment and education, along with other pertinent information they may have, and hereby waive any actions which I may have against either party(ies) for providing a reference. I understand any future employment will be contingent on the Company receiving satisfactory employment references.

Chainalysis COVID-19 Policy - USA

All employees are required to have or obtain a COVID-19 vaccination as a condition of employment at Chainalysis, unless an exemption has been approved. All employees shall be required to report their vaccine status. All new employees shall be required to provide proof of their vaccination status prior to the start of their employment.

Chainalysis COVID-19 Policy - EMEA

As an employer, Chainalysis is obliged to ensure a healthy and safe working environment. This means that we must try to prevent the coronavirus from spreading inside the workplace and all employees are obliged to follow the local regulations issued by the relevant health authorities.
To help support a safe work environment, we encourage all employees in EMEA to get fully vaccinated against COVID-19.
Employees will not be required to attend an event or in-person customer meeting.
Employees in the EU and the UK are allowed to travel internationally for internal meetings to any country deemed “green or amber” by the EU and the UK authorities. All attendees for Chainalysis in-person events or meetings will be required to adhere to the following guidelines:
International travel will only be permitted if you receive approval from both your manager and Executive Leader
You must familiarize yourself and comply with any screening/safety protocols imposed by the entity/individual hosting the in-person meeting or event
You must comply with any and all safety guidelines and travel restrictions established by applicable law
If you are in close or proximate contact with others at the event/customer site and test positive for COVID-19, you must immediately notify the People Team and avoid contact with others for 10 days

Chainalysis COVID-19 Policy - APAC

With circumstances changing on a regular basis and parts of our APAC team going in and out of mandatory lockdown, APAC will continue to follow country legislation and guidelines.


Show more Show less"
2819640987,Data Engineer,Giig,2021-12-03,United States,United States ,,Full-time,,"Project Description:

Our client is a global online learning platform that offers anyone, anywhere, access to online courses and degrees from leading universities and companies.

Looking for 3 senior engineers.




Must have skills: Django, SQL




Nice to have skills: AWS (Amazon Web Services), Azure (Microsoft Azure), Spark, Amazon Kinesis




Project Responsibilities:

Engineers will work with the current team to build ETL pipelines for data lakes.

Data modeling - understand the data and how it is modeled, especially the analytical part of it.
Very good coding experience/computer science background - Python, SQL
Experience with dealing with Data, an eye for ambiguity




Location Constraints: 9am-1pm EST




Expected Engagement Length: 12 months




Please apply here for immediate consideration!

Show more Show less"
2780743251,Data Engineer,Allegiant,2021-11-05,United States,"Las Vegas, NV",,Full-time,,"The Data Engineer is responsible for architecting, developing, and maintaining Allegiant’s enterprise data infrastructure. The Data Engineer will oversee our transition from on-premise data marts to a cloud hosted warehouse data and develop the next generation of our data tools. 




Visa Sponsorship Available

Yes




Minimum Requirements

Combination of Education and Experience will be considered. Must be authorized to work in the US as defined by the Immigration Act of 1986. Must pass a Criminal Background Check.

Education: Bachelor’s Degree

Education Details:  In Computer Science, Engineering, or a related technical field.

Years of Experience:  

Minimum three (3) years of experience as a Data Engineer.

• Strong SQL Server and Amazon Redshift skills.

• Python development skills strongly preferred.

• In depth understanding of database architecture.

• Work experience in data mart development and data warehousing, including experience working with ETL processes, OLAP structures, and dimensional modeling.

• Manage time effectively to meet deadlines across multiple projects.

• Excellent critical thinker and effective problem solver with creative solutions.

• Detail oriented and highly organized.

• Results-driven; accepting responsibility for individual performance and contributions to team projects.

• Ability to work a hybrid schedule with the expectation to be in the office 3 days a week or 12 days a month (when campus is open) and to work he remainder remotely.

• Must be able to work in a high pressure environment.

• Must have sufficient vision and ability to safely perform the essential functions of the position. 




Job Duties

• Develop and maintain Allegiant data marts and data warehouses.

• Migrate Allegiant’s existing on-premise infrastructure to the AWS Redshift environment.

• Serve as a database and SQL guru for business teams.

• Design, build, and implement data transformation, conversion, and validation of data required for BI applications.

• Maintain SQL Server and Redshift data marts, databases, and data warehouses.

• Provide services to replicate data from various data sources to reporting database servers for enterprise reporting applications.

• Work closely with the business to understand and translate user requirements into practical data models.

• Develop and maintain repeatable, systemic processes while finding ways to make internal team processes more efficient.

• Other duties as assigned.




Physical Requirements

The Physical Demands and Work Environment described here are a representative of those that must be met by a Team Member to successfully perform the essential functions of the role. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of the role.

Office/IT - While performing the duties of this job, the Team Member is regularly required to stand, sit, talk, hear, see, reach, stoop, kneel, and use hands and fingers to operate a computer, key board, printer, and phone. May be required to lift, push, pull, or carry up to 50 lbs. May be required to work various shifts/days in a 24 hour situation. Regular attendance is a requirement of the role. Exposure to moderate noise (i.e. business office with computers, phones, printers, and foot traffic), temperature and light fluctuations. Ability to work in a confined area as well as the ability to sit at a computer terminal for an extended period of time. Some travel may be a requirement of the role.




COVID-19 Vaccination National Mandate

Allegiant Travel Company is a government contractor and has more than 100 employees. To comply with the Safer Federal Workforce COVID-19 Vaccine Mandate, all team members must be fully vaccinated with an FDA approved COVID-19 vaccination by December 8, 2021 in order to remain employed by Allegiant Travel company and all related subsidiaries. Proof of vaccination will be required. Requests for medical and religious exemptions will be considered with substantiating documentation.




Essential Services Provider

Allegiant as a national air carrier is deemed an essential service provider during declared national and state emergencies. Team Members will be required to report to their assigned trip or work location during national and state emergencies unless prohibited by local, state or federal order.




EEO Statement

Equal Opportunity Employer: Disability/Veteran

For more information, see https://allegiantair.jobs




People of color, women, LGBTQIA+, immigrants, veterans and persons with disabilities are encouraged to apply.

Show more Show less"
2812761388,Data Engineer,Nintendo,2021-11-04,United States,"Redmond, WA","Business Development, General Business, and Analyst",Full-time,"Computers and Electronics, Entertainment, and Computer Games","Nintendo of America Inc.

The worldwide pioneer in the creation of interactive entertainment, Nintendo Co., Ltd., of Kyoto, Japan, manufactures and markets hardware and software for its Nintendo Switch™ system and the Nintendo 3DS™ family of portable systems. Since 1983, when it launched the Nintendo Entertainment System™, Nintendo has sold billions of video games and hundreds of millions of hardware units globally, including Nintendo Switch and the Nintendo 3DS family of systems, as well as the Game Boy™, Game Boy Advance, Nintendo DS™ family of systems, Super NES™, Nintendo 64™, Nintendo GameCube™, Wii™, and Wii U™ systems. It has also created industry icons that have become well-known, household names, such as Mario, Donkey Kong, Metroid, Zelda and Pokémon. A wholly owned subsidiary, Nintendo of America Inc., based in Redmond, Wash., serves as headquarters for Nintendo’s operations in the Americas. For more information about Nintendo, please visit the company’s website at http://www.nintendo.com.

Nintendo is an equal opportunity employer. We offer a welcoming and inclusive environment in service to one another, our products, the diverse consumers we represent, and the communities we call home. We do all of this with kindness, empathy and respect for each other.

Description Of Duties

Design, implement and support stable, scalable data pipelines that cleanse, structure and integrate disparate big data sets into a readable and accessible format for end user analyses and targeting.
Develop quality framework to ensure delivery of high quality data and analyses to stakeholders.
Implement/improve version control, deployment strategies, notifications to ensure product quality, agility and recoverability.
Work with business customers in understanding the business requirements and implementing data solutions.
Manage small projects, hold stakeholder communication and ensure objectives are met.

Summary Of Requirements

3+ years of quantitative and qualitative experience in building fault tolerant ETL data flows in large scale data warehouses and BI reporting systems.
Implement data structures using best practices in data modeling, ETL/ELT processes, and SQL.
Hands-on knowledge on Hadoop, Hive, Presto, AWS Services, Redshift.
Hands-on knowledge in using advanced SQL queries (analytical functions), experience in writing and optimizing efficient SQL queries
1+ years of experience with scripting in Python.
Experienced in testing and monitoring data for anomalies and rectifying them.
Excellent communication skills to be able to work with business owners to develop and define key business uses and to build data sets that address them.
Experience in working with Data visualization tools such a Tableau is a plus.
Prior experience with marketing data is preferred.
Bachelor’s degree or equivalent in an engineering or technical field such as Computer Science, Physics, Mathematics, Statistics, Engineering or similar.
Show more Show less"
2795146119,Data Engineer,Activision Blizzard,2021-10-17,United States,"Austin, TX","Design, Information Technology, and Engineering",Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Job Title

Data Engineer

Requisition ID

R009328

Job Description

Activision is seeking a high performing Data Engineer to the join the Corporate IT Business Intelligence team. The Data Engineer will be working closely with architects/product owners/business analysts and various functional teams to understand the data requirements and implement solutions in Google Cloud Platform.

This position will be part of the Business Intelligence team being responsible for the design and development of data pipelines to extract, transform, and load data from various internal/external data sources in varied data formats to the cloud data warehouse. The position will have opportunities to push the boundaries of new business capabilities using new google technologies including AI & ML. If you want to create amazing user experiences using the latest technologies, then this is the right job for you.

Responsibilities

Priorities can often change in a fast-paced environment like ours, so this role includes, but is not limited to, the following responsibilities

Work with architects and business partners to build out technical solutions to import data from external cloud and internal application sources, utilizing industry standards to cleanse, integrate, transform, and load this data into the cloud data warehouse
Partner with cross-functional teams to design and implement data requirements to drive organizational strategies and objectives.
Develop and support the entire data warehouse lifecycle, including requirements gathering, data profiling, design, development, testing, ongoing support and enhancements for analytics and management teams.
Design, implement & maintain ETL procedures for intake of data from both internal and cloud sources; ensure data is verified and quality is checked. ETL/ELT knowledge is required.
Create complex SQL queries, data transformation & aggregations to support analytics.
Consult with business partners, analytics teams, management, and other business analysts to clarify program objectives, determine scope, identify problems, and recommend solutions
Uses comprehensive knowledge and understanding of relational data base concepts, including data architecture, operational data stores, ETL/ELT processes, interface processes, multidimensional modeling, data warehouse concepts, master data management, and data manipulation.
Work with REST APIs to integrate third party data sources to the data warehouse
Support implemented BI solutions by working with the infrastructure teams to carry out monitoring, tuning, and performance analysis, addressing user questions regarding data integrity, and communicating functional and technical issues.
Participate in administering, maintenance, patching and upgrade of ETL/ELT and visualization tools.

Player Profile

3+ years’ experience in designing, building and operationalizing enterprise data solutions and applications using one or more of the leading cloud providers. GCP being preferred
Required experience with GCP or similar cloud tool like - Spark, Hive, Cloud DataProc, Cloud Dataflow, Apache Beam/ composer, BigQuery, Cloud PubSub, Cloud storage & Cloud Functions.
4+ years’ hands on experience working with an ELT/ETL tools for data transformation.
4+ years’ experience working in SQL using relational/columnar databases such as BigQuery, Redshift etc.
3+ years’ experience working with python and Unix scripting
2+ years’ experience working with Visualization tools like Tableau/Looker/Qlik etc.
Experience migrating applications from on-premise to cloud platforms.
Experience with data warehouse design and participated in at least 1 end to end cloud data warehouse implementation
Experience implementing data warehouse data segregation and security policies in a cloud environment.
Highly organized team player with the ability to innovate, multi-task and set priorities effectively
Self-starter with strong verbal and written communication skills
Ability to interface effectively and decisively with all infrastructure teams, various levels of management & departments.
Must have a solid understanding of BI best practices and advanced knowledge of data structures, modeling, structured query language (SQL) and data warehouse techniques.

Pluses

Experience working with Git or other cloud version control tools
Experience with ML & AI capabilities.
Experience working with and administering Tableau Server.
Experience working with cloud platforms GCP or AWS
Experience working with Java
Experience working in the entertainment or video game industries

Our World

Activision Blizzard, Inc. (NASDAQ: ATVI), is one of the world's largest and most successful interactive entertainment companies and is at the intersection of media, technology and entertainment. We are home to some of the most beloved entertainment franchises including Call of Duty®, World of Warcraft®, Overwatch®, Diablo®, Candy Crush™ and Bubble Witch™. Our combined entertainment network delights hundreds of millions of monthly active users in 196 countries, making us the largest gaming network on the planet!

Our ability to build immersive and innovate worlds is only enhanced by diverse teams working in an inclusive environment. We aspire to have a culture where everyone can thrive in order to connect and engage the world through epic entertainment. We provide a suite of benefits that promote physical, emotional and financial well-being for ‘Every World’ - we’ve got our employees covered!

The videogame industry and therefore our business is fast-paced and will continue to evolve. As such, the duties and responsibilities of this role may be changed as directed by the Company at any time to promote and support our business and relationships with industry partners.

Activision is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, protected veteran status, or any other basis protected by applicable law and will not be discriminated against on the basis of disability.
Show more Show less"
2824514940,Data Engineer,PARAGON Alpha - A Hedge Fund Talent business,2021-12-02,United States,New York City Metropolitan Area,Information Technology,Full-time,Investment Management,"We have a new live position with a leading Global Multi-Strategy Hedge Fund who are seeking to hire a Data Engineer to join an expanding Systematic Trading Platform.




Requirements:

Python, Java (or C++), SQL experience
Exposure to Data Modelling
Broad knowledge & experience of database
Exposure to cloud technologies and data infrastructure
Knowledge of financial data
Exposure to KDB or similar time series processing technology




Qualifications:

Bachelors in Computer Science, Engineering, Statistics, or STEM related discipline with excellent academic credentials
Show more Show less"
2812761857,Data Engineer,EXL,2021-11-29,United States,United States,,Full-time,,"Job Description – Data Engineer




The Data Engineer will be responsible for utilizing their analytical and programming skills to analyze and interpret large sets data in Cloud environment and/or On-premise data. Working with project lead and other business leaders you will be responsible for defining objectives, determining timelines and advanced business analysis and presentation of results to the lead.

Location: USA

Hot Skills: databricks, Spark, Python/Java/Scala, SQL, Hive, One or more cloud platforms (Azure/GCP/AWS)

Job Description

·        Define technical scope and objectives through research and participation in requirements gathering and definition of processes

·        Ingest and Process data from various sources in raw, structured, semi-structured, and unstructured format into Big Data ecosystem

·        Experience in building Data Pipeline or being part of one full cycle implementation  - desired skill

·        Expertise in Big Data technologies in Hadoop ecosystem

-         Spark, Yarn, Kafka, Oozie, HBase, Hive, Spark, HDFS, MapReduce etc.

-         Hadoop distributions like Cloudera (preferred)

·        Expertise with data services on one of the clouds (AWS, Azure, GCP) – Good to Have

·        Ability to quickly learn and adapt to the new cloud platforms / technologies

·        Extensive development experience in Python/Java

·        Real time data feed processing using Big Data ecosystem

·        Design, review, implement and optimize data transformation processes in Big Data ecosystem

·        Test and prototype new data integration tools, techniques and methodologies

·        Participate in overall test planning for the application integrations, functional areas and projects.

·        Work with cross functional teams in an Agile/Scrum environment to ensure a quality product is delivered




Technical Skills

Qualifications

·        3+ years of hands on experience with enterprise scale applications and systems

·        Expertise in Big Data technologies in Hadoop ecosystem

·        Spark, Yarn, Kafka, Oozie, HBase, Hive, Spark, HDFS, MapReduce etc.

·        Hadoop distributions like Cloudera (preferred)

·        Expertise with data services on one of the clouds (AWS, Azure, GCP)

·        Ability to quickly learn and adapt to the new cloud platforms / technologies

·        Extensive development experience in Python/Java

·        Experience with Scala is desirable

·        Strong understanding of data analytics and data visualization

·        Experience with Python and Ruby is a plus

·        Excellent analytical and problem solving skills

·        Excellent one-on-one communication and presentation skills, specifically able to convey technical information in a clear and unambiguous manner

·        Working knowledge of Linux operating system

Qualification

·        Technically focused Bachelor’s degree in Computer Science, Engineering, Math, etc.

·        Master Degree is a plus




What we offer:

EXL Health offers an exciting, fast paced and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. From your very first day, you get an opportunity to work closely with highly experienced, world class analytics consultants.

You can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth

Analytics requires different skill sets at different levels within the organization. At EXL Health, we invest heavily in training you in all aspects of analytics as well as in leading analytical tools and techniques.

We provide guidance/ coaching to every employee through our mentoring program wherein every junior level employee is assigned a senior level professional as advisors.

Sky is the limit for our team members. The unique experiences gathered at EXL Health sets the stage for further growth and development in our company and beyond.

Show more Show less"
2812771758,Data Engineer with AWS,RADISH CONSULTANTS,2021-11-29,United States,United States,,Contract,,"We Have an Immediate Requirement for Data Engineer with AWS

(COMPLETE REMOTE)

Only US candidates

Job title- Data Engineer with AWS

Experience: 10+ years

Duration- 12+ months

OPEN for W2/1099/C2C(own corp)




Job Description: Provides and trains others inexpert level data solutions by using software to process, store, and serve data to others. Tests data quality and optimizes data availability. Ensures that data pipelines are scalable, repeatable, and secure. Leads, instructs, and mentors less experienced Data Engineers in providing the deepest dive analytical skillset on a variety of internal and external data. Contributes to strategic planning and aligns end-to-end processes with cross-departmental and cross-divisional goals.




Core Responsibilities

1. Writes the most complex ETL (Extract / Transform / Load) processes, designs database systems, and develops tools for real-time and offline analytic processing.

2. Troubleshoots software and processes for data consistency and integrity. Leads the integration of highly complex and large scale data from a variety of sources for business partners to generate insight and make decisions.

3. Translates business specifications into design specifications and code. Establishes analytical rigor and methods for writing complex programs, ad hoc queries, and reports. Ensures that all code is well structured, includes sufficient documentation, and is easy to maintain and reuse.

4. Partners with internal clients and leaders to gain an expert understanding of highly strategic, high risk business functions and informational needs. Contributes to strategic planning for Data Engineering at Vanguard. Works closely with other technical and data analytics experts across the business to implement data solutions.

5. Leads all phases of solution development. Explains technical considerations at related meetings, including those with internal clients and less experienced team members.

6. Assesses data quality and tests code thoroughly for accuracy of intended purpose. Acts as the highest point of escalation for data analysis and serves as a technical consultant for the client.

7. Educates and develops junior data engineers on the team while applying quality control to their work and increasing their knowledge in specialized Data Engineering techniques and processes. Leads data engineering standards and contributes expertise to other data expert teams across Vanguard.

8. Tests and implements highly complex new software releases through regression testing. Identifies issues and engages with vendors to resolve and elevate software into production.

9. Participates in special projects and performs other duties as assigned.




#dataengineerjobs #awsjobs

Show more Show less"
2816595517,Associate Data Engineer,Tesla,2021-12-02,United States,"Austin, TX",Information Technology,Full-time,"Renewable Energy Semiconductor Manufacturing, Motor Vehicle Manufacturing, and Utilities","Overview Of Role

Tesla is looking for an individual experienced with Quality Systems and Analytics to contribute to the Cell Manufacturing team at Gigafactory Texas. As a Data Analyst, you will support a world-class manufacturing program from the ground up. You will leverage your experience with Manufacturing Execution Systems to perform advanced analytics, developing predictive models and making data applications that enable cross functional teams to leverage a wealth of manufacturing, equipment, and controls data both efficiently and effectively. Candidate will have experience working with large data sets, finding best ways to engineer the data to help create critical KPI metrics, building innovative visualizations and dashboards all the while keeping in mind what improvements can be driven in underlying data systems. In this role, you will work within the Quality Systems organization providing support to Production, Engineering, and Quality Operations teams.

Responsibilities

Analyze manufacturing, equipment, and quality data and extract useful statistics and insights about failures in order to drive meaningful improvements to production quality and customer experience
Work effectively with engineers and conduct end-to-end analyses, from data requirement gathering, to data processing and modeling
Interpret data, analyze results using statistical techniques, and provide ongoing reports
Identify data sources where the potential value is not fully realized and invent new means with which to interact and gather insights from them
Monitor key product metrics, understanding root causes of changes in metrics
Identify, analyze, and interpret trends or patterns in complex data sets and depict the story via dashboards and reports
Acquire data from primary or secondary data sources and maintain databases/data systems to empower operational and exploratory analysis
Maintain existing data visualizations and dashboard enhancement requests
Drive underlying data systems improvement by working with key cross-functional stakeholders
Perform data quality validations to ensure data creation is as per the business needs and expectations
Work closely with Controls, Process, and Quality Engineers to develop and improve data collection activities and reporting tools within a high-volume manufacturing environment
Work with management to prioritize business and information needs

Requirements

Bachelor's/Master’s degree or higher in quantitative discipline (e.g. Statistics, Computer Science, Mathematics, Physics, Electrical Engineering, Industrial Engineering) or the equivalent in experience and evidence of exceptional ability
Advanced abilities with Excel and SQL queries
Basic Python scripting
Data visualization veteran, familiar with tools and techniques such as Superset, Plotly, Tableau, Power BI
Familiarity/understanding of APIs
Strong analytical skills with ability to combine and find patterns across multiple datasets
Strong attention to details and data accuracy

Desired Requirements

Data mining and database (e.g. MySQL) experience
Data visualization experience (Tableau)
Show more Show less"
2825178419,Senior-Big Data Engineer,AT&T,2021-12-02,United States,"Middletown, NJ",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Wireless Services, and Telecommunications","Join AT&T and reimagine the communications and technologies that connect the world. We’re committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won’t just imagine the future – you’ll create it.

The Big Data Engineer will be responsible for interpreting the requirements of various Big Data Analytic Use Cases and Scenarios, and driving the design and implementation of specific data models to ultimately help drive better business decisions through insights from a combination of external and AT&Ts data assets. This is someone who is also motivated by their ongoing learning and willingness to pursue and complete professional .certifications on a continuing basis – and can use time management skills to balance learning with project related needs.

Key Roles and Responsibilities

Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the Big Data Environment.
Support the standardization, customization and ad-hoc data analysis, and will develop the mechanisms to ingest, analyze, validate, normalize and clean data.
Implements statistical data quality procedures on new data sources, and by applying rigorous iterative data analytics, supports Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value.
Will work with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data.
Develop and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods and techniques.

Qualifications

Preferred Bachelors of Science in Computer Science, Math or Scientific Computing preferred.
Typically requires 5-8 years experience.
Python, Azure or AWS, Data wrangling and Data pipeline design required
The ideal candidate will have fluency in programming, but also analytical skills since they will be working and exchanging ideas with data scientists

Ready to join our team? Apply today!

#ChiefDataOffice

JobCategory:Technology
Show more Show less"
2812310193,Data Engineer,orangepeople,2021-12-04,United States,"Plano, TX",Information Technology and Engineering,Contract,IT Services and IT Consulting,"OrangePeople is looking for a Data Engineer for our client's Labs team to help make data pipelines more efficient and contribute to the design and development of data services for the platform. Our engineering and data science teams build efficient streaming solutions, smart analytic products, and dashboards.

Responsibilities:

Operate in a highly-iterative Agile development environment
Engineer efficient, adaptable, and scalable data pipelines in the cloud to process unstructured big data
Think independently to solve difficult data problems
Work closely with product owners and other team members to deliver next-generation connected car data services
Build data expertise and own data quality for ingestion pipelines
Make information available to large scale, next-generation, predictive analytics applications
Design, build and launch new data extraction, transformation, and loading processes in production
Develop and recommend innovative solutions and approaches to solving business and technical problems
Standardize terminology and transformation of data through the architectural zones

Qualifications:

Skilled in Python and preferably in one or more programming languages like C++, Java, Go, etc
3+ years of collective experience in data engineering and data analysis
2+ years of experience architecting, building, and administering large-scale distributed applications
Experience with Docker. Kubernetes experience is a plus
Experience working with SQL and NoSQL based database solutions
Public cloud technology experience in production (Azure, AWS, or Equivalent)
Experience in engineering data pipelines using Big Data technologies (Hadoop, Spark, Storm, Kafka, etc) on large scale unstructured data sets is a plus
Familiarity with distributed data stores like Elasticsearch is a plus

Additional Responsibilities:

Participate in OrangePeople monthly team meetings, and participate in team-building efforts.
Contribute to OrangePeople technical discussions, peer reviews, etc.
Contribute content and collaborate via the OrangePeople-Wiki/Knowledge Base.
Provide status reports to OrangePeople Account Management as requested.

About us:

OrangePeople is an Enterprise Architecture and Project Management solutions company. Our most valuable asset is our people: dynamic, creative thinkers, who are passionate about doing quality work. As a member of the OrangePeople team, you will have access to industry-leading consulting practices, strategies & technologies, innovative training & education. An ideal Orange Person is a technology leader with a proven track record of technical achievements and strong process/methodology orientation.

Show more Show less"
2791842461,Data Engineer,IBM,2021-11-12,United States,"Raleigh, NC",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2819413048,Data Engineer,Robin Healthcare,2021-11-30,United States,"Dallas, TX",Information Technology,Full-time,"Computer Software, Financial Services, and Hospitals and Health Care","Robin Healthcare is a tech-healthcare startup with a mission to transform our healthcare system from its very core: the doctor-patient encounter. We marry medical scribing with the Robin Assistant™, our proprietary smart device, to help streamline documentation, coding, and other administrative tasks in the background of natural patient care.

Why:

The purpose of this role in the short term is to prototype and build out the data sets, reports, KPIs and dashboards to operate Robin's business on the new Assist platform, with an explicit goal to democratize Robin's most widely-used data for teams outside the Data Science & Analytics group to consume. In the longer-term, this role will be responsible for analysis, insights, reports, and actionable recommendations for the most challenging business problems at Robin. This role will also provide strong technical guidance to other data analysts in the Data Science & Analytics group.

What You'll Be Doing:

Use data, logic, and intuition to improve business outcomes through analysis, insights, reports, and actionable recommendations
Develop democratized dashboards, data sets, and KPIs that empower less technical owners and operators across the business to make data-driven business decisions
Design durable and forward-looking data models and data sets for the Data Science & Analytics group to develop on and provide technical direction to other analysts
Partner with Product Management, Engineering, and Creative to condense feedback from users & customers, explore & experiment to (in)validate hypotheses, and measure the outcomes of product initiatives
Partner with Client Success and account managers to build creative tools and insights to increase provider and practice satisfaction, grow revenue, and communicate performance to our customers
Partner with Operations, Talent Acquisition, and Content to create diagnostic metrics and reveal opportunities to increase the satisfaction, efficiency, and performance of our scribe population


What You'll Bring:

Adept at distilling complicated analytical concepts to broad audiences and influencing decision making through compelling data narratives
Experience building clean visualizations and performant dashboards using Jupyter, Tableau, Looker, or similar software
Experience writing performant code in BigQuery SQL
Expert programming skills in one or more general purpose languages (Python, R, Scala, etc.)
Experience with statistical and machine learning methods to build descriptive and predictive models
Familiarity writing production ETL using data technologies that allow analysis of large amounts of data (Spark, Hadoop, Hive, Presto, etc)
Familiarity with a variety of business domains and their common data and analytics needs


Graduate-level degree or equivalent proven experience in a quantitative field such as mathematics, statistics, engineering or natural sciences

What We Offer

Amazing Mission - Break new ground in a stable, well-funded company and fix a broken healthcare system
Barrier Free Culture- No Micro-Management!! We Remove Bureaucracy and Empower Our People
Decide How and When You Work
100% Remote Work Environment OR WeWork Space Of Your Choice
Your Choice of Laptop (PC or Mac) and Home Office Setup Stipend
Flexible Schedule- Build Your Work Around Your Life
Generous Stock Options
Unlimited Vacation Time (Must Take At Least 2 Weeks and Shut Off Your Phone)
Great Benefits - Medical, Dental, Vision, Life, Disability, 401k, etc.
Paid Family Leave (Up To 16 Weeks)
Investment Into Your Career With Resourcing For Education And Development
Close, Fun, And Engaging Community
Work With Brilliant, Hard-Working, Caring People Daily
Netflix Watch Parties, Pilates/Yoga classes, Clubs & Social Events


Equal Opportunity Employer: Successful applicants must be eligible to work in the US (visa sponsorship is not provided at this time) and must be able to pass a pre-employment background test. Robin Healthcare is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

To request reasonable accommodation or if you need assistance to complete the job application, contact hiring@robinhealthcare.com
Show more Show less"
2810028195,Big Data Engineer - Telecommute,Optum,2021-11-01,United States,"Columbia, MD",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Wellness and Fitness Services, and Hospitals and Health Care","Combine two of the fastest-growing fields on the planet with a culture of performance, collaboration and opportunity and this is what you get. Leading edge technology in an industry that's improving the lives of millions. Here, innovation isn't about another gadget, it's about making health care data available wherever and whenever people need it, safely and reliably. There's no room for error. Join us and start doing your life's best work.(sm)

Responsible for Hadoop and Big-Data development, operations and maintenance. Responsible for implementing Hadoop based analytics and reporting solutions including loading from disparate data sets, preprocessing using MapReduce, Hive and Pig or similar technologies. A professional at this position level within Optum has the following responsibilities: Scopes and delivers various Big Data solutions. Designs solutions independently based on high-level architecture. Manages the technical communication between the survey vendor and internal systems. Maintains the production systems (Kafka, Hadoop, MongoDB, and Elasticsearch) while testing changes in the lower environments. Collaborates with other development, analysis and research teams.

A professional at this position level within Optum has the following responsibilities: Scopes and delivers various Big Data solutions. Designs solutions independently based on high-level architecture. Manages the technical communication between the survey vendor and internal systems. Maintains the production systems (Kafka, Hadoop, MongoDB, and Elasticsearch) while testing changes in the lower environments. Collaborates with other development, analysis and research teams.

You’ll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges.

Job Responsibilities

Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet business requirements
Identify, design and implement internal process improvements, automate manual processes, optimize data delivery, and propose re-designing of infrastructure as appropriate to achieve scalability and cost reduction
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies
Build and/or maintain analytics tools that utilize the data pipeline to provide actionable insights into operational efficiency and other key business performance metrics
Work collaboratively with management, client and stakeholders to assist with data-related technical issues and support their data reporting needs
Ensure that data is maintained and secured keeping in mind the ‘least-privilege’ security principle for teams’ access to it
Support the technical teams to design, develop, test and implement cost-effective strategies for assimilating and reporting of data
Identify risks and form contingency plans as soon as possible
Analyze existing operations and schedule training sessions and meetings to discuss improvements
Support the testing and auditing team members to ensure quality checks involved in reporting of sensitive data
Keep up-to-date with industry trends and developments

You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Required Qualifications

Bachelors or Master’s degree in Computer Science, Engineering, or Math, or equivalent experience
3+ years of experience as a Big Data Engineer or similar role
3+ years of experience programming in a back end language (Spark, Java, J2EE, Kafka, etc.)
2+ Experience with Data Analytics and Reporting
Experience with Spark, or the Hadoop ecosystem and similar frameworks
Advanced working SQL and No-SQL knowledge and experience working with a variety of databases (MySQL, NoSQL, Hadoop, MongoDB, etc.)
Solid analytic skills related to working with unstructured datasets
Familiarity with various cloud technologies such as AWS (EMR, RDS, Redshift, etc.) and Azure
Creative and innovative approach to problem-solving and attention to detail
Full COVID-19 vaccination is an essential requirement of this role. UnitedHealth Group will adhere to all federal, state and local regulations as well as all client requirements and will obtain necessary proof of vaccination prior to employment to ensure compliance

Preferred Qualifications

Experience working with the Health and Human Services (HHS)
Experience working in CMMI Level 3 (or higher) environments
Confident and proactive self-starter, skilled in taking initiative, assessing requirements, coming up with plans, and taking the lead in making plans reality
Demonstrate a high degree of adaptability, comfortable in establishing new directions, managing rapid change, and trying different approaches to deal with uncharted territories
Possess excellent interpersonal skills to build and maintain positive, productive relationships with colleagues, managers, external stakeholders and client
Possess excellent written and verbal communication skills to coordinate team work and collaborate with management and stakeholders
Comfortable and experienced operating in an outcome oriented environment

UnitedHealth Group requires all new hires and employees to report their COVID-19 vaccination status.

Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm)

Colorado, Connecticut or Nevada Residents Only: The salary range for Colorado residents is $79,700 to $142,600. The salary range for Connecticut/Nevada residents is $87,900 to $156,900. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you'll find a far-reaching choice of benefits and incentives.

All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy.

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.

Job Keywords: MapReduce, Spark, Apache HBase, Hbase, Scala, Hive, Python, Shell Scripting, big data, Hadoop, Maryland, Washington D.C., Virginia, backend, Java, J2EE, Kafka, Spark, Data Analytics, No-SQL, SQL, MySQL, MongoDB, AWS, Azure, data pipeline architecture, Telecommute, Telecommuter, Telecommuting, Work at Home, Work from Home, Remote
Show more Show less"
2801606191,Data Engineer,Samsung Austin Semiconductor,2021-11-20,United States,"Austin, TX",Information Technology,Full-time,"IT Services and IT Consulting, Appliances, Electrical, and Electronics Manufacturing, and Industrial Machinery","Position Summary

Samsung Austin Semiconductor is one of the most advanced semiconductor manufacturing facilities in the world with more than 3,000 employees and 2.45 million square feet of floor space. Samsung Austin Semiconductor has broad semiconductor process technology offerings serving customers in various application areas including mobile, consumer, networking/high performance computing, Internet of Things, RF and automotive. Since 1996, its parent company, Samsung Electronics Co., Ltd has invested approximately $17 billion in Samsung Austin Semiconductor’s Austin, Texas campus, making it one of the largest direct foreign investments in United States history. Samsung Austin Semiconductor is a premier employer who provides a great place to work, as well as advanced and upskilled training to thriving employees. Visit www.samsung.com/us/sas. Samsung Austin Semiconductor strives to be the World's Best Foundry.The Defect Engineering team is seeking an innovative self-starter to join their Systems team. You would work alongside a team of data scientists, dev-ops engineers, and full stack developers to create reports to drive factory decisions and shape the priorities of the factory. If you are passionate about data, enjoy finding new signals, which could improve business metrics, then please apply.

Role and Responsibilities


Build and monitor pipelines which ingest high volume data from various internal systems (Databases, Websites, APIs).
Perform data cleaning, augmentation, normalization to prepare data for proper modeling.
Collaborate with internal customers gathering additional data when needed to improve their decision-making capability.
Create and maintain data visualizations, and key metrics used to drive business decisions across the factory.
Driving new data insights from concept to business impact.
Mentoring others who have a passion in data engineering.
Ability to write SQL queries handling high volume data, aggregation, to on premise data stores.
History of designing and modifying database schema to ingest new data (understanding of data types, normalization).
History of creating interactive dashboards to make data insights visible (Tibco Spotfire X, Tableau).
Experience with troubleshooting ETLs or optimizing databases (indexing, understanding query plans).
Experience with setting up big-data technologies (Spark cluster, Kubernetes Clusters).
Experience with setting up streaming technologies (RabbitMQ or Kafka).
Researching ways to optimize existing logic and implement continuous improvements.
Semiconductor process knowledge and terminology a plus.
Interaction with leading-edge tech manufacturing that produces TBs of data daily.
Collaboration with a highly motivated team to find, develop and implement defect solutions.
Bonus programs, Employer matched 401k, medical, dental, paid-time-off.
Amenities (soccer field, 2 gyms, full court basketball / tennis courts, frisbee golf, walking trails).
Height adjustable standing desks giving employees improved health focused options for work.
Subsidized lunches from two on-site cafeterias offering plenty of daily food choices.
Workdays and hours: 1st shift, Monday-Friday 8am-5pm.


Skills and Qualifications


B.S or M.S Engineering Degree.
1-5 professional experience, previous manufacturing environment a plus.
Experience with SQL and relational databases.
Ability to troubleshoot, improve existing Python code.
Strong problem-solving skills with attention to detail and motivation to drive to root cause.
Excellent communication, interpersonal, with ability to communicate to various technical levels across the organization.


* Please visit Samsung membership to see Privacy Policy, which defaults according to your location. You can change Country/Language at the bottom of the page. If you are European Economic Resident, please click here .



* Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and  provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.



Samsung Electronics America is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application process. If you have a disability and require a reasonable accommodation in order to participate in the application process, please contact our Reasonable Accommodation Team (855-557-3247) or SEA_Accommodations_Ext@sea.samsung.com for assistance. This number is for accommodation requests only and is not intended for general employment inquiries.


Show more Show less"
2794212579,Big Data Engineer,Levi Strauss & Co.,2021-11-16,United States,"San Francisco, CA",Engineering and Information Technology,Full-time,"Apparel and Fashion, Design, and Retail","Job Description

At Levi Strauss & Co, we are revolutionizing the apparel business and redefining the way denim is made.

We are taking one of the world’s most iconic brands into the next century:

from creating machine learning-powered denim finishes to using block-chain for our factory workers’ wellbeing, to building algorithms to better meet the needs of our consumers and optimize our supply chain.

Be a pioneer in the fashion industry by joining our global Data, Analytics & AI “startup with assets,” where you will have the chance to build exciting solutions that will impact our Global business and at the same time be part of a bigger, across-continents, data community.

As a Big Data Engineer, you will bring to life and execute architecture blueprints & help our teams by mapping out solutions to some of their complex technical challenges. You’ll provide technical expertise, mitigate risk and offer solutions tailored for their business needs. From migrations of existing workloads to building advanced cloud solutions, you’ll help shape and execute to increase agility, improve security, reduce costs and meet utilization targets.

This role will work closely with the Data Engineering, Data Science, Infrastructure & Platform and will focus on creating blueprints to nourish a culture of engineering excellence. We need someone who will bring thoughtful perspective, empathy, creativity, and a positive attitude to solve problems at scale.

About The Job

Experience in at-scale infrastructure design, build and deployment with a focus on distributed systems.
Build and maintain architecture patterns for data processing, workflow definitions, and system to system integrations using BigData and Cloud technologies.
Evaluate and translate technical design to workable technical solutions/code and technical specifications at par with industry standards. Drive creation of re-usable artifacts.
Actively scan and evaluate relevant new technologies which drive standardization and reduction of complexity within the enterprise.
Contribute to and promote good software engineering practices across the team.
Works on the collaborative Enterprise team and deliveries work products that support a digital transformation by leading assigned product and solution teams.
Performs technical design reviews and code reviews, to include cloud-based architecture and integrations.

About You

Bachelor's Degree or higher in Computer Science or related discipline
Minimum of 7 years in a hands-on technical role as an engineer and/or Data engineering role.
Experience with at least one cloud provider solution (AWS, GCP, Azure)
Strong experience working with Big Data technologies ex: Spark, Spark SQL, Pyspark Structured Streaming, Kafka.
Experience designing various consumption patterns on top of data lake/lake house to cater to different personas within organization.
Strong experience with at least one object-oriented/functional languages: Python, Java, Scala, etc.
Strong knowledge of data pipeline and workflow management tools (Airflow).
Hands-on experience in Data engineering Spectrum, for e.g. developing metadata based framework based solutions for Ingestion, Processing etc., building Data Lake/Lake House solutions.
Strong experience working with a variety of relational SQL and NoSQL databases and ability to choose a database based on the need.
Working knowledge of Git hub /Git Toolkit.
Strong experience with MPP Database systems like Teradata, Oracle or SAP Hana.
Experience with data modeling, data warehousing, KPI generation etc.
Embody the values and passions that characterize Levi Strauss & Co., with empathy to engage with colleagues from a wide range of backgrounds.
EOE M/F/Disability/Vets LOCATIONSan Francisco, CA, USAFULL TIME/PART TIMEFull time Current LS&Co Employees, apply via your Workday account.
Show more Show less"
2765293520,Data Engineer,Dell Technologies,2021-10-18,United States,"Round Rock, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Hardware Manufacturing, and Computer Software","Advisor – Data Engineer

Join us as a Data Engineer on our EBI team in Round Rock,Tx, Hopkinton, MA or remote to do the best work of your career and make a profound social impact.

What You’ll Achieve

At Dell Technologies we are enabling the next data decade for our businesses and customers. With some of the biggest data implementations in the industry, the Dell Digital Data team is constantly reimagining and innovating the way data is consumed and enabled.

In this role we are looking for individuals who are passionate about data and the possibilities of leveraging it to power intelligent, insightful and impactful outcomes. You will be working with some of the best minds and talents in the data space including business stakeholders, architects, application teams, privacy, security, governance etc. We believe in empowering our teams and leaders to take end to end ownership of the outcomes with the highest focus on quality, stability, security and customer satisfaction.

Design and develop analytical design for business problem statement and progress the solution from design though the software development lifecycle to implementation using various analytics tools and techniques.

You Will

Analyzes business needs and creates software and hardware solution blueprints.
Work closely with Data Product Managers and Solution Architects to define use cases and measurable business metrics
Works with engineering teams to check the feasibility of the solution, build stories and architects the solution for the Projects. Drives use cases through complete lifecycle.
Prepares flow charts, systems diagrams and design documentation to assist in problem analysis.
Designs, codes, tests and debugs software according to Dell’s standards, policies and procedures.
Mentoring junior team members on technical and functional skills. Should be a great team player. Functional knowledge of business processes is required.

Take the first step towards your dream career

Essential Requirements

Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role:

3-5 years of relevant IT experience in Data-Warehousing Technologies with excellent communication and Analytical skills
Possesses and applies a broad knowledge of application programming processes and procedures to the completion of complex assignments.
Competent to analyze diverse and complex problems.
Advanced ability to effectively troubleshoot program errors.
Build high reliability, high quality, high volume data pipelines
Setup batch, micro batch, streaming pipelines needed for data ingestion, transformation, processing
Automated tests and tie outs, self-healing data jobs
Ability to communicate complex insights in a precise and actionable manner
Mindset to think differently; alignment to Industry standards; awareness of emerging technologies and industry trends
Experience in working in Agile (SCRUM) Methodology

Desirable Requirements

Bachelor of Engineering or Master of Computer Applications
Experience in handling Data Security and Governance
Prior experience in delivering full stack Applications, APIs

Benefits

We offer highly competitive salaries, bonus programs, world-class benefits, and unparalleled growth and development opportunities — all to create a compelling and rewarding work environment.

Our EVP

Our Culture Code unites us and makes us a great family of companies and a great place to work. It’s how we run the business, go to market, work together and provide inspirational leadership. Our culture code is defined by our values and are made real every day by defining expectations for how we work and how we lead.

Here’s our story; now tell us yours

Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress.

What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life -- while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more.

We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today.

You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here.

Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Employment Opportunity Policy here.

Job Id: R142533
Show more Show less"
2803474500,Data Engineer,University of Pittsburgh,2021-11-22,United States,United States,,Full-time,,"Pitt IT is currently seeking a Data Engineer in support of the implementation of advanced data analytics capabilities. As a Data Engineer you will focus on the design, implementation, and operation of cloud-based data management systems to meet the University’s business needs. This includes designing how the data will be stored, managed, and consumed by different reporting/analytics systems using cloud architecture. This position will work together with other members of the Analytics team to identify, create, and populate optimal data architectures, structures, and systems. Additional responsibilities include developing prototypes and proofs of concept for the selected solutions, and implementing complex data projects with a focus on collecting, parsing, managing, and analyzing large sets of data using multiple platforms.

Additionally, this role will help support the existing Oracle data warehouse while designing and implementing AWS based solutions for those legacy workloads. This role will ensure that data pipelines are scalable, repeatable, and secure, and can serve multiple users within the organization; help facilitate getting data from a variety of different sources, getting it in the right formats, and assuring that it adheres to data quality standards.
Show more Show less"
2819508024,(1356156)Data Engineer,Cisco,2021-12-03,United States,"Atlanta, GA",Information Technology,Full-time,"Computer Hardware Manufacturing, Computer Software, and Computer Networking Products","Who We Are

Today’s challenging business environment is more than that – it’s a period of disruption between the pandemic, global business change, and internal process complexity. For us to focus on simplicity and the best customer experience, we need great talent and the right skillsets to be successful. This is now a mantra for our Cisco leadership team and for us.

The Digital Enterprise Solutions team is changing the way we run Cisco’s operations by maximizing the power of technology, the best of business processes and superior data insights. Together, we will Reimagine the Cisco experience. Show the world how to Reinvent applications and leverage the future of the Internet to Showcase the power of Cisco our people, products, processes, systems, and data. Please join us and make this journey together!

What You'll Do



We have an outstanding opportunity for a Data Engineer that wants to develop their technical skills by crafting and building innovative cloud data pipelines between Anaplan, Oracle, Snowflake, and other data sources for our partners in the Sales and Finance organizations. You would play a critical role in the team guiding the tactical design and execution of our development teams. Responsibilities would include

Partnering with business architects, operational teams, and domain specialists to build, improve, test, deploy, document, and support existing data pipelines.
Automating and innovating on existing data flows to enable Data Science, Data Analytics, and Data Services that are essential for business transformation.
Managing a cloud-based data framework used in auditing millions of transactions daily to find compensation anomalies for Sellers.
Modernize legacy data pipelines to build configurable, reliable, and secure data transportation to critical Sales systems.
Follow agile development methodologies to delivery solutions and product features following industry standards.
Identifying and resolving issues raised by users.
Discerning impacts to downstream systems and working multi-functionally to explore solutions.


Who You'll Work With

As part of the Digital Enterprise Solutions team, you will be in a team focused on delivering capabilities and features for Sales Territory/Account Planning, and Financial Goaling. You will work with the Data & Analytics, Sales, Finance, and internal program teams to develop the strategy for new data features. You will partner with architects, leads, and project managers to implement innovative technical solutions. Through these collaborations you will drive exceptional experiences to showcase our technical capabilities through secure and scalable enterprise solutions.

Who You Are



A hardworking and experienced professional who enjoys digging into complicated problems and exploring details of technical solutions. Someone who has a clear passion for technology and thrives in bringing clarity to ambiguous situations. A standout colleague capable of influencing within and outside of the team, as well as being an agent for change and transformation. Someone with an ability to take the lead in developing business solutions and clearly communicate complex concepts.

Our Minimum Requirements Are As Follows

7+ years of professional experience as a Data Engineer or other technical role working closely with data.
Experience with AWS cloud based tools like Glue, SC3, and Lambda.
Expertise with databases like MongoDB, Oracle, and Snowflake, as well as data languages like SQL, Spark, Java, and Python.
Strong experience with source control systems such as GIT, and Jenkins for build deployments.
Proven experience in automating data pipelines and resolving complex data integration problems.
Familiarity with data visualization tools like PowerBI and Tableau.
Understanding of machine learning principles and algorithms.
Superb communication and collaboration skills.
Experienced in Agile and Waterfall development methodologies.
Understanding of software development lifecycles and tools, including design and operations.
Highly dedicated and execution-focused, with a willingness to deliver results.
Lead and maintain an agile partnership between business, operations, and IT.
Experienced in facilitating estimation sessions and value driven decision making.


Why Cisco

#WeAreCisco, where each person is unique, but we bring our talents to work as a team and make a difference powering an expansive future for all.

We adopt digital, and help our customers implement change in their digital businesses. Some may think we’re “old” (36 years strong) and only about hardware, but we’re also a software company. And a security company. We even invented an intuitive network that adapts, predicts, learns and protects. No other company can do what we do – you can’t put us in a box!

But “Digital Transformation” is an empty buzz phrase without a culture that allows for innovation, creativity, and yes, even failure (if you learn from it.)

Day to day, we focus on the give and take. We give our best, give our egos a break, and give of ourselves (because giving back is built into our DNA.) We take accountability, bold steps, and take difference to heart. Because without diversity of thought and a dedication to equality for all, there is no moving forward.

So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture geek? Many of us are. Passion for technology and world changing? Be you, with us!
Show more Show less"
2820706844,Data Engineer,Tandem Theory,2021-12-03,United States,United States,Information Technology,Full-time,"Marketing and Advertising, Online Media, and Insurance","Tandem Theory

Tandem Theory is made up of people just like you – smart, funny folks who know that building an agency is and should be a fun endeavor. Working here is very much like working for a startup – things move quickly, and you get to wear many hats. You’ll get the opportunity to work on high-level projects, and the opportunity to engage directly with clients. Tandem Theory offers a flat, collaborative working environment, right from the comfort of your home. But please don’t wear your pajamas to work.

We are seeking a Data Engineer to join our growing Technology team.

Description

Here is a summary of the role:

This experienced developer must be able to develop and manage data pipelines across the disciplinary teams and support the requirements of the business: planning, design, documentation, integration, quality assurance, automation including marketing and business intelligence integrations.

This person must demonstrate strong domain expertise in relational and non-relational data models, emerging technologies, command of key programming languages and be the influential and objective technologist voice in the room.

We are looking for a modern-day ETL/ELT/IPaaS developer, one who can work in today’s analytical environment and understands the marketing landscape, where disparate data is everywhere. We do whatever it takes to solve problems, while embracing change each day.

What You Will Do

Manage data transformation development life cycle for marketing and analytical platforms
Responsible for collecting requirements, performing data exploration and developing gap analysis
Recommend and design database solutions
Manage critical steps to success and timelines
Develop data pipelines and integrations with complex source data and API services
Responsible for moving data across multiple platforms using established ETL/ELT patterns
Leverage 3rd party data and tools for data enrichment and hygiene
Coordinate development of best practices needed to support new and evolving sources of data used in marketing communications, transaction processing and analytics
Conduct data platform performance tuning, troubleshooting, support and capacity estimation
Develop, adhere to, and be a proponent for data warehouse development standards
Develop and maintain documentation for all developed data movement/transformation processes, including process flow and data mapping
Create and manage audit reporting and quality improvement processes to ensure accurate and consistent delivery of data
Work closely with internal and external teams to rapidly troubleshoot issues

What You Should Have

Bachelor's degree or equivalent combination of education and experience preferred, in computer sciences or Information systems
An understanding of data warehouse design principles
3-5 years' experience with an RDBMS such as PostgreSQL, SQL Server, SnowFlake & Google Big Query
3-5 years ETL/ELT development in SQL, python and Apache Airflow
Advanced SQL query techniques and automating import/export tasks
Proficient in creating stored procedures, index and database IO performance tuning
A big plus if candidate has any of the following skills and experiences:
API development
DBA duties and responsibilities
Python, Spark, Hadoop, C#, Java
Stitch, Fivetran, Informatica
Proactively identify, troubleshoot and resolve complex data integrity issues
Reverse engineer existing SQL code to determine business logic
Agency and marketing experience preferred
Strong analytical skills, with ability to communicate technical details
Excellent verbal and written communication skills
Work with minimal supervision in an agile environment
Ability to pivot quickly based on changes in analytical needs

Here Is a Little Bit About Us

Tandem Theory is a culture-first agency built to create better client experiences. We deliver on this promise by focusing on three core behaviors - teamwork, transparency, and trust – the three things that we found were most often missing from the traditional agency experience. They’re not just words on a poster. We apply them every day to guide our internal and client relationships, and our clients tell us they feel the difference.

Headquartered in Dallas, Texas, Tandem partners with several leading brands. These brands value working with an agency led by a proven team that provides simple but impactful solutions, transparent pricing, and performance-based compensation.

Other than waking up and being excited to get to work each day, here are some additional benefits:

The salary for this exempt-level position will be based on experience and qualifications within an established pay range. Benefits include 85% employer paid medical, eligibility to participate in vision and dental insurance as well company paid STD, LTD coverage plus a flat amount company paid toward Basic Life and AD&D, as well as a generous 401(k) retirement contribution plan eligible after 90-days of employment.

Working Conditions

We operate as a work, not live, from anywhere model and utilize the office space as a co-working space as needed. That said, whether in the office or at a remote location, we try to operate in the traditional office norm model. You will be working with a computer, telephone, copier, or other office equipment as necessary for long stretches of time. There may be some occasional long, irregular hours. You are expected to communicate effectively (verbal and written), and maintain professionalism under stress. Occasionally you will need to bend, pull, push and/or reach to access job-related materials. You will also be expected to work with frequent interruptions such as Slack messages, emails, phone calls, drive-by visits to your desk, whether that is from a co-worker at the office or your dog barking while working remotely. You are required to attend all video conference calls on camera, as it is important to see facial expressions and reactions to enhance connection and collaboration.

Eligibility

All new employees must provide documented proof of their identity and employment authorization and pass a background screening process. No work Visa sponsorships available at this time.

Here is where we are located in case you are curious:

15400 Knoll Trail #503

Dallas, TX 75248
Show more Show less"
2802444797,Big Data Engineer,Integral,2021-10-26,United States,"Chicago, IL",Engineering and Information Technology,Full-time,Marketing and Advertising,"Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry and we're looking for a Big Data Engineer to join our Data Engineering team. If you are excited by technology that has the power to handle hundreds of thousands of transactions per second; collect tens of billions of events each day; and evaluate thousands of data-points in real-time all while responding in just a few milliseconds, then IAS is the place for you!

As a Big Data Engineer you will build and expand upon the testing framework and testing infrastructure of IAS' core ad verification, analytics and anti ad fraud software products.

What You'll Do

Planning delivery of data pipelines and API endpoints for IAS (Integral Ad Science) product offerings
Architect and build data pipelines and data stores specialized for data science needs
Design architecture to streamline data science processes
Design and implement systems for large-scale data analysis and machine learning
Build tools and frameworks for use across the data science and data engineering teams
Define and implement best practices and development processes
Partner with engineering teams on deployments of data science driven solutions
Participate in training and mentoring of data engineers

You Should Apply If You Have Most Of This

Bachelors or Masters in Computer Engineering, Computer Science, Electronics Engineering, or related fields
2-5 yrs. of experience designing and building data-intensive applications
Excellent interpersonal and communication skills
Excellent hands-on coding - Java/Scala/Python
In-depth understanding of algorithms, scalability and various tradeoffs in a Big Data setting
Expertise in using Big Data frameworks (e.g., Hadoop, Spark) and MPP databases (e.g., RedShift, Vertica, Snowflake) for complex data assembly and transformation
Knowledge of database technology, SQL, schema design and query optimization techniques
Understanding of full software development life cycle, agile development and continuous integration

What Puts You Over The Top

Digital advertising or web technology experience
Experience working with AWS Analytics technologies
Experience working with Apache Airflow
Experience implementing machine learning algorithms

About Integral Ad Science

Integral Ad Science (IAS) is a global leader in digital media quality. IAS makes every impression count, ensuring that ads are viewable by real people, in safe and suitable environments, activating contextual targeting, and driving supply path optimization.

Our mission is to be the global benchmark for trust and transparency in digital media quality for the world's leading brands, publishers, and platforms. We do this through data-driven technologies with actionable real-time signals and insight. Founded in 2009 and headquartered in New York, IAS works with thousands of top advertisers and premium publishers worldwide. For more information, visit integralads.com.

Equal Opportunity Employer

IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.

California Applicant Pre-Collection Notice

We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.

To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN

Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.
Show more Show less"
2749494893,Data Engineer,Vanguard,2021-10-08,United States,"Charlotte, NC",Research and Analyst,Full-time,Financial Services,"Job Description

Opportunity to join an industry leader in the institutional retirement space. As a Data Engineer, you will provide advanced data solutions by using software to process, store, and serve data to others. Tests data quality and optimizes data availability. Ensures that data pipelines are scalable, repeatable, and secure. Utilizes a deep dive analytical skillset on a variety of internal and external data.

Core Responsibilities

Engages with internal partners to understand business strategy, questions, and goals. Brings structure to business requests, translates requirements into an analytical project approach, and supports projects through completion.
Acquires and compiles structured and unstructured data and verifies its quality, accuracy and reasonableness.
Performs analyses of historical data to surface trends and insights using analytical methods.
Prepares and delivers visualizations and internal presentations that translate analytic insights into tangible, actionable solutions for business partners to implement.
May own and manage recurring analytic or reporting processes.
Participates in special projects and performs other duties as assigned.

Required Skills

Python
SQL
AWS exposure

Qualifications

Minimum of three years related work experience.
Undergraduate degree or equivalent combination of training and experience.

Good To Have Skills

Dash
Flask
PySpark
Hadoop
Hive

About Vanguard

We are Vanguard. Together, we’re changing the way the world invests.

For us, investing doesn’t just end in value. It starts with values. Because when you invest with courage, when you invest with clarity, and when you invest with care, you can get so much more in return. We invest with purpose – and that’s how we’ve become a global market leader. Here, we grow by doing the right thing for the people we serve. And so can you.

We want to make success accessible to everyone. This is our opportunity. Let’s make it count.

Inclusion Statement

Vanguard’s continued commitment to diversity and inclusion is firmly rooted in our culture. Every decision we make to best serve our clients, crew (internally employees are referred to as crew), and communities is guided by one simple statement: “Do the right thing.”

We believe that a critical aspect of doing the right thing requires building diverse, inclusive, and highly effective teams of individuals who are as unique as the clients they serve. We empower our crew to contribute their distinct strengths to achieving Vanguard’s core purpose through our values.

When all crew members feel valued and included, our ability to collaborate and innovate is amplified, and we are united in delivering on Vanguard's core purpose.

Our core purpose: To take a stand for all investors, to treat them fairly, and to give them the best chance for investment success.
Show more Show less"
2806961512,Data Engineer,Orange County's Credit Union,2021-11-24,United States,"Santa Ana, CA",,Full-time,,"Are you looking to join a dynamic, fast-paced team environment with a culture of collaboration and belonging? If so, let’s talk.




Orange County's Credit Union is now seeking a talented and driven individual to accelerate our efforts and be a major part of our team and culture.




Our team members are grounded in core values, have a strong capacity to learn, the energy to get things done, and bring real world experiences to help us think in new ways. Orange County's Credit Union actively invest in our team members to support their long-term growth so they can continue to advance our mission and achieve their highest potential.




Are you passionate about the future? Are you a data engineer who specializes in wrangling a wide range of data into versatile, accessible sources of knowledge? If yes, PLEASE APPLY IMMEDATELY!




Open to candidates in CA or TX, 100% remote work available.




Essential Functions:

Collaborate with delivery team and engage with organizational stakeholders (Business and IT) to design, develop and deliver end-to-end enterprise data analytics solutions to enable data-driven insights and decision making.
Translate business requirements to technical solutions by applying technical knowledge and strong business acumen.
Solve business problems and complex data requirements/challenges by incorporating standards and best practices into engineering solutions, and leveraging modern data science programming languages (e.g., SQL, Python, R, Scala, SAS) and Azure data and analytics services.
Develop and implement database designs (logical and physical) and data models (normalized and dimensional) to support the new analytics platform.
Design, implement and maintain data ingestion/integration and end-to-end data pipeline processes using Azure technologies for a wide variety of traditional and non-traditional data sources/formats (structured, unstructured, and semi-structured) through various protocols (e.g., REST, SOAP, SFTP, MQ, etc).
Show more Show less"
2827284511,Data Engineer,Deserve,2021-12-04,United States,"San Francisco, CA",Information Technology,Full-time,Financial Services,"About Deserve

Through a digital-first, mobile-centric, highly configurable credit card solution, Deserve is powering the future of fintech. Using machine learning and alternative data, Deserve partners with universities, associations, financial institutions, fintechs, and modern consumer brands to develop, rapidly deploy and power white label and co-branded credit card programs for any audience. Deserve is a venture-backed fintech company whose investors include Goldman Sachs, MasterCard, Visa, Sallie Mae, Accel, Pelion Venture Partners, Aspect Ventures, and Mission Holdings.

About The Role

In this role, your primary responsibility will be owning the data infrastructure, data warehousing, cloud infrastructure as well as data services. You will help us develop new features in the existing data services, build new services to make data access easier and automated, evaluate new tools/infrastructures to make the daily work easier and deploy your work to AWS etc. You will also work closely with Data Scientists, Data Analyst inside Deserve to deploy Machine Learning models, create dashboards and reporting, and improve data quality.

Qualifications

3+ years experience in a Data Engineer / Machine Learning Engineer role
Degree in Computer Science, Statistics, Information Systems or another quantitative field
Experience with an object-oriented / object function language such as Python, Java, Scala etc.
Advanced working SQL knowledge and experience working with relational databases, query authoring / tuning with a variety of databases
Experience with data pipeline and workflow management tools such as Airflow, Luigi etc.
Strong analytical skills and interested in working with unstructured dataset
Experience with AWS cloud services such as EC2, Redshift, S3, Kinesis etc.
Familiarity with Docker tools
Experience supporting and working with cross-functional teams in a dynamic environment
Nice to Have

Experiences in Machine Learning implementation / deployment
experiences with stream-processing systems such as Spark-Streaming, Flink etc.
*Must have received or be willing to receive the COVID-19 vaccine by date of hire to be considered for U.S. based jobs.
Show more Show less"
2816176416,Technology Engineer (Data Engineer),PNC,2021-11-16,United States,"Dallas, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Banking, and Financial Services","Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. We work together each day to foster an inclusive workplace culture where all of our employees feel respected, valued and have an opportunity to contribute to the company’s success.

As a Technology Engineer (Data Engineer) for PNC's Security Analytics Hub, you will have the opportunity to work fully remote. Our team focuses on producing data driven insights into multiple areas of risk facing the bank, including cybersecurity and physical security.

Day To Day Responsibilities

Acquire/map datasets that align with our business partner needs
Develop algorithms that shape data into useful and actionable information
Build, test, and maintain database pipeline architectures
Collaborate with management to understand and meet company objectives
Form new data validation methodologies and data analysis tools
Ensure continued compliance with data security policies and governance

Technical Qualifications

Education: BS/BA in technical discipline
5+ years of Python development
5+ years of experience with development/decomposition of complex SQL (RDMS Platforms)
3+ years of experience with test-driven development. Continuous Integration/ Development (e.g. GIT, Jenkins, Maven)
3+ years with CRON/Shell Scripting
Experience with utilization of REST API and/or EDPI
Hands on experience with project management tools such as JIRA, Confluence
Ability to work with end users (BI analysts, data scientists, etc.) to solve technical issues
Experience working in an Agile Team construct
Extensive knowledge of databases, data warehouses, systems integrations, and data flows is mandatory for this role.
Additionally, candidates should be well-versed in data architecture, data development, with a proven history of providing effective data solutions.

Required Skills To Be Considered For This Role

Coding: Proficiency in coding languages is essential to this role. Common programming languages used by the team include SQL, Python.
Relational and non-relational databases: You should be familiar with both relational and non-relational databases, and how they work (Teradata, Oracle, etc).
ETL (extract, transform, and load) systems: Moving data from databases and other sources into a single repository, like a data warehouse.
Data storage knowledge: As solutions are designed, when to use a data lake versus a data warehouse, for example.
Automation and scripting. Candidate should be able to write scripts to automate repetitive tasks (e.g. Cron jobs, Linux, shell scripting).
Big data tools: Understanding of Hadoop, MongoDB, and Kafka helpful, but not required.
Data security: Securely managing and storing data to protect it from loss or theft per PNC guidelines.

Job Description

Leverages technical knowledge and industry experience to design, build and maintain technology solutions. Assists with selecting appropriate platforms, integrates and configures solutions.
Develops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.
May provide consultation on common issues and best practices for junior staff.
Provides a systematic analysis on client requirements within the traceability framework and resolves any functional problems encountered.
Ensures quality of project deliverables while maintaining compliance with relevant standards and processes.

PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:

Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.

Competencies

Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.

Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.

Effectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.

Emerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.

Industry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.

IT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).

IT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.

Planning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.

Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Work Experience

Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

Education

Bachelors

Additional Job Description

COMPENSATION

Base Salary

$55,000 to $142,600

Role

Placement within the compensation range is based on the specific role and the following factors

Where a person is paid in the compensation range is aligned to their experience and skills.

– Lower in range –Building skills and experience in the job

– Within the range–Experience and skills align with proficiency in the role

– Higher in range –Experience and skills add value above typical requirements of the role

– Compensation Range may vary based on Geographic Location

INCENTIVE

Role is incentive eligible with the payment based upon company, business and individual performance.

Benefits

PNC offers employees a comprehensive range of benefits to help meet your needs now and in the future. Depending on your eligibility, options for full-time employees include medical/prescription drug coverage (with a Health Savings Account feature); dental and vision options; employee and spouse/child life insurance; short- and long-term disability protection; maternity and parental leave; paid holidays, vacation days and occasional absence time; 401(k), pension and stock purchase plans; dependent care reimbursement account; back-up child/elder care; adoption assistance; educational assistance and a robust wellness program with financial incentives. To learn more about these and other programs, including benefits for part-time employees, visit pncbenefits.com > New to PNC.

Disability Accommodations Statement

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.

The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO)

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.

California Residents

Refer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.
Show more Show less"
2814272093,Data Engineer,Insight Global,2021-11-30,United States,"Brea, CA",,Full-time,,"Must-haves
3+ years of SQL experience
Experience with SSIS, specifically creating packages
3+ years of experience loading, importing, and exporting data into and from databases
1+ year of experience with SSRS (generating PDF's using RDL)
Great verbal and written communication
Bachelors Degree

Plusses
Experience with Google Analytics
Experience generating reports from databases
Experience in healthcare

Day-to-Day
An employer in Brea is looking for a Data Engineer/Analyst to work for a large specialty care client. This candidate will be gathering requirements from the business, translate them with how they relate to data, and the load/import the relevant data to meet the business requirements. They will also be exporting the data and generating the reports. This team works with both non-technical and technical teams in the US and India. This role is 100% remote but must work PST hours and be open to working with the team in India within their time zone. Note - this is not a BI/Data Science role - this role is purely getting data into a database to make a system work.

Show more Show less"
2826840225,Data Engineer,CVS Health,2021-12-04,United States,"Hartford, CT",Information Technology,Full-time,"IT Services and IT Consulting, Financial Services, and Hospitals and Health Care","Job Description

Participates in the design, build and management of large scale data structures and pipelines and efficient Extract/Load/Transform (ETL) workflows.

The ideal candidate must have strong problem solving skills and critical thinking ability. Strong collaboration and communication skills within and across teams. Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment. Experience building data transformation and processing solutions. Has strong knowledge of large scale search applications and building high volume data pipelines.

Required Qualifications

3+ years of ETL experience.

COVID Requirements

COVID-19 Vaccination Requirement

CVS Health requires its Colleagues in certain positions to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, pregnancy, or religious belief that prevents them from being vaccinated.

If you are vaccinated, you are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status within the first 10 days of your employment. For the two COVID-19 shot regimen, you will be required to provide proof of your second COVID-19 shot within the first 45 days of your employment. Failure to provide timely proof of your COVID-19 vaccination status will result in the termination of your employment with CVS Health.
If you are unable to be fully vaccinated due to disability, medical condition, pregnancy, or religious belief, you will be required to apply for a reasonable accommodation within the first 10 days of your employment in order to remain employed with CVS Health. As a part of this process, you will be required to provide information or documentation about the reason you cannot be vaccinated. If your request for an accommodation is not approved, then your employment may be terminated.

Preferred Qualifications

Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources.

Ability to understand complex systems and solve challenging analytical problems.

Experience with bash shell scripts, UNIX utilities & UNIX Commands.

Knowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similar.

Bachelor's degree in Computer Science, Engineering, Machine Learning, or related discipline.

Education

Bachelor's degree or equivalent work experience

Business Overview

At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.
Show more Show less"
2826942209,Data Engineer,Radancy,2021-12-04,United States,"Carol Stream, IL",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Radancy’s Data Engineering team is seeking a motivated Data Engineer to build data products and services. The Data Engineering team works on data services across product organizations within Radancy and supports building a customer facing data visualization product. Team also supports an enterprise grade recruitment platform focusing on talent acquisition and job opportunity exploration.

The team has extensive experience in ETL development, works with large scale data in real time, and collaborates with other engineering teams across the organization.

Build and maintain ETL pipelines, Automated workflows, Data products and services, Reporting Suite etc. using latest technologies and tools i.e. Python, Docker, SQL Server, BigQuery, PostgreSQL, Airflow, Luigi, Tableau, ASP .NET, RabbitMQ, Kafka and many others
Work with Cloud Computing Platforms (GCP/AWS), ETL Orchestration tools(Luigi/Airflow), and other advanced open-source technologies
Data modeling, schema design, and SQL development
Ingest and aggregate data from both internal and external data sources to build our world class datasets
Develop and lead the testing and fixing of new or enhanced solutions for data products and reports, including automating ETL testing
Collaborate with Product Owner and domain experts to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
Assist with the development and review of technical and end user documentation including ETL workflows, research, and data analysis
Work with Product team to define data collection and engineering frameworks
Build monitoring dashboards and automate data quality testing
Own meaningful parts of our service, have an impact, grow with the company
3+ years of Python, SQL, and ETL development
Experience with at least one - Client Facing Product or Services or Reporting suite
Strong Understanding of ETL pipeline, data lakes and data warehouse development
Exposure to at least one cloud computing platform (GCP/AWS/Azure), and cloud data warehouse (BigQuery/Redshift)
Experience delivering applications that run in a containerized environment is a plus
Basic knowledge of Machine Learning, ML Pipelines and tools is a plus
Some experience with any of these is a plus - NLP, MLOps, DataOps, tensorflow/keras/pytorch
Exposure to agile methodologies and particularly scrum
Experience working with large datasets for several organizational units internally as well as externally is a huge plus
Enthusiastic about working with and exploring new data sets
Detail oriented, strong communicator, quick thinking and acting with minimal supervision
Bachelor's degree in related area (Computer Science, Information Systems, Engineering) or an equivalent combination of education and experience

Join the global leader in talent acquisition technologies that’s committed to finding new ways to leverage software, strategy and creative to enhance our clients’ employer brands – across every connection point. We’re looking for unconventional thinkers. Relentless collaborators. And ferocious innovators. Talented individuals who are ready to work towards solutions that transform the way employers and job seekers connect.

Radancy is an equal opportunity employer and welcomes all qualified applicants regardless of race, ethnicity, religion, gender, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. We actively work to create an inclusive environment where all of our employees can thrive.
Show more Show less"
2791844219,Data Engineer,IBM,2021-11-12,United States,"Chicago, IL",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2811107089,Data Engineer,Massachusetts General Hospital,2021-11-04,United States,"Boston, MA",Information Technology,Full-time,"Non-profit Organizations, Wellness and Fitness Services, and Hospitals and Health Care","The mission of Home Base, A Red Sox Foundation and Massachusetts General Hospital Program, is to heal the “invisible wounds” of Veterans, Service Members and their families, including post-traumatic stress disorder (PTSD) and traumatic brain injury (TBI), by connecting them to world class care. Home Base provides clinical care and support services, as well as community education, and innovative research. We provide clinical care to currently serving men and women (Active duty, National Guard, and Reserve), Veterans, and their families.

Home Base seeks to hire a data engineer to start January 2022, who will support a variety of database/warehouse management, ETL scripting, and data validation tasks that include but are not limited to: querying databases, restructuring data, cleaning and validating data, performing manual ETL tasks, automating ETL tasks using tools and custom scripting, full pipeline management/monitoring, improving systems and processes, and documenting data systems. The qualified candidate will be highly detail-oriented and have a strong interest in and aptitude for data management and engineering. Some specific focus areas would be determined based on the candidate's skills and interests.

The successful candidate must be highly organized, motivated, and able to thrive in a fast-paced team environment and must enjoy the challenge of a dynamic environment with evolving needs. It is extremely important that the candidate possess the ability to carefully keep track of multiple work streams.

Principal Duties And Responsibilities

Relevant activities include, but are not limited to the following:

Home Base seeks to hire a data engineer to start January 2022, who will support a variety of database/warehouse management, ETL scripting, and data validation tasks that include but are not limited to: querying databases, restructuring data, cleaning and validating data, performing manual ETL tasks, automating ETL tasks using tools and custom scripting, full pipeline management/monitoring, improving systems and processes, and documenting data systems. The qualified candidate will be highly detail-oriented and have a strong interest in and aptitude for data management and engineering. Some specific focus areas would be determined based on the candidate's skills and interests.

Achieving an extremely detailed understanding of our current data ecosystem, including its structure, data meaning, history, flow/processing, and challenges
Utilizing, improving, and constructing and ETL tools and data warehousing solutions
Running current SQL, Python, PHP, and/or Tableau Prep ETL scripts
Using various monitoring and evaluation methods to validate that data flowing through these pipelines is accurate and troubleshooting/addressing issues when they are discovered
Data warehouse maintenance and support
Improving and better integrating scripts (ETL and validation) and warehouse elements into various data pipelines to achieve greater efficiency, reliability, and functionality
Constructing new ETL tools and warehouse components as necessary, specifically including a dedicated-use pipeline for a new collaborative research project
Data Cleaning
Writing queries (SQL) and scripts (Python) to identify data quality problems
Investigating the root cause of data quality problems
Working with appropriate team members to determine appropriate data remediation and process improvement plans
Developing queries and scripts as needed to repair data in bulk
Developing and managing data quality and infrastructure monitoring dashboards
Additional Responsibilities
Supporting the team as needed with data querying (particularly of the data warehouse), processing, analysis and reporting for both regular and ad-hoc requests from clinical, executive, and external audiences
Researching potential new data engineering solutions, analyze feasibility, and assist technical leadership in road-mapping and designing the evolution of our data infrastructure
Creating and maintain documentation across our data ecosystem The mission of Home Base, A Red Sox Foundation and Massachusetts General Hospital Program, is to heal the “invisible wounds” of Veterans, Service Members and their families, including post-traumatic stress disorder (PTSD) and traumatic brain injury (TBI), by connecting them to world class care. Home Base provides clinical care and support services, as well as community education, and innovative research. We provide clinical care to currently serving men and women (Active duty, National Guard, and Reserve), Veterans, and their families.

The successful candidate must be highly organized, motivated, and able to thrive in a fast-paced team environment and must enjoy the challenge of a dynamic environment with evolving needs. It is extremely important that the candidate possess the ability to carefully keep track of multiple work streams.

Principal Duties And Responsibilities

Relevant activities include, but are not limited to the following:
Achieving an extremely detailed understanding of our current data ecosystem, including its structure, data meaning, history, flow/processing, and challenges
Utilizing, improving, and constructing and ETL tools and data warehousing solutions
Running current SQL, Python, PHP, and/or Tableau Prep ETL scripts
Using various monitoring and evaluation methods to validate that data flowing through these pipelines is accurate and troubleshooting/addressing issues when they are discovered
Data warehouse maintenance and support
Improving and better integrating scripts (ETL and validation) and warehouse elements into various data pipelines to achieve greater efficiency, reliability, and functionality
Constructing new ETL tools and warehouse components as necessary, specifically including a dedicated-use pipeline for a new collaborative research project
Data Cleaning
Writing queries (SQL) and scripts (Python) to identify data quality problems
Investigating the root cause of data quality problems
Working with appropriate team members to determine appropriate data remediation and process improvement plans
Developing queries and scripts as needed to repair data in bulk
Developing and managing data quality and infrastructure monitoring dashboards
Additional Responsibilities
Supporting the team as needed with data querying (particularly of the data warehouse), processing, analysis and reporting for both regular and ad-hoc requests from clinical, executive, and external audiences
Researching potential new data engineering solutions, analyze feasibility, and assist technical leadership in road-mapping and designing the evolution of our data infrastructure
Creating and maintain documentation across our data ecosystem
Background
Degree in Health Informatics, Computer Science, Statistics, Mathematics, Engineering, or a similar field
Familiarity with behavioral health clinical practice and/or research preferred
Technical
Procedural programming for data manipulation using Python, NumPy, and Pandas
PHP, Java, or other languages are a plus
Knowledge of relational database platforms, data modeling, and warehousing
Comfortable extracting data from and loading data into sources ranging from an Enterprise Data Warehouse to an Excel or text file, using built-in tools or custom-written ETL scripts
Knowledge of data aggregation and transformation processes (e.g. pivot, merge, union, hierarchical grouping, aggregation functions)
Above average SQL skills (e.g. familiar with subqueries, multiple joins, and grouping), specifically MySQL. SQL Server experience a plus
Comfortable with complex multi-stage, multi-technology ETL pipelines
Comfortable using APIs to transmit data in both an ad-hoc and automated manner
Familiar with concepts/tools of Data Quality Management as well as Data Governance practices
Professional
Ability to interpret and follow-through on data requirements and with strong attention to detail
Strength in independently validating and debugging code and analyses, including consulting documentation, Stack Exchange, etc.
Demonstrates personal initiative and time management skills, as well as the ability to work effectively and kindly as part of a team
Excellent verbal and written communication skills
Familiar with agile software development methodologies
Interest in identifying process improvement opportunities is a plus

LICENSES, CERTIFICATIONS, And/or REGISTRATIONS

Required: Undergraduate degree in Health Informatics, Computer Science, Statistics, Mathematics, Engineering, or a related subject.
Preferred: Graduate degree in one of the above.

Preferred Coursework Would Include Most Of The Following

Intermediate Databases and SQL
Intermediate Programming (Procedural and/or OO)
Data Structures and Algorithms
Data Quality Management
Data Flow and Automation
Agile Project Management

Equivalent Experience – Equivalent time and aptitude achieved through work experience may substitute for some of the preferred courses listed above.

Experience

Preferred: 2+ years of experience in data management in a healthcare/clinical setting, however recent or anticipated college graduates will be considered.

Primary Location

MA-Charlestown-MGB OCC

Work Locations

MGB OCC

Job

IT/Health IT/Informatics-Engineer

Organization

Massachusetts General Hospital(MGH)

Schedule

Full-time

Standard Hours

40

Shift

Day Job

Employee Status

Regular

Recruiting Department

MGH Psychiatry

Job Posting

Nov 4, 2021
Show more Show less"
2791846011,Data Engineer,IBM,2021-11-12,United States,"Charlotte, NC",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2814230389,Data Engineer,Power Digital Marketing,2021-11-30,United States,United States,Marketing and Advertising,Full-time,Marketing and Advertising,"About the Company:

Power Digital is a leading, data-driven marketing company that is nationally recognized for its ability to combine the best of art and science. As a full-service firm, the company offers best-in-class services including: SEO, Content Marketing, Paid Media, Social Media Marketing, Public Relations, Influencer Marketing, Email + SMS, Conversion Rate Optimization, Amazon Marketing, Creative, and Web Development.




Power Digital is hyper-focused on helping brands scale revenue and increase profits by using data and analytics to guide strategy, ultimately driving irrefutable value for clients. Unique to Power Digital is their proprietary, machine-learning platform SPRnova™ that can analyze any business’s growth opportunities with a corresponding roadmap of how to execute and track progress across every marketing channel. Leveraging their team of the nation’s leading consumer strategists, creatives and data scientists, Power Digital provides scalable and tangible marketing solutions for each stage of the funnel and for every milestone of the consumer journey.




About the Role:

Power Digital Marketing is looking for an experienced Data Engineer who is an expert in data aggregation, organization, and ETL pipelines.

In 2020 Power Digital launched nova, our proprietary platform for digital marketing auditing, forecasting, planning, and reporting. The nova platform integrates data from hundreds of clients and dozens of data sources. Using this data, it can analyze and make predictions for over 50 marketing strategies in 13 marketing channels to provide insights and tools for our customers.  




A key responsibility for this Data Engineer will be to develop and maintain connections and data pipelines from 3rd party APIs in order to improve our data quality and volume used to generate insights, recommendations, and reports. This position will play a central role in our long term data strategy and architecture as we expand our data warehouse, leveraging AI and machine learning to improve the accuracy of our prediction and planning tools.

As a part of our technology team, this role will contribute to our nova software by developing and maintaining new and existing software features, conducting code reviews, and deploying new releases. This includes participating in agile development processes like sprint planning, standups, reviews, retrospectives, sprint boards, backlogs, and ticket management. This engineer will work with team members to continue to grow the department capabilities and support our clients.




*This is a remote opportunity open to anyone legally eligible to work in the U.S.




Responsibilities:

Develop and maintain integrations with 3rd party API data sources
Develop and improve ETL pipelines
Lead architecture planning and data design
Lead data stewardship
Develop and maintain new APIs for data access
Support and maintain existing APIs for data access
Optimize code for scale and performance
Help maintain code quality, organization, and testing
Participate in the entire application lifecycle
Support other engineering team members
Ads, Facebook Marketing, Hubspot, Salesforce, Shopify, Bing Ads, and Criteo
Experience with API development
Experience with GraphQL
Experience with Laravel or other MVC frameworks
Perform code reviews
Troubleshoot and resolve errors




Requirements:

Bachelor’s degree or higher in a quantitative/technical field (e.g. Computer Science, Economics, Finance, Mathematics, Statistics, Engineering) OR equivalent experience
2+ years building and maintaining large scale data-centric API systems
4+ years object-oriented programming experience with more than one major language including Java, .NET, PHP, Python, Go, and Node
Understanding of architecting, maintaining and developing cloud technologies (especially AWS)
Experience with Amazon Redshift
Experience connecting to marketing industry APIs including Google Analytics, Google sts, writers, developers and engineers all passionate about driving results for our awesome clients.

We are passionate about digital marketing and web solutions and are looking for some great technical talent to join our team! We would love to talk to you if you think you could help our team.




Benefits & Perks:

Robust Medical, Dental, Vision insurance plans with significant employer contribution towards employee monthly premium
Employer sponsored life insurance, short- and long-term disability coverage
401k plan with up to 4% employer match after 6 months of service
Unlimited PTO
Employee assistance program
Monthly & quarterly team bonding activities
Commission and bonus opportunities each month/quarter
Flexible Return to Work options post-pandemic

Show more Show less"
2805947568,Staff Big Data Engineer (Analytics),App Annie,2021-12-03,United States,"San Diego, CA",Engineering and Information Technology,Full-time,Internet Publishing,"*YOU CAN WORK REMOTELY FROM ANY LOCATION AS LONG AS YOU ARE LOCATED IN PST/PDT OR MST TIME ZONE




Something about us

App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. More than 1,300 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business. We are a global company, headquartered in San Francisco but as a “remote” first company, we care about your results and not your location.

Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.




What can you tell your friends when they ask you what you do?




I am an experienced Big Data engineer who can create innovative new products in the analytics and data space. I participate in the development that creates the world's #1 app stores analytics service. Together with my team I build out new product features and applications using agile methodologies and open source technologies. I work directly with Product Managers, Software Architects, and I am on the front lines of coding new and exciting analytics and data mining products. I love what I do and excited to join an entrepreneurial company with a start-­up culture!




You will be responsible for and take pride in….

As a Big Data Engineer, you will be in charge of our data analysis projects and to build clean, robust and maintainable data processing program that can support these projects on huge amount of data, this includes:

Able to design and implement complex product components based on requirements with possible technical solutions.
Write data analysis and statistics programs using Pyspark with a commitment to maintaining high quality work while being confident in dealing with data mining challenges.
Discover any feasible new technologies lying in the Big Data ecosystem, share them to team with your professional perspectives.
Get up to speed in the machine learning domain, implementing analysis components in a distributed computing environment with instruction from Data Scientists.
Be comfortable conducting detailed discussions with Data Scientists regarding specific questions related to specific data models.
You should be a strong problem solver with proven experience in big data.

You should recognize yourself in the following…

Master's degree in Math or Computer Science and at least 5+ years of experience in Big Data Engineering.
Hands-on experience and deep knowledge of Hadoop ecosystem.
Knowledge and experience with PySpark, Mapreduce, HDFS, Linux, Storm, Kafka.
Proficient with programming in Python, experience in Pandas, Sklearn or Other data science and data analysis toolset is a big plus.
Having a background of data mining and machine learning domain, familiar with common algorithms and libs is a plus.
Passion for cloud computing (AWS in particular) and distributed systems.
You must be a great problem solver with the ability to dive deeply into complex problems and emerge with clear and pragmatic solutions.
Good communication, and cooperation globally.




This is what we offer…

We provide a $1,000 (country equivalent) WFH allowance to set you up for remote work success.
Remote working from anywhere in PST time zone! We are not office centric anymore and never will be.
90-days global passport. Work from anywhere in the world for 90 days a year!
Internet allowance for stable internet connection, so your video does not freeze on Zoom.
Flexible working days. We love to meet, but if you need to get your kids behind school-zoom, need to leave early to get to your band repetition or gym classes, do your thing.
Paid leave, so long as you promise to come back!
Health and dental benefits.
An international team of talented and engaged people from different cultural backgrounds and locations.
Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!
Unlimited access to online learning platform Udemy to help you develop your skills.
Virtual initiatives and events to keep you connected with your colleagues.
Generous Employee Referral Program. Up to $10,000 for specific roles.




Yes, I want this job!

Show more Show less"
2814760171,Data Engineer,"VMC Soft Technologies, Inc",2021-12-01,United States,"Austin, Texas Metropolitan Area",,Full-time,,"Need some one with strong Data Engineering experience with below skill sets

Python
R
Snowflake
Big Data
ETL
AWS
PL/SQL
Show more Show less"
2822083930,Data Engineer,Insight Global,2021-12-01,United States,"Jacksonville, FL",,Full-time,,"Must Haves:

2+ years of experience in Data Engineering/ETL Development with either Informatica or Hadoop
Understanding of Data Strategy
data asset classification, ETL processes, data exchange definition, data naming standards, data modeling, data interoperability standards and data governance
Experience with maintaining software on Windows and Unix systems




Plusses:

Cloud/AWS Experience
Streaming experience
Kafka and/or Streamsets




Job Description:

The Data Engineer is responsible for supporting and advocating the company’s data strategy. The Data Engineer will architect, configure, deploy and manage the multi-server data platform and its overall health. The Data Engineer will be responsible for ensuring designs follow the Data Governance guidelines and the support the Enterprise data strategy. The Data Engineer will conduct Data Architecture development activities to inventory and analyze the company’s data assets, and research/evaluate/support adoption of Data strategy best practices. The Data Engineer bridges the gap between business and the technical implementation of the data-based solutions. Data Engineer provides expertise as it relates to articulating business requirements into data-based solutions, decision-making of the implementation and the overall execution of the data strategy. The company relies upon this position to have extensive knowledge of data trends in order to support current and future opportunities.

Show more Show less"
2814200667,Data Engineer,Goldman Sachs,2021-11-30,United States,"Richardson, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Job Description

ENGINEERING

What We Do

At Goldman Sachs, our Engineers don’t just make things – we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets .

Engineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.

Who We Look For

Goldman Sachs Engineers are innovators and problem-solvers, building solutions in risk management, big data, mobile and more. We look for creative collaborators who evolve, adapt to change and thrive in a fast-paced global environment.

Job Overview

We are looking for a Data Engineer to join our fast growing team. This person will be responsible for expanding and optimizing our current cloud based data pipeline architecture for the various cross functional teams. The ideal candidate has experience building robust data pipelines and reporting tools. However, someone with a strong application development background with keen interest in data engineering would be considered. The candidate will be collaborating extensively with Engineering, Analytics and Product teams to support functional use-cases and take data driven decisions.

Who we are looking for

Strong background in data processing & software engineering and can build high-quality, scalable data oriented products.
Industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, EMR, etc..) for building efficient, large-scale data pipelines.
Strong Software Engineering experience with in depth understanding of Python, Scala, Java or equivalent
Strong understanding of data architecture, modeling and infrastructure
Experience with building workflows (ETL pipelines)
Experience with SQL and optimizing queries
Problem solver with attention to detail who can see complex problems in the data space through end to end
Willingness to work in a fast paced environment
MS/BS in Computer Science or relevant industry experience.

Strongly recommended (but optional)

Experience building scalable applications on the Cloud (Amazon AWS, Google Cloud, etc..)
Experience building stream-processing applications (Spark streaming, Apache-Flink, Kafka, etc..)

About Goldman Sachs

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers .

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https:// www.goldmansachs.com/careers/footer/disability-statement.html

© The Goldman Sachs Group, Inc., 2021. All rights reserved.

Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity
Show more Show less"
2820846328,Data Engineer,Centrifuge LLC,2021-11-30,United States,"Virginia, United States",,Full-time,,"Requirement:

A minimum of 7 years of experience in complete software development lifecycle using Agile methodologies
5+ years of Python or Scala development experience
2+ years of experience with distributed processing using Spark (PySpark), Amazon EMR and S3
Experience with Amazon Lambdas is a plus.
5+ years of experience with Relational Database Systems and SQL
3+ years of experience with UNIX/Linux and shell scripting
Delivering solutions using Amazon Web Services (AWS EC2, RDS, S3, VPC, SQS, SNS and EMR)




Location: VA (temporary remote)

Duration: 6 months+

Contract: open




Centrifuge LLC is an Equal Opportunity Employer: All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Show more Show less"
2758752547,"Data Engineer, Core Growth",Snap Inc.,2021-12-04,United States,"Mountain View, CA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Snap Inc. is a camera company. We believe that reinventing the camera represents our greatest opportunity to improve the way people live and communicate. Our products empower people to express themselves, live in the moment, learn about the world, and have fun together.

We’re looking for a Data Engineer to join the Core Growth product engineering organization. Working from one of our west coast offices in Santa Monica, CA, Mountain View, CA, or Seattle, WA, you’ll collaborate with Software Engineers, Data Scientists, and Product Managers to help Snapchat grow across the globe. The Core Growth team is Snap’s growth engineering platform and its mission is to grow our community by promoting real friendships while they feel safe to express themselves, live in the moment, learn about the world and have fun together. The team builds and operates key products for user acquisition, activation, discovery, and retention at Snap such as registration and onboarding, friend recommendations, search, sharing, notifications, among others. In this role, you will build the data infrastructure and tools that will deliver insights to broaden and deepen user engagement and improve product experience for our hundreds of millions of passionate users. You will have an opportunity to tackle large-scale engineering and product challenges while working alongside kind, smart, and creative colleagues. Come grab a front row seat to witness and influence how Snapchat grows to become the world's camera!

What You’ll Do

Define data models for instrumentation and reporting in partnership with Engineering, Data Science, and Product Management to support product analytics.
Build scalable aggregation pipelines to deliver performant datasets that can be consumed through surfaces such as Looker, Tableau, Superset, and Jupyter.
Drive data quality end-to-end from instrumentation to reporting. Build automated controls and processes to prevent and fix regressions.
Democratize data access amongst engineers, PMs, and scientists with well-documented and extensible pipelines and datasets.
Partner with Snap’s Data Governance and Insights teams to make high-quality datasets in the Growth domain available for external and partner reporting.

Knowledge, Skills & Abilities

Experience in building data pipelines to serve reporting needs
Experience owning all or part of a team roadmap
Experience with data visualization tools like Looker and Tableau
Ability to prioritize requests from multiple stakeholders in disparate domains
Ability to effectively communicate complex projects to non-technical stakeholders

Minimum Qualifications

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
3+ year experience in SQL or similar languages
3+ years development experience in at least one object-oriented or scripting language (Python, Java, Scala, etc), Python preferred
Experience in ETL / Data application development

Preferred Qualifications

Hands on experience with Google BigQuery
Experience using and sharing notebook solutions like Jupyter
Experience in version control systems such as Git
Data architecture and warehousing experience
Experience with Airflow and Druid
Show more Show less"
2826785465,Data Engineer - Remote,TechFetch.com - On Demand Tech Workforce hiring platform,2021-12-04,United States,"Schaumburg, IL",Information Technology,Part-time,IT Services and IT Consulting,"""ALL our jobs are US based and candidates must be in the US with valid US Work Authorization. Please apply on our website directly."" Combine two of the fastest-growing fields on the planet with a culture of performance, collaboration and opportunity and this is what you get. Leading edge technology in an industry that's improving the lives of millions. Here, innovation isn't about another gadget, it's about making health care data available wherever and whenever people need it, safely and reliably. There's no room for error. Join us and start doing your life's best worksm)Primary Responsibilities Develops and implements scripts for maintenance and monitoringDemonstrates understanding of data structuresKnows modern tools and techniquesStays current with evolving technologiesSchedules jobs to provide required operational supportWorks within a domain to design and build data modelsStreamlines data within a domainUnderstands their responsible component of the technology stackSeeks to understand how customer will interact with system and how best to design solution from their perspectiveDemonstrates awareness of importance of security, scalability, reliability and feasibility in solution designSeeks out information to learn about systems that support or rely upon solution to better understand integrations and impactsEvaluates service areas to identify opportunities for automationStays current with evolving technologiesUnderstands data within a book of business for a line of business and is able to identify actionable insightsFocuses on one or two specific technologies Possesses basic business knowledgeContributes to the identification/prioritization of solution through analysis and discussionsUnderstands regulatory environment, sales and digital experience, and channel;Designs solutions within a single channelGathers facts and data to inform decision makingUses existing data sourcesUses and responds to information providedIdentifies cause and effect relationships between known variablesAdheres to quality control guidelines & practicesConsiders internal and external customers when evaluating decisionsTracks, identifies and promptly reports issues that may affect solution quality and bring forward improvement recommendationsYou?ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.Required Qualifications Undergraduate degree or equivalent experience.2 to 4 years in a data role with focus on domain modeling , data mapping and building of entity relationship diagramsAbility to work independently with minimal oversight on work product and approachDemonstrated ability to work with business teams to draw out data requirements and needs.Self motivated and able to work in a loosely defined role within a project or set of projectsUnderstands how to organize and execute against a proof of conceptCareers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best worksmAll Telecommuters will be required to adhere to UnitedHealth Group?s Telecommuter Policy.Colorado Residents Only: The salary range for Colorado residents is $64,800 to $116,000 Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements No matter where or when you begin a career with UnitedHealth Group, you?ll find a far-reaching choice of benefits and incentives Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity / Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment. Keywords: Data Engineer, Remote, WFH, WAH, Telecommute, Data, Engineer, Hiring Immediately, #RPO
Show more Show less"
2814248499,Data Engineer,Consumers Energy,2021-11-30,United States,"Jackson, MI",,Full-time,,"Our Customer Data Analytics team is looking for a hands-on Data Engineer who is open to travel to Jackson or Lansing, Michigan 1-2x a month but may remain remote otherwise.

Must be able to collect data from various systems and have strong communication skills. This person will be building critical data processing pipelines to solve ambitious challenges integrating our SAP and various systems.

Technologies: SQL, NoSQL, PySpark, Python, R. ETL and scheduling technologies and data pipelining (e.g. Azure Data Factory, Informatica, Apache)
Show more Show less"
2817847742,Data Engineer,IBM,2021-11-29,United States,"Baton Rouge, LA",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

tTtThe IBM Client Innovation Center in Baton Rouge is expanding and has immediate opportunities for experienced forward-thinking Data Engineer with a passion for growth and innovation. The success of IBM is in your hands as you transform vital business needs into innovation solutions to drive growth for our clients. Our clients are some of the world’s leading companies and you will be part of challenging projects to build and support technical solutions for their needs You will have access to the latest education, tools and technology, and a limitless career path with the world’s technology leader. Come to IBM and make a global impact!

The position of the Data Engineer plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. The Data Engineer defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business. Develops applications on Big Data and Cognitive technologies including API development. Expected to have traditional Application Development background along with knowledge of Analytics libraries, open-source Natural Language Processing, statistical and big data computing libraries. Strong technical abilities to understand, design, write and debug complex code.

The role of the Data Engineer is to work directly with the client using Pyspark,Scala, Hadoop, Hive and Postgre SQL. The Data Analyst must possess an understanding of the relational databases. The Data Engineer must also possess the skills to effectively collaborate with the client Subject Matter Experts (SMEs) to provide necessary solutions.

The successful candidates for this position will become members of our Client Innovation Team. You will work closely across the CIC network to delight our customers with leading edge solutions with a keen focus on quality and client satisfaction. In addition to strong collaboration across the team, you will be virtually integrated into our deep learning and knowledge program as well as employee engagement across NA. All resources in our CIC network may be requested to travel depending on specific client project needs. US Travel is typically related to knowledge transfer and client relationship building at the client site, as well as subsequent travel for key milestones or project initiatives. Travel is generally no more than 50% of the time. Preferred Locations: Lake Charles & New Orleans LA; Mobile AL; Pensacola FL; Gulfport, Hattiesburg, Jackson & Oxford MS; Beaumont & Galveston TX.

This position requires relocation to Louisiana within 30 days of the office reopening. This position requires up to 50% travel. This is not a permanent work from home position.

sprgg21

Required Technical and Professional Expertise

Minimum 3 Years Relevant Experience

Should have a strong knowledge on Pyspark, Scala, Hadoop,Hive and/or Postgre SQL

Preferred Technical And Professional Expertise

Unless specified as a Required Skill, the following are additionally preferred but not required:


Experience with big data solutions such as Hadoop, MapReduce, Hive, Pig, Kafka, Storm etc. is a major plus.


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2813266757,Software/Data Engineer,Deloitte,2021-10-31,United States,"Raleigh, NC","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

Work you'll do

Fast learning and fast thinking software engineer/data engineer that will work in a cross functional team. The team works in a fast paced environment to prototype and solve high profile problems in the Defense Sector.

The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Bachelor's degree required
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Must be able to obtain and maintain the required clearance for this role
Travel up to 25%
2+ years of experience using Java, JavaScript, HTML5, Python, MS Azure SQL

Preferred:

Active Secret Clearance
Previous Federal Consulting experience

How you'll grow

At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
Show more Show less"
2818943452,Data Engineer,Madison Logic,2021-12-03,United States,United States,Information Technology,Full-time,Marketing and Advertising,"We are seeking a Data Engineer with a highly analytical mind who is skilled at understanding data and is able to translate it into actionable insights. In this role you will develop easy to understand reports, dashboards, and tools with the aim of optimizing and streamlining the way data is viewed. In this highly collaborative role, you will work closely with the architecture and data teams to reach business objectives.




What You'll Do:

Use SQL/Python to create reports, dashboards, and visualizations.
Aggregate/Model data and use that data to build reports in Domo
Analyze data to help improve business performance.
Identify the best data sources for a given analysis.
Develop processes for data mining, data modeling, and data production.
Offer insights and recommendations to improve data reliability and quality.

What You Have:

Bachelor’s degree in computer science, statistics or mathematics
5+ year’s experience with Python or Node.js
5+ year’s experience with SQL or mySQL
5+ year’s experience with cloud computing services (AWS)
Working understanding of big data analytics
Experience working with data cleaning and standardizing process






Perks & Benefits:

Opportunities for Advancement – As We Grow, You Grow!
Competitive Benefits including Medical, Dental, Vision, and FSA plans
Employer-paid Life, AD&D and STD insurance
401k with Company Match
Generous Paid Time Off including: 9 paid Holidays, 17 Vacation Days (to start!), Sick Time, Summer Friday Program, and Parental Leave
2 Paid Volunteer Days
$100/month Work from Home Stipend
Legal & Financial Services Benefits
Company Outings, Social & Charity Events, Sponsored Healthy Hours & Happy Hours
Wellness initiatives
An innovative, energetic culture and a fantastic team!




Who We Are:

Our Vision: We empower B2B organizations globally to convert their best accounts faster




Our Values: #TEAM #OWNIT #RESPECT #EXCEL #EMPOWER




Our Commitment to Diversity & Inclusion:

Madison Logic is proud to be an equal opportunity employer. We are committed to equal employment opportunity regardless of sex, race, color, religion, national origin, sexual orientation, age, marital status, disability, gender identity or Veteran status.




Privacy Disclosure:

All of the information collected in this form and/or by your application by submission of your online profile is necessary and relevant to the performance of the job applied for. We will process the information provided by you in this form, your CV (including physical and online resume profiles), by the referees you have noted, and by the educational institutions with whom we may undertake to verify your qualifications with, in accordance with our privacy policy and for recruitment purposes only.




For more information on how we process the information you have provided including relevant lawful bases (where relevant) please see our privacy policy which is available on our website (https://www.madisonlogic.com/privacy/).

Show more Show less"
2818438741,Junior Data Engineer,IBM,2021-12-01,United States,"Baton Rouge, LA",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

The position of the Data Engineer plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. The Data Engineer defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business. Develops Big Data and Cognitive technologies including API development. Expected to have experience with ETL tools & Data warehouses. Strong technical abilities to understand, design, write and debug complex code.

Required Technical and Professional Expertise


Minimum 2 years of hands-on coding experience in Java
Minimum 1 years of hands-on coding experience in SCALA
Minimum 1 years of hands-on experience working with Kafka
Minimum 1 years of experience in Big Data technologies (Hadoop, Spark)
Minimum 1 years of hands-on experience with Spring Boot or Spring Cloud
Minimum 1 years of experience using SQL and good RDBMS conceptual knowledge
Minimum 1 years of experience with ETL tools


Experience with ADO or Jenkins for CI/CD

Preferred Technical And Professional Expertise


Experience in Kubernetes and Docker
Experience coding in Python
Big Data Certifications on Cloudera/Hortonworks/AWS/GCP/Azure
Certification on Snowflake Pro


Experience in Azure, AWS, GWP, IBM cloud etc.

About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2813662520,Data Engineer,Zions Bancorporation,2021-11-24,United States,"Salt Lake City, UT",Information Technology,Full-time,"Computer Software, Banking, and Financial Services","Zions Bancorporation’s Enterprise Technology and Operations (ETO) team is transforming what it means to work for a financial institution. We operate in a fast-paced, information-driven environment, which means we need people who bring diverse experiences, perspectives, and expertise to meet the ever-changing demands of a technology-driven world. We are grounded in the belief that “improving the work is the work” as we drive to create simple, easy, and fast solutions for our customers. Your ability to adapt, learn, and innovate helps increase revenue, reduce operational costs, and mitigates risk.

ETO provides opportunities for you to own your career growth through Diversity, Equity, and Inclusion, Women in Technology, and Workforce of the Future initiatives that allow you to network across the organization, volunteer in our community, and build your technical and soft skills. Together we are building a culture that values diversity and creates a space of belonging for all our team members. We believe that investing in your success is an investment in our customers and our business. Our people are what sets us apart and make us great.

Zions Bancorporation is currently looking for an experienced Data Engineer. The Data Engineering team is responsible for ingesting and processing terabytes of data a day to make quick and accurate business decisions in various domains. Our team is lean and agile. You must want to be part of a motivated and driven team and work with respected leaders. We need someone who is proactive, has a great attitude, is confident and wants to inspire others to achieve bank initiatives.

Responsibilities

Responsible for developing and deploying enterprise grade platforms that enable data-driven solutions.
Automate and maintain scalable infrastructure.
Ensures delivery of a highly available and scalable systems.
Monitor all systems and applications and ensure optimal performance.
Research and test new tools and applications.
Analyzes and designs technical solutions to address business needs.
Participate in troubleshooting applications and systems issues.
Identifies, investigates and proposes solutions to technical problems.
Develops, tests, and modifies software to improve efficiency of data platforms and applications. Provides technical support for issues.
Monitors system performance to maintain consistent up time.
Provides technical expertise where required within Information Technology Projects.
Prepares and maintains necessary documentation.
Participate in regular agile ceremonies, such as program increment planning, daily standups, team backlog grooming, iteration retrospectives, team demos and inspect & adapt, etc.
Keep up with the committed features and stories in the team backlog.
Work with the project manager/scrum master to remove impediments.
Serve in the goalie rotation to support Production.
Support test and QA efforts on the various data projects.
Coordinate with data operations teams to deploy changes into production.
Highest level may function as a lead.
Other duties as assigned.

Qualifications

Requires a Bachelor's in Computer Science, Computer Engineering or related field
4+ experience ETL, SQL, UNIX/Linux, Big Data distributed systems, various programming languages like Java and Python, orchestration tools and processes or other directly related experience. A combination of education and experience may meet qualifications.
Basic knowledge of search technology, building real-time data pipelines and various programming languages like Java and Python. Knowledge of ETL, UNIX/Linux, scheduling and orchestration tools and processes.
Good analytical, organizational and problem-solving skills.
Ability and desire to learn new technologies quickly.
Ability to elicit, gather and analyze user requirements.
Ability to work independently and collaborate with others at all levels of technical understanding.
Able to meet deadlines.
Good judgment and project management skills.
Ability to communicate both verbally and in writing with both technical and non-technical staff.
Ability to work in a team environment and have good interpersonal skills.
Ability to adapt to changing technology and priorities.
Must be able to work independently, handle multiple concurrent projects, with an ability to prioritize and manage projects effectively.
Must be able to interpret, validate and map business requirements to an appropriate solution.

Pay Range: $90,000-$120,000
Show more Show less"
2814491969,Data Engineer,DoorDash,2021-12-01,United States,"Seattle, WA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Data is at the foundation of DoorDash success. The Data Engineering team builds database solutions for various use cases including reporting, product analytics, marketing optimization and financial reporting. By implementing dashboards, data structures, and data warehouse architecture; this team serves as the foundation for decision-making at DoorDash.

DoorDash is looking for a Data Engineer to be a technical powerhouse to help us scale our data infrastructure, dashboards and tools to meet growing business needs.

What You Will Do

Work with business partners and stakeholders to understand data/reporting requirements
Work with engineering, product teams and 3rd parties to collect required data
Design, develop and implement large scale, high volume, high performance data models and pipelines for Data Lake and Data Warehouse.
Develop and implement data quality checks, conduct QA and implement monitoring routines.
Build and implement ETL frameworks to improve code quality and reliability
Build and enforce common design patterns to increase code maintainability
Manage reliability and scaling of portfolio of pipelines and data marts
Document new and existing models, solutions, and implementations
Mentor and coach team members to improve their designs and solutions

Qualifications

Hiring at various job and qualification levels.

10+ years of professional experience
7+ years experience working in data engineering, business intelligence, or a similar role
Proficiency in programming languages such as Python/Java
3+ years of experience in ETL orchestration and workflow management tools like Airflow, flink, Oozie and Azkaban using AWS/GCP
Expert in Database fundamentals, SQL and distributed computing
3+ years of experience with the Distributed data/similar ecosystem (Spark, Hive, Druid, Presto) and streaming technologies such as kafka/Flink.
Experience working with Snowflake, Redshift, PostgreSQL and/or other DBMS platforms
Excellent communication skills and experience working with technical and non-technical teams
Knowledge of reporting tools such as Tableau, superset and Looker
Comfortable working in fast paced environment, self starter and self organizing
Ability to think strategically, analyze and interpret market and consumer information

Why You’ll Love Working at DoorDash

We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies.
We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day.
We are learners - We’re not afraid to dig in and uncover the truth, even if it’s scary or inconvenient. Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute.
We are customer obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility.
We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.
We offer great compensation packages and comprehensive health benefits.

About DoorDash

DoorDash is a technology company that connects customers with their favorite local and national businesses in all 50 US states, Canada, and Australia. Founded in 2013, DoorDash empowers merchants to grow their businesses by offering on-demand delivery, data-driven insights, and better in-store efficiency, providing delightful experiences from door to door. By building the last-mile delivery infrastructure for local cities, DoorDash is bringing communities closer, one doorstep at a time. Read more on the DoorDash Engineering blog or www.doordash.com.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.
Show more Show less"
2807574832,Data Engineer,Cervello,2021-11-25,United States,"Boston, MA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Summary

You have experience with client projects and in handling vast amounts of data – working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.

Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science

Qualifications

Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds

ABOUT US: OUR WORKPLACE IS FUN AND FAST-PACED:

We are Cervello. We believe in the power of connected data. We are laser focused on helping organizations harness the interconnectedness of digital, data and decision-making. We are problem solvers and builders focused on helping our clients win with data. Our culture is cool and innovative. Our environment is casual and conducive to collaboration and problem solving. We take our work seriously but not ourselves. It’s the perfect balance of freedom and accountability. If you want to be part of something great – join us!

Equal Employment Opportunity and Nondiscrimination

Cervello prides itself on providing a culture that allows employees to bring their best selves to work every day. Our people can feel comfortable, confident, and joyful to do great things for our firm, our teams, and our clients. Cervello aims to build diverse capabilities to help our clients solve their most mission critical problems. Cervello is committed to building a diverse, unbiased and inclusive workforce. Cervello is an equal opportunity employer; we recruit, hire, train, promote, develop, and provide other conditions of employment without regard to a person’s gender identity or expression, sexual orientation, race, religion, age, national origin, disability, marital status, pregnancy status, veteran status, genetic information or any other differences consistent with applicable laws. This includes providing reasonable accommodation for disabilities, or religious beliefs and practices. Members of communities historically underrepresented in analytics and consulting are encouraged to apply.
Show more Show less"
2797891087,Data Engineer,Nomi Health,2021-11-16,United States,"Austin, TX",,Full-time,,"WHO ARE WE?




The way healthcare is paid for and delivered in America today is fundamentally flawed, making it cost too much and take too long for most Americans. We pay more for our health care than any other developed country, and yet our healthcare outcomes lag far behind. COVID is a wake up call.




Nomi Health was founded in 2019 as a direct healthcare company with a simple yet bold mission: rewire how we pay for healthcare and how it is delivered in order to create the cost-effective -- and simply effective -- experiences we all deserve as employers, patients and providers.




Our COVID-19 public health programs are a perfect example of a more direct, digital-first health care model at work. Since the start of the pandemic, we have delivered several of the very few “burden-free” testing and vaccination programs in America -- not requiring insurance, a doctor’s note or cost. Our programs have supported millions of Americans with digital scheduling and result delivery and 24-48 hour test result turnaround times, as well as mobile-based programs to take COVID tests and vaccines directly where they are needed most. Our operational know-how means we can deliver these programs to local governments, organizations and employers at among the lowest per unit costs in the country. Today, we are focused on locking arms with governments and organizations on effective COVID response programs that help Americans return to school, work and life.




Having delivered millions of COVID tests and hundreds of thousands of vaccinations to date, Nomi’s journey is just starting in delivering integrated care the way it should be. Our mission won’t rest until we rewire health care infrastructure and deliver the kind of health care experience we all deserve in America.




The system must change, and we’re the ones to do it. Join us on the journey.




WHAT IS A DAY IN THE LIFE?




As a Data Engineer, you will provide technical and domain subject knowledge to the company and future customers. You should be comfortable working in a fast-paced, startup environment. You should be able to know how to examine new data systems requirements and implement migration models. You will also spend a good deal of time problem solving, analyzing architecture, and assessing architect models, reviewing data migrations, selecting platforms, and onboarding of data management solutions that meet the technical and operational needs of the business. You must be hands-on with tools and code.




OK, HOW ABOUT A FEW SPECIFIC RESPONSIBILITIES?




Contribute to the development of the AI & ML capabilities for the Nomi Health
Develop and implement data models to guide business decisions
Work in a fast paced, startup environment
Mapping data sources, including descriptions of the business meaning of the data, its uses, its quality, the applications that maintain it and the database technology in which it is stored. Documentation of a data source must describe the semantics of the data so that the occasional subtle differences in meaning are understood.
Documenting interfaces and data movement by recording how mapped data is moved around the virtual enterprise. This includes the frequency of movement, the source and destination of each step, how the data is transformed as it moves, and any aggregation or calculations.
Designing the movement of data through the enterprise, including sources of data and how the data is moved around in order to be improved.
Defining integrative views of data to draw together data from across the enterprise. Some views will use a database of extracted data and others will bring together data in near real time, considering data currency, availability, response times and data volumes. Designing canonical data views to limit technical debt as data flows from point-to-point transformation.
Defining technical standards and guidelines. Assess and document when and how to use the architected producers and consumers, the technologies to be used for various purposes, and models of selected entities, objects, and processes. The guidelines should encourage reuse of existing data stores, as well as address issues of security, timeliness, and quality.
Investigate and participate in emerging technologies and new release Proofs of Concept (PoCs).
Leveraging existing [core] data assets.
Managing related metadata to include business descriptions of the data, details of any calculations or summaries, descriptions of the sources of the data, and indications of data quality and currency.
Communicating the data architecture across the enterprise.
Ensuring a focus on data quality by working effectively with data stewards so they can understand data semantics and identify opportunities for improving data quality.




REQUIREMENTS

Bachelor's degree in Computer Science, Computer Engineering, or relevant field.
A minimum of 2-3 years’ experience in a similar role (production environment preferred)
Must have AWS experience. (Snowflake, Databricks, S3, Glue, RDS, Lambda desirable)
Must have big data experience
Must have coding experience (python preferred)
Experience with building APIs (REST or SOAP)
Familiarity of system concepts and tools within an enterprise architecture framework.
Knowledge of various modern data formats, tools, and methodologies. (Informatics desirable)
Knowledge of Clojure or Go (bonus)
Ability to work in a fast paced, startup environment
Excellent organizational and analytical abilities.
Outstanding problem solver.
Good written and verbal communication skills.

Show more Show less"
2803437535,"Data Engineer, Core Automation Services",Tesla,2021-10-28,United States,"Fremont, CA",Information Technology,Full-time,"Renewable Energy Semiconductor Manufacturing, Motor Vehicle Manufacturing, and Utilities","Role

Data is deeply embedded in the product and engineering culture at Tesla. We rely on data – lots of it – to improve manufacturing, to optimize hardware designs, to proactively detect faults, and to optimize load on the electrical grid.

We're a small but fast-growing team which is building and operating the new data pipelines in the manufacturing environment at Tesla. We collect massive amounts of IoT data, provide storage, access, and high-volume processing. Our stack is built on top of open source technologies, including Spark, Kafka, and related.

We're looking for a talented engineer to join us as a foundational member of the team to deliver new and improved big data services and infrastructure. Your work will affect many hundreds of Tesla engineers daily, as well as improving the functionality of our cars, chargers, and batteries worldwide.

Responsibilities

Employ and improve industry-leading, scalable, distributed open-source technologies
Build back-end systems from scratch that are capable of handling trillion+ events per day
Facilitate operation of highly-available distributed systems at scale and across multiple locations
Facilitate others in deploying, operating, and extending upon your clean, tested code
Help define a platform that is highly leveraged, multi-tenant, and self-serviced
Work with data engineers and data scientists to drive efficient solutions from the platform
Help define the data story and enable data-driven solutions at Tesla, both technically and culturally

Requirements

Strong programming fundamentals, particularly in data structures, concurrency, Go, Python, and Java
Deep understanding of a complex distributed system, such as Kafka, Spark, HBase, ElasticSearch
Have built and optimized highly available, scalable, distributed back-end services
Ability to break down and deeply understand complex problems and communicate complex matters efficiently
Strong problem solving skills, optimizing for the simplest, most robust yet practical solutions
Reliable, dependable, trustworthy, participating team member
Smart but humble, with a bias for action
Show more Show less"
2798050764,REMOTE Sr. Big Data Engineer,Experian,2021-10-24,United States,"Costa Mesa, CA",Engineering,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Company Description

Experian is the world’s leading global information services company, unlocking the power of data to create more opportunities for consumers, businesses and society. We are thrilled to share that FORTUNE has named Experian one of the 100 Best Companies to work for. In addition, for the last five years we’ve been named in the 100 “World’s Most Innovative Companies” by Forbes Magazine.

Job Description

Experian’s Business Information Services is a leader in providing data and predictive insights to organizations. By leveraging state-of-the-art technology and superior data compilation techniques, we provide market-leading tools that assist small and midsize businesses in making real-time decisions

What You’ll Be Doing

Define technical scope and objectives through research and participation in requirements-gathering and definition of processes
Ingest and Process data from various sources in raw, structured, semi-structured, and unstructured format into Big Data ecosystem
Realtime data feed processing using Big Data ecosystem
Design, review, implement and optimize data transformation processes in Big Data ecosystem
Test and prototype new data integration tools, techniques and methodologies
Participate in overall test planning for the application integrations, functional areas and projects.
Work with cross functional teams in an Agile/Scrum environment to ensure a quality product is delivered

Qualifications

What your background looks like

Technical Skills

10+ years of hands-on experience with enterprise scale applications and systems
5+ Year of expertise in Big Data technologies in Hadoop ecosystem (Spark, Yarn, Kafka, Oozie, HBase, Hive, Spark, HDFS, MapReduce etc.), Hadoop distributions like Cloudera (preferred)
5+ Extensive development experience in Java specifically in Spring Framework and related technologies (Springboot, SpringData, SpringCloud, SpringSecurity etc...)
Experience with Scala is highly desirable
Strong understanding of data analytics and data visualization
Experience with Python and Ruby is a plus
Excellent analytical and problem solving skills
Excellent one-on-one communication and presentation skills, specifically able to convey technical information in a clear and unambiguous manner
Working knowledge of Linux operating system

Qualification

Technically focused Bachelor’s degree in Computer Science, Engineering, Math, etc.
Master Degree is a plus

Perks

Competitive pay and comprehensive benefits package
Flexible work schedule and relaxed dress code

Additional Information

All your information will be kept confidential according to EEO guidelines.

Experian is proud to be an Equal Opportunity and Affirmative Action employer. Our goal is to create a thriving, inclusive and diverse team where people love their work and love working together. We believe that diversity, equity and inclusion is essential to our purpose of creating a better tomorrow. We value the uniqueness of every individual and want you to bring your whole, authentic self to work. For us, this is The Power of YOU and it ensures that we live what we believe.
Show more Show less"
2793483609,Staff Big Data Engineer (Analytics),App Annie,2021-12-03,United States,"San Francisco, CA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","*PLEASE NOTE THAT YOU CAN WORK REMOTELY BUT YOU NEED TO BE LOCATED IN PST/PDT OR MOUNTAIN TIME ZONE TO APPLY FOR THIS ROLE

Something about us

App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. We are headquartered in San Francisco with 12 offices worldwide. More than 1,200 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business.

Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.

What can you tell your friends when they ask you what you do?

We’re looking for an experienced Big Data engineer who can create innovative new products in the analytics and data space. You will participate in the development that creates the world's #1 app stores analytics service. Together with the team you will build out new product features and applications using agile methodologies and open source technologies. You will work directly with Product Managers, Software Architects, and will be on the front lines of coding new and exciting analytics and data mining products. You should be passionate about what you do and excited to join an entrepreneurial start-­up.

You will be responsible for and take pride in….

As a Big Data Engineer, we will need you to be in charge of model implementation and maintenance, and to build clean, robust and maintainable data processing program that can support these projects on huge amount of data, this includes

Able to design and implement complex product components based on requirements with possible technical solutions.
Write data programs using pyspark with a commitment to maintaining high quality work while being confident in dealing with data mining challenges.
Discover any feasible new technologies lying in the Big Data ecosystem, share them to team with your professional perspectives.
Get up to speed in the machine learning domain, implementing analysis components in a distributed computing environment with instruction from Data Scientists.
Be comfortable conducting detailed discussions with Data Scientists regarding specific questions related to specific data models.
You should be a strong problem solver with proven experience in big data.

You should recognize yourself in the following…

Hands-on experience and deep knowledge of Hadoop ecosystem
Must: Spark, Mapreduce, HDFS
Plus: Storm, Kafka
Must have Linux environment development experience.
Proficient with programming in Python, experience in Pandas, Sklearn or Other data science and data analysis toolset is a big plus.
Having a background of data mining and machine learning domain, familiar with common algorithms and libs is a plus.
Passion for cloud computing (AWS in particular) and distributed systems.
You must be a great problem solver with the ability to dive deeply into complex problems and emerge with clear and pragmatic solutions.
Good communication skills and cooperation globally.
Major in Math or Computer Science.

This is what we offer…

We provide a $1,000 (country equivalent) WFH allowance to set you up for remote work success.
Internet allowance for stable internet connection, so your video does not freeze on Zoom.
Flexible working days. We love to meet, but if you need to get your kids behind school-zoom, need to leave early to get to your band repetition or gym classes, do your thing.
Paid leave, so long as you promise to come back!
Health and dental benefits.
An international team of talented and engaged people from different cultural backgrounds and locations.
Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!
Unlimited access to online learning platform Udemy to help you develop your skills.
Virtual initiatives and events to keep you connected with your colleagues.
Generous Employee Referral Program. Up to $10,000 for specific roles.

Yes, I want this job!

Show more Show less"
2826003810,Data Engineer,Roadie,2021-12-03,United States,"Atlanta, GA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Roadie is a crowdsourced delivery service that connects businesses with items to deliver with drivers already on the road. Roadie works with businesses across virtually every industry to provide a faster, cheaper, and more scalable solution for same-day deliveries nationwide. Roadie reaches 90% of U.S. households — the largest local same-day delivery footprint in the nation.

Roadie is seeking a Data Engineer who's passionate about data and making data-driven decisions to join our growing Data Engineering team. This role will focus on building, maintaining, and scaling our data pipelines and warehouses by working closely with our business and product owners to create useful, easy-to-consume data for reporting and analytics. You will also have the opportunity to help develop strategy for long term Data Platform architecture. Our data is dynamic across many teams, so a collaborative and communicative spirit is essential to ensuring you're successful in this role.

What You'll Be Doing

Implement automated data solutions to support the organization's rapidly scaling data platform
Build and maintain ETL/ELT pipelines pulling from OLTP and other sources to extend internal data warehouses
Partner with engineers and business stakeholders from various teams to build data insights and help them to achieve their business goals
Participate in code and design reviews to maintain our high development standards
Write well designed, testable, efficient Python code for data processing and automation
Provide production support for data tools and data needs across the business
Evaluate open source/vendor tools for data lineage, data integrations, and data quality frameworks


What You Bring

2 to 3 years experience with scaling production systems, ideally in a start-up environment
Expertise in SQL with ability to build complex queries across platforms
At least 2 years of experience in Python
Experience with cloud-based architectures on AWS, GCE, or similar
Experience with PostgreSQL, as well as MPP databases such as Redshift
Experience working with data systems, data warehouse solutions, and ETL/ELT
Experience with various data visualization tools such a Redash/Superset/Tableau/Looker/Power BI
Experience working with workflow management tools such as Airflow/Luigi/ Dagster
Familiarity with OLAP datastores such as Clickhouse, Apache Pinot, Druid
Experience working with structured and unstructured data
Demonstrated ability to learn new technologies quickly
Strong critical thinking and problem solving skills
Experience writing clean, stable and maintainable code in production environments
Bachelor's degree in Computer Science or related technical field or equivalent practical experience


Bonus

Experience with NoSQL technologies and distributed computing frameworks
Experience working with Databricks/Qubole or similar platforms using Spark/PySpark/Scala
Experience in creating real time data analytics using tools such as Kafka, Kinesis, Flink, etc.
Familiar with continuous integration and development tools (e.g. Jenkins, Circle CI, Travis CI)
Understanding of DevOps tools such as Docker, Kubernetes, AKS, Helm, Terraform, etc.


Why Roadie?

Competitive pay, great health benefits (medical/dental/vision/life), 401k with company match. Flexible schedule with generous PTO, guaranteed monthly 3-day weekends, and the technology you need to get the job done.

All team members are working remotely and enjoying a monthly WFH stipend.
Show more Show less"
2816394475,Data Engineer,Masterworks.io,2021-11-30,United States,New York City Metropolitan Area,,Full-time,,"COMPANY OVERVIEW:

Masterworks is the only company to allow individuals to invest and trade shares in SEC-registered blue-chip paintings whose markets appreciate between 8-20%+ with low correlation to the stock market.

At 250,000 investors, the business has been featured in most major media publications such as NY Times, CNBC, CNN, WSJ, and more. It is already profitable and is a “unicorn,” being valued at more than $1 billion.




POSITION OVERVIEW:

As a Data Engineer, you will help create a robust and scalable data platform for other teams across the company to leverage.

Join a rapidly growing team with the job of evolving our data platform to enables the business to scale its operations
Work cross-functionally with various engineering teams, finance and product partners to design the next generation of our data platform
Ideally you will be a self-starter, detail and quality oriented, and excited about the prospect of having a big impact with data at Masterworks




KEY TASKS & DUTIES:

Assist in architecting a scalable and flexible data platform for Masterwork’s products and internal data engineering and data science teams
Make Masterworks data more discoverable, organized and easy to use for Data Scientists and Analysts across the company
Mature our existing data processing pipelines to modern tools and languages
Identify data infrastructure issues and propose solutions
Setup and configure Data Warehouse solutions, utilizing dimensional modeling techniques to create easy to use, scalable data infrastructure




QUALIFICATIONS:

BS degree in Computer Science or equivalent
8+ years of experience in software engineering
5+ years of experience in data engineering
Experience with Dimensional Modeling (Kimball methodology) & Data Warehouse design
Experience building ETLs via DAGs (Airflow)
Experience in Data Reporting & Visualization tools like Mode, Domo, Looker, Tableau and Redash
Experience with AWS data tools like EMR, RDS, Redshift, Glue, Athena, S3 and Lambda
Advanced knowledge of Python (Pandas, Jupyter Notebooks, Programmatic AWS via Boto)
Advanced knowledge of SQL (CTE, rank()ing / Windowing functions)
Ability to make sound, complex decisions in a fast-paced technical environment
Passion for cyber security and raising the security bar




MEASUREMENTS OF SUCCESS IN THE FIRST 90 DAYS:

Assess the current data solutions (storage, ETL, dashboarding) and determine a roadmap for meeting our business needs
Considering AWS tools like Redshift to construct a data warehouse source of truth
Determine a plan for replacing Redash with a modern reporting platform
Identify legacy data pipelines and storage mechanisms and port to industry standards
Determine how to scale our data platform by leveraging industry trends and best practices
Estimate efforts, identify risks, and participate in project planning and status meetings
Be a self-starter, able to work independently, be flexible and be able to succeed in a fast-paced, high intensity startup environment




OTHER REQUIREMENTS:

Ability to work anywhere in the US (Fully remote) - If you are in the tristate area, you are welcome into the new NYC office
Must be eligible to work in the US - no exceptions
Show more Show less"
2817379274,Big data engineer,Schneider Electric,2021-12-01,United States,"Andover, MA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Schneider Electric is the global specialist in energy management and automation. With revenues of ~€25 billion in FY2018, our 144,000+ employees serve customers in over 100 countries, helping them to manage their energy and process in ways that are safe, reliable, efficient and sustainable. From the simplest of switches to complex operational systems, our technology, software and services improve the way our customers manage and automate their operations. Our connected technologies reshape industries, transform cities and enrich lives.

At Schneider Electric, we call this Life Is On.

Schneider Electric is leading the Digital Transformation of Energy Management and Automation in Homes, Buildings, Data Centers, Infrastructure and Industries.With global presence in over 100 countries, Schneider is the undisputable leader in Power Management – Medium Voltage, Low Voltage and Secure Power, and in Automation Systems. We provide integrated efficiency solutions, combining energy, automation and software.

In our global Ecosystem, we collaborate with the largest Partner, Integrator and Developer Community on our Open Platform to deliver real-time control and operational efficiency.

We believe that great people and partners make Schneider a great company and that our commitment to Innovation, Diversity and Sustainability ensures that Life Is On everywhere, for everyone and at every moment. www.schneider-electric.com

Schndier Electric is looking for a big data engineer to join big data platform team located in Boston region, MA.

As part of the data platform team, you will be responsible for developing, testing , deploying and maintaining big data platform components and big data solutions. As a big data engineer, you’ll work on collecting, storing, processing, and analyzing of huge sets of data and make this data easily accessible across the company and usable in multiple different projects.

Duties And Responsibilities

Use big data technologies to develop distributed, fault-tolerant scalable data solultions.
Collect and process data at scale from a variety of sources for different project needs.
Participate in identifying, evaluating, selecting and integrating big data frameworks and tools required for the big data platform.
Design, develop, and maintain data pipelines , data platforms using selected frameworks and tools based on requirements from different projects.
Convert structured and unstructured data in to the form that is suitable for processing. Provide support to different teams in analysizing data.
Design, develop and maintain data API’s.
Integrate data from variety of data sources using federation techniques.
Develop solutions independently based on high-level design and architecture with minimal supervision.
Monitor the performance of the big data platform on a regular basis and tune the infrastructure and platform components accordingly to ensure the best performance.
Maintain a high level of expertise in data technologies and stay current on latest data technologiess.


Qualifications

Overall 7+ year experience in software development.
3+ years of experience in data engineering.
Prior experience with implementing big data platform components that are scalable, high performing, and lower in operations cost.
Proven experience with integration of data from multiple heterogeneous and distributed data sources.
Experience with processing large amounts of data (structured and unstructured.
Experience in production support and troubleshooting.
Hands-on knowledge of containers, API designing and implementing is a must.
Experience with NoSQL databases, Graph databases, relataional databases, time series databases.
Excellent knowledge of various ETL techniques and frameworks, various messaging systems, stream-processing systems, Big data ML toolkits, big data querying tools
Experience in Python, Go, Perl, Javascript, Kafka, Spark, Kubernetees.
Good knowledge of Agile software development methodology.
Excellent interpersonal, communication (verbal and written) skills.
Proven experience in managing and working with teams based in multiple geograhies.
Bachelor’s Degree or higher in Computer Science or a related field.


Schedule: Full-time

Req: 007GFR
Show more Show less"
2816542400,Data Engineer,Independent Financial Partners (IFP),2021-12-02,United States,"Tampa, FL",,Full-time,,"Data Engineer (THIS IS NOT A REMOTE POSITION)

Company

At IFP, innovation and user experience drive everything that we do. As we grow, we are excited to provide our teams new opportunities. We are a financial services company that puts our financial professionals first. Our goal is to be the easiest firm to work with in the industry and we’re looking for creative and talented people to help us achieve that goal.




Team

IFP’s technology team is a growing team, responsible for building out and maintaining our technology infrastructure (including our proprietary software, Advisor[X]), harnessing data to enhance solutions and decision making, and leveraging a modern approach to automation to efficiency to daily workflows.




Responsibilities

Reporting and data analysis using various platforms, including AWS and Salesforce
Communicating outcomes and insights to various stakeholders to aid strategic decisions for improvements
Identify and drive scalable solutions for building and automating reports, dashboards, and infrastructure to monitor key performance metrics and workforce strategy
Support software engineering team in feature development and research

Qualifications

Experience managing data and reporting in Salesforce and AWS
Experience in a quantitative and/or analytical role using data wrangling and automation tools such as Python, Salesforce and SQL
Effective communication skills and the ability to understand complex processes and apply creative problem solving to find efficiencies and improvements




IFP Is an Equal Opportunity Employer

Show more Show less"
2813964417,Data Engineer - Site Reliability,Morgan Stanley,2021-11-22,United States,"Alpharetta, GA","Project Management, Analyst, and Engineering",Full-time,"Financial Services, Investment Banking, and Investment Management","Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. Morgan Stanley can provide a superior foundation for building a professional career - a place for people to learn, to achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology works as a strategic partner with Morgan Stanley business units and the world's leading technology companies to redefine how we do business in ever more global, complex, and dynamic financial markets. Morgan Stanley's sizeable investment in technology results in quantitative trading systems, cutting-edge modeling and simulation software, comprehensive risk and security systems, and robust client-relationship capabilities, plus the worldwide infrastructure that forms the backbone of these systems and tools. Our insights, our applications and infrastructure give a competitive edge to clients' businesses—and to our own.

The Data Engineering group, RTOI is responsible for design and support for continuous data streams from disparte sources into a variety of targets. Includes design and development of applications to consolidate data from various sources (Internal + External), integration and enrichment with other sources of data with central repositories, applications to manage data flows between heterogeneous sources and applications to uniformly distribute data for downstream consumption. Working in a highly collaborative and dynamic environment to engineer, develop and integrate a variety of systems and applications through multiple environments.

Tasks Include, But Are Not Limited To

Design and support Data pipeline initiatives
System design, site reliability, administration and performance tuning. Engineer optimizations and solutions for real time streaming applications.
Ensure performance, availability and scalability of data solutions including Kafka and Elastic Search (ELK)

Skills

Strong Unix / Linux skills
Apache Kafka
Elastic stack
Working knowledge of scripting languages (e..g, Shell + python)
Understand continuous data stream concepts
Working knowledge of XML
Strong troubleshooting skills
Database (eg: SQL, Sybase, DB2)
Team oriented and can work well within a global collaborative model
Be comfortable expressing your ideas in meetings, design sessions, etc.
Good analytical and problem solving skills that are coupled with strong communication
Self-sufficient and show ability to lead given the opportunity

Posting Date

Nov 23, 2021

Primary Location

Americas-United States of America-Georgia-Alpharetta

Education Level

Bachelor's Degree

Job

Engineering

Employment Type

Full Time

Job Level

Associate
Show more Show less"
2814722919,Big Data Platform Engineer,Experian,2021-11-06,United States,"Costa Mesa, CA",Engineering,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Company Description

Ascend Sandbox is an integrated BigData and analytics platform. Our clients, some of the America’s largest financial institutions, use this platform to understand consumer credit behavior and build models for credit decisioning, marketing and account review purposes. We are looking for an expert platform engineer with in-depth knowledge on BigData analytics & public cloud platforms to help us run this peta-byte scale BigData platform and provide the best possible experience for our clients.

What You’ll Do Here

Responsible for continuous platform enhancements, upgrades, availability, reliability and security of the Ascend Sandbox platform.
Provide end-to-end observability of our Ascend Sandbox platform.
Responsible for resolving incidents reported by Sandbox users and take preventive actions.
Help Sandbox users with troubleshooting failed MapReduce/Hive/Spark applications.
Help Sandbox users to improve the performance and optimize their MapReduce/Hive/Spark applications.
Participate in follow-the-sun on-call rotation to address any emergency production incidents affecting the Sandbox platform.

What You'll Need To Succeed

Must Have Skills

Deep understanding of Linux, networking fundamentals and security.
Solid professional coding experience with at least one scripting language - Shell, Python etc.
Experience working with AWS cloud platform and infrastructure.
Experience managing large BigData clusters in production (at least one of -- Cloudera, Hortonworks, EMR)
Excellent knowledge and solid work experience providing observability for BigData platforms using tools like Prometheus, InfluxDB, Dynatrace, Grafana, Splunk etc.
Experience managing BigData clusters with compute decoupled from storage (Eg: S3) on public cloud platforms.
Expert knowledge on Hadoop Distributed File System (HDFS) and Hadoop YARN.
Decent knowledge of various Hadoop file formats like ORC, Parquet, Avro etc.
Deep understanding of Hive (Tez), Hive LLAP, Presto and Spark compute engines.
Ability to understand query plans and optimize performance for complex SQL queries on Hive and Spark.
Hands on experience supporting Spark with Python (PySpark) and R (SparklyR, SparkR) languages.
Experience working with Data Analysts, Data Scientists and at least one of these related analytical applications like SAS, R-Studio, JupyterHub, H2O etc.
Able to read and understand code (Java, Python, R, Scala), but expertise in at least one scripting language.
Experience managing JVM based applications in production.
Excellent written and oral communication.

Nice To Have Skills

Experience with workflow management tools like Airflow, Oozie etc.
Implementation history of Terraform, Packer, Ansible, Chef, Jenkins or any other similar tooling.
Prior working knowledge of Active Directory and Windows OS based VDI platforms like Citrix, AWS Workspaces etc.
Professional coding experience in at least one programming language, preferably Java.
Experience with other public cloud platforms like Azure and GCP is a bonus

Additional Information

All your information will be kept confidential according to EEO guidelines.

Experian is proud to be an Equal Opportunity and Affirmative Action employer. Our goal is to create a thriving, inclusive and diverse team where people love their work and love working together. We believe that diversity, equity and inclusion is essential to our purpose of creating a better tomorrow. We value the uniqueness of every individual and want you to bring your whole, authentic self to work. For us, this is The Power of YOU and it ensures that we live what we believe.
Show more Show less"
2791839719,Data Engineer,IBM,2021-11-12,United States,"San Antonio, TX",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2816509299,Data Engineer,Marsh McLennan,2021-12-02,United States,New York City Metropolitan Area,Information Technology,Full-time,Financial Services,"Role

The Data Engineer role within the Data Strategy group at Guy Carpenter (“GC”) provides an opportunity to own the build-out and implementation of data solutions to power one of the world’s largest and most respected risk management and reinsurance firms. The Data Strategy group has a “start-up style” mandate and internal consulting role (within a $1.3 billion company) to effectively enhance the acquisition, storage, analysis, fidelity, and monetization of massive amounts of client, internal, and third-party data across the GC organization.
As a member of the Data Strategy group, the Data Engineer will work with fellow data scientists, product managers, business analysts, and stakeholders from other internal groups to design and improve data-centric projects with the dual mandate of (1) increasing the efficiency of the data collection and analysis process across GC and (2) driving the monetization of data via newly designed and existing products for GC’s reinsurance clients. The data engineer will be the lead facilitator on innovative initiatives and will have ownership over the design, development, and delivery of projects which will require direct reporting to senior-level management in both business and technical groups.




Responsibilities

Develop, implement, and deploy custom data pipelines powering machine learning algorithms, insights generation, client benchmarking tools, business intelligence dashboards, reporting and new data products.
Innovate new ways to leverage enormous amounts of various datasets to drive revenues via the development of new products with the Data Strategy team, as well as the enhanced delivery of existing products
Consume data from a variety of sources (relational DBs, APIs, NetApp and other cloud storage, FTPs) & formats (excel, CSV, XML, parquet, unstructured))
Construct and maintain data pipelines between GC’s databases, and other sources, with the data lake utilizing modern ETL frameworks
Own the role of data steward for a variety of high value datasets and implement innovative quality assurance practices
Establish and implement metadata management standards and capabilities, including lineage mapping
Enforce strong development standards across the team through code reviews, unit testing, and monitoring
Perform basic data analysis within Jupyter Notebooks to validate the fulfillment of requirements for data pipelines
Evangelize data strategy techniques and best practices throughout global strategic advisory
Keep up-to-date on the latest trends and innovation in data technology and how these trends apply to GC's business and data strategy




Required Qualifications

5+ years of relevant experience as a data engineer or in a similar role
Bachelor’s or master's degree in data science, computer science or related quantitative field such as applied mathematics, statistics, engineering, or operations research
Extensive experience with Spark, Python, and SQL
Extensive experience integrating data from semi-structured sources
Experience deploying/maintaining cloud resources (AWS, Azure, or GCP)
Knowledge of various industry-leading SQL and NoSQL database systems
Experience working in an Agile environment to facilitate the quick and effective fulfillment of group goals
Good interpersonal skills for establishing and maintaining good internal relationships, working well as part of a team and for presentations and discussions
Strong analytical skills and intellectual curiosity as demonstrated through academic experience or work assignments
Good ability to prioritize workload according to volume, urgency, etc. and to deliver on required projects in a timely fashion




Preferred Qualifications

Strong understanding of entity resolution, streaming technologies, and ELT/ETL frameworks
Ability to articulate the advantages of various cloud and on-premises deployment options
Experience with Master Data Management
Experience with web scraping and crowd sourcing technologies
Familiarity with modern data productivity frameworks and their alternatives such as Databricks, DataRobot, and Alteryx
Experience with the MS Azure cloud environment, including ARM template deployments
Strong knowledge of CI/CD principles and practical experience with a CI/CD technology (Azure Devops, GitLab, Travis, Jenkins)
Show more Show less"
2822601710,Cloud & Big Data Engineer,Pegasus Knowledge Solutions,2021-12-01,United States,United States,Information Technology,Contract,IT Services and IT Consulting and Telecommunications,"The Senior Cloud & Big Data Engineer is expected to be proficient in all the Cloud & Big Data technologies. With limited guidance, the Senior Engineer drives quality improvement practices to ensure our Cloud & Big Data technology is functioning at an optimal performance level, is flexible for business needs and can be scaled for growth needs.




The primary work function of this position is initially focused on Cloud (AWS/Azure) cloud engineering and process improvements to our cloud program. The ideal candidate will come in with AWS/Azure administration and engineering experience and will have some Python or Terraform experience to help with some of the automation. Additionally, will also help the team by expanding their experience beyond Cloud to the Big Data technology.




Other than the performance improvement process aspect, functionally, this is more of an engineering/administration versus an ETL or code development type of position.




Qualifications

• 5+ years administrating 2 or more of the following: Cloudera Hadoop / Confluent Kafka / AWS / MongoDB / EDB-PostgreSQL

• 5+ years of experience with Cloud or Big data related principles, practices, and procedures

• Experience working with application developers to understand their needs in order to help them and their programs to access Big Data platforms

• Experience with Agile methodologies including Scrum

• Ability to present at executive level and highly technical individuals

• Ability to develop and maintain process workflows

• Ability to use Jira to drive or update project activities

• Experience with partitioning within Hadoop

• Experience with creating and managing Kafka topics

• Experience with managing RDBMS and NoSQL

• Experience with native AWS modules and moving applications to AWS and supporting it

• Experience with Cloud Center of Excellence and Cloud Maturity Models

• Experience with RESTful API, Services is a plus…

o Experience with partitioning within Hadoop

o Experience with crafting and handling Kafka topics

o Experience with handling RDBMS and NoSQL technology

o Experience with Linux systems and scripting languages

• Experience with functional programming (Scala, Python, Terraform)

Show more Show less"
2814243530,Remote Data Engineer,Toughbyte,2021-11-30,United States,United States,,Full-time,,"Our partner provides a smart enterprise platform that builds a deep language intelligence operating system for technical domains, including Insurance, Financial Services, and Life Sciences. Their platform, built by the former leadership of the MIT Media Lab, harnesses AI and Natural Language Understanding to deliver new capabilities to augment human performance. Their NLU platform is a pre-built “no-code” drag and drop solution to reduce the deployment time of applications from months to days.




Now they are looking for a Data Engineer experienced with orchestration of data and ML pipeline workflows and writing batch and stream data processing pipelines for: ingestion, ETL, and analytics.




Tasks:

Collaborate with the VP Eng. on the overall data strategy for the B2B SaaS applications and API functionality delivery, breaking down tasks into manageable and achievable deliverables
Work cross-functionally with AI scientists, Backend Engineers, DevOps and Product Managers to design and implement new data models for the product line
Expand the current data-processing framework to include all active projects across multiple environments
Process unstructured data into a form suitable for analysis
Mentor other data engineers on best practices
Understand the products from a customer perspective and the software from an engineering perspective
Own assignments from proof-of-concept to design, architecture, code delivery, and deployment




Must-have: 

Strong programming skills in Python 
Experience working with Google Cloud Composer (Airflow) 
Experience with Google Cloud DataFlow or Apache Beam and its runners (knowing how things work under the hood is a plus)
Experience with Elasticsearch and PostGres and an interest in learning Graph databases (Neo4j and DGraph)
Experience with DataLakes, Google Cloud Storage




Nice-to-have: 

Knowledge of other programming languages
Knowledge of other workflow orchestration tools
Knowledge of S3, Delta lake
Familiarity with dashboard technologies (Looker, Ploty, Tableau, Grafana, ELK, etc.)
Familiarity with scaling (Redis, SQL, Elasticsearch, PostGres, Graph Dbs, Kafka, etc.)
Knowledge of data warehousing and ETL concepts
Familiarity with AWS equivalent tech stack: Glue, EMR, Data Pipelines
Data security, sub-second latency, Machine Learning and NLP experience




Benefits:

Fully-remote position
Additional vacation week between Christmas and New Year




Interview process:

Intro call with Toughbyte
1-2 hour Technical interview with VP of Engineering 
1h call with the team
Show more Show less"
2791919706,Big Data Engineer,IT Resource Hunter,2021-11-09,United States,"Alpharetta, GA",,Contract,,"Position :: Big Data Tech Lead
Duration :: Contract (Long Term) C2C / W2
Location :: Atlanta Georgia
Experience :: 8+ year

Job Description:
• This is a lead role, so this person will need to be very hands on but will also be providing mentorship to more junior team members and will be participating in code reviews and will be viewed as a thought leader on the project
Must-Have:
• Strong Java Development experience
• Strong Big Data experience
• Either GCP OR Apache Beam---they function very similarly so one or the other is fine, Big Table or Data Proc is also a tool that could be interchangeable here
• Some lead experience (doesn’t need to have been their official title, but someone who has experience mentoring and reviewing code and who likes to do that kind of work)
Nice to Haves
• Python—they will be doing some work with Python down the road so it would be nice if they already have it but no big deal if not.

Show more Show less"
2825638726,Data Engineer,Zenex Partners,2021-12-03,United States,"Dallas, TX",Information Technology and Engineering,Full-time,IT Services and IT Consulting and Computers and Electronics,"Data Engineer

Location:- Dallas, TX

Duration:- full time




Job description:-

As a part of this team, you will work with our clients to gather requirements and develop scalable data solution, Use cloud services to integrate different data sources and develop data lakes, Provide recommendations to optimize data pipelines and data warehouse queries.




Requirements for Data Engineer

Bachelor’s degree in computer science, MIS related area, or equivalent experience
Ability to work well in a team environment, meet deadlines, demonstrate good time management, and multi-task in a fast-paced project environment
Experience developing data pipelines (EMR/Glue) in AWS cloud
3+ years of experience with Apache Spark (Python or Scala)
Familiarity with basic Linux commands and writing Shell scripts
1+ years of experience working on Snowflake and proficient with SQL”
Strong understanding of data warehousing concepts and dimensional modeling Willingness and ability to learn new tools and technologies




Preferred skills for Data Engineer

Experience developing stream processing jobs and familiarity with Kafka, NoSQL databases – MongoDB, Cassandra, DynamoDB, HBase, Neo4j, etc

Show more Show less"
2791846004,Data Engineer,IBM,2021-11-12,United States,"Philadelphia, PA",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2804667230,Hadoop Administrator - Big Data Platform Engineer,Visa,2021-11-23,United States,"Austin, TX",Engineering,Full-time,"IT Services and IT Consulting, Financial Services, and Consumer Services","Company Description

As the world's leader in digital payments technology, Visa's mission is to connect the world through the most creative, reliable and secure payment network - enabling individuals, businesses, and economies to thrive. Our advanced global processing network, VisaNet, provides secure and reliable payments around the world, and is capable of handling more than 65,000 transaction messages a second. The company's dedication to innovation drives the rapid growth of connected commerce on any device, and fuels the dream of a cashless future for everyone, everywhere. As the world moves from analog to digital, Visa is applying our brand, products, people, network and scale to reshape the future of commerce.

At Visa, your individuality fits right in. Working here gives you an opportunity to impact the world, invest in your career growth, and be part of an inclusive and diverse workplace. We are a global team of disruptors, trailblazers, innovators and risk-takers who are helping drive economic growth in even the most remote parts of the world, creatively moving the industry forward, and doing meaningful work that brings financial literacy and digital commerce to millions of unbanked and underserved consumers.

You're an Individual. We're the team for you. Together, let's transform the way the world pays.

Essential Functions

Job Description

Person will be responsible to Perform Big Data Platform Administration and Engineering activities on multiple Hadoop, Kafka, Hbase and Spark clusters
Work on Performance Tuning and Increase Operational efficiency on a continuous basis
Monitor health of the platforms and Generate Performance Reports and Monitor and provide continuous improvements
Working closely with development, engineering and operation teams, jointly work on key deliverables ensuring production scalability and stability
Develop and enhance platform best practices
Ensure the Hadoop platform can effectively meet performance & SLA requirements
Responsible for Big Data Production environment which includes Hadoop (HDFS and YARN), Hive, Spark, Livy, SOLR, Oozie, Kafka, Airflow,Nifi, Hbase etc
Perform optimization, debugging and capacity planning of a Big Data cluster
Perform security remediation, automation and self heal as per the requirement
QualificationsBasic Qualifications

2 years of work experience with a Bachelor's Degree or an Advanced Degree
Hands on Experience in Hadoop Admin , Hive ,Spark, Kafka is must.

Preferred Qualifications

Minimum 3 years of work experience in maintaining, optimization, issue resolution of Big Data large scale clusters, supporting Business users and Batch process.
Hands-on Experience No SQL Databases HBASE is plus
Prior Experience in Linux / Unix OS Services, Administration, Shell, awk scripting is a plus
Excellent oral and written communication and presentation skills, analytical and problem solving skills
Self-driven, Ability to work independently and as part of a team with proven track record
Experience on Hortonworks distribution or Open Source preferredAdditional InformationVisa has adopted a COVID-19 vaccination policy to safeguard the health and well-being of our employees and visitors. As a condition of employment, all employees based in the U.S. are required to be fully vaccinated for COVID-19, unless a reasonable accommodation is approved or as otherwise required by law.

Work Hours: Varies upon the needs of the department

Travel Requirements: This position requires travel 5-10% of the time.

Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.

Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.

Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.

Job Number: REF001419W
Show more Show less"
2805488819,Data Engineer,Twilio,2021-11-24,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Internet Publishing, and Telecommunications","Because you belong at Twilio

The Who, What, Why And Where

Twilio is seeking a Data Engineer to join our world-class B2B Marketing team. Efficient systems are at the heart of any agile, data-driven organization, and as a Data Engineer, will join us to build a scalable data platform.

This person will design and build data integrations, ETL workflows, dimensional data models, and manage our data warehouse and integration infrastructure that fuels strategic business decisions across Twilio. They will lead us towards a deeper understanding of our customer experience, and help us identify initiatives that will set the bar for customer engagement. Our team is heavily reliant on data to make strategic decisions and investments. As a result, this is an influential role in which someone will collaborate cross-functionally with engineering, product, and data teams to implement end-to-end analytical solutions that will have direct and measurable impact on Twilio’s core growth strategy.

Who?

In addition to strong technical skills, this person has the desire to make our partner teams more nimble, and ultimately serve our customers better. If you feel this is you, we’d love to hear from you!

You’re driven and passionate about enabling your teammates. You thrive in a cross-functional environment, think creatively, and have strong attention to detail. You have a penchant for deconstructing and solving complex problems.
7+ years of experience in a software engineering role. We’re looking for someone who has strong SQL skills, and is proficient in at least one major language such as Python, Scala, or Java. Prior exposure to building scalable data processing frameworks is a plus.
Strong communication skills, and can effectively partner with product managers, engineers, and marketers on your team. Prior experience with marketing systems (or a desire to learn about them) is a bonus.

What?

In short, we’re searching for someone who lives the Twilio Magic . In particular, this role will:

Draw the owl: Instrument the user journey taken by millions of Twilio users, identify meaningful stages in their lifecycle, architect a singular view of the customer, and devise metrics based on pattern mining and predictive modeling.
Write it down: Specify your hypotheses, defend your decisions, and be methodical in your approach to finding solutions that will work well into the future.
Wear the customer’s shoes: Build trust with our internal partners, and develop empathy for their day-to-day challenges. Identify their biggest challenges, and systematically address their problems.
Be an Owner: Design and build robust data pipelines, while simultaneously optimizing for performance and stakeholder requirements.

Why?

Marketers depend on systems to improve the efficiency of their programs. Smart decisions, swift execution, and a focus on the long-term will allow you to excel in this role and have a lasting impact on Twilio.

Twilio is a company that is empowering the world’s developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation and we want you and your ideas to thrive at Twilio.

Where?

This position is open to anyone in the US. You’re also welcome to work out of our San Francisco office if you would prefer a local setting. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, Wednesday dinners, bi-weekly All Hands and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers’ experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About Us

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world’s communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world’s most demanding applications. By making communications a part of every software developer’s toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world’s largest organizations — to reinvent how companies engage with their customers.

In accordance with applicable law, the following represents Twilio's reasonable estimate of the range of possible compensation for this role if hired in Colorado. Please note that this information is provided for those hired in Colorado only, and this role is open to candidates outside of Colorado as well.

Salary

Denver/Boulder Metro:

Salary Range: $132,928 - $166,160

Rest Of Colorado

Salary Range: $116,312 - $145,390

Additionally, this role is eligible to participate in Twilio's equity plan.

An overview of Twilio’s benefits offered is listed below:

Benefits

At the time of this posting, this role is eligible to participate in the following benefits, which Twilio reserves the right to modify at any time for any reason in accordance with applicable law

Twilio is committed to delivering a comprehensive benefits program that provides support needed for you and your loved ones. It’s likely that you don’t think about benefits every day; however, they are an important component of your total compensation, and we want you to understand the options available to you so that you can make the most of your benefit dollars.

Healthcare Insurance and Leave

Prescription Drug
Dental
Vision
Flexible Spending and Health Savings Accounts
Leave programs for all of life’s moments: maternity, parental/bonding, as well medical leave to care for yourself or a loved one

Financial Benefits

Short and Long Term Disability Insurance
Life and Accidental Death & Dismemberment Insurance
401(k) Retirement Savings Plan with a match

Reimbursement Programs & Stipends

$65 per month work-from-home stipend
Up to $50 per month for wellness expenses and activities
Up to $30 per month to use towards books/eBooks

Important COVID-19 Guidance (For candidates applying to roles in the United States):

To comply with Executive Order 14042, all Twilio employees working in the U.S. are required to submit proof of vaccination for COVID-19 unless they qualify for a medical or religious accommodation / exemption. Employees onboarded after January 4, 2022 must submit proof of vaccination or receive approval for an exemption prior to their Twilio start date.
Show more Show less"
2794064560,Big Data Engineer,Chance River,2021-11-10,United States,"New York, NY",Engineering and Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Looking for multiple Big Data Engineers with 3-8 years of relevant experience.

Essential skills -Build deploy large-scale ETL and stream processing pipelines in serverless microservice infrastructure built on top of industry standard technology like Kubernetes

Kafka. -Manage workflows in support of both product and our AIData Science pipeline, You will be introduced to our unique ingest and processing pipelines turning proprietary data assets into ground breaking solutions -Build stream ingestion processes to efficiently send, process, analyze publish data -Programming skills in Python or Scala or Java and strong SQL skills Position is remote for now
Show more Show less"
2813658984,Data Engineer,Zions Bancorporation,2021-11-24,United States,"Salt Lake City, UT",Information Technology,Full-time,"Computer Software, Banking, and Financial Services","Zions Bancorporation’s Enterprise Technology and Operations (ETO) team is transforming what it means to work for a financial institution. We operate in a fast-paced, information-driven environment, which means we need people who bring diverse experiences, perspectives, and expertise to meet the ever-changing demands of a technology-driven world. We are grounded in the belief that “improving the work is the work” as we drive to create simple, easy, and fast solutions for our customers. Your ability to adapt, learn, and innovate helps increase revenue, reduce operational costs, and mitigates risk.

ETO provides opportunities for you to own your career growth through Diversity, Equity, and Inclusion, Women in Technology, and Workforce of the Future initiatives that allow you to network across the organization, volunteer in our community, and build your technical and soft skills. Together we are building a culture that values diversity and creates a space of belonging for all our team members. We believe that investing in your success is an investment in our customers and our business. Our people are what sets us apart and make us great.

Zions Bancorporation is currently looking for an experienced Data Engineer. The Data Engineering team is responsible for ingesting and processing terabytes of data a day to make quick and accurate business decisions in various domains. Our team is lean and agile. You must want to be part of a motivated and driven team and work with respected leaders. We need someone who is proactive, has a great attitude, is confident and wants to inspire others to achieve bank initiatives.

Responsibilities

Responsible for developing and deploying enterprise grade platforms that enable data-driven solutions.
Automate and maintain scalable infrastructure.
Ensures delivery of a highly available and scalable systems.
Monitor all systems and applications and ensure optimal performance.
Research and test new tools and applications.
Analyzes and designs technical solutions to address business needs.
Participate in troubleshooting applications and systems issues.
Identifies, investigates and proposes solutions to technical problems.
Develops, tests, and modifies software to improve efficiency of data platforms and applications. Provides technical support for issues.
Monitors system performance to maintain consistent up time.
Provides technical expertise where required within Information Technology Projects.
Prepares and maintains necessary documentation.
Participate in regular agile ceremonies, such as program increment planning, daily standups, team backlog grooming, iteration retrospectives, team demos and inspect & adapt, etc.
Keep up with the committed features and stories in the team backlog.
Work with the project manager/scrum master to remove impediments.
Serve in the goalie rotation to support Production.
Support test and QA efforts on the various data projects.
Coordinate with data operations teams to deploy changes into production.
Highest level may function as a lead.
Other duties as assigned.

Qualifications

Requires a Bachelor's in Computer Science, Computer Engineering or related field
4+ experience ETL, SQL, UNIX/Linux, Big Data distributed systems, various programming languages like Java and Python, orchestration tools and processes or other directly related experience. A combination of education and experience may meet qualifications.
Basic knowledge of search technology, building real-time data pipelines and various programming languages like Java and Python. Knowledge of ETL, UNIX/Linux, scheduling and orchestration tools and processes.
Good analytical, organizational and problem-solving skills.
Ability and desire to learn new technologies quickly.
Ability to elicit, gather and analyze user requirements.
Ability to work independently and collaborate with others at all levels of technical understanding.
Able to meet deadlines.
Good judgment and project management skills.
Ability to communicate both verbally and in writing with both technical and non-technical staff.
Ability to work in a team environment and have good interpersonal skills.
Ability to adapt to changing technology and priorities.
Must be able to work independently, handle multiple concurrent projects, with an ability to prioritize and manage projects effectively.
Must be able to interpret, validate and map business requirements to an appropriate solution.

Pay Range: $90,000-$120,000
Show more Show less"
2826938726,Data Engineer,Radancy,2021-12-04,United States,"Burbank, IL",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Radancy’s Data Engineering team is seeking a motivated Data Engineer to build data products and services. The Data Engineering team works on data services across product organizations within Radancy and supports building a customer facing data visualization product. Team also supports an enterprise grade recruitment platform focusing on talent acquisition and job opportunity exploration.

The team has extensive experience in ETL development, works with large scale data in real time, and collaborates with other engineering teams across the organization.

Build and maintain ETL pipelines, Automated workflows, Data products and services, Reporting Suite etc. using latest technologies and tools i.e. Python, Docker, SQL Server, BigQuery, PostgreSQL, Airflow, Luigi, Tableau, ASP .NET, RabbitMQ, Kafka and many others
Work with Cloud Computing Platforms (GCP/AWS), ETL Orchestration tools(Luigi/Airflow), and other advanced open-source technologies
Data modeling, schema design, and SQL development
Ingest and aggregate data from both internal and external data sources to build our world class datasets
Develop and lead the testing and fixing of new or enhanced solutions for data products and reports, including automating ETL testing
Collaborate with Product Owner and domain experts to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
Assist with the development and review of technical and end user documentation including ETL workflows, research, and data analysis
Work with Product team to define data collection and engineering frameworks
Build monitoring dashboards and automate data quality testing
Own meaningful parts of our service, have an impact, grow with the company
3+ years of Python, SQL, and ETL development
Experience with at least one - Client Facing Product or Services or Reporting suite
Strong Understanding of ETL pipeline, data lakes and data warehouse development
Exposure to at least one cloud computing platform (GCP/AWS/Azure), and cloud data warehouse (BigQuery/Redshift)
Experience delivering applications that run in a containerized environment is a plus
Basic knowledge of Machine Learning, ML Pipelines and tools is a plus
Some experience with any of these is a plus - NLP, MLOps, DataOps, tensorflow/keras/pytorch
Exposure to agile methodologies and particularly scrum
Experience working with large datasets for several organizational units internally as well as externally is a huge plus
Enthusiastic about working with and exploring new data sets
Detail oriented, strong communicator, quick thinking and acting with minimal supervision
Bachelor's degree in related area (Computer Science, Information Systems, Engineering) or an equivalent combination of education and experience

Join the global leader in talent acquisition technologies that’s committed to finding new ways to leverage software, strategy and creative to enhance our clients’ employer brands – across every connection point. We’re looking for unconventional thinkers. Relentless collaborators. And ferocious innovators. Talented individuals who are ready to work towards solutions that transform the way employers and job seekers connect.

Radancy is an equal opportunity employer and welcomes all qualified applicants regardless of race, ethnicity, religion, gender, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. We actively work to create an inclusive environment where all of our employees can thrive.
Show more Show less"
2826940473,Data Engineer,Radancy,2021-12-04,United States,"South Holland, IL",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Radancy’s Data Engineering team is seeking a motivated Data Engineer to build data products and services. The Data Engineering team works on data services across product organizations within Radancy and supports building a customer facing data visualization product. Team also supports an enterprise grade recruitment platform focusing on talent acquisition and job opportunity exploration.

The team has extensive experience in ETL development, works with large scale data in real time, and collaborates with other engineering teams across the organization.

Build and maintain ETL pipelines, Automated workflows, Data products and services, Reporting Suite etc. using latest technologies and tools i.e. Python, Docker, SQL Server, BigQuery, PostgreSQL, Airflow, Luigi, Tableau, ASP .NET, RabbitMQ, Kafka and many others
Work with Cloud Computing Platforms (GCP/AWS), ETL Orchestration tools(Luigi/Airflow), and other advanced open-source technologies
Data modeling, schema design, and SQL development
Ingest and aggregate data from both internal and external data sources to build our world class datasets
Develop and lead the testing and fixing of new or enhanced solutions for data products and reports, including automating ETL testing
Collaborate with Product Owner and domain experts to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
Assist with the development and review of technical and end user documentation including ETL workflows, research, and data analysis
Work with Product team to define data collection and engineering frameworks
Build monitoring dashboards and automate data quality testing
Own meaningful parts of our service, have an impact, grow with the company
3+ years of Python, SQL, and ETL development
Experience with at least one - Client Facing Product or Services or Reporting suite
Strong Understanding of ETL pipeline, data lakes and data warehouse development
Exposure to at least one cloud computing platform (GCP/AWS/Azure), and cloud data warehouse (BigQuery/Redshift)
Experience delivering applications that run in a containerized environment is a plus
Basic knowledge of Machine Learning, ML Pipelines and tools is a plus
Some experience with any of these is a plus - NLP, MLOps, DataOps, tensorflow/keras/pytorch
Exposure to agile methodologies and particularly scrum
Experience working with large datasets for several organizational units internally as well as externally is a huge plus
Enthusiastic about working with and exploring new data sets
Detail oriented, strong communicator, quick thinking and acting with minimal supervision
Bachelor's degree in related area (Computer Science, Information Systems, Engineering) or an equivalent combination of education and experience

Join the global leader in talent acquisition technologies that’s committed to finding new ways to leverage software, strategy and creative to enhance our clients’ employer brands – across every connection point. We’re looking for unconventional thinkers. Relentless collaborators. And ferocious innovators. Talented individuals who are ready to work towards solutions that transform the way employers and job seekers connect.

Radancy is an equal opportunity employer and welcomes all qualified applicants regardless of race, ethnicity, religion, gender, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. We actively work to create an inclusive environment where all of our employees can thrive.
Show more Show less"
2789811547,Data Developer/Engineer,VanData Consulting,2021-11-10,United States,"Grand Rapids, MI",,Full-time,,"**This position is for immediate hire**




About the Job

At VanData, you will have the chance to further develop your unique skillset with the use of a wide range of different technologies. As a Data Developer/Engineer, you won’t be stuck working with just one client or project, you will be getting experience working with multiple different projects for several of our clients at a time with the support of our developer team. We pride ourselves on the fact that each and every employee has the opportunity to work with new technology and expand their skillset with cross-training in many different technologies during their time at VanData. We are looking for someone with a strong SQL and data background who is willing to expand their knowledge with every project. The ideal candidate is a self-motivated individual who is looking for consistent growth personally and professionally.

This is a full-time, in-office position in Grand Rapids, Michigan.




Who We Are

VanData is composed of a group of highly motivated, supportive individuals. We strive to make the workplace and world more cohesive. If you are a highly motivated individual that enjoys a workplace with an open layout, frequent team outings, and the occasional game of pig or darts, consider applying today!




Responsibilities

Analyzing database tables
Developing custom business intelligence reports and modifying existing ones
Troubleshooting report issues and implementing enhanced solutions
Verifying report accuracy and credibility
Data Migrations and ETL processes
Application development and customization
Learning and working independently




Required Qualifications

Bachelors Degree or equivalent in computer science, information systems, data analysis, business, database administration, software development, mathematics, engineering, or other related fields strongly preferred
3+ years experience in SQL
3+ years experience in one or more of the following:
Crystal Report or SSRS
Qlik or PowerBI
SSIS or scripting language
Experience with developing custom business intelligence reports and building ETL processes
Must possess a valid U.S. drivers license
Excellent team skills
Ability to work in-office 9am-5pm M-F




Preferred Qualifications

Tableau, Interfaces, RHP, Java, Python, APIs, ERP System Interface, Analytics, Interface Development, Microsoft Access, Git, and Jira
Requirement gathering and estimating development
We are looking for developers with experience in EFI (Electronics for Imaging) applications: Radius, MDSF, PSV, and PACE




Familiarity in the following industries is a plus

Printing and Packaging
Manufacturing
Construction
Banking/Finance
Education
Healthcare/Medical




Benefits

VanData is currently offering full-time employees the following benefits:

Simple IRA
Medical, Dental, and Vision insurance.
All new full-time employees start with 10 days PTO, one floating holiday, and 5 days of paid sick leave, in addition, VanData also offers 3 days of Bereavement leave.




About VanData

VanData was founded in Grand Rapids, MI on April 7th, 2015 by Nick VanderLaan. Nick aimed to create a business intelligence company after years of experience with information systems and database reporting. He endeavored to offer quality, personalized IT services. Today, VanData is composed of energetic, talented individuals, each bringing their own ingenious solutions to the company. Diversity is an integral aspect of the VanData culture today, which allows us to deliver such a variety of services with positive results. At VanData, we believe adapting for the future is key for organizations to maintain profitability and remain sustainable. Our database development and implementation provide the instantaneous information companies need to survive in today's world and to prosper in the future.




We are unable to offer relocation assistance for the time being

Show more Show less"
2791846007,Data Engineer,IBM,2021-11-12,United States,"New York, NY",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2825853140,Data Engineer,Apex Systems,2021-12-03,United States,"Plano, TX",Information Technology,Contract,IT Services and IT Consulting,"One of our clients is looking for a Data Engineer!




Title of Position: Data Engineer

Start Date: ASAP

Contract type (contract-to-hire, contract only, direct hire): Contract OR C2h

Location (city & campus): Remote for now; might come in later. Candidate can be anywhere in US since this is currently remote.

Contract Length: 2 year+







Brief description of the project and what this person will be doing:

Supporting DRM Data Relationship Management

Governs all meta data in CFO

Oracle product

Processes that run in Hadoop; run processes in DataStage

EDMCS- moving to that Oracle cloud product

Need knowledge in java/javascript










Must have skills/technologies:

1. Oracle DRM or EDMCS

2. Object oriented language (Java ideally)

3. Agile experience- working on scrum teams







Nice to haves skills/technologies:

1. ETL – DataStage or Informatica

2. SQL

3. Hadoop







Shift: M-F 8-5 with some overnights/after 5p













EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystemsinc.com or 844-463-6178.

Show more Show less"
2808117708,Data Engineer,Deckers Brands,2021-11-25,United States,"Austin, TX",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2827167531,Data Engineer,eStaff,2021-12-04,United States,"Houston, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","eStaff LLC is seeking a Data Engineer for their banking client to work remotely and join their Data Organization.

This is a 100% remote position.

If you meet the minimum requirements and are wanting to work for an innovative start-up company with strong backing from creative and strategic thinking backers, then we want to talk to you!! Apply Now!!!

What will my day-to-day look like?

This individual will partner directly with product managers, engineers, marketing, and other business partners across the business to design, develop and continuously improve the data infrastructure, pipeline, and applications to collect, track and monitor various formats of data to enable data-driven decision and growth.

Design, develop and deliver/implement data solutions to include architecture design, prototyping of concepts to proof of concept, development of standards, design, and development of test plans, code and module design, development and testing, data solution debugging, and design and implementation
Optimize existing data pipelines and create new ones to manage data sets while learning the platforms from which we extract data; Develop and maintain third-party API processes for data pipelines
Design, implement and manage data warehouse solutions
Support and maintain data and database systems to meet business delivery specifications and needs. Document structure and processes
Work with Data Science to create and launch new models
Work with various business and engineering teams to ensure reliable, scalable, robust architecture for our data platform

Requirements

4+ Years of Software Engineering Experience with a focus on Data
Bachelor's degree in Computer Science, a related field or equivalent experience
Must have Python, CICD, & Webdriverio
Must be able to work on a W-2
Experience programming in one or more general purpose programming languages, including but not limited to Python, Java, or Javascript
Experience programming in SQL (No-SQL is a plus)
Experience with ETL tools such as Talend/Stitch, Alooma, Fivetran, or similar tools DBT tools
Experience with Data Warehousing solutions such as BigQuery, Snowflake, Redshift, or similar managed solutions
Expert data modeling skills with experience tuning and optimizing for performance
Experience designing and operating data services & data pipelines
Familiarity with GCP's data tooling (e.g. Dataflow, CloudComposer, BigQuery, PubSub) or similar cloud tooling
Experience with financial datasets and associated reporting

We have been the most trusted Technical Recruiting Partner for companies in Austin, Central Texas and nationwide for over 10 years. Are you looking to hire? The process of Placing Ads and reviewing hundreds of resumes is tedious, time consuming and may be impossible to get done with your already busy schedule.

Well, worry no more! The experts at Estaff LLC offer over 50 years of recruiting experience to give you the fastest access to the most qualified resumes meeting your requirements. Our helpful, knowledgeable team can help you understand what you are looking for and have you fully staffed in no time.
Show more Show less"
2816723925,Big Data Engineer,Robert Half,2021-11-03,United States,"Bloomington, MN ",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Description

Robert Half is seeking experienced Data Engineers with varying modern technology stack experience, who can adapt to new client environments and learn new technologies quickly.

We are looking for consultants with deep expertise in specific modern technologies, but we always want people to apply what they know, but if you don’t know a particular technology of interest, we provide vast opportunities to learn new capabilities.

Our work is presently remote, and our teams support clients across all of our markets. As we plan to re-open our offices, our Enterprise Dev Center provides for unparalleled opportunities to collaborate with your colleagues on our clients’ most challenging technology-enabled business problems. If and when you choose.

Responsibilities

Collaborate and work closely with team to build data platforms.
Maintain and manage Hadoop clusters in development and production environments.
Assemble large, complex data sets that meet functional/non-functional business requirements.
Work with team members and functional leads to understand existing data requirements and validation rules to support moving existing data warehouse workloads into a distributed data platform.
Create custom software components (e.g. specialized UDFs) and analytics applications.
Employ a variety of languages and tools to marry systems together.
Recommend ways to improve data reliability, efficiency and quality.
Implement & automate high-performance algorithms, prototypes and predictive models.

Qualifications

Experience building data pipelines to connect analytics stacks, client data visualization tools and external data sources.
Knowledge of cloud and distributed systems principles
Experience with Python, R, sh/bash and JVM-based languages including Scala and Java.
Experience with Hadoop family languages including Pig and Hive.
Experience with high performance data libraries including Spark, NumPy and TensorFlow.
Experience building stream-processing applications using Storm, Spark-Streaming, Kafka and MQ.
Ability to manually and programmatically interact with relational and NoSQL databases
Intermediate SQL programming and query performance tuning techniques
3+ years in data engineering
Preferred: College degree or equivalent in technology-related field (computer science, engineering, information technology, etc.)
Practical education or experience in a technology related field – could include bootcamps and focused educational programs
Project experience in delivering technology solutions in a team-based environment, ideally Agile development

Requirements

Hadoop, Python, JVM Based Languages, Scala, Java, Hadoop Hive, Apache Pig, Apache Spark, NumPy, TensorFlow, SQL Programming, Storm, Apache Kafka, MQ

Technology Doesn't Change the World, People Do.®

Robert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.

Robert Half puts you in the best position to succeed by advocating on your behalf and promoting you to employers. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity – even on the go. Download the Robert Half app and get 1-tap apply, instant notifications for AI-matched jobs, and more.

Questions? Call your local office at 1.888.490.4429. All applicants applying for U.S. job openings must be legally authorized to work in the United States. Benefits are available to contract/temporary professionals. Visit

© 2021 Robert Half. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to
Show more Show less"
2808485016,Data Engineer | Remote,Rappi,2021-11-21,United States,"Location, WV",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","YOUR NEXT STEP IS AT RAPPI!

Rappi is one of the first Latin American unicorns and a start-up that continues to focus on growing and making life easier for our users. As a company, we seek to continue improving the services we already offer, add more to our offer and continue expanding throughout the Latin American continent.

At Rappi we think big! We are building our financial ecosystem willing to become the biggest digital bank in Latin America. To accomplish this mission we need a world class team that delivers high quality financial products into the market.

Data is our biggest asset and we are building a truly data driven company.

We are hiring the most talented engineers in Latin America and we want you to join them. Working in Technology at Rappi Pay is not about fixing legacy systems. It is about building world-class products from the ground up that will be used by millions.

We are looking for a Data Engineer who will be responsible for building, improving and maintaining a scalable data pipeline infrastructure required for extraction, transformation, and loading of terabytes of data from thousands of sources to our analytics platform.

You will have the opportunity to apply cutting-edge technologies in large scale environment with a challenging rapid growth pace, taking ownership of both internal and external services, and applying all your skills to make an impact on the whole company.

You will be working with a skilled group of international tech specialists, on a high pressure hard-work environment.

Skills

Design and Implementation of distributed services
Design and implementation of REST APIs
Data modeling and mining
DataBase and Data Warehousing modeling
ETLs design and implementation
Knowledge of Unix o Linux operating systems
Monitoring and Debugging
SelfContained environments
Knowledge of AWS cloud infrastructure
Knowledge of Airflow o similar data orquestator
Knowledge of Docker and/or Kubernetes.
Knowledge of SQL, Redis, Kafka, Kinesis.
Programming languages: Python, Java or Go.
Rappi operates in more than 100 cities in 9 countries in Latin America. We have debit cards with VISA in Colombia, Mexico and Brasil and we will soon launch credit cards in Colombia, Mexico and Perú.

He leído y acepto la Autorización de Datos Personales de Rappi S.A.S

https://docs.google.com/document/d/e/2PACX-1vRFEkFojVd3AfFsARRsdZpiSjA_xQGK5Y7ZCBT3gw19MOdQVqH5nRAuSqyu3yZq2A/pub

Conforme a la Política de Tratamiento de Datos Personales

https://legal.rappi.com/colombia/politica-de-proteccion-y-tratamiento-de-datos-personales-rappi-s-a-s/

I have read and accept the Authorization of Personal Data from Rappi S.A.S

https://docs.google.com/document/d/e/2PACX-1vRFEkFojVd3AfFsARRsdZpiSjA_xQGK5Y7ZCBT3gw19MOdQVqH5nRAuSqyu3yZq2A/pub

In accordance with the Personal Data Treatment Policy

https://legal.rappi.com/colombia/autorizacion-de-tratamiento-de-datos-personales-rappitenderos-rappi-s-a-s/
Show more Show less"
2818862042,Data Engineer,Confidential,2021-12-03,United States,United States,,Contract,,"Python Developer / Data Engineer

Location: Minnesota / Minnesota / Tennessee (Remote to start)

Length: Long term contract or contract to hire




Python+SQL – THIS POSITION IS LOOKING FOR A COMBINATION OF PYTHON SOFTWARE & DATA ENGINEERS. We are also ok to look for one or the other because it’s a big team, but the goal is that they’d have both skillsets in hand.

 

Must-Haves (Concepts & Tools):

Python (need to have a software skillset & data engineering) – they use 3.6
Flask API (Microservices)
Kubernetes (Containerization / Docker)
Oracle – DB skills (PL/SQL) – needs to have solid skills in SQL & performance skills
Could be ok with some other RDBMS, but they would have to have rock solid SQL skills
CI/CD & Cloud 




Show more Show less"
2777845998,Data Engineer,Bloomberg Industry Group,2021-10-06,United States,"Arlington, VA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Full timeBloomberg Industry Group runs on data. As the Commercial Analytics team, we are responsible for driving analytics throughout the organization to improve our products, engage better with our customers, create greater efficiencies, and drive new businesses by providing data insights. Our data captures the who, what, when, where and why of how our company goes to market. Senior business leaders rely on our work every day to make strategic decisions.

What You Will Do

Work with senior business stakeholders to break down business problems and design analytics solutions
Weave together data from many different sources to create data sets for reporting and analysis
Develop automated solutions to replace manual data processes
Refine and enhance reporting data models

You'll Need To Have

3 years of hands-on development experience with SQL and an ETL tool. Alteryx is preferred, but any similar tool can be considered.
Bachelors degree in a financial or technical field, or equivalent work experience.

Bloomberg Industry Group IS AN EQUAL OPPORTUNITY EMPLOYER and fully subscribes to the principles of Equal Employment Opportunity. Bloomberg Industry Group has adopted an Affirmative Action Program to ensure that all applicants and employees are considered for hire, promotion, and job status without regard to race, color, religion, sex, national origin, age, disability, gender identity, sexual orientation, marital or familial status, pregnancy, childbirth, or related medical issues, genetic information, disabled veteran, veteran, a veteran of the Vietnam Era, or any other classification protected by law.
Show more Show less"
2803446591,Data Engineer,IBM,2021-11-21,United States,"Lansing, MI",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

The position of the Data Engineer plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. The Data Engineer defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business. Develops applications on Big Data and Cognitive technologies including API development. Expected to have traditional Application Development background along with knowledge of Analytics libraries, open-source Natural Language Processing, statistical and big data computing libraries. Strong technical abilities to understand, design, write and debug complex code.

The successful candidates for these positions may be based anywhere in MICHIGAN and will work collaboratively with the Client Innovation Team. While this is not a fully remote role, work on-site at the IBM Client Innovation Center in Lansing MI is expected to be minimal with a focus on Team Meetings, Collaboration and Client Visits. It’s anticipated that a Michigan resource would typically spend an average 2-3 days/month on-site at the Center. Additionally, some travel is expected, and all candidates must be willing and able to travel to meet our client needs across the US. Travel is typically related to knowledge transfer and training at the client site (Monday thru Friday). You may need to travel up to 50% of the time Post-Covid depending on individual project needs.

Required Technical and Professional Expertise


At least 3 years relevant experience.
Strong background in computer science and demonstrated ability to develop in Python
Understanding of applied machine learning (ML) topics and an ability to explain the logic and implementation of common ML algorithms.
Experience with scalable ML (MapReduce, streaming)
2+ years coding challenge experiences including LeetCode and Hackerrank, etc.
2+ years experience in predictive analytics (supervised vs unsupervised learning), statistical modeling (evaluation metrics, Bias/variance), regression, classification, clustering, deep learning, NLP, NLU, optimization, time series analysis, forecasting
Fluent in data manipulations (native Python, Pandas, NumPy, etc.)


Preferred Technical And Professional Expertise


Snowflake Pro Certification
Minimum 1 year of hands-on experience with Kafka
Minimum 1 year of hands-on experience with Cloud Platforms (AWS or Azure)


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.


Show more Show less"
2791842408,Data Engineer,IBM,2021-11-12,United States,"Seattle, WA",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2825130755,Data Engineer,"ActiveSoft, Inc",2021-12-03,United States,United States,Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Financial Services","Title: Sr. Data Engineer

Location: Remote

Length: 12 month contract

Required Experience

Snowflake developer, deep understanding of Cloud technology, Snowflake credits etc.

Hands-on experience for at least 2 years, in large scale data-warehouse
Migration experience from Teradata or Big data to Snowflake
Experience with Snowflake warehouse and developing applications on Snowflake, SnowSQL, Snowpipe, Javascript UDF & Stored procedures
Experience in creating and consuming data from platforms such as Web APIs, Kafka, and CDC
Experienced in consuming data from flat files from other Cloud environments
Proficient in one or more programming languages such as Java, Scala, JavaScript or Python
Proficient in SQL and complex queries
Experience in source data analysis, data profiling and debugging
Experience in ETL and data processing with tools such as SSIS, Talend, Spark,
Experience with development work to support data migration, cloud applications and related work


Day to Day:

Functions may include database architecture, engineering, design, optimization, security, and administration; as well as data modeling, big data development, Extract, Transform, and Load (ETL) development, storage engineering, data warehousing, data provisioning and other similar roles. Responsibilities may include Platform-as-a-Service and Cloud solution with a focus on data stores and associated eco systems. Duties may include management of design services, providing sizing and configuration assistance, ensuring strict data quality, and performing needs assessments. Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging data storage and retrieval system capabilities. Manages relationships with software and hardware vendors to understand the potential architectural impact of different vendor strategies and data acquisition. May design schemas, write SQL or other data markup scripting and helps to support development of Analytics and Applications that build on top of data. Selects, develops and evaluates personnel to ensure the efficient operation of the function.

Powered by JazzHR

fS4PVo1Vid
Show more Show less"
2816176409,Technology Engineer (Data Engineer),PNC,2021-11-16,United States,"Austin, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Banking, and Financial Services","Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. We work together each day to foster an inclusive workplace culture where all of our employees feel respected, valued and have an opportunity to contribute to the company’s success.

As a Technology Engineer (Data Engineer) for PNC's Security Analytics Hub, you will have the opportunity to work fully remote. Our team focuses on producing data driven insights into multiple areas of risk facing the bank, including cybersecurity and physical security.

Day To Day Responsibilities

Acquire/map datasets that align with our business partner needs
Develop algorithms that shape data into useful and actionable information
Build, test, and maintain database pipeline architectures
Collaborate with management to understand and meet company objectives
Form new data validation methodologies and data analysis tools
Ensure continued compliance with data security policies and governance

Technical Qualifications

Education: BS/BA in technical discipline
5+ years of Python development
5+ years of experience with development/decomposition of complex SQL (RDMS Platforms)
3+ years of experience with test-driven development. Continuous Integration/ Development (e.g. GIT, Jenkins, Maven)
3+ years with CRON/Shell Scripting
Experience with utilization of REST API and/or EDPI
Hands on experience with project management tools such as JIRA, Confluence
Ability to work with end users (BI analysts, data scientists, etc.) to solve technical issues
Experience working in an Agile Team construct
Extensive knowledge of databases, data warehouses, systems integrations, and data flows is mandatory for this role.
Additionally, candidates should be well-versed in data architecture, data development, with a proven history of providing effective data solutions.

Required Skills To Be Considered For This Role

Coding: Proficiency in coding languages is essential to this role. Common programming languages used by the team include SQL, Python.
Relational and non-relational databases: You should be familiar with both relational and non-relational databases, and how they work (Teradata, Oracle, etc).
ETL (extract, transform, and load) systems: Moving data from databases and other sources into a single repository, like a data warehouse.
Data storage knowledge: As solutions are designed, when to use a data lake versus a data warehouse, for example.
Automation and scripting. Candidate should be able to write scripts to automate repetitive tasks (e.g. Cron jobs, Linux, shell scripting).
Big data tools: Understanding of Hadoop, MongoDB, and Kafka helpful, but not required.
Data security: Securely managing and storing data to protect it from loss or theft per PNC guidelines.

Job Description

Leverages technical knowledge and industry experience to design, build and maintain technology solutions. Assists with selecting appropriate platforms, integrates and configures solutions.
Develops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.
May provide consultation on common issues and best practices for junior staff.
Provides a systematic analysis on client requirements within the traceability framework and resolves any functional problems encountered.
Ensures quality of project deliverables while maintaining compliance with relevant standards and processes.

PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:

Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.

Competencies

Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.

Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.

Effectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.

Emerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.

Industry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.

IT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).

IT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.

Planning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.

Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Work Experience

Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

Education

Bachelors

Additional Job Description

COMPENSATION

Base Salary

$55,000 to $142,600

Role

Placement within the compensation range is based on the specific role and the following factors

Where a person is paid in the compensation range is aligned to their experience and skills.

– Lower in range –Building skills and experience in the job

– Within the range–Experience and skills align with proficiency in the role

– Higher in range –Experience and skills add value above typical requirements of the role

– Compensation Range may vary based on Geographic Location

INCENTIVE

Role is incentive eligible with the payment based upon company, business and individual performance.

Benefits

PNC offers employees a comprehensive range of benefits to help meet your needs now and in the future. Depending on your eligibility, options for full-time employees include medical/prescription drug coverage (with a Health Savings Account feature); dental and vision options; employee and spouse/child life insurance; short- and long-term disability protection; maternity and parental leave; paid holidays, vacation days and occasional absence time; 401(k), pension and stock purchase plans; dependent care reimbursement account; back-up child/elder care; adoption assistance; educational assistance and a robust wellness program with financial incentives. To learn more about these and other programs, including benefits for part-time employees, visit pncbenefits.com > New to PNC.

Disability Accommodations Statement

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.

The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO)

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.

California Residents

Refer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.
Show more Show less"
2819589513,Data Engineer,General Motors,2021-12-04,United States,"Austin, TX",Information Technology,Full-time,"IT Services and IT Consulting, Appliances, Electrical, and Electronics Manufacturing, and Motor Vehicle Manufacturing","Job Description

This is a Hybrid position within our IT Organization. The role will allow employees to work remotely, but will also require onsite work based on business needs. The selected candidate will be expected to live a commutable distance to the innovation center they are selected for. Relocation will be provided as needed.

For all external applicants, we are targeting a start date on or after January 10th 2022 for this position.

About GM

We're dedicated to achieving our vision of a world with Zero Crashes, Zero Emissions and Zero Congestion. We are looking for people who are passionate about helping us create safer, better and more sustainable solutions for personal mobility. Our bold vision won't happen overnight, but just as we transformed how the world moved in the last century, we are committed to transforming how we move today and in the future.

Why Work for Us

Our culture is focused on building inclusive teams, where differences and unique perspectives are embraced so you can contribute to your fullest potential as you pursue your career. Our locations feature a variety of work environments, including open work spaces and virtual connection platforms to inspire productivity and flexible collaboration. And we are proud to support our employees volunteer interests, and make it a priority to join together in efforts that give back to our communities

About The Role

This role requires experience in software development and data engineering best practices, as well as an ability to research and use emerging technologies to solve problems and create new opportunities. The software developer will perform hands on design and programming.

Qualifications

Additional Job Description

Strong problem solver with ability to evaluate a challenge and understand solution patterns
Experience in data aggregation and manipulation of large data sets.
Knowledge of data quality, data cleansing, data wrangling, and data standards.
Knowledge and willingness to learn to be proficient with industry leading large-scale data platforms (i.e. Hadoop, Greenplum, Oracle)
Experience with open source languages and architectures including Python, Spark, Scala, Kubernetes and Docker
Ability to rapidly learn innovative technologies and apply to solving business problems
Experience with DataStage and ETL patterns
Experience with optimization and performance tuning
Contribute to building and leveraging re-usable data integration frameworks and patterns
Knowledge of database modeling and data structure principles, techniques and best practices.
Demonstrated knowledge in multiple software development disciplines (i.e. Agile, Scrum, SDLC)
Understanding of good architecture and design patterns, programming practices, development standards and QA/testing processes

The policy of General Motors is to extend opportunities to qualified applicants and employees on an equal basis regardless of an individual's age, race, color, sex, religion, national origin, disability, sexual orientation, gender identity/expression or veteran status. Additionally, General Motors is committed to being an Equal Employment Opportunity Employer and offers opportunities to all job seekers including individuals with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, email us at Careers.Accommodations@GM.com In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.

About GM

Our vision is a world with Zero Crashes, Zero Emissions and Zero Congestion and we embrace the responsibility to lead the change that will make our world better, safer and more equitable for all.

Why Join Us

We aspire to be the most inclusive company in the world. We believe we all must make a choice every day - individually and collectively - to drive meaningful change through our words, our deeds and our culture. Our Work Appropriately philosophy supports our foundation of inclusion and provides employees the flexibility to work where they can have the greatest impact on achieving our goals, dependent on role needs. Every day, we want every employee, no matter their background, ethnicity, preferences, or location, to feel they belong to one General Motors team.

Benefits Overview

The goal of the General Motors total rewards program is to support the health and well-being of you and your family. Our comprehensive compensation plan incudes, the following benefits, in addition to many others:

Paid time off including vacation days, holidays, and parental leave for mothers, fathers and adoptive parents;
Healthcare (including a triple tax advantaged health savings account and wellness incentive), dental, vision and life insurance plans to cover you and your family;
Company and matching contributions to 401K savings plan to help you save for retirement;
Global recognition program for peers and leaders to recognize and be recognized for results and behaviors that reflect our company values;
Tuition assistance and student loan refinancing;
Discount on GM vehicles for you, your family and friends.

Diversity Information

General Motors is committed to being a workplace that is not only free of discrimination, but one that genuinely fosters inclusion and belonging. We strongly believe that workforce diversity creates an environment in which our employees can thrive and develop better products for our customers. We understand and embrace the variety through which people gain experiences whether through professional, personal, educational, or volunteer opportunities.GM is proud to be an equal opportunity employer.

We encourage interested candidates to review the key responsibilities and qualifications and apply for any positions that match your skills and capabilities.

Equal Employment Opportunity Statements

The policy of General Motors is to extend opportunities to qualified applicants and employees on an equal basis regardless of an individual's age, race, color, sex, religion, national origin, disability, sexual orientation, gender identity/expression or veteran status. Additionally, General Motors is committed to being an Equal Employment Opportunity (EEO) Employer and offers opportunities to all job seekers including individuals with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, email us atCareers.Accommodations@GM.com. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.
Show more Show less"
2808671457,Big Data Engineer,Redjack,2021-10-27,United States,"Silver Spring, MD",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Computer and Network Security","We are looking for people who share our core values of heroism, audacity, curiosity, and excellence to join our team. We are a tight-knit group of engineers, analysts, and business professionals who have organically built a company that monitors more than 8% of the Internet's public IP space and 40 trillion business communications per year. We've had a huge impact on the Fortune-50 and Government sectors over the past year, so we're looking to grow rapidly while maintaining our culture and diversity.

As a cyber resilience company, we solve security, continuity, regulatory, and efficiency problems for our customers. You'll help protect the jobs and security of millions of people while working on and advancing novel techniques in computer science. You'll be connected to everything that's happening; every developer on the team is responsible for our products' quality, everyone ships production code, and everyone directly supports the mission.

As a Big Data Engineer at Redjack, you'll be responsible for data analysis solutions to automate the understanding and protection of the world's largest digital enterprises. Your data science skills will be translated into opportunities for customers through the use of algorithmic, statistical, machine learning, and visualization techniques. You will demonstrate initiative and creativity by proposing ways to address problems often with large or incomplete data sets and validate findings using an experimental and iterative approach.

Your job

Your job will be to develop software to store and analyze massive amounts of customer enterprise data to reduce threat surface, increase cyber resilience, and facilitate digital transformations of some of the world's largest enterprises. Specifically, you will:

Leverage cloud-based data stores and write software using exciting, modern approaches to manage information on massive cyber environments.
Collaborate with members of the engineering team to increase their big data engineering IQ and understand the needs of our customers.
Design, develop and implement novel detectors and classifiers of critical systems and activity through machine learning and other modern approaches.


What you should have accomplished

We'll assess your skills and ensure your impact will scale with your ability. What we're looking for to start:

Bachelor's degree or higher in mathematics, statistics, engineering, or computer science.
3+ years experience with modern data science and machine learning approaches, big data analytics, and software development skills.
Knowledge and ability to explain both the code and the underlying statistical or analysis approac
hes used by modern data science algorithms/models.
Analytical and problem-solving skills.
Communication skills, critical thinking, and strategic thinking skills above and beyond the technical knowledge and implementation experience.


PM20
Show more Show less"
2811702613,Data Engineer,The Hartford,2021-10-30,United States,"Charlotte, NC",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

Join a fast-paced and talented Agile Scrum team to unlock Data Capabilities for The Hartford. You will have an opportunity to participate in the entire software development lifecycle process in support of continuous DATA delivery, while growing your knowledge with emerging technologies. We use the latest DATA technologies, software engineering practices, Agile delivery framework, and are passionate about technology and building well architected and innovative solutions that drive optimal business value generation. This cutting edge and forward focused team presents the opportunity for collaboration, self-organization within the Scrum Team and visibility as we focus on continuous Business data delivery.

What’s in it for you?

Experience deeper understanding of Data analysis, Emerging technologies and Development practices.
Collaboration with a high-performing, forward-focused team, Product Owner(s) and Business stakeholder(s) engagement.
Opportunity to expand your communication, analytical, interpersonal, and organization capabilities.
Enhance your entrepreneurial mindset – network opportunity and influencing outcomes.
Appreciation and opportunity to learn and support rapid software construction and deployment using a mix of technologies.
Supporting environment that fosters can-do attitude and opportunity for growth and advancement based on consistent demonstrative performance.
Optimize business value by leveraging your DATA experience and depth.
Be part of a Scrum Team – driving work independently or collaboratively towards achieving business outcomes.
Ability to collaborate daily alongside our senior investment professionals to develop technology driven solutions which will deliver a competitive advantage to EDO.

Qualifications

Bachelor degree with at least 4 years of applicable work experience.
Desired educational experience includes, but are not limited to: Computer Science, Engineering, IT, Management Information Systems, Data Analytics, Applied Mathematics, and Business.
Experience with prior Data Engineer/ETL competencies.
Experience in one or more of the following disciplines: SQL, Oracle, PL/SQL, Talend (or similar ETL Technology), Autosys, data warehousing architecture, and data modeling, Cloud technologies - AWS, Snowflake.

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$90,480 - $135,720

Benefits

Our company’s success is due to our employees’ dedication and passion for their work. They are our greatest asset. That’s why we are committed to offering employees and their families a comprehensive benefits package and award-winning well-being programs. By helping our employees achieve their full potential, we unlock our own. Visit https://www.thehartford.com/careers/benefits for details.

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

Data Engineer - GE08AE
Show more Show less"
2791839731,Data Engineer,IBM,2021-11-12,United States,"Houston, TX",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2818592543,Data Engineer,Bharathvio Technologies,2021-11-29,United States,"Texas, United States",,Contract,,"**ONLY W2**




Job Description

Translating business problems into analytical solutions by crunching data into a business decision model. The role requires skills in data engineering, ETL, data modeling, math/logic, visualization and continuous improvement lifecycle. It requires to establish data lineage across multiple analytical models to provide a front to back data model servicing the post trade flow – starting from collecting data, data modeling, warehousing, visualizations and business insights

Academic Qualifications: Engineering (or) masters in analytics/data science (or) any math/statistics/quant background
Expertise in data munging/wrangling methods on large datasets
Dimensional modeling, OLTP & OLAP structures, relational data models
Analytics tools/platforms: Alteryx (preferred)
Visualization: Tableau (preferred), QlikView
Programming languages: Python (Intermediate), R
ETL processes, data integration, data quality framework
Experience solving business problems using data and created analysis
Databases/Warehousing Platforms: Microsoft SQL server, MySQL, AWS, Snowflake

Preferred Qualifications: 

Has engineering or any quantitative background
Hands-on experience of Data Engineering & BI – worked end-end from modeling data to analysis and solve business problems
Expertise in relational DBs, data modeling and ability to convert business logic/decisions into business metrics

Preferred MS-SQL, Alteryx, Tableau & Python

Show more Show less"
2787898950,Data Engineer,Decido - Decisions Made Easy,2021-11-10,United States,United States ,,Full-time,,"Decido is a hyper-growth digital media startup with several high-scale online properties and adtech platforms. We specialize in explosive growth marketing technology and complex data models for real-time media attribution and optimization.




Our ideal candidate is an intellectually curious, passionate individual looking to propel their career to new heights in record time. If you're looking to solve really hard problems and learn something new every day, Decido is the place for you. we work hard, and play hard!




This role will have the opportunity to lead a large number of projects, end-to-end, impacting millions of users, which reach across the entire spectrum of the product development lifecycle from idea to production at unparalleled scale.




TO SUCCEED YOU SHOULD HAVE

- Burning desire to be a part of something really BIG

- Extreme sense of ownership, responsibility, and accountability for the architecture, design, code quality, stability, and resiliency of the platform

- Experience in scoping complex tasks and projects, and break them down into smaller tangible tasks

- Be comfortable executing end-to-end, from start to finish

- Strong analytical and statistical analysis skills to understand and interpret the data

- Strong communication and problem-solving skills




QUALIFICATIONS

- 5+ years of experience in Data Science and/or Data Engineering

- Strong proficiency in Python and complex SQL queries

- Knowledge of data warehousing, real-time data platforms, ETLs, and reporting/analytics tools. BigQuery and/or Airflow is a plus

- Implement Machine Learning or statistics based algorithm for prediction and optimization

- Design and build predictive customer behavior models for targeting and personalization

- Solid understanding of cloud architectures

- Experience in online advertising is preferred but not required

Show more Show less"
2817138383,Hadoop ETL/Data Engineer,Maintec Technologies Inc.,2021-12-03,United States,United States,,Contract,,"Job Description:

Job Title: Hadoop ETL/Data Engineer

Location: Fully Remote




Description:

•        7+ years of hands-on experience in building Data lake using Hadoop skills.

•        4+ years of Hands-on experience in Spark /Scala.

•        Hands-on data ingestion into Hadoop and extraction from Hadoop.

•        Excellent data handling and data management skills in transform the data.

•        Working experience in AirFlow.

•        Working experience in relational databases ( Teradata and PostgreSQL.

•        excellent Debugging and problem-solving skills.

•        Should have excellent communication skills to gather/understand/document business requirements.

•        Prior experience of Prod deployment of Hadoop packages.

•        Working experience in Jenkins.

•        Knowledge of the Healthcare industry and experience with healthcare datasets is preferred

·        Good to have AWS knowledge










Show more Show less"
2810799504,Data Engineer,Expero,2021-10-29,United States,"Houston, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Expero builds advanced analytics applications in challenging domains for expert users; scientists, traders and engineers. These are not your normal applications and our consultants work across a spectrum of technologies. We find the same thing over and over again out in the world: crappy batch-mode big data systems. What fires us up is shaking up this status quo by bringing fast event-driven data flow programming to systems with complex data science: Incremental graph algorithms, relational projections, monte carlo simulations, all connected to data firehoses. We think dataflow programming and materializations are the Next Great Thing in advanced analytics and we’re looking for people who share our passion and compulsive need to tinker.

We’re looking for engineers that are fascinated by data, in whatever state it’s in. If you are drawn to wrangling free range data, performing ETL, ELT, ELTL, or any combination of those letters, you’ll enjoy the types of problems we have here. Creating and maintaining optimal data pipeline architectures comes with the territory. If this is your thing, then we’re interested in finding out more about you.

Requirements

5+ years building data infrastructure and plumbing
Apache Airflow / DAGs
Microservice and API architecture and implementation
Streaming architectures and tools like Kafka or Spark Streaming
Working knowledge of Python, Java, and/or Scala
Experience with major cloud vendors’ data engineering products like GCP’s Dataflow or AWS’s Redshift
Knowledge of message queuing, stream processing, and scalable data stores
Experience deploying machine learning systems at scale for big bonus points!


Benefits

We get better work done for our clients when all our employees are paid well and have excellent benefits, including group health, dental, and life insurance, family leave, and a retirement plan. So that’s the way we do it.

Expero is committed to being an equal opportunity employer. Our focus is solving challenging problems, not where you came from or how you live your life. We are an E-Verify workplace.
Show more Show less"
2813793289,Data Engineer,remoti,2021-11-25,United States,United States,,Full-time,,"Hello USA!!!




We are looking for experienced Data Engineers to help build out its new reporting suite. You will be significantly helping multiple business units such as Finance, Accounting, Compliance, and Sales by automating data retrieval and providing an elegant self-service reporting suite.




The right candidate for this position is detail-oriented, deeply technical, and driven. You are eager to learn new technologies and complex systems. You build resiliency and scalability into the platform at every step.




If you're looking to have a massive impact in a high-growth startup in one of the most exciting markets in decades, you will find this role challenging and rewarding in equal measure. 




Responsibilities

Support the company's vital business by providing a self-service reporting tool
Work with platform engineers to set up new services
Respond to production issues and alerts




Requirements

5-7 years of experience, preferably in the FinTech space.
Proficiency in English (C1+)
A humble and scrappy get-it-done mindset; you're resourceful and in your element going from 0 to 1.
Excellent problem-solving skills - can troubleshoot complex systems.
Deep proficiency in Python, SQL, Redshift, AWS
Experience with data warehousing solutions
Experience building ETL pipelines
Experience with data streaming solutions
Comfort with ambiguity; the ability to independently layout and test clear hypotheses and solve problems without well-defined direction
Excellent verbal and written communication skills




Preferred

Bachelors in computer science or equivalent experience
Experience with the SciPy stack, specifically Pandas Experience at a banking-as-a-service, brokerage-as a service, payment-as-a-service business
Experience with creating and maintaining data pipelines
Experience with digital assets
An understanding of financial services reconciliation tools




Salary up to 120K USD

Show more Show less"
2787809126,Big Data Engineer,Tredence Inc.,2021-11-10,United States,United States,"Engineering, Information Technology, and Analyst",Full-time,Management Consulting,"About Tredence:

Tredence focuses on last mile delivery of insights into actions by uniting its strengths in business analytics, data science, and software engineering. The largest companies across industries are engaging with Tredence and deploying its prediction and optimization solutions at scale –empowering end users to improve decision making. Headquartered in the San Francisco Bay Area, the company serves clients in the US, Canada, Europe, and SE Asia. Learn more at www.tredence.com




Job Descriptions:




Data Platform is the core foundation driving all our Experimentation products that directly impact the customer experience. The Platform is leveraged across all product lines from spanning Marketing Analytics, Targeting, Recommendations and large-scale Ingestion. This platform based primarily on one of our retail client’s customer interactions & transactional data, processes billions of events a day and we’ve built many sophisticated data pipelines that can power a variety of analytical queries at web scale. We are looking for a strong Distributed Systems Engineer to build cutting-edge capabilities on the Data Platform for our rapidly growing enterprise customer base.




ELIGIBILITY CRITERIA:

Experience in building scalable, robust applications using Big Data technologies like Hadoop, Spark, Hive, Map reduce
Proficient with SQL
Experience with Scripting – Python, shell
Nice to have - Experience with MySQL
Nice to have – Cloud experience




Other Skills/Qualifications:

Bachelor's and/or master’s degree in computer science or equivalent experience.
Strong communication, analytical and problem-solving skills with a high attention to detail.




About you:

You are self-motivated, collaborative, eager to learn, and hands on
You love trying out new apps, and find yourself coming up with ideas to improve them
You stay ahead with all the latest trends and technologies
You are particular about following industry best practices and have high standards regarding quality




Why join Tredence?




There is a reason we are one of the fastest growing private companies in the country! You will have the opportunity to work with some of the smartest, friendliest, hardest working people in the data analytics space. You will work with the latest technologies and interface directly with the key decision stakeholders at our clients, some of the largest and most innovative businesses in the world. We offer a 401k match; full medical, dental and vision benefits, a fun team atmosphere and a work life balance. Our people are our greatest asset and we value every one of them. Come see why we’re so successful in one of the most competitive and fastest growing industries in the world.

Show more Show less"
2786713706,Big Data Engineer,FinTech LLC,2021-11-09,United States,"Philadelphia, PA",Engineering and Information Technology,Full-time,"Appliances, Electrical, and Electronics Manufacturing, Manufacturing, and Retail","Experience and Requirements

A successful Data Engineer will have the following:
• Must be from Data warehouse/Big data background.
• Experience in advanced Apache Spark processing framework, spark programming languages such as Scala/Python/Advanced Java with sound knowledge in shell scripting.
• Experience in working with Core Spark, Spark Streaming, Data Frame API, Data set API, RDD APIs & Spark SQL programming dealing with processing terabytes of data. Specifically, this experience must be in writing """"Big Data"""" data engineering jobs for large scale data integration in AWS.
• Advanced SQL experience using Hive/Impala framework including SQL performance tuning
• Experience in writing spark streaming jobs integrating with streaming frameworks such as Apache Kafka or AWS Kinesis.
• Create and maintain automated ETL processes with special focus on data flow, error recovery, and exception handling and reporting
• Gather and understand data requirements, work in the team to achieve high quality data ingestion and build systems that can process the data, transform the data
• Knowledge of using, setting up and tuning resource management framework such as standalone spark, Yarn or Mesos.
• Experience in physical table design in Bigdata environment
• Experience working with external job schedulers such as autosys, aws data pipeline, airflow etc.
• Experience working in Key/Value data store such as Hbase
• Experience in AWS services such as EMR, Glue (server less architecture), S3, Athena, IAM, Lambda and Cloud watch is required.""



Job Duties and Responsibilities
• Evangelist for data engineering function leveraging big data processing framework.
• Creation and optimization of data engineering pipelines for analytics projects.
• Support data and cloud transformation initiatives
• Support our software engineers and data scientists
• Contribute to our cloud strategy based on prior experience
• Understand the latest technologies in a rapidly innovative marketplace
• Independently work with all stakeholders across the organization to deliver enhanced functionality""

Show more Show less"
2791844236,Data Engineer,IBM,2021-11-12,United States,"San Francisco, CA",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2812551596,Big Data Engineer,Macrosoft,2021-11-24,United States,"Plano, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Computer Networking Products","The Big Data Software Engineer is responsible for the development of high performance batch and streaming data pipelines on-premises and the Cloud using Hadoop, NiFi, Kafka, Spark, MySQL and other ""Big Data"" technologies in a Linux environment. analyzes, designs, programs, debugs and modifies software used in distributed, large scale analytics and visualization solutions. Works in a highly agile environment with other developers, solution architects, testers and project managers.
Show more Show less"
2798007884,Data Engineer,Cedars-Sinai,2021-10-24,United States,"Los Angeles, CA",Information Technology,Full-time,"IT Services and IT Consulting, Research Services, and Hospitals and Health Care","Grow your career at Cedars-Sinai!

The Enterprise Information Services (EIS) team at Cedars-Sinai understands that true clinical transformation and the optimization of a clinical information systems implementation is fueled through the alignment of people, processes, and technologies.

What Will You Be Doing In This Role

The Software Developer is responsible for application development supporting business objectives while providing mid to senior level experience in software development lifecycle phases from concept and design to testing. Analyses, designs, and builds component-based applications including introduction of an application layer, modeling techniques, component and object-oriented design, sophisticated algorithmic coding, and detailed approaches to application integration. Works on new and existing applications. Performs hands-on coding and assists in architecting solutions.

Designs, develops, and supports applications using python.
Scopes, implements, tests, and deploys new features and versions of core applications, databases, and utilities.

#Jobs
Show more Show less"
2758750992,Data Engineer,Snap Inc.,2021-12-04,United States,"Seattle, WA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Snap Inc. is a camera company. We believe that reinventing the camera represents our greatest opportunity to improve the way people live and communicate. Our products empower people to express themselves, live in the moment, learn about the world, and have fun together.

We’re looking for a Data Engineer on our Analytics Engineering team! Working from one of our west coast offices in Santa Monica, CA, Mountain View, CA, or Seattle, WA, you’ll collaborate with teams across the organization (engineering, finance, sales, marketing, and strategy) to build pipelines and systems to deliver the data necessary for making the right decision in the moment. Our team strives to improve decision quality across the company by ensuring metrics are trustworthy, discoverable, and easily consumable.
What you’ll do:
Work closely with stakeholders in engineering, finance, sales, marketing, strategy, and governance to make high quality datasets available to consumers in a timely manner
Develop data pipelines adhering with privacy and governance principles
Become familiar with our data consumption portals and their capabilities
Build expertise and ownership of data quality for supported domains
Establish and implement data quality standards and controls
Build tooling and implement systems to overcome limitations of the data consumption portals when appropriate
Drive adoption of the data sets you’ve produced
Knowledge, Skills & Abilities:
Experience in building data pipelines to serve reporting needs
Experience owning all or part of a team roadmap
Ability to prioritize requests from multiple stakeholders in disparate domains
Ability to effectively communicate complex projects to non-technical stakeholders
Minimum Qualifications:
BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
3+ year experience in SQL or similar languages
3+ years development experience in at least one object-oriented or scripting language (Python, Java, Scala, etc)
Experience in ETL / Data application development
Preferred Qualifications:
Hands on experience with Google BigQuery
Experience in version control systems such as Git
Data architecture and warehousing experience
Experience leading a small team of data or software engineers
Experience with Airflow

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at accommodations-ext@snap.com .

_________________________________________________________________________________________________

For more information on what to include when writing your job description, please check out this resource: OFCCP | Job Description Template Details .
Show more Show less"
2813545893,Data Engineer,Optum,2021-11-30,United States,"Plymouth, MN",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Our OmniChannel team is transforming our contact center infrastructure through a multi - year program entitled Omni. The Omni program provides a platform level technical refresh for the delivery of inbound customer calls to :75,000 agents globally. It will also refresh and deliver new customer channel interactions through outbound, chat, email, click-to-call, and other contact types. This is a highly visible role performing a critical function as a subject matter expert relative to Data and Reporting capabilities for the new Omni platform.

Primary Responsibilities

Understanding Contact Center operational KPIs
Analyzing, designing, configuring, implementing and supporting SSIS development
Creating custom Tableau/PowerBI reports
Interfacing with end users to help them navigate data as needed
Assisting in determining root causes behind operational issues as needed (such as increases in call Average Handle Time, Increases in Call Abandon Rates, etc.)
Actively participating in highly functional Agile SRE teams

You'll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Technology Careers with Optum. Information and technology have amazing power to transform the health care industry and improve people's lives. This is where it's happening. This is where you'll help solve the problems that have never been solved. We're freeing information so it can be used safely and securely wherever it's needed. We're creating the very best ideas that can most easily be put into action to help our clients improve the quality of care and lower costs for millions. This is where the best and the brightest work together to make positive change a reality. This is the place to do your life's best work.(sm)

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity / Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.

Undergraduate degree or equivalent experience.
3+ years of experience in Microsoft ETL and SSIS process development
3+ years of SQL development
1+ years of SSRS experience
1+ years of Call Center reporting experience
1+ years of Tableau experience

Preferred Qualifications

Genesys Pulse configuration
Genesys GI2 experience
Call Center Operations and workforce management
Call metric calculations and reporting
Avaya and Genesys KPI reporting

Technology Careers with Optum. Information and technology have amazing power to transform the health care industry and improve people's lives. This is where it's happening. This is where you'll help solve the problems that have never been solved. We're freeing information so it can be used safely and securely wherever it's needed. We're creating the very best ideas that can most easily be put into action to help our clients improve the quality of care and lower costs for millions. This is where the best and the brightest work together to make positive change a reality. This is the place to do your life's best work.SM

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.
Show more Show less"
2808120276,Data Engineer,Deckers Brands,2021-11-25,United States,"Seattle, WA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2826943029,Data Engineer,Radancy,2021-12-04,United States,"Bolingbrook, IL",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Radancy’s Data Engineering team is seeking a motivated Data Engineer to build data products and services. The Data Engineering team works on data services across product organizations within Radancy and supports building a customer facing data visualization product. Team also supports an enterprise grade recruitment platform focusing on talent acquisition and job opportunity exploration.

The team has extensive experience in ETL development, works with large scale data in real time, and collaborates with other engineering teams across the organization.

Build and maintain ETL pipelines, Automated workflows, Data products and services, Reporting Suite etc. using latest technologies and tools i.e. Python, Docker, SQL Server, BigQuery, PostgreSQL, Airflow, Luigi, Tableau, ASP .NET, RabbitMQ, Kafka and many others
Work with Cloud Computing Platforms (GCP/AWS), ETL Orchestration tools(Luigi/Airflow), and other advanced open-source technologies
Data modeling, schema design, and SQL development
Ingest and aggregate data from both internal and external data sources to build our world class datasets
Develop and lead the testing and fixing of new or enhanced solutions for data products and reports, including automating ETL testing
Collaborate with Product Owner and domain experts to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
Assist with the development and review of technical and end user documentation including ETL workflows, research, and data analysis
Work with Product team to define data collection and engineering frameworks
Build monitoring dashboards and automate data quality testing
Own meaningful parts of our service, have an impact, grow with the company
3+ years of Python, SQL, and ETL development
Experience with at least one - Client Facing Product or Services or Reporting suite
Strong Understanding of ETL pipeline, data lakes and data warehouse development
Exposure to at least one cloud computing platform (GCP/AWS/Azure), and cloud data warehouse (BigQuery/Redshift)
Experience delivering applications that run in a containerized environment is a plus
Basic knowledge of Machine Learning, ML Pipelines and tools is a plus
Some experience with any of these is a plus - NLP, MLOps, DataOps, tensorflow/keras/pytorch
Exposure to agile methodologies and particularly scrum
Experience working with large datasets for several organizational units internally as well as externally is a huge plus
Enthusiastic about working with and exploring new data sets
Detail oriented, strong communicator, quick thinking and acting with minimal supervision
Bachelor's degree in related area (Computer Science, Information Systems, Engineering) or an equivalent combination of education and experience

Join the global leader in talent acquisition technologies that’s committed to finding new ways to leverage software, strategy and creative to enhance our clients’ employer brands – across every connection point. We’re looking for unconventional thinkers. Relentless collaborators. And ferocious innovators. Talented individuals who are ready to work towards solutions that transform the way employers and job seekers connect.

Radancy is an equal opportunity employer and welcomes all qualified applicants regardless of race, ethnicity, religion, gender, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. We actively work to create an inclusive environment where all of our employees can thrive.
Show more Show less"
569502027,Data Engineer,"White Box Technologies, Inc.",2021-11-19,United States,"West Valley City, UT",,Full-time,,"As a member of the programming team, the Database Integration Engineer works closely with

data analysts and data engineers to build integration solutions and implement conversion code. In addition to working on our services projects, Database Integration Engineers build reusable tools to allow future projects to be done more efficiently. Because every project is a little different, with its own set of complications, the successful candidate will be able to adapt to new situations quickly and easily. The engineer should be someone who enjoys challenges and building software solutions to overcome those challenges.




This position has the ability to telecommute and create a flexible schedule that works for you. We offer competitive pay, benefit packages including medical insurance, dental, and generous paid time off.




For a full list of experience and responsibilities, please visit our website. 

https://www.whiteboxtechnology.com/careers/

Show more Show less"
2817802434,Data Engineer (Remote),Stash,2021-12-03,United States,"New York, NY",Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","Want to help everyday Americans invest and build wealth? Financial inequality is increasing, and too many people are getting left behind. At Stash, we are passionate about democratizing wealth creation through education, advice, and products that help customers achieve greater financial freedom.

At Stash, data is at the core of how we make decisions and build great products for millions of users. As a Data Engineer you will be a part of our Data Platform Team which is leading the architectural design decisions and implementation of a modern data infrastructure at scale. You will build distributed services and large scale processing systems that will support various teams to work faster and smarter. You will partner with Data Science to help productionize machine learning models and algorithms into actual data driven products that will help make smarter products for our users.

Tools And Technologies In Our Tech Stack (evolving)


Hadoop, Yarn, Spark, MongoDB, Hive
AWS EMR/EC2/Lambda/kinesis/S3/Glue/DynamoDB/API Gateway, Redshift
ElasticSearch, Airflow, and Terraform.
Scala, Python


What You'll Do


Build core components of data platform which will serve various types of consumers including but not limited to data science, engineers, product, qa
Build various data ingestion and transformation job/s as and when they are needed
Productionize our machine learning models and algorithms into data-driven feature MVPs that scale
Leverage best practices in continuous integration and deployment to our cloud-based infrastructure
Build scalable data services to bridge the gap between analytics and application space
Optimize data access and consumption for our business and product colleagues
Develop an understanding of key product, user, and business questions


Who We’re Looking For


3+ years of professional experience working in data engineering
BS / MS in Computer Science, Engineering, Mathematics, or a related field
You have built large-scale data products and understand the tradeoffs made when building these features
You have a deep understanding of system design, data structures, and algorithms
Experience (or a strong interest in) working with Python or Scala
Experience with working with a cluster manager (YARN / Mesos / Kubernetes)
Experience with distributed computing and working with Spark, Hadoop, or MapReduce Framework
Experience working on a cloud platform such as AWS
Experience with ETL in general


Gold Stars


Experience working with Apache Airflow
Experience working with AWS Glue
Experience in Machine Learning and Information Retrieval


At Stash it is our mission to help everyday Americans invest and build wealth. That includes people of all races, genders, and abilities, so it is important to us to acknowledge and address the issues of inequality in financial services head on.

Diversity and inclusion are essential to living our values, promoting innovation, and building the best products. Our success is directly related to our employees and we believe that our team should reflect the diversity of the customers that we serve. As an Equal Opportunity Employer, Stash is committed to building an inclusive environment for people of all backgrounds.

If you require any reasonable accommodations to make your application process more accessible please reach out to recruiting@Stash.com.

Invest In Yourself


Equity & Stash Accounts [Invest, Retire, Custodial, Bank]
Flexible PTO
Learning & Development Fund
Work from Home Stipends
Parental Leave [Primary & Secondary]


Recognition


BuiltIn’s Best Places to Work (2019, 2020, 2021)
Forbes Fintech 50 (2019, 2020, 2021)
Best Digital Bank, Finovate Awards (2020)
Tearsheet Challenge Awards, Best Banking Card Product - Stock-Back® Card, 2020
LendIt Fintech Innovator of the Year (2019 & 2020)
No recruiters, please**


Show more Show less"
2767096014,Senior Big Data Engineer,Nike,2021-11-16,United States,"Beaverton, OR",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","NIKE, Inc., Beaverton, OR. Implement database management systems with standards, guidelines and quality assurance for database deliverables. Design and document conceptual database model and logical database model to support internal and external application program interface data. Implement data loading plan, data maintenance plan and security policy for enterprise databases. Communicate to all team members where needed to ensure requirements are understood, questions are answered, issues are raised, and solutions are delivered effectively and efficiently. Develop complex programs using big data platforms. Analyze and profile data for the purpose of designing scalable solutions. Develop extraction, transformation and load pipelines. Build reports on data warehouse and Data Lake to support business users. Drive and collaborate reviews of design, code, test plans and dataset implementation performed by other data engineers in support of maintaining data engineering standards. Develop a clear understanding of end to end processes from a technical perspective including integration points, migration strategy, data model changes, reporting, and other requirements for technical design and the visual representation of data and information.

Applicant must have a Master’s degree in Computer Science, Computer Information Systems, Computer Application, Applied Computer Science, or Engineering and 2 years of experience in the job offered or a related occupation. Experience must include:

Python;
Snowflake;
AWS, Azure, or similar cloud platform;
Terraform;
Kinesis or Kafka;
Oracle;
Big Data solutions/tools;
Airflow;
Java;
Agile development;
SQL; and
Database Management


OR

Applicant must have a Bachelor’s degree in Computer Science, Computer Information Systems, Computer Application, Applied Computer Science, Engineering and 5 years of progressive post-baccalaureate experience in the job offered or a related occupation. Experience must include:

Python;
Snowflake;
AWS, Azure, or similar cloud platform;
Terraform;
Kinesis or Kafka;
Oracle;
Big Data solutions/tools;
Airflow;
Java;
Agile development;
SQL; and
Database Management.
Show more Show less"
2803980093,"Big Data Engineer, AmazonBot",Amazon,2021-11-23,United States,"Sunnyvale, CA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

DESCRIPTION

The Web consists of trillions pages from billions of domains. Our mission is to automatically identify ""the needles in the haystack:"" the small subset of high-value Web data that we can leverage to make Alexa smarter. Frugality, innovation, and scale are par for the course.

Why should you join the Alexa team? Here are a few reasons:

We ship software frequently, get fast feedback from real customers around the globe, and see the results of our work come to fruition.

There are real-world problems to solve that you won’t find ready-made answers for. For example, how do you process massive data in the least time possible. How can you improve Alexa to to answer more questions?

We look for ways to make the our service configurable, maintainable and visible as easy, intuitive and time efficient as possible.

Key job responsibilities

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with customer teams to understand data requirements, and to build ETL to ingest and export data at scale. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to create necessary data flows. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

About The Team

Our team tries to have a healthy balance between work and play. We celebrate our successes and milestones and we are not afraid to take risks, even if it causes unintentional mistakes along the way. We believe in learning from our mistakes and moving forward.

Location: This role can be fully remote or open to these office locations: Sunnyvale, Manhattan Beach or Seattle.


Basic Qualifications

3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL
This position requires a Bachelor's Degree in Computer Science or a related technical field, and 5+ years of meaningful employment experience.
5+ years of work experience with ETL, Data Modeling, and Data Architecture.
Expert-level skills in writing and optimizing SQL.
Experience with Big Data technologies such as Hive/Spark.
Proficiency in one of the scripting languages - python, linux or similar.
Experience operating very large data warehouses or data lakes.

Preferred Qualifications

Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
Experience with building data pipelines and applications to stream and process datasets at low latency.
Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
Knowledge of Engineering and Operational Excellence using standard methodologies.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon.com Services LLC

Job ID: A1694696
Show more Show less"
2818888484,Data Engineer,Parker and Lynch,2021-12-03,United States,United States,Information Technology and Product Management,Full-time,Computer Software and Gambling Facilities and Casinos,"Parker + Lynch is seeking a remote Data Engineer for a global leader in professional services. Candidate will design, implement, and contribute to transforming data into actionable models. This role directly contributes to the successful delivery of business intelligence throughout the technical community. This position requires collaboration with other teams, understanding clients, maintenance of technical skills and knowledge of market trends.




Responsibilities:

• Understand client's data landscape, technology and business priorities and success measures to design reliable data pipelines and data marts

• Collaborate with data architects, business stakeholders and information designers to identify and define required data structures, formats, pipelines, metadata, and workload orchestration capabilities

• Maintain technical skills and knowledge of market trends and competitive insights; collaborate and share with technical community




Requirements:

• 3-5 years of experience in data engineering

• Bachelor's Degree or higher in STEM areas i.e. Computer Science, Information Systems, Big Data & Analytics, or equivalent work experience

• 2+ years of experience in translating business requirements to technical requirements. Experience in agile methodology is highly preferred

• 3+ years of hands-on experience in building data pipelines using SQL

• Good understanding of relational and non-relational data bases including data modelling and data structure

• At least 2 years of experience in programming language/s (Python, Scala or Java)

• Experience with software configuration management environments and tools such as JIRA, Git, Jenkins, Bitbucket, etc

• Experience with Azure










• Travel requirement (25-50%)

Show more Show less"
2825870490,Data Engineer,Kforce Inc,2021-12-03,United States,"Los Angeles, CA",Information Technology,Full-time,"IT Services and IT Consulting, Information Services, and Wireless Services","Responsibilities

Kforce has a client that is seeking a Data Engineer in Los Angeles, CA. Summary: A collaborative and innovative culture, our client offers highly advanced technology to identify and track purchasers in a physical retail store. Their technology relies on data science and probabilistic modeling to identify and track the purchasers. Their platform gives retail chains the same level of customer insight (and revenue growth) as data-savvy online retailers like Amazon, leveraging hundreds of millions of daily data points. Responsibilities of the Data Engineer:

The Data Engineer who will be architecting a highly scalable data integration and transformation platform processing high volume of data under defined SLA
You will be creating and building the platform that includes ingestion and transformation of data, data governance, machine learning, analytics, and consumer insights
You will be solving complex problems with a business that celebrates innovation and values your contributions
Data Engineer will use their platform is a combination of a large-scale near-real time data pipeline (10s of billions of data points of sale transaction data from major retailers) and over 100 microservices
Our client's current tech stack includes Flink, Cassandra, Elasticsearch, AWS Athena, Glue, Redshift, EMR, and DynamoDB

What They Offer

REQUIREMENTS:

A fantastic opportunity to be part of a growing start-up; A chance to work with a passionate, driven, and fun team
An incredible work environment - fun, casual and fast-paced
Monthly team activities and outings
Loft-style office with plenty of break-out space
Fully stocked company snack area complete with every drink and snack your heart desires
Great benefits - Health, Dental, Vision, and Vacation
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

Salary: Competitive
Show more Show less"
2800099872,Data Engineer,Fisher Investments,2021-11-15,United States,"Tampa, FL",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Overview

The Opportunity:

As a Workforce Analyst at Fisher Investments, you will help improve our workforce through employee related insights to help build and further a diverse, engaged workforce. Reporting to the Workforce Analytics Manager, you will partner with leaders in Human Capital and across the business to improve people performance and planning through the discovery, interpretation and communication of meaningful patterns in workforce-related data. Through these insights and optimization, you will help the firm achieve its long-term strategic goals.

The Day-to-Day:

Construct data queries from multiple data sources to aggregate, model and prepare information for analysis
Be an expert on data flows from Human Capital data systems to data consumers and identify improvements in the data pipeline
Recommend business process or system enhancements to improve data quality and reporting capabilities
Help implement reporting from Human Capital data systems (Workday, iCIMS, etc.)
Create new service opportunities to further our goal of supporting the firm's talent development and management
Perform analysis on employee related datasets to find actionable insights that support essential decision makers
Adhere and maintain the Human Capital data governance model through proper documentation of data processes and definitions


Your Qualifications:

2+ years of experience in a quantitative or consulting based role using analytics and visualizations to solve business problems
Experience working with data visualization tools (Tableau, Looker, PowerBI, etc.)
Experience with SQL for querying and modeling data
Experience creating reporting in common Human Capital Management Systems (Workday, iCIMS, etc.)
U.S. candidates must be fully vaccinated as defined by the medical community against COVID-19 and provide proof of such vaccination by date of hire


Why Fisher Investments:

At Fisher Investments, we work for a bigger purpose: bettering the investment universe. From unmatched service to unique perspectives on investing, it's the people that make the Fisher purpose possible. And we invest in them by offering exceptional benefits like:

100% paid medical, dental and vision premiums for you and your qualifying dependents
A 50% 401(k) match, up to the IRS maximum
20 days of PTO*, plus 9 paid holidays
8 weeks paid Primary Caregiver Parental Leave
Back-up Child Care Program available, offering up to 10 days annually
A cumulative learning and development framework customized for every employee
An award-winning work environment - we're Great Place to Work Certified, and Top Workplace winners from The Oregonian


We take great pride in our inclusive culture. We value the different perspectives and unique skills you bring to the team – it makes us all better. Success at Fisher Investments is motivated by results, a collaborative mindset and a commitment to accomplishing great things – so if you are ready to do that, we are ready for you! Apply today to be a part of a team environment where you make a difference in the lives of people by bettering the investment universe.

California employees accrue up to 17 days of PTO and 3 days of sick time per year.


FISHER INVESTMENTS IS AN EQUAL OPPORTUNITY EMPLOYER
Show more Show less"
2821374508,Big Data Engineer,Zachary Piper Solutions,2021-11-29,United States,United States,Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Piper Companies is looking for a Big Data Engineer for a leader in supporting the mortgage and real estate services lifecycle in Philadelphia, Pa.

This position is 100 remote.

Qualifications for the Big Data Engineer bull Data Science space supporting AI initiatives.

bull Work closely with the data scientists to make sure the data infrastructureenvironment is built out and can support all the data.

bull Spark, beam and batch processing experience bull Experience with Kafka, SQS, Kinesis bull Experience working with data, images around MLS Data

Job Responsibilities for the Big Data Engineer bull Cleansing, retrieving the data, ETL versus developing bull Key enabler for the scientific research (spark (MapReduce, Hadoop) and Kafka or similar experience)

bull Run scalable efficient jobs that can move terabytes of data around bull Solutions around how they enable this work and build.

Benefits and Details bull Comprehensive benefit package Medical, Dental, Vision, 401k
Show more Show less"
2825865747,Data Engineer,Kforce Inc,2021-12-03,United States,"Los Angeles, CA",Information Technology,Contract,"IT Services and IT Consulting, Information Services, and Wireless Services","Responsibilities

Kforce has a client that is seeking a Data Engineer in Los Angeles, CA. Summary: A collaborative and innovative culture, our client offers highly advanced technology to identify and track purchasers in a physical retail store. Their technology relies on data science and probabilistic modeling to identify and track the purchasers. Their platform gives retail chains the same level of customer insight (and revenue growth) as data-savvy online retailers like Amazon, leveraging hundreds of millions of daily data points. Responsibilities of the Data Engineer:

The Data Engineer who will be architecting a highly scalable data integration and transformation platform processing high volume of data under defined SLA
You will be creating and building the platform that includes ingestion and transformation of data, data governance, machine learning, analytics, and consumer insights
You will be solving complex problems with a business that celebrates innovation and values your contributions
Data Engineer will use their platform is a combination of a large-scale near-real time data pipeline (10s of billions of data points of sale transaction data from major retailers) and over 100 microservices
Our client's current tech stack includes Flink, Cassandra, Elasticsearch, AWS Athena, Glue, Redshift, EMR, and DynamoDB

What They Offer

REQUIREMENTS:

A fantastic opportunity to be part of a growing start-up; A chance to work with a passionate, driven, and fun team
An incredible work environment - fun, casual and fast-paced
Monthly team activities and outings
Loft-style office with plenty of break-out space
Fully stocked company snack area complete with every drink and snack your heart desires
Great benefits - Health, Dental, Vision, and Vacation
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

Salary: Competitive
Show more Show less"
2806115082,Data Engineer,Innovaccer,2021-11-23,United States,United States,Information Technology,Full-time,IT Services and IT Consulting and Hospitals and Health Care,"YOUR ROLE




We are looking for a highly talented and passionate individual to join our team of engineers

deployed to the front line. This is where the rubber meets the road, where the product has to

meet customer needs and create value. You are an engineer who loves data and wants to see

technology and data used successfully. You have great attention to detail and are very proactive

in seeking potential roadblocks to success. You have great people skills and know-how to

manage the trust and expectations of a customer.







A Day in the Life




Enabling customers for success

Understand customer’s business and requirements for the technology Innovaccer has to offer.
Measure and communicate impact to our customers. We love to measure the impact of what we do and we have saved over $800 million in healthcare cost while increasing 400 basis points in quality of care.
Enabling customers on how to activate data themselves, either using SQL or BI tools or APIs to solve for questions they have at speed.




Shaping the healthcare data platform for customer needs

Shaping data models visible to the customer
Creating analytical views that drive a new insight customer needs
Building actionable dashboards and reports for customers




Finally, making people healthy and reducing the cost of healthcare, all while enjoying to do

what you love, data!




What You Need




0-3 years of experience in a Data Engineer role, Graduate degree in Computer Science,
Statistics, Informatics, Information Systems or another quantitative field.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Proficient in at least one programming language (like Python, R, Scala) and at least data language (like SQL)
Ability to engage with both the business and technical teams of a client
Ability to explain technical problems or concepts in a clear and concise way to non-technical users.
Show more Show less"
2791842412,Data Engineer,IBM,2021-11-12,United States,"Atlanta, GA",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2810190967,Data Engineer,Lockheed Martin,2021-10-29,United States,"Herndon, VA",Information Technology,Full-time,"Construction, IT Services and IT Consulting, and Computer Software","COVID-19 continues to significantly impact our employees, families and communities. With employee health and safety as our top priority, and as a federal contractor, Lockheed Martin is taking action to address the increased risk and uncertainty COVID variants pose in the workplace and ensuring we meet our commitments to national security.

As directed by Executive Order 14042: Ensuring Adequate COVID Safety Protocols for Federal Contractors, all current and newly hired employees, in the United States, are required to be fully vaccinated by January 18, 2022.

Description:The coolest jobs on this planet… or any other… are with Lockheed Martin Space.

At the dawn of a new space age, Lockheed Martin is a pioneer, partner, innovator and builder. Our amazing people are on a mission to make a difference in the world and every single day we use our skills and experiences to create, design and build solutions to some of the worlds’ hardest engineering problems. Our culture encourages employees to dream big, perform with excellence and create incredible products. We provide the resources, inspiration and focus and if you have the passion and courage to dream big, we want to build a better tomorrow with you.

The 21st Century Warfare Program is looking for a motivated Data Engineer to join our Joint All Domain Operations Center (JADOC) team. This application is for the next generation of all domain capabilities; built in preparation for live real world exercises. The ideal candidate has a passion and enthusiasm towards handling such complex efforts.

In This Role You Will

Respond with agility and purpose when interacting with stakeholders from multiple business areas, not exclusively Space.
Be focused on aiding a team to develop new data oriented software that tracks and maintains knowledge of entities across the globe.
Help design the database that will be the core of this application.
Aid the team in data management and querying.
Construct displays to show the stored data and analytics on it.
Clearly communicate ideas and collaborate with their team and others.

Typically has 9 - 15 years of professional experience.

To promote the sharing of ideas, Lockheed Martin fosters an inclusive work environment that encourages differences and big-picture thinking.

Here Are Some Of The Benefits You Can Enjoy

Our employees play an active role in strengthening the quality of life where we live and work by volunteering more than 850,000 hours annually.

Medical
Dental
401k
Paid time off
Work/life balance
Career development
Mentorship opportunities
Rewards & recognition

Learn more about Lockheed Martin’s competitive and comprehensive benefits package.

Basic Qualifications

Proficiency with languages/tools such as SQL, Java, and/or GIT
Database experience with SQL (e.g. PostGreSql, AWS RDS, etc.)
Experience with relational/structured database design/development
Proficiency with data visualization tools (e.g. ELK, Tableau, etc.)
Experience with agile development practices

Desired Skills

Experience with data security, data access methods, and authentication protocols
Experience with continuous integration and development tools (e.g. Jenkins, GitLab CI/CD, Travis)
Experience in creating real time data analytics

Job.Qualifications

BASIC QUALIFICATIONS:

Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.

As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.

Experience Level

Experienced Professional
Show more Show less"
2813123289,Data Engineer,Butter Payments,2021-11-25,United States,"San Francisco, CA",Information Technology,Full-time,IT Services and IT Consulting,"This position can be based in San Francisco or Remote.

Butter is building the payments stack for the modern subscription economy. We're creating an inclusive remote-first culture that enables our employees to contribute from anywhere in the world. Come join our team to help modernize subscription payments!

Tldr

You're our data handler. You make sure our data shows up on time, arrives in good condition and leaves the party when appropriate.

Problem TLDR

Dirty data gets in the way of reporting, machine learning models and our general sanity.

Problem Expanded

We ingest 3rd-party data from multiple payment providers, such as Stripe, clean it and normalize it for our schema and machine learning pipelines. We're seeking to build transformation and validation layers as far upstream as possible to ensure a smooth flow of data through our system. The transformation layer will make the data easier to work with for our reporting products and ML models, while the validation layer will ensure the data conforms to our expectations. For example: Is it null, NULL, or 'null'? Is 342 a valid country abbreviation code?

As we expand our product offering and ingest data from additional companies and 3rd-party providers the complexity of the challenge will evolve over time, keeping the problem fresh.

Scope

You'll get to architect our system and lay the foundation for the future from both a technology and a system design perspective. No longer will data show up without being tested and structured, as you'll create a system that checks its worst tendencies. You'll work closely with our ML and Eng team to ensure the design meets their requirements and that data properly flows through the system.

Areas You're Comfortable With

You'll have 3+ years experience and be familiar with distributed systems and data processing frameworks such as Scala and Spark and workflow orchestration tools like Argo and Airflow. You've worked in a cloud environment such as AWS, GCP or Azure. Yes, other languages/tools are fine as long as you can articulate how you've used the technology to solve similar problems.

Designing a data system from scratch is something that excites you and you're able to clearly articulate the tradeoffs of different approaches. You've likely built some version of this before, validated data, created reports and perhaps dabbled in an ML model or too.

Philosophies

You strongly believe that action creates information.

You want to work on a small team and have lots of responsibility.

You look forward to being scrappy and enjoy overcoming challenges.

We are focused on building a diverse and inclusive workforce. If you’re excited about this role, but do not meet 100% of the qualifications listed above, we encourage you to apply.

Butter Payments is an Equal Opportunity Employer and considers applicants for employment without regard to race, color, religion, sex, orientation, national origin, age, disability, genetics or any other basis forbidden under federal, state, or local law. Atomic considers all qualified applicants in accordance with the San Francisco Fair Chance Ordinance.

Please review our CCPA policies here.

This role can be performed remotely anywhere in the United States with the exception of Colorado.
Show more Show less"
2826035428,Data Engineer,Ascent Services Group,2021-12-03,United States,"Denver, CO",Information Technology,Contract,"IT Services and IT Consulting, Financial Services, and Hospitals and Health Care","Job Req #: 21-13058

Job Description: Data Engineer

Location: Remote.

Job Type: Contract-to-hire or Direct Hire

Key Responsibilities And Qualifications

Functional and proficient SQL development
NoSQL (mongo database)
SQL (MySQL, MS SQL Server) - Native Replication services in both DBS engines.
AWS Kinesis, AWS Firehose, AWS Data Migration Services, AWS Athena
Data Warehouse, Data Mart, and Data Lake architectural patterns
ETL, shaping, and model development of universal data sets across the enterprise from n number of upstream transactional systems.
Data governance program concepts. Ability to function on a team defining, building, executing, and advocating for data governance across the enterprise and multiple internal stakeholder groups.
Python (as option but not mandate)
AWS Cloud (RDS, EC2)
Tableau BI and BI concepts => familiar with supporting KPI development across disparate and 'separate' internal stakeholder customer groups with an eye for generating common data domain metrics.
Comfort or experience working in close collaboration with Data Science / Data Analytic team members building datasets, shaping, data frame, and data related solutions. Measuring, tuning, calibrating data driven solutions. Validating progressive data driven solutions along stated product roadmaps.
Comfortable working on distributed teams with distributed team members.
Comfortable working on large data sets (300+ Gigs a day)
Comfortable working in close collaboration with DevOps and Back end Engineering teams in a joint application development environment.
Predicative modeling, algorithmic based solution development
Articulate, honest, humble, highly collaborative, self starter and collective ownership of outcome attitude.
Principled and willing to learn.
Excellent team member (band of brothers/sisters). Customer focused.

Diane Douglas

Senior Technical Recruiter

303-521-7100

About Ascent

The Ascent Services Group (ASG) is a nationally recognized technology staffing and consulting firm whose fundamental business is providing staffing services to Small, Medium, and Large Enterprise clients in our core market verticals: Financial Services, Healthcare, Technology and Life Sciences. As consultants for ASG, you will have access to many of the top clients within the industries we serve. Our goal is to deliver innovative talent through proven best practices and effective resource optimization. Become one of ASG's candidates and experience the difference!
Show more Show less"
2796568043,Data Engineer,Abbott,2021-11-12,United States,"Chicago, IL",Information Technology,Full-time,Hospitals and Health Care,"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals, and branded generic medicines. Our 109,000 colleagues serve people in more than 160 countries.

Our location in Chicago, IL, currently has an opportunity for a Data Engineer. This role will assist in development of data platforms, business solutions, and proof of concept to assist the big data team in realizing business goals.

What You’ll Do
Demonstrate high degree of analytic agility to meet fluid and dynamic business needs
Use data engineering techniques to design and build solutions/ products for analyzing large data sets and identify patterns and relationships
Create, deploy and optimize large scale data
Assist in rapid development of new data and analytics prototypes
Explore data sources to better understand the availability and quality of data.
Document available data sources and how they are being transformed.
Embrace an environment that supports innovation and process improvement
Manage data sources, organize data and create data assets using identified open source or proprietary tools
Work closely with SMEs, functional experts in Commercial, R&D, finance, etc. for building data pipeline from structure and unstructured data sources
Assist with scoping, pricing, architecting, and selling large project engagements
Hands on experience leading large-scale global data warehousing and analytics projects.
Work on newest tools and technologies to achieve results - Scala, Scalding, Spark, Hadoop
Mentor Jr Data Engineers in their day to day activity.
Part of the centralized team responsible for building and managing advanced analytics products/ solutions in Abbott
Works under direction of managers, manages activities per milestones and completes tasks assigned by supervisor(s)

Required

EDUCATION AND EXPERIENCE YOU’LL BRING

Bachelor’s degree in any of the following – Math, Physics, Computer Science, Statistics, Economics, Quantitative Sciences
5-6 years’ experience covering the entire software lifecycle in a team-oriented environment.
Strong problem-solving skills
Experience manipulating and analyzing complex, high-volume data from varying sources
Experience in any data analytics solution component from AWS and Microsoft Azure.
Experience with Python, R, Spark, hive, HBase, Hadoop, Kafka, YARN etc.
Programming skills in one of Python, Scala, Golang or Nodejs is desired.

Preferred

Spark knowledge
Attention to detail and organization/ documentation skills
Ability to prioritize and triage deadline-driven tasks in a high-pressure environment
Ability to communicate complex quantitative analysis in a clear, precise, actionable manner
The candidate must possess good oral and written communication skills.

What We Offer

At Abbott, you can have a good job that can grow into a great career. We offer:

Training and career development, with onboarding programs for new employees and tuition assistance
Financial security through competitive compensation, incentives and retirement plans
Health care and well-being programs including medical, dental, vision, wellness and occupational health programs
Paid time off
401(k) retirement savings with a generous company match
The stability of a company with a record of strong financial performance and history of being actively involved in local communities

Learn more about our benefits that add real value to your life to help you live fully: www.abbottbenefits.com

Follow your career aspirations to Abbott for diverse opportunities with a company that provides the growth and strength to build your future. Abbott is an Equal Opportunity Employer, committed to employee diversity.

Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.
Show more Show less"
2797254529,Data Engineer - 2021 (United States),Amazon,2021-11-18,United States,"Bellevue, WA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Do you enjoy problem-solving and using data to analyze information on a grand scale? Are you passionate about manipulating data to tackle complex internal and external customer problems and improve business results? Do you want to be a part of a fast-paced environment and contribute to one of the most visited sites on the Internet?

At Amazon, we hire the best minds in technology to innovate on behalf of our customers. The intense focus we have on our customers is why we are one of the world’s most beloved brands – customer obsession is part of our company DNA. Data engineers use cutting-edge technology to solve complex problems and get to see the impact of their work first-hand.

The challenges data engineers solve for at Amazon are big and impact millions of customers, sellers, and products around the world. Our path is not always simple, so we are selective about who joins us on this journey. There is a certain kind of person who takes on this role at Amazon – someone who is excited by the idea of creating new products, features, and services from scratch while managing ambiguity and the pace of a company whose ship cycles are measured in weeks, not years.

Come chart your own path at Amazon.

Note: By applying to this position, your application will be considered for all locations we hire for in the United States including but not limited to: Seattle/Bellevue, WA, Nashville, TN; Austin, TX; Greater Bay Area, CA; DC Metro Area; Denver, CO; Detroit, MI; Greater Boston Area, MA; Greater Denver Area, CO; Greater Los Angeles Area, CA; Greater New York Area; Irvine, CA; Madison, WI; Minneapolis, MN; Phoenix, AZ; Portland, OR; San Diego, CA. To qualify, applicants should have earned a Bachelor’s or Master’s degree within the last six months (at time of application) or be on track to earn their Bachelor’s or Master’s degree prior to the role start date.

Responsibilities

As a data engineer, you will/may:

Design, implement, and automate deployment of our distributed system for collecting and processing log events from multiple sources
Design data schema and operate internal data warehouses and SQL/NoSQL database systems
Own the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions
Monitor and troubleshoot operational or data issues in the data pipelines
Drive architectural plans and implementation for future data storage, reporting, and analytic solutions
Work collaboratively with business analysts, data scientists, and other internal partners to identify opportunities/problems
Provide assistance to the team with troubleshooting, researching the root cause, and thoroughly resolving defects in the event of a problem


Basic Qualifications

Currently enrolled in or will receive a Bachelor’s or Master’s Degree in math/statistics/engineering or other equivalent quantitative discipline at time of application (or graduated less than six months prior to application)
Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)
Experience with one or more scripting language (e.g., Python, KornShell)
Experience with data mining, data warehouse solutions, and ETL

Preferred Qualifications

Previous technical internship(s)
Master’s or advance technical degree
Experience with several query languages, schema definition languages, and scripting languages
Experience in writing and optimizing SQL queries in a business environment with large-scale, complex datasets
Experience with data visualization software (e.g., AWS QuickSight or Tableau) or open-source project
Experience with big data processing technology (e.g., Hadoop or ApacheSpark), data warehouse technical architecture, infrastructure components, ETL, and reporting/analytic tools and environments
Ability to deal with ambiguity in a fast-paced environment

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, ethnicity, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.


Company - Amazon.com Services LLC

Job ID: A1676477
Show more Show less"
2820750160,Big Data Engineer,Nisum,2021-12-03,United States,"San Jose, CA",Engineering and Information Technology,Full-time,IT Services and IT Consulting,"Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto “ Building Success Together® ,” Nisum has grown to over 1,400 professionals across the United States, Chile, India, and Pakistan. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today’s world, with immersive and seamless experiences across digital and physical channels.

What You’ll Do

Design, develop and implement the Kafka ecosystem by creating a framework for leveraging technologies such as Kafka Connect, KStreams/KSQL, Attunity, Schema Registry, and other streaming-oriented technology
Assist in building out the DevOps strategy for hosting and managing our SDP micro service and connector infrastructure in AWS cloud
Strong track record of design/implementing big data technologies around Apache Hadoop, Kafka streaming, No SQL, Java/J2EE and distributed computing platforms in large enterprises where scale and complexity have been tackled.
Proven experience participating in agile development projects for enterprise-level systems component design and implementation
Deep understanding and application of enterprise software design for implementation of data services and middleware.
What You Know

5+ years of experience in relevant Streaming/Queueing implementation roles
Experience in monitoring the health of Kafka cluster (data loss and data lagging) and strategy for short TTD (time to detect) of broker failure and fast TTR (time to recover)
Strong coder who can implement Kafka producers and consumers in various programming languages following the common patterns and best practices
Experience in various integration with Kakfa such as Elastic Search, Databases (RDBMS or NoSQL)
Experience in Spark stream processing is a plus
Experience in RDBMS change log streaming is a plus
Systems integration experience, including design and development of APIs, Adapters, and Connectors and Integration with Hadoop/HDFS, Real-Time Systems, Data Warehouses, and Analytics solutions.
Financial Industry experience
Education

Bachelor degree in Technical discipline; Masters preferred


Nisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace.
Show more Show less"
2789681188,"Staff Big Data Engineer, Data Modeling",App Annie,2021-12-03,United States,United States,Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","PLEASE NOTE THAT YOU CAN WORK REMOTELY BUT YOU NEED TO BE LOCATED IN PST/PDT OR MST TIME ZONE TO APPLY FOR THIS ROLE

Something About Us

App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. We are headquartered in San Francisco with 12 offices worldwide. More than 1,200 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business.

Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.

What can you tell your friends when they ask you what you do?

We’re looking for an experienced Big Data engineer who can create innovative new products in the analytics and data space. You will participate in the development that creates the world's #1 app stores analytics service. Together with the team you will build out new product features and applications using agile methodologies and open source technologies. You will work directly with Product Managers, Software Architects, and will be on the front lines of coding new and exciting analytics and data mining products. You should be passionate about what you do and excited to join an entrepreneurial start-­up.

You will be responsible for and take pride in….

As a Big Data Engineer, we will need you to be in charge of model implementation and maintenance, and to build clean, robust and maintainable data processing program that can support these projects on huge amount of data, this includes

Able to design and implement complex product components based on requirements with possible technical solutions.
Write data programs using pyspark with a commitment to maintaining high quality work while being confident in dealing with data mining challenges.
Discover any feasible new technologies lying in the Big Data ecosystem, share them to team with your professional perspectives.
Get up to speed in the machine learning domain, implementing analysis components in a distributed computing environment with instruction from Data Scientists.
Be comfortable conducting detailed discussions with Data Scientists regarding specific questions related to specific data models.
You should be a strong problem solver with proven experience in big data.

You should recognize yourself in the following…

Hands-on experience and deep knowledge of Hadoop ecosystem
Must: PySpark, Mapreduce, HDFS
Plus: Storm, Kafka
Must have 2+ years Linux environment development experience.
Proficient with programming in Python, experience in Pandas, Sklearn or Other data science and data analysis toolset is a big plus.
Having a background of data mining and machine learning domain, familiar with common algorithms and libs is a plus.
Passion for cloud computing (AWS in particular) and distributed systems.
You must be a great problem solver with the ability to dive deeply into complex problems and emerge with clear and pragmatic solutions.
Good communication, and cooperation globally.
Major in Math or Computer Science.

This Is What We Offer…

We provide a $1,000 (country equivalent) WFH allowance to set you up for remote work success.
You can work remotely from anywhere as long as you are based in the PST time zone.
Internet allowance for stable internet connection, so your video does not freeze on Zoom.
Flexible working days. We love to meet, but if you need to get your kids behind school-zoom, need to leave early to get to your band repetition or gym classes, do your thing.
90-days global passport. Work remotely from anywhere in the world for 90 days a year!
Paid leave, so long as you promise to come back!
Health and dental benefits.
An international team of talented and engaged people from different cultural backgrounds and locations.
Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!
Unlimited access to online learning platform Udemy to help you develop your skills.
Virtual initiatives and events to keep you connected with your colleagues.
Generous Employee Referral Program. Up to $10,000 for specific roles.

Yes, I want this job!
Show more Show less"
2806145247,Data Engineer,National Basketball Association (NBA),2021-11-23,United States,"Indianapolis, IN",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Summary

The Data Engineer will be involved in building and maintaining the data infrastructure for Pacers Sports & Entertainment. This role is primarily responsible for the acquisition, storage, transformation, and extraction of data for analysis across all PS&E brands.

Essential Duties And Responsibilities

Work with outside vendors to develop strategies for warehouse implementation, data acquisition, matching, archiving, and recovery
Identify, design, and implement internal process improvements to automate manual processes and optimize data delivery for reporting and analysis
Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs
Build data models and define the structure, attributes, and nomenclature of data elements
Evaluate new data sources for adherence to the organization’s quality standards and ease of integration. Maintain the integrity and cleanliness of PS&E data
Work with IT to assist in the design, implementation, and enforcement of security policies that protect systems and data from access by unauthorized users. Manage procedures for data access, protection, and backup
Other duties as assigned

Qualification Requirements

To perform this job successfully, an individual must be able to perform each duty satisfactorily. The requirements listed below are representative of the knowledge, skill and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

EDUCATION And/or EXPERIENCE

Bachelor’s degree in information science, engineering, computer science, or related field.
Entry-level experience in data engineering, data warehousing, or database administration.

Computer Skills

Experience with integrating multiple data sources and managing large data structures (data warehouse, data lake) in cloud architectures (Azure).
Previous experience using APIs, web services, and automating tasks.
Advanced working SQL knowledge and experience working with relational and non-relational databases.
Experience with visualization tools such as Tableau and PowerBI and/or working with Salesforce and Ticketmaster is a plus.
Proven ability to communicate effectively with technical and non-technical stakeholders.
Object-oriented/object function scripting language experience preferred (Python, Java, C++, Scala, R, etc.)
Knowledge of BI, analytics, AI, and machine learning.

Reasoning Ability

Ability to define problems, collect data, establish facts, and draw valid conclusions. Ability to interpret directions and technical diagrams.

Problem Solving Requirements

Ability to read, analyze, and interpret instructions and reports. Ability to write reports and correspondence with extremely high accuracy and attention to detail. Ability to effectively present information and respond to questions from all levels of the organization. Ability to communicate and sell ideas to peers and executives. Ability to create and deliver presentations to all levels of employees and upper management. Must be very well-organized and highly self-motivated. Must deal with various internal and external constituents to solve problems and deliver projects on time with accuracy, professionalism, and outstanding customer service.

Physical And Environmental Demands

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to individuals with disabilities to perform the essential functions.

While performing the duties of this job, the employee is regularly required to sit, stand, walk, reach, lift, use a telephone, use a computer, speak, hear, and write.

While performing the duties of this job, the noise level in the office environment is usually moderate and the noise level in the Fieldhouse / game environment is usually loud. The stress level may become high during certain times of the year.

We are an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, age, disability, gender identity, marital or veteran status, or any other protected class.

All applicants for full-time employment at Pacers Sports & Entertainment are required to be fully vaccinated against COVID-19 prior to commencing employment. Applicants who receive a conditional offer of employment will be required to produce proof of vaccination status prior to their first day of employment.
Show more Show less"
2801440112,Data Engineer(Remote),ASICS Digital,2021-11-16,United States,"Boston, MA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Are you looking for the opportunity to shape the future of data engineering at a fast-growing company? If you’re a Data Engineer, looking for the next challenge to help scale our production and analytics databases to handle massive volume, then the Platforms team at ASICS Digital has the role for you!

ASICS Digital creates and brings to market cutting-edge digital apps and products for the ASICS brand. With over 50 million users, we possess an incredible wealth of data rooted in fitness training, goal-setting, and how technology can contribute to a healthy lifestyle. Managing and making sense of all that data is an extraordinary challenge and opportunity.

The Data Engineer will help build, run and improve the current data engineering platform while contributing to the design and rollout of the next platform iteration. You’ll be working cross-functionally with several teams including Analytics, Product, Marketing and eCommerce. Your key focuses will be building up our data warehousing infrastructure and providing best practices for data engineering.

ASICS Digital is a division of ASICS Corporation based in Boston, Massachusetts. Our goal is to build innovative digital technologies and commerce experiences to better connect consumers to the ASICS brand. We are responsible for the continued development of innovative ecommerce solutions and other digital services that inspire people to move, get fit and stay healthy.

What You'll Do

Design, implement, maintain, and QA the data warehousing and other data engineering platforms

Contribute to the direction, tooling, and platforms that deliver data to the global business and its initiatives
Working closely with our regional and internal stakeholders; our Product, Marketing and eCommerce teams, to build out necessary data warehousing infrastructure
Own and drive data-engineering initiatives autonomously; identifying issues and providing solutions
Maintain and scale our ETL tooling process to ensure flexibility for future enhancements
Tune and implement improvements—in terms of quality, reliability, scalability, or data access—for our production data stores
Bring an analytical mindset to every conversation across the company
Provide guidance and mentorship to other team members

What You've Done

3+ years experience with Data Warehousing principles and practices
3+ years experience handling large sets of data (i.e., hundreds of millions of rows of data) and make it performant
3+ years experience developing pipelines and automation with Python & SQL
Experience with cloud based columnar data warehouse such as Snowflake (Redshift, Azure Data Warehouse, and Big Query ok as well)
Experience with relational, non-relational, and file based databases
Experience extracting data from APIs and web scraping
Experience with ETL services such as Fivetran, Stitch, Matillion
Experience with docker/containerized applications
Experience with AWS services such as EventBridge, Lambda, S3, Elastic Container Service, etc.

Nice To Have

Experience testing data integrity with automation
Exposure to the platforms, processes, and practices related to Continuous Integration and Continuous Delivery (CI/CD)
Experience working with orchestrator


Become a Part Of The ADI Community

ADI is taking active steps towards becoming a diverse, equitable, and inclusive workplace. We aim to engage in D&I work that permeates our organization and all employees are expected to be actively involved.

ADI is a strong, global community where we collaborate and care for each other.
We value a diversity of opinion, everyone’s input, and increasing the number of voices at the table.
You’ll have the opportunity to join the D&I task force, participate in affinity spaces, learn and grow on your anti-racist journey. We all need to know what anti-racist is so that everyone can talk about what it actually means.
We center our employees as full people. We don’t just accept difference, we celebrate it, support it, and thrive on it for the benefit of our employees, our products, and our community.


Equal Opportunity Employer Description

At ADI, we don’t just accept diversity— we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products, and our community. ASICS Digital is proud to be an equal opportunity workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, veteran status, or fitness level.
Show more Show less"
2807595415,Data Engineer,Activision,2021-10-31,United States,"Austin, TX",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Job Title

Data Engineer

Requisition ID

R009328

Job Description

Activision is seeking a high performing Data Engineer to the join the Corporate IT Business Intelligence team. The Data Engineer will be working closely with architects/product owners/business analysts and various functional teams to understand the data requirements and implement solutions in Google Cloud Platform.

This position will be part of the Business Intelligence team being responsible for the design and development of data pipelines to extract, transform, and load data from various internal/external data sources in varied data formats to the cloud data warehouse. The position will have opportunities to push the boundaries of new business capabilities using new google technologies including AI & ML. If you want to create amazing user experiences using the latest technologies, then this is the right job for you.

Responsibilities

Priorities can often change in a fast-paced environment like ours, so this role includes, but is not limited to, the following responsibilities

Work with architects and business partners to build out technical solutions to import data from external cloud and internal application sources, utilizing industry standards to cleanse, integrate, transform, and load this data into the cloud data warehouse
Partner with cross-functional teams to design and implement data requirements to drive organizational strategies and objectives.
Develop and support the entire data warehouse lifecycle, including requirements gathering, data profiling, design, development, testing, ongoing support and enhancements for analytics and management teams.
Design, implement & maintain ETL procedures for intake of data from both internal and cloud sources; ensure data is verified and quality is checked. ETL/ELT knowledge is required.
Create complex SQL queries, data transformation & aggregations to support analytics.
Consult with business partners, analytics teams, management, and other business analysts to clarify program objectives, determine scope, identify problems, and recommend solutions
Uses comprehensive knowledge and understanding of relational data base concepts, including data architecture, operational data stores, ETL/ELT processes, interface processes, multidimensional modeling, data warehouse concepts, master data management, and data manipulation.
Work with REST APIs to integrate third party data sources to the data warehouse
Support implemented BI solutions by working with the infrastructure teams to carry out monitoring, tuning, and performance analysis, addressing user questions regarding data integrity, and communicating functional and technical issues.
Participate in administering, maintenance, patching and upgrade of ETL/ELT and visualization tools.

Player Profile

3+ years’ experience in designing, building and operationalizing enterprise data solutions and applications using one or more of the leading cloud providers. GCP being preferred
Required experience with GCP or similar cloud tool like - Spark, Hive, Cloud DataProc, Cloud Dataflow, Apache Beam/ composer, BigQuery, Cloud PubSub, Cloud storage & Cloud Functions.
4+ years’ hands on experience working with an ELT/ETL tools for data transformation.
4+ years’ experience working in SQL using relational/columnar databases such as BigQuery, Redshift etc.
3+ years’ experience working with python and Unix scripting
2+ years’ experience working with Visualization tools like Tableau/Looker/Qlik etc.
Experience migrating applications from on-premise to cloud platforms.
Experience with data warehouse design and participated in at least 1 end to end cloud data warehouse implementation
Experience implementing data warehouse data segregation and security policies in a cloud environment.
Highly organized team player with the ability to innovate, multi-task and set priorities effectively
Self-starter with strong verbal and written communication skills
Ability to interface effectively and decisively with all infrastructure teams, various levels of management & departments.
Must have a solid understanding of BI best practices and advanced knowledge of data structures, modeling, structured query language (SQL) and data warehouse techniques.

Pluses

Experience working with Git or other cloud version control tools
Experience with ML & AI capabilities.
Experience working with and administering Tableau Server.
Experience working with cloud platforms GCP or AWS
Experience working with Java
Experience working in the entertainment or video game industries

Our World

Activision Blizzard, Inc. (NASDAQ: ATVI), is one of the world's largest and most successful interactive entertainment companies and is at the intersection of media, technology and entertainment. We are home to some of the most beloved entertainment franchises including Call of Duty®, World of Warcraft®, Overwatch®, Diablo®, Candy Crush™ and Bubble Witch™. Our combined entertainment network delights hundreds of millions of monthly active users in 196 countries, making us the largest gaming network on the planet!

Our ability to build immersive and innovate worlds is only enhanced by diverse teams working in an inclusive environment. We aspire to have a culture where everyone can thrive in order to connect and engage the world through epic entertainment. We provide a suite of benefits that promote physical, emotional and financial well-being for ‘Every World’ - we’ve got our employees covered!

The videogame industry and therefore our business is fast-paced and will continue to evolve. As such, the duties and responsibilities of this role may be changed as directed by the Company at any time to promote and support our business and relationships with industry partners.

Activision is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, protected veteran status, or any other basis protected by applicable law and will not be discriminated against on the basis of disability.

R009328
Show more Show less"
2805947529,Sr. Big Data Engineer (Analytics),App Annie,2021-12-03,United States,"California, United States",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","*YOU CAN WORK REMOTELY FROM ANY LOCATION AS LONG AS YOU ARE LOCATED IN PST/PDT OR MST TIME ZONE




Something about us

App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. More than 1,300 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business. We are a global company, headquartered in San Francisco but as a “remote” first company, we care about your results and not your location.

Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.




What can you tell your friends when they ask you what you do?




I am an experienced Big Data engineer who can create innovative new products in the analytics and data space. I participate in the development that creates the world's #1 app stores analytics service. Together with my team I build out new product features and applications using agile methodologies and open source technologies. I work directly with Product Managers, Software Architects, and I am on the front lines of coding new and exciting analytics and data mining products. I love what I do and excited to join an entrepreneurial company with a start-­up culture!




You will be responsible for and take pride in….

As a Big Data Engineer, you will be in charge of our data analysis projects and to build clean, robust and maintainable data processing program that can support these projects on huge amount of data, this includes:

Able to design and implement complex product components based on requirements with possible technical solutions.
Write data analysis and statistics programs using Pyspark with a commitment to maintaining high quality work while being confident in dealing with data mining challenges.
Discover any feasible new technologies lying in the Big Data ecosystem, share them to team with your professional perspectives.
Get up to speed in the machine learning domain, implementing analysis components in a distributed computing environment with instruction from Data Scientists.
Be comfortable conducting detailed discussions with Data Scientists regarding specific questions related to specific data models.
You should be a strong problem solver with proven experience in big data.

You should recognize yourself in the following…

Master's degree in Math or Computer Science and at least 2+ years of experience in Big Data Engineering.
Hands-on experience and deep knowledge of Hadoop ecosystem.
Knowledge and experience with PySpark, Mapreduce, HDFS, Linux, Storm, Kafka.
Proficient with programming in Python, experience in Pandas, Sklearn or Other data science and data analysis toolset is a big plus.
Having a background of data mining and machine learning domain, familiar with common algorithms and libs is a plus.
Passion for cloud computing (AWS in particular) and distributed systems.
You must be a great problem solver with the ability to dive deeply into complex problems and emerge with clear and pragmatic solutions.
Good communication, and cooperation globally.




This is what we offer…

We provide a $1,000 (country equivalent) WFH allowance to set you up for remote work success.
Remote working from anywhere in PST time zone! We are not office centric anymore and never will be.
90-days global passport. Work from anywhere in the world for 90 days a year!
Internet allowance for stable internet connection, so your video does not freeze on Zoom.
Flexible working days. We love to meet, but if you need to get your kids behind school-zoom, need to leave early to get to your band repetition or gym classes, do your thing.
Paid leave, so long as you promise to come back!
Health and dental benefits.
An international team of talented and engaged people from different cultural backgrounds and locations.
Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!
Unlimited access to online learning platform Udemy to help you develop your skills.
Virtual initiatives and events to keep you connected with your colleagues.
Generous Employee Referral Program. Up to $10,000 for specific roles.




Yes, I want this job!

Show more Show less"
2753281910,Data Engineer,Procter & Gamble,2021-09-22,United States,"Cincinnati, OH","Project Management, Design, and Information Technology",Full-time,Manufacturing,"About Procter And Gamble

P&G was founded over 180 years ago as a simple soap and candle company. Today, we’re the world’s largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We’ve spanned three centuries thanks to three simple ideas: Leadership, Innovation, and Citizenship.

The insight, innovation, and passion of talented teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.

About The Role

We are looking for a Data Engineer to help us develop data products that help Retail Team, Categories, and Market Functions deliver and activate real-time insights that drive profitable category growth with our retailers faster than ever before. You’ll work within the North American IT Market Operations Team, reporting to our Senior Director of Data and Analytics.

What You Will Be Doing

Design, develop, and support data pipelines, warehouses, data models, and reporting systems to tackle business process, user, and product opportunities
Partner with business stakeholders, upstream infrastructure platform teams, and downstream data consumers to understand data and translate business requirements into technical design of building and leveraging scalable data pipelines
Use your expertise in data engineering best practices to guide stakeholders to do the same through building proofs of concept and prototypes
Build efficient solutions on top of the Azure Stack


You Have

Qualifications

Experience with ETL in SQL and NoSQL data stores
Experience in coding languages like R and Python
Hands on experience with the Azure Stack, including computing services and data warehouses
Familiarity with a range of data engineering approaches, covering theoretical best practices and the technical applications of these methods
Familiarity with GCP and AWS cloud providers
Excellent communication skills with business intuition and ability to understand business systems, versatility and willingness to learn new technologies on the job


Bonus Points

Experience using automation best practices for CI/CD
Experience with best practices for development including query optimization, version control, code reviews, and documentation
Familiarity with end-user visualization tools like Power BI and Tableau


Our Benefits

Health Care Benefits
Paid Time Off
Wellness Programs
Retirement Plan
Flex Benefits/Flexcomp
Tuition Reimbursement
Work-Live Balance Options: Work from Home, flexible scheduling, personal leave of absence


All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status, disability status, age, sexual orientation, gender identity and expression, marital status, citizenship, HIV/AIDS status or any other legally protected factor.

Immigration sponsorship is not available for this role. As a general matter, Procter & Gamble does not sponsor candidates for nonimmigrant visas or permanent residency. However, Procter & Gamble may make exceptions on a discretionary basis. Any exceptions would be based on the Company's specific business needs at the time and place of recruitment as well as the particular qualifications of the individual.

Procter & Gamble participates in e-verify as required by law.

Qualified individuals will not be disadvantaged based on being unemployed.
Show more Show less"
2808118465,Data Engineer,Deckers Brands,2021-11-25,United States,"Denver, CO",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2753281910,Data Engineer,Procter & Gamble,2021-09-22,United States,"Cincinnati, OH","Project Management, Design, and Information Technology",Full-time,Manufacturing,"About Procter And Gamble

P&G was founded over 180 years ago as a simple soap and candle company. Today, we’re the world’s largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but meaningful ways. We’ve spanned three centuries thanks to three simple ideas: Leadership, Innovation, and Citizenship.

The insight, innovation, and passion of talented teams has helped us grow into a global company that is governed responsibly and ethically, that is open and transparent, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.

About The Role

We are looking for a Data Engineer to help us develop data products that help Retail Team, Categories, and Market Functions deliver and activate real-time insights that drive profitable category growth with our retailers faster than ever before. You’ll work within the North American IT Market Operations Team, reporting to our Senior Director of Data and Analytics.

What You Will Be Doing

Design, develop, and support data pipelines, warehouses, data models, and reporting systems to tackle business process, user, and product opportunities
Partner with business stakeholders, upstream infrastructure platform teams, and downstream data consumers to understand data and translate business requirements into technical design of building and leveraging scalable data pipelines
Use your expertise in data engineering best practices to guide stakeholders to do the same through building proofs of concept and prototypes
Build efficient solutions on top of the Azure Stack


You Have

Qualifications

Experience with ETL in SQL and NoSQL data stores
Experience in coding languages like R and Python
Hands on experience with the Azure Stack, including computing services and data warehouses
Familiarity with a range of data engineering approaches, covering theoretical best practices and the technical applications of these methods
Familiarity with GCP and AWS cloud providers
Excellent communication skills with business intuition and ability to understand business systems, versatility and willingness to learn new technologies on the job


Bonus Points

Experience using automation best practices for CI/CD
Experience with best practices for development including query optimization, version control, code reviews, and documentation
Familiarity with end-user visualization tools like Power BI and Tableau


Our Benefits

Health Care Benefits
Paid Time Off
Wellness Programs
Retirement Plan
Flex Benefits/Flexcomp
Tuition Reimbursement
Work-Live Balance Options: Work from Home, flexible scheduling, personal leave of absence


All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status, disability status, age, sexual orientation, gender identity and expression, marital status, citizenship, HIV/AIDS status or any other legally protected factor.

Immigration sponsorship is not available for this role. As a general matter, Procter & Gamble does not sponsor candidates for nonimmigrant visas or permanent residency. However, Procter & Gamble may make exceptions on a discretionary basis. Any exceptions would be based on the Company's specific business needs at the time and place of recruitment as well as the particular qualifications of the individual.

Procter & Gamble participates in e-verify as required by law.

Qualified individuals will not be disadvantaged based on being unemployed.
Show more Show less"
2808118465,Data Engineer,Deckers Brands,2021-11-25,United States,"Denver, CO",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2826866320,Data Engineer (Level 2),Lockheed Martin,2021-11-29,United States,"Fort Worth, TX",Information Technology,Full-time,Defense and Space Manufacturing,"Lockheed Martin Aeronautics. Be More Than You Can Imagine.

At Lockheed Martin Aeronautics, we're taking innovation to the next level. From designing the most advanced air vehicle to designing aircraft that defies gravity, our engineers live on the cutting edge of technology. Never have the opportunities for a technical career been so limitless.

As part of the Advanced Analytics team, you will be part of a team that has enterprise-wide responsibility for establishing consistent and predictable process execution, measuring performance and process health, and optimizing business decision-making through the use of advanced analytical models.

Specific responsibilities for this position will concentrate around developing scalable data pipelines for deployed Analytics applications:

Working with local, distributed and cloud-based technologies

Design and implement the data security required to protect and access the data

Building data pipelines that clean, transform and aggregate unorganized data into databases or data sources

Creating conceptual, logical and physical data model architecture, data extract/transform/load processes, reporting and analytics

Demonstrated ingenuity in crafting technical approach to meet business need

Collaboration with data analysts and data scientists to properly develop/scale data pipeline for business applications

A level 2 employee Typically has 2 - 5 years of professional experience.

Learn more about Lockheed Martin’s comprehensive benefits package here.

Fort Worth, TX

This position is in Fort Worth, TX Discover Fort Worth.
Show more Show less"
2808829549,Data Engineer,Even,2021-10-28,United States,"Oakland, CA",Information Technology,Full-time,Financial Services,"COVID Update - Even has begun to re-open its offices. Office use is available to anyone who the CDC has cleared to gather safely indoors without masks or social distancing. Employees may continue working from home indefinitely. Even is a Remote-Equal company. The experience of working 100% remotely feels the same as working from the office in all of the ways that matter: camaraderie, engagement, and opportunity.

The problem

More than half of American workers live paycheck-to-paycheck. Stuck in this cycle, they collectively lose over $120 billion each year on payday loans, bank overdrafts, and fees. We're trying to fix that by building new financial services that make it easier to plan ahead, pay down debt, and save. And we're doing it as a transparent, straightforward business that only profits when our members do.

The role

Data Engineers at Even build the data transformation pipelines & reporting infrastructure that serve our members and run our company. Besides writing, reviewing, and shipping code, engineers collaborate with others across the company, from product, design, and data to sales, compliance, and customer support. Data Engineers at Even are highly technical, communicative and emotionally intelligent.

What you'll do:

Building and maintain Even's data infrastructure
Develop and own Even's streaming data transformation pipeline
Manage our reporting tools
Collaborate closely with our Data Analysts
Tracking and defining metrics around performance


What you'll need:

2+ years of related experience
Self-motivated
Love working with new tech
Passion for building stable and scalable solutions


Tools we use:

Languages: Python, Golang, Typescript
Data: DBT, DMS, Redshift, PostgreSQL
Infra: GitHub, Bazel, Docker


What you'll get from us:

The chance to work on a serious problem that affects more than half the U.S. population.
A culture that gives you the time and space required to build great things.
Competitive compensation, equity, and healthcare packages.
401(k) with 50% match from Even on up to 6% of your salary.
A $5,000 annual educational stipend to invest in your learning and development.
A $500 annual stipend to use towards personal financial advice.
A $100 monthly stipend for health and wellness expenses.
A 5-year exercise window on stock options after 2 years at Even.
A flexible vacation policy and a team that understands building a company is a marathon, not a sprint.
3 months bonding leave for both birthing and non-birthing parents. An additional 1.5 months of fully paid leave for pregnancy disability.
A culture that gives you the autonomy you need to do great work, and the transparency you need to make good decisions.


Want to learn more about what we look for in a team mate? Check out this blog post written by our cofounder, Quinten Farmer.

Even is used by people of all backgrounds, and we believe the best products are built by teams that represent their users. We value unique contributions and actively welcome people of all backgrounds, experiences, and perspectives to join us at Even. We are committed to working with and providing access and reasonable accommodation to applicants with mental and/or physical disabilities. If you think you may require an accommodation for any part of the recruitment process, please send a request to: accommodations@even.com. All requests for accommodations are treated discreetly and confidentially, as practical and permitted by law.
Show more Show less"
2820895337,Big Data - Data Engineer,"Quadrant, Inc.",2021-11-30,United States,"Falls Church, VA",Information Technology,Contract,Computer Software and Computer and Network Security,"Data Engineer

Falls Church, VA, San Antonio, TX, Remote

Must

Eligible or Current Public Trust

4+ years of profession experience as a data engineer working databases, data modeling, data management, and data curation

Strong experience with Alteryx Designer

Experience with Alteryx server is a big plus

Data preparation experience using SQL or scripting languages to create ETL processes, perform data cleansing, check data integrity

Strong ETL scripting experience is a must

SQL RDBMS experience (preferably MS SQL Server)

Some expereince with PowerBI is a plus

Strong communcation skills both written and verbal

Bachelors degree in related field is required

Duties

Ideal candidate will work on the analytics team to support business intelligence reporting

Help prepare data automation and data clensing of data warehouses

work on a team supporting cybersecurity analytics and robotic process automation using your data engineering and data wrangling skills to help create the data foundation for larger projects

Quadrant, Inc. is an equal opportunity and affirmative action employer. Quadrant is committed to administering all employment and personnel actions on the basis of merit and free of discrimination based on race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or status as an individual with a disability. Consistent with this commitment, we are dedicated to the employment and advancement of qualified minorities, women, individuals with disabilities, protected veterans, persons of all ethnic backgrounds and religions according to their abilities.
Show more Show less"
2771707270,Data Engineer,Ceros,2021-12-04,United States,United States,Information Technology,Full-time,Internet Publishing,"About Ceros

Ceros is an experiential platform that empowers the creation of bespoke, immersive digital experiences without code. We’re passionate about helping companies transform their static digital content into engaging experiences. From custom microsites to immersive interactive webpages, you can build it with Ceros. Publish and update live content and instantly embed it into your site or social media platforms such as Pinterest or Snapchat. Join us and be part of the movement to enable everyone to create experiences that matter.




Our customers include some of the world’s leading brands, such as Mashable, Bloomberg, Red Bull, United Airlines, and AIG.




We are well-funded and institutionally-backed by prominent investors including Sumeru Equity Partners, Grotech Ventures, Greycroft, and Starvest Partners.




The Role

As a data engineer, you'll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.




In order to stand out as a candidate, you should express humility and patience. Data engineering is about building the underlying infrastructure, and so being able to pass the limelight to someone else is imperative. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them. Furthermore, being able to listen to your colleagues is essential.




We are looking for a person who can maintain, transform, analyze and extract valuable insights from our different data sources and make these insights available to various stakeholders across the company. We are looking for candidates with an entrepreneurial spirit that will always be looking for ways to improve our data infrastructure and make our data more accessible to the business.




Key Responsibilities

Creating and maintaining the optimal data pipeline architecture
Assembling large, complex sets of data that meet business requirements
Identifying, designing and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies
Working with stakeholders including design, product and executive teams and assisting them with data-related technical issues
Optimizing data retrieval and developing dashboards, reports and other visualizations for stakeholders
Creating and maintaining documentation about our databases and ETL processes
Optimizing our data infrastructure for performance, scalability, security and redundancy
Developing insights and evangelizing the value of our data to other stakeholders




Practical stuff we anticipate you having

Excellent communication skills to interface with multiple departments and stakeholders
Experience building and maintaining data infrastructure utilizing infrastructure as code (IaC) principles and technologies.
Experience deriving insights through the use of predictive analytics and/or machine learning techniques
Excellent knowledge of both SQL and NoSQL database technologies and their pros and cons
Deep knowledge of SQL and database design
At least 3 years experience as a data engineer or in a similar role
Knowledge of programming languages (e.g. Javascript and Python)
Experience with ETL tools such as Matillion and AWS DMS.
Experience with business intelligence (BI) and visualization tools (e.g. Metabase, Looker, Tableau, etc..)
Experience with data-related cloud services (e.g. Redshift, Aurora, S3, Glue, DMS)
Experience maintaining and working with Elasticsearch




What we’re looking for from the heart

Be a self-starter and operate with an entrepreneurial spirit
Identify things that need to be done and get them done
Identify opportunities to help Ceros scale and implement them
An eagerness to learn. We’re looking for engineers who are able and eager to keep up with the pace of our rapidly evolving field




Key Things to Know

We want you to start ASAP
This is a full-time position
This is a remote first role with the ability to work on east coast time; travel periodically to our NY offices and team meetups




Benefits

Competitive salary
Stock options
Premium health insurance
401K match
Paid parental leave
Unlimited vacation days
Wellness Fridays (Half Day Fridays)
Excellent gear (Macbook Air, external monitor, etc.)
Stipend for WFH set-up
Growth and learning opportunities
Virtual experiences in which Cerosians can collaborate, educate, and create social connections with one another

At Ceros, we are deeply committed to the recruitment, retention, and growth of diverse talent; uniting people from unique backgrounds in our shared passion for unlocking creativity through technology.

As an equal opportunity employer, we prohibit any unlawful discrimination against a job applicant on the basis of their race, color, religion, veteran status, parental status, gender identity or expression, transgender status, sexual orientation, national origin, age, disability or genetic information. We respect the laws enforced by the EEOC and are dedicated to going above and beyond in fostering diversity across our company.

Show more Show less"
2820810520,Data Engineer,Cognizant,2021-11-30,United States,"Tampa, FL",Information Technology,Full-time,IT Services and IT Consulting and Management Consulting,"Not Applicable

Qualification

Not Applicable

Responsibility

Not Applicable

Must Have Skills

Apache Hadoop

Employee Status : Full Time Employee

Shift : Day Job

Job Posting : Nov 30 2021

About Cognizant

Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.

Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.

Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.
Show more Show less"
2818846409,Data Engineer,Purple Drive Technologies,2021-12-03,United States,"Dallas, TX",,Full-time,,"·        5 years of relevant experience

·        Python, SQL, Spark, Py-Spark, Spark SQL, Spark Streaming, Relational/SQL,

·        Experience with NoSql(Cassandra or MongoDB), HDPF, Hbase, Map Reduce, Kafka

·         4+ years proven experience in developing and deploying data pipelines, preferably in the Cloud; Azure and Snowflake experience is a plus.

·        2+ years of proven expertise in creating pipelines for real time integration.

·        Proven experience with Spark SQL, Spark Streaming and using Core Spark API to explore Spark features to build data pipelines.

·        2 years of experience with at least one programming language like Python, Java, or Scala




Show more Show less"
2826020010,Big Data Engineer,Robert Half,2021-11-08,United States,"King of Prussia, PA",Engineering and Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Financial Services","Description

Robert Half Technology is seeking a Data Engineer for a client based out of the King of Prussia, PA area. This role will be 100% Remote for the foreseeable future. For consideration, please contact Abigail Fox - (267) 996-3437

Responsibilities Include

Contribute to the end-to-end analytics vision for raw data ingestion to analytics solution
Create re-usable, trustworthy and accessible data products within Snowflake for use in Data Analytics and Data Science solutions (using dbt and various data sources crm, erp, entitlement, product usage)
Building / Maintaining analytics layer of snowflake providing an environment where data products can be integrated with each other and support various analytics solutions
Provide transparent documentation on data transformations and technical processes
Collaborate with Data Analysts and Data Scientists in the creation of data products to align with business needs
Integrate and productionize data science models alongside data science resources
Identify gaps in data collection and propose solutions to solve
Work with data analysts / scientists and data owners to better understand business problems and propose enhancements to how data is being used / processed to meet needs
Stay up to date with latest technologies and snowflake / dbt / github product direction and capabilities. Maintain a working knowledge of data mining and visualization best practices.

Requirements

Microsoft SQL, Snowflake, Data Analytics

Technology Doesn't Change the World, People Do.®

Robert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.

Robert Half puts you in the best position to succeed by advocating on your behalf and promoting you to employers. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity – even on the go. Download the Robert Half app and get 1-tap apply, instant notifications for AI-matched jobs, and more.

Questions? Call your local office at 1.888.490.4429. All applicants applying for U.S. job openings must be legally authorized to work in the United States. Benefits are available to contract/temporary professionals. Visit

© 2021 Robert Half. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to
Show more Show less"
2817265167,Technology Engineer (Data Engineer),PNC,2021-11-28,United States,United States,Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Banking, and Financial Services","Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. We work together each day to foster an inclusive workplace culture where all of our employees feel respected, valued and have an opportunity to contribute to the company’s success.

As a Technology Engineer (Data Engineer) for PNC's Security Analytics Hub, you will have the opportunity to work fully remote. Our team focuses on producing data driven insights into multiple areas of risk facing the bank, including cybersecurity and physical security.

Day To Day Responsibilities

Acquire/map datasets that align with our business partner needs
Develop algorithms that shape data into useful and actionable information
Build, test, and maintain database pipeline architectures
Collaborate with management to understand and meet company objectives
Form new data validation methodologies and data analysis tools
Ensure continued compliance with data security policies and governance

Technical Qualifications

Education: BS/BA in technical discipline
5+ years of Python development
5+ years of experience with development/decomposition of complex SQL (RDMS Platforms)
3+ years of experience with test-driven development. Continuous Integration/ Development (e.g. GIT, Jenkins, Maven)
3+ years with CRON/Shell Scripting
Experience with utilization of REST API and/or EDPI
Hands on experience with project management tools such as JIRA, Confluence
Ability to work with end users (BI analysts, data scientists, etc.) to solve technical issues
Experience working in an Agile Team construct
Extensive knowledge of databases, data warehouses, systems integrations, and data flows is mandatory for this role.
Additionally, candidates should be well-versed in data architecture, data development, with a proven history of providing effective data solutions.

Required Skills To Be Considered For This Role

Coding: Proficiency in coding languages is essential to this role. Common programming languages used by the team include SQL, Python.
Relational and non-relational databases: You should be familiar with both relational and non-relational databases, and how they work (Teradata, Oracle, etc).
ETL (extract, transform, and load) systems: Moving data from databases and other sources into a single repository, like a data warehouse.
Data storage knowledge: As solutions are designed, when to use a data lake versus a data warehouse, for example.
Automation and scripting. Candidate should be able to write scripts to automate repetitive tasks (e.g. Cron jobs, Linux, shell scripting).
Big data tools: Understanding of Hadoop, MongoDB, and Kafka helpful, but not required.
Data security: Securely managing and storing data to protect it from loss or theft per PNC guidelines.

Job Description

Leverages technical knowledge and industry experience to design, build and maintain technology solutions. Assists with selecting appropriate platforms, integrates and configures solutions.
Develops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.
May provide consultation on common issues and best practices for junior staff.
Provides a systematic analysis on client requirements within the traceability framework and resolves any functional problems encountered.
Ensures quality of project deliverables while maintaining compliance with relevant standards and processes.

PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:

Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.

Competencies

Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.

Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.

Effectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.

Emerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.

Industry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.

IT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).

IT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.

Planning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.

Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Work Experience

Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

Education

Bachelors

Additional Job Description

COMPENSATION

Base Salary

$55,000 to $142,600

Role

Placement within the compensation range is based on the specific role and the following factors

Where a person is paid in the compensation range is aligned to their experience and skills.

– Lower in range –Building skills and experience in the job

– Within the range–Experience and skills align with proficiency in the role

– Higher in range –Experience and skills add value above typical requirements of the role

– Compensation Range may vary based on Geographic Location

INCENTIVE

Role is incentive eligible with the payment based upon company, business and individual performance.

Benefits

PNC offers employees a comprehensive range of benefits to help meet your needs now and in the future. Depending on your eligibility, options for full-time employees include medical/prescription drug coverage (with a Health Savings Account feature); dental and vision options; employee and spouse/child life insurance; short- and long-term disability protection; maternity and parental leave; paid holidays, vacation days and occasional absence time; 401(k), pension and stock purchase plans; dependent care reimbursement account; back-up child/elder care; adoption assistance; educational assistance and a robust wellness program with financial incentives. To learn more about these and other programs, including benefits for part-time employees, visit pncbenefits.com > New to PNC.

Disability Accommodations Statement

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.

The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO)

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.

California Residents

Refer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.
Show more Show less"
2798282178,Princ. Big Data Engineer,"Plume Design, Inc",2021-10-19,United States,"Palo Alto, CA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Summary:

Plume is a fast growing unicorn startup that develops and deploys cloud based control planes with scale to manage tens of millions of customer homes through some of the world's largest Internet Service Providers. Our smart home services and experiences include WiFi network management and optimization, online protection, IoT security, motion detection, and end customer user interaction through mobile apps. We serve the consumer home market via our B2B and B2C product offerings.

To manage the explosive growth in data and applications, and power our Business Intelligence and Data products, we are building a world class team for our Enterprise Data Warehouse initiative.

The Opportunity:

As a Principal Data Engineer at Plume, you will focus on providing actionable insights and build highly available resilient systems that will impact and help make business decisions. You will ensure that the platform we are delivering will meet both ours and our customers' reliability and scalability expectations.

What you will do:

Interact with business stakeholders to understand and analyze BI requirements and design and document updates to dimensional model and schemas to support desired queries
Understand available sources of data and design, implement, validate, deploy, manage, tune and monitor data pipelines to deliver the target schemas to the performance and quality spec.
Adhere to data protection requirements including data access, retention, residency and de-identification.
Create data validation checks and scripts to ensure high data quality and availability.
Be responsive in triaging and fixing any issues related to production data quality and availability.
Mentor and assist junior team members and new hires to become successful and productive.
Build infrastructure and abstractions that can enable anyone (engineer or data scientist) to craft scalable pipelines for whatever the purpose is: metrics, analysis, machine learning, dashboard visualizations


Who you are:
BA/BS in Computer Science, Information Systems or a related technical field with 6+ years of industry experience. Alternately, MS in Computer Science, Information Systems or a related technical field with 3+ year of industry experience.
Experienced: 6+ years building, scaling, tuning, managing and supporting production ETL pipelines for multiple terabytes of data.
Prolific Programmer - 3+ years of Scala or Java.
Technology Framework Expert - in a variety of data infrastructures, such as:
Batch processing: Apache Spark
Messaging: Kafka, Zookeeper, Pulsar
Storage: Hive, Mongo DB, Athena, Cassandra, PostgreSQL
A technical leader: you make intuitive decisions about what services, frameworks, and capabilities need to be in place before they are needed.
Self Driven - able to own a project from inception to completion
Mentor - open and active in sharing knowledge as well as excellent communication skills
SQL Savvy - able to query and discover data with SQL
Show more Show less"
2600119850,Big Data Engineer,Amazon Web Services (AWS),2021-12-04,United States,"Dallas, TX","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

AWS World Wide Revenue Ops is seeking a Big Data Engineer to join our Business Performance Management team, building a new Sales Revenue data solution. Our vision is to collect and process billions of usage and billing transactions every single day and relate it to the largest data feed supported by Salesforce.com. We apply business logic to transform to this raw data to generate the daily and monthly Sales Revenue utilized for daily and monthly AWS Sales Revenue reporting and the processing of quarterly Sales Commissions for AWS Sales on Incentive plans.

We are truly leading the way to disrupt the big data industry. We are accomplishing this vision by bringing to bear Big Data technologies like Elastic Map Reduce (EMR) in addition to data warehouse technologies like Spectrum to build a data platform capable of scaling with the ever-increasing volume of data produced by AWS services.

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build ETL to ingest the data into the data lake. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

Location: This role open to these locations: Seattle & Dallas. Relocation offered from within the US to any of these locations.

Inclusive Team Culture
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have twelve employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.


Basic Qualifications

This position requires a Bachelor's Degree in Computer Science or a related technical field, and 5+ years of meaningful employment experience.
5+ years of work experience with ETL, Data Modeling, and Data Architecture.
Expert-level skills in writing and optimizing SQL.
Experience with Big Data technologies such as Hive/Spark.
Proficiency in one of the scripting languages - python, ruby, linux or similar.
Experience operating very large data warehouses or data lakes.

Preferred Qualifications

Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
Experience with building data pipelines and applications to stream and process datasets at low latency.
Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
Knowledge of Engineering and Operational Excellence using standard methodologies.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role

/*AWS WWRO Galaxi Data Platform*/

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon Web Services, Inc.
Job ID: A1588981
Show more Show less"
2824298405,DATA ENGINEER,Axiom Consulting Partners,2021-12-02,United States,"Chicago, IL",,Full-time,,"Axiom Consulting Partners help clients grow and transform their businesses by ensuring their workforce and operating model remains aligned with changing market conditions. We use our expertise in behavioral and data science to set strategic direction and improve how our clients operate in order to achieve their goals. We are looking for data and analytics-savvy professionals to join our Chicago-based team of consultants who have proven Data Analytics and Engineering expertise and have some experience working with other data analysts and project-based resources. This role is client-facing and requires close collaboration with Axiom team members to break down, tease apart and solve complex business and people problems.




Primary Responsibilities

Work with the Axiom team to develop hypotheses that diagnose business problems or opportunities, and then create the analytical work plan to test them
Create and manage highly structured data requests that acquire the right information in the right format to execute on the analytical work plan
Serve as lead point of contact with the client and be accountable for all matters related to data acquisition, cleaning, integration, management, transformation, interpretation, and analytics
Work with Power BI or Tableau to present and visualize new insights or reveal complex relationships between variables in a clear, accurate, and compelling manner that supports evolving ideation
Lead discussions internally around the relationship between different data elements to add to the Axiom team’s knowledge, awareness, clarity, and depth in addressing the client situation and potential solutions
Develop and provide meaningful insights and relevant points-of-view on complex concepts directly to clients through simple, plainspoken materials
Contribute to leading-edge thinking that deepens the Firm’s capabilities in data science and engineering and differentiates Axiom in the market




Required Qualifications & Experiences

Ideally bachelor’s degree in computer science, mathematics, engineering or related field but we are open to considering professionals that have taken a non-linear path to building skills called out in this posting
At least two years of experience working with data to solve tough problems for clients or internal teams
Experience communicating directly with clients (internal or external) to effect change
Passion for learning and a track record of keeping up to date on technologies, platforms, and tools
Some travel may be required




Required Knowledge, Skills & Capabilities

Business acumen
Teamwork and collaboration
Critical thinking and ideation
Project management
Experience with and ability to work with:




1) Production databases (e.g., SQL Server)

2) Python (preferable) or R

3) Business Intelligence tools (e.g., Power BI, Tableau)




Preferred Knowledge, Skills & Capabilities

Working knowledge of Azure
Experience with one or more programming languages
Experience managing databases in the cloud (as well as AWS)
Working knowledge of data transformation tools (e.g., Alteryx)
Experience operationalizing data pipelines to support analytics in a production environment
Coursework or qualification in Machine Learning




You will need to pass a remote assessment on data structure and manipulation using SQL before we initiate the interview process.




Please Note

We are unable to consider any applicants without US citizenship or a green card at this time. The position will be located in our Chicago office but we expect a hybrid working arrangement will make most sense for you and us.

Show more Show less"
2796472445,Data Engineer,The Hartford,2021-10-18,United States,"Charlotte, NC",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

Join a fast-paced and talented Agile Scrum team to unlock Data Capabilities for The Hartford. You will have an opportunity to participate in the entire software development lifecycle process in support of continuous DATA delivery, while growing your knowledge with emerging technologies. We use the latest DATA technologies, software engineering practices, Agile delivery framework, and are passionate about technology and building well architected and innovative solutions that drive optimal business value generation. This cutting edge and forward focused team presents the opportunity for collaboration, self-organization within the Scrum Team and visibility as we focus on continuous Business data delivery.

What’s in it for you?

Experience deeper understanding of Data analysis, Emerging technologies and Development practices.
Collaboration with a high-performing, forward-focused team, Product Owner(s) and Business stakeholder(s) engagement.
Opportunity to expand your communication, analytical, interpersonal, and organization capabilities.
Experience working in a fast paced environment – driving business outcomes in Agile ways of working.
Enable and influence the timely and successful delivery of business data capabilities and/or technology objectives.
Enhance your entrepreneurial mindset – network opportunity and influencing outcomes. Appreciation and opportunity to learn and support rapid software construction and deployment using a mix of technologies.
Supporting environment that fosters can-do attitude and opportunity for growth and advancement based on consistent demonstrative performance.
Optimize business value by leveraging your DATA experience and depth. Be part of a Scrum Team – driving work independently or collaboratively towards achieving business outcomes.
Experience in working with IT offshore vendor partners.
Ability to collaborate daily alongside our senior investment professionals to develop technology driven solutions which will deliver a competitive advantage to EDO.
Strong ability to estimate project tasks and to deliver upon committed dates. Ability to develop and maintain systems according to a defined set of standards.
Act as a mentor for colleagues.

Qualifications

Bachelor degree with at least 4 years of applicable work experience.
Desired educational experience include, but are not limited to: Computer Science, Engineering, IT, Management Information Systems, Data Analytics, Applied Mathematics, and Business.
Experience with prior Data Engineer/ETL competencies and prior experience with successful enablement of Data Delivery initiatives.
Understanding of current and emerging IT products, services, processes and methodologies.
Experience in the following disciplines is required: SQL, Oracle, PL/SQL, Talend (or similar ETL Technology), Autosys, data warehousing architecture, and data modeling, Cloud technologies - AWS, Snowflake.
Certifications in the following is preferred(not mandatory) - AWS Cloud practitioner, SnowPro Core certified.

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$90,480 - $135,720

Benefits

Our company’s success is due to our employees’ dedication and passion for their work. They are our greatest asset. That’s why we are committed to offering employees and their families a comprehensive benefits package and award-winning well-being programs. By helping our employees achieve their full potential, we unlock our own. Visit https://www.thehartford.com/careers/benefits for details.

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

Data Engineer - GE08AE
Show more Show less"
2808115810,Data Engineer,Deckers Brands,2021-11-25,United States,"San Jose, CA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2819413047,Data Engineer,Robin Healthcare,2021-11-30,United States,"Berkeley, CA",Information Technology,Full-time,"Computer Software, Financial Services, and Hospitals and Health Care","Robin Healthcare is a tech-healthcare startup with a mission to transform our healthcare system from its very core: the doctor-patient encounter. We marry medical scribing with the Robin Assistant™, our proprietary smart device, to help streamline documentation, coding, and other administrative tasks in the background of natural patient care.

Why:

The purpose of this role in the short term is to prototype and build out the data sets, reports, KPIs and dashboards to operate Robin's business on the new Assist platform, with an explicit goal to democratize Robin's most widely-used data for teams outside the Data Science & Analytics group to consume. In the longer-term, this role will be responsible for analysis, insights, reports, and actionable recommendations for the most challenging business problems at Robin. This role will also provide strong technical guidance to other data analysts in the Data Science & Analytics group.

What You'll Be Doing:

Use data, logic, and intuition to improve business outcomes through analysis, insights, reports, and actionable recommendations
Develop democratized dashboards, data sets, and KPIs that empower less technical owners and operators across the business to make data-driven business decisions
Design durable and forward-looking data models and data sets for the Data Science & Analytics group to develop on and provide technical direction to other analysts
Partner with Product Management, Engineering, and Creative to condense feedback from users & customers, explore & experiment to (in)validate hypotheses, and measure the outcomes of product initiatives
Partner with Client Success and account managers to build creative tools and insights to increase provider and practice satisfaction, grow revenue, and communicate performance to our customers
Partner with Operations, Talent Acquisition, and Content to create diagnostic metrics and reveal opportunities to increase the satisfaction, efficiency, and performance of our scribe population


What You'll Bring:

Adept at distilling complicated analytical concepts to broad audiences and influencing decision making through compelling data narratives
Experience building clean visualizations and performant dashboards using Jupyter, Tableau, Looker, or similar software
Experience writing performant code in BigQuery SQL
Expert programming skills in one or more general purpose languages (Python, R, Scala, etc.)
Experience with statistical and machine learning methods to build descriptive and predictive models
Familiarity writing production ETL using data technologies that allow analysis of large amounts of data (Spark, Hadoop, Hive, Presto, etc)
Familiarity with a variety of business domains and their common data and analytics needs


Graduate-level degree or equivalent proven experience in a quantitative field such as mathematics, statistics, engineering or natural sciences

What We Offer

Amazing Mission - Break new ground in a stable, well-funded company and fix a broken healthcare system
Barrier Free Culture- No Micro-Management!! We Remove Bureaucracy and Empower Our People
Decide How and When You Work
100% Remote Work Environment OR WeWork Space Of Your Choice
Your Choice of Laptop (PC or Mac) and Home Office Setup Stipend
Flexible Schedule- Build Your Work Around Your Life
Generous Stock Options
Unlimited Vacation Time (Must Take At Least 2 Weeks and Shut Off Your Phone)
Great Benefits - Medical, Dental, Vision, Life, Disability, 401k, etc.
Paid Family Leave (Up To 16 Weeks)
Investment Into Your Career With Resourcing For Education And Development
Close, Fun, And Engaging Community
Work With Brilliant, Hard-Working, Caring People Daily
Netflix Watch Parties, Pilates/Yoga classes, Clubs & Social Events


Equal Opportunity Employer: Successful applicants must be eligible to work in the US (visa sponsorship is not provided at this time) and must be able to pass a pre-employment background test. Robin Healthcare is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

To request reasonable accommodation or if you need assistance to complete the job application, contact hiring@robinhealthcare.com
Show more Show less"
2803976452,"Big Data Engineer, AmazonBot",Amazon,2021-11-23,United States,"Sunnyvale, CA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

DESCRIPTION

The Web consists of trillions pages from billions of domains. Our mission is to automatically identify ""the needles in the haystack:"" the small subset of high-value Web data that we can leverage to make Alexa smarter. Frugality, innovation, and scale are par for the course.

Why should you join the Alexa team? Here are a few reasons:

We ship software frequently, get fast feedback from real customers around the globe, and see the results of our work come to fruition.

There are real-world problems to solve that you won’t find ready-made answers for. For example, how do you process massive data in the least time possible. How can you improve Alexa to to answer more questions?

We look for ways to make the our service configurable, maintainable and visible as easy, intuitive and time efficient as possible.

Key job responsibilities

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with customer teams to understand data requirements, and to build ETL to ingest and export data at scale. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to create necessary data flows. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

About The Team

Our team tries to have a healthy balance between work and play. We celebrate our successes and milestones and we are not afraid to take risks, even if it causes unintentional mistakes along the way. We believe in learning from our mistakes and moving forward.

Location: This role can be fully remote or open to these office locations: Sunnyvale, Manhattan Beach or Seattle.


Basic Qualifications

3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL
This position requires a Bachelor's Degree in Computer Science or a related technical field, and 5+ years of meaningful employment experience.
5+ years of work experience with ETL, Data Modeling, and Data Architecture.
Expert-level skills in writing and optimizing SQL.
Experience with Big Data technologies such as Hive/Spark.
Proficiency in one of the scripting languages - python, linux or similar.
Experience operating very large data warehouses or data lakes.

Preferred Qualifications

Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
Experience with building data pipelines and applications to stream and process datasets at low latency.
Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
Knowledge of Engineering and Operational Excellence using standard methodologies.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon.com Services LLC

Job ID: A1694695
Show more Show less"
2818442223,Data Engineer,IBM,2021-12-01,United States,"Baton Rouge, LA",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

The position of the Data Engineer plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. The Data Engineer defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business. Develops applications on Big Data and Cognitive technologies including API development. Expected to have traditional Application Development background along with knowledge of Analytics libraries, open-source Natural Language Processing, statistical and big data computing libraries. Strong technical abilities to understand, design, write and debug complex code.

The role of the Data Analyst is to work directly with the client using Pyspark,Scala, Hadoop, Hive and Postgre SQL. The Data Analyst must possess an understanding of the relational databases. The Data Analyst must also possess the skills to effectively collaborate with the client Subject Matter Experts (SMEs) to provide necessary solutions.

This position requires relocation to Louisiana within 30 days of the office reopening. This position requires up to 50% travel. This is not a permanent work from home position.

sprgg21

Required Technical and Professional Expertise


2 years + experience with JavaScript, Java, or other object-oriented programming languages.
Hands-on experience and understanding of object-oriented programming, data structures, algorithms, profiling & optimization (stacks, queues, linked lists, hash tables, trees, arrays, common algorithms, iteration and recursion, etc.)
2 years + coding challenge experiences including LeetCode and Hackerrank, etc.


Minimum 3 – 5 years relevant experience as: Should have a strong knowledge on Pyspark, Scala, Hadoop,Hive and Postgre SQL

Preferred Technical And Professional Expertise

Unless specified as a Required Skill, the following are additionally preferred but not required:


Experience with big data solutions such as Hadoop, MapReduce, Hive, Pig, Kafka, Storm etc. is a major plus.
Experience in Node.JS, Database, REST, Event Source, Web Sockets, HTML5, CSS3, RWD, JQuery is highly desirable.


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.


Show more Show less"
2801075632,Big Data Engineer(remote),HireResources,2021-11-16,United States,"Portland, OR",Engineering and Information Technology,Full-time,"Appliances, Electrical, and Electronics Manufacturing, Computer Software, and Staffing and Recruiting","Job Title PySpark Data Engineer

Duration Full Time

Location Remote

REMOTE work is available for the right candidate
Candidate should have a Bachelor's degree with a minimum of 3 years of extensive experience in designing, building, and deployment of PySpark-based applications
He / She should have expertise in handling complex large-scale Big Data environments preferably (20Tb+)
Candidate should have a minimum 3 years of experience in the following: HIVE, YARN, HDFS preferably on Hortonworks Data Platform
He / She should have good implementation experience of OOPS concepts
Candidate should have hands-on experience writing complex SQL queries, exporting, and importing large amounts of data using utilities
You should have experience in generating / parsing XML, JSON documents, and REST API request / response

HireResources recruiters are not generalists; they are specialists in their industries providing quick access to industry top talent in select industry sectors. We speak your language and understand the factors critical to your business. Each HireResources Sector Team has a specialized target recruitment function. In fact, if we do not have expertise in your industry, we will let you know this upfront.

HireResources was established in 2002, in 2015 we began a growth phase by restructuring our core business, today, HireResources is a fast-growing Staffing & Recruitment platform headquartered in Connecticut. HireResources is an open source staffing and recruiting model giving flexibility and support to top executive recruiters across the country. HireResources recruiters are thoroughly vetted and are proven professionals in the recruiting industry.
Show more Show less"
2802894438,Data Engineer,2U,2021-11-17,United States,"Cambridge, MA",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","What We’re Looking For

We accept applications from remote employees in the following US states: CO, CT, ME, NH, NJ, NY and VT.

Data Engineering has built a best in class data platform leveraging tools such as snowflake, dbt_ and prefect. Now that the foundations have been laid the team is beginning to look toward what is next; and evolving our foundation to climb to the next rung of the analytics maturity model.

edX is looking to add a Data Engineer to set their vision on that next rung and to help us climb.

Your work will enable the Data group to evolve, automate and scale and impact edXers across the company as we keep the data flowing and enable edX to continue to mature as a data-driven organization - and achieve our potential to transform education for learners globally.

The Data Engineering (DE) team’s work lies at the foundation of all that edX does. The accurate, timely and usable data that DE provides to the organization drives business reporting and decision-making, product innovation, customer-facing data offerings and more.

Data Engineering works alongside data analysts and scientists, product engineering, and business stakeholders across the organization to provide the data platform and technical solutions that enable edX to drive value from its data. If you are looking to make an outsized impact on an organization, Data Engineering at edX is the place for you.

Responsibilities Include, But Are Not Limited To

Maintain and help improve Data Engineering’s best in class infrastructure
Be relentless in your distaste for toil; automating and removing processes and systems that are no longer serving their purpose
Build automation and tooling to help data move fast, we strive for idempotent, reproducible systems and results
Be data driven in your work, instrumenting the tools Data Engineering builds and tuning system performance
Rapidly diagnose and resolve faults with data services and pipelines as a member of an on-call rotation - ensuring the data flows throughout our ecosystem smoothly
Collaborate with peers in and out of the Data team to troubleshoot and propose and document solutions
Proactively communicate issues, status or roadblocks
Help optimize alerting, data processes and on-call rotations to reduce fatigue and improve efficiency of our operations

Things That Should Be In Your Background

Experience in a dev-ops or site reliability engineering role or
Experience building efficient data pipelines, performance tuning, and integrating disparate data sources and types, including high volume semi-structured and unstructured data (e.g., JSON, etc.)
Understanding of cloud-based data warehousing and ELT/ETL techniques and processes
Experience working in AWS systems
Experience working in Python
Collaborative and pragmatic, with and enthusiasm for learning and continuous improvement

Other Attributes That Will Help You In This Role

Experience with Snowflake and dbt_ (https://www.getdbt.com/)
Experience with pipeline data pipeline tools such as Prefect, Luigi or Airflow
Experience with or a desire to learn about Terraform and Kubernetes.
Experience master data management, data modeling and preparing data for analysis
Enthusiasm for Agile/Scrum processes

About EdX

edX is the education movement for restless learners. Together with our founding partners Harvard and MIT, we’ve brought together more than 38 million learners, the majority of top-ranked universities in the world, and industry-leading companies onto one online learning platform that supports learners at every stage. And we’re not stopping there—as a global nonprofit, we’re relentlessly pursuing our vision of a world where every learner can access education to unlock their potential, without the barriers of cost or location.

About 2U, Inc. (NASDAQ: TWOU)

2U is comprised of 3 lines of business: Graduate Degree Programs, Short Course, and Boot Camps. Going beyond traditional learning management systems, we use tech, people, and data to help top universities and enterprise organizations transform in the digital era—and eliminate the back row in higher ed. We support lifelong learning which means thinking beyond a single degree. It means finding ways for students to gain the skills they need to change careers, evolve their expertise, and meet the challenges of the changing world head-on. We help our partners fill those needs—developing new digital education technologies and offerings capable of supporting students at different points in their lives. Whether they need a simple refresher, to learn something new, or to change their career trajectories completely, our partners are there to help them succeed. Together with our partners, 2U has positively transformed the lives of more than 275,000 students and lifelong learners.

2U Diversity and Inclusion Statement

At 2U, we are committed to creating and sustaining a culture that embodies diverse walks of life, ideas, genders, ages, races, cultures, sexual orientations, abilities and other unique qualities of our employees. We strive to offer a workplace where every employee feels empowered by the ways in which we are different, as well as the ways in which we are the same.

Benefits & Culture

Working at 2U means working with individuals that are passionate and mission driven. We collaborate on tough problems to deliver the best outcomes for our partners, students, and each other. You will find team members working together in our open office spaces, gathered in the kitchen grabbing a snack, or taking a break in our game rooms.

2U Offers a Comprehensive Benefits Package

Medical, dental, and vision coverage
Life insurance, disability and 401(k)
Unlimited snacks and drinks
Generous paid leave policies including unlimited PTO
Additional time off benefits include: volunteer days, parental leave, and a company-wide winter break

In Colorado, the anticipated base salary for this role is $100,000.00 with potential bonus. Note: The final compensation for this position may consider factors including the geographic location where the work is performed (candidate’s assigned office) and prior work experience of the candidate.

To learn more, visit 2U.com. #NoBackRow

Note: The above statements are intended to describe the general nature and level of work performed by individuals assigned to this position, and are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required. All employees may be required to perform duties outside of their normal responsibilities from time to time, as needed.

2U is an equal opportunity employer that does not discriminate against applicants or employees and ensures equal employment opportunity for all persons regardless of their race, creed, color, religion, sex, sexual orientation, gender identity, pregnancy, national origin, age, marital status, disability, citizenship, military or veterans’ status, or any other classifications protected by applicable federal, state or local laws. 2U’s equal opportunity policy applies to all terms and conditions of employment, including but not limited to recruiting, hiring, training, promotion, job benefits and pay.
Show more Show less"
2820745690,Big Data Engineer E1579,Nisum,2021-12-03,United States,"San Jose, CA",Engineering and Information Technology,Full-time,IT Services and IT Consulting,"Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto “ Building Success Together® ,” Nisum has grown to over 1,400 professionals across the United States, Chile, India, and Pakistan. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today’s world, with immersive and seamless experiences across digital and physical channels.

What You Know

Must be Strong in JAVA/SCALA programming
C/Python experience is a plus
Big Data Experience – 4+ years experience.
AWS Experience is a must – EMR, S3, Cloud Watch, Lambda, Step Functions
Good communication skills to work with various stakeholders on operational support work
Education

Bachelors degree is a must.


Nisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace.
Show more Show less"
2816520392,Data Engineer,Zemantics Inc.,2021-12-02,United States,United States,,Contract,,"Please review the JD before you Apply and make a note on below required skills which are Must.

Visa Status : OPT, H4 EAD, GC and USC are eligible.

W2 Only Please




Must haves:

• Python

• Pyspark

• Spark

• Hadoop

• GCP

• Big query

• Data proc




Show more Show less"
2758162917,Data Engineer,Skechers,2021-12-02,United States,"Manhattan Beach, CA",Information Technology,Full-time,"Apparel and Fashion, Retail, and Luxury Goods and Jewelry","Company Description

Join the thousands of innovators, advocates and forces who are making an impact every day at one of the biggest footwear brands in the world. Whether you love to connect with consumers on the retail floor or want to drive our award-winning powerhouse in new directions, the SKECHERS team is the place to be. Learn more about our brand at skx.com.

Job Description

We are looking for a Data Engineer with both conceptual and hands-on experience working on structured/semi structured/Complex data processing RDBMS and NoSQL data stores. As a member of our Data Services team you will be a member of a service group responsible for continuing organizational expansion of our data processing projects. Ideal candidate must be enthused about all spectrum of data development, including data transport, data processing, data warehouse/ETL integration, quick learning and self-starting. This is a demanding role that will require hands-on experience with data processing development to be deployed on Linux. You will be responsible for the day to day operation and new developments. We are seeking a candidate with good skills in software development life cycle. This position includes 24x7 production support.

Responsibilities

Design, implement and deliver successful data solutions.
Implement defined data pipeline requirements for the underlying data lake, data warehouse and data marts.
Involved in the design and implementation of full cycle of data services, from data ingestion, data processing, ETL to data delivery for reporting .
Identify, troubleshoot and resolve production data integrity and performance issues.
Design, develop and support various data platform applications
Design and develop applications to process large amounts of critical information in batch and near real-time to power business insights.

Qualifications

Experience in managed services for data ingestion/processing with hands on experience working in AWS environment.
A solid understanding of NoSQL data stores with extensive experience in working with SQL
Proven experience of distributed systems driving large-scale data processing and analytics
Experience working with SAAS Data Warehouse Snowflake (Preferred) / Redshift
Working experience with CDC tools such as Qlik replicate / Debezium
Experience with Linux KSH/bash scripting
Experience working with any one of ETL toolset: Talend
Comfortable programming in Python / Java or Scala or similar programming languages
Experience with DevOps process and have used GitHub, Jenkins and JFrog

PLUS

Experience in Apache Kafka, the Confluent platform.
Experience with the following data processing technologies: Spark, Kafka, Kinesis
Experience with Presto, Hive, Impala or similar SQL based engine for Big Data

Work Experience

3+ years of experience defining, designing and delivering data pipelines and solutions
3+ years of experience working with Linux based operating systems
3+ years relevant experience developing and integrating frameworks and database technologies that support highly scalable data processing
2+ years of programming experience with Python / Java
At least 2 years of experience working within cloud environments, preferably AWS
2+ year experience with cloud-based data warehousing systems (e.g. Snowflake / Redshift)
Proficient in any flavor of SQL
Demonstrable ability in data modeling, ETL development, data warehousing, batch, and real time data processing
Demonstrable experience with Stream Processing and workload management for data transformation, augmentation, analysis, etc.

JOB-RELATED EDUCATION

B.S. in Computer Science, Computer Information Systems, Engineering, or another technical field, or equivalent work experience

Additional Information

PHYSICAL DEMANDS

While performing the duties of this job, the employee is regularly required to stand; use hands to finger, handle, or feel, and talk or hear. The employee frequently is required to walk, sit, reach with hands and arms, stoop, and kneel. The employee is occasionally required to sit for long period of times.

All your information will be kept confidential according to EEO guidelines.


Show more Show less"
2816392248,Big Data Engineer - Security Data Service,bp,2021-11-30,United States,"Houston, TX","Information Technology, Consulting, and Engineering",Full-time,"Computer Software, Computer and Network Security, and Oil and Gas","At bp, we’re reimagining energy for people and our planet. With operations working across almost every part of the energy system, we’re leading the way in reducing carbon emissions and developing more sustainable methods for solving the energy challenge.

We’re a diverse team of engineers, scientists, traders and business professionals determined to find answers to problems that must be solved. But we know we can’t do it alone. We’re looking for people who share our passion for reinvention to bring a new point of view, collaborative spirit, and to challenge our thinking in our ambition to achieve net zero!




Role Synopsis

The goal of the Security Data Service is to empower its customers to understand and improve the security posture of BP by providing a consolidated, easy to use data platform for reporting and analytics

We are looking for an someone who understands data security data and comes with strong technical expertise in Big Data, who is interested in joining our team to create and manage our data infrastructure and tools, including collecting, storing, processing and analyzing a range of security data and data systems.




As a key member of this team, you will be working as part of the small empowered, customer-centric agile squad to deliver a consolidated and easy to use data platform for reporting and analytics.




Key Accountabilities

Collect and process raw data at scale for a variety of projects and initiatives.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Build ingestion pipelines and ETL jobs to consume data feeds from security source systems (e.g. Azure feeds, O365, AD, Syslog, APIs).
Designing and implementing Continuous Integration / Continuous Delivery (CI/CD) solution using BP standards for the squad.
Creation and managing of data pipelines, transformation, and efficient storage.
Build monitoring and alerting mechanisms for data pipelines and transformations.
Managing infrastructure for Big Data and data pipelines.
Build flexible data solutions that support the ingestion, or the consumption needs of our data lake and its customers.
You will be a pivotal member of the squad and can shape and support the success of this service.




Essential Education

Focus on experience rather than education.
General understanding of Azure data engineering concepts.
AWS Foundational knowledge.




Essential Experience & job Requirements:

Working knowledge of developing using the Azure analytics components including Data Lake, Power BI, Data Factory, Azure Data Explorer, Azure Synapse, Data Warehouse, and Data Bricks.
General understanding of Agile and DevOps development methodology and concepts as applied to data driven analytics projects. Including CI/CD Coding, security testing best practice and standards.
Experience in DevOps in Azure cloud environments.
Experience with designing, building, and operating analytics solutions using Azure cloud and server-less technologies.
Data Management experience e.g. data profiling, large volume data handling.
Experience in automated data driven testing.
General knowledge of scripting Languages such as Python, Scala, or PowerShell (at least one of them).
General knowledge of database programming including relational (SQL, Maria) and nonrelational (NoSQL, MongoDB, Cassandra) databases.




Desirable Criteria & Qualifications

Experience with security related data sets.
Object Oriented Programming knowledge is a plus.
General understanding of Machine Learning Models.




Why join us

At bp, we support our people to learn and grow in a diverse and challenging environment. We believe that our team is strengthened by diversity. We are committed to fostering an inclusive environment in which everyone is respected and treated fairly.

There are many aspects of our employees’ lives that are important, so we offer benefits to enable your work to fit with your life. These benefits can include flexible working options, a generous paid parental leave policy, and excellent retirement benefits, among others!

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Show more Show less"
2801728062,Data Engineer,Fooda,2021-11-16,United States,"Chicago, IL",Information Technology,Full-time,Food and Beverage Services,"Who We Are:

We believe a workplace food program is something employees should love and look forward to every day. Powered by technology and a network of over 2,000 restaurants, Fooda feeds hungry people at work through our ongoing food programs located within companies and office buildings. Every day, each Fooda location is served by different restaurants that come onsite and serve fresh lunch from their chef’s unique menus. Fooda operates in over 20 major US cities and plans to continue its expansion across the United States.




Who We Are:

We believe a workplace food program is something employees should love and look forward to every day. Powered by technology and a network of over 2,000 restaurants, Fooda feeds hungry people at work through our ongoing food programs located within companies and office buildings. Every day, each Fooda location is served by different restaurants that come onsite and serve fresh lunch from their chef’s unique menus. Fooda operates in over 20 major US cities and plans for continued expansion.




About the Team:

Our Data Science & Analytics team is changing the way Fooda uses data. Do you want to get in on the ground floor of an analytics team at a high growth startup? The company has placed a huge strategic focus on building out our data science and analytics capabilities and you will be core to this growth. The team is responsible for all reporting & analytics for the company partnering closely with Product, Engineering, Sales, Marketing, Finance, and Operations to drive innovative analytic solutions.

Will you join us?




POSITION OPPORTUNITIES AND RESPONSIBILITIES:

As a Data Engineer, you will work on the Data Science and Analytics team to drive and evolve the analytics solutions and data systems at Fooda. You will contribute to analytics decision making, analysis, and data integration to enable Fooda to become a world-class data driven organization.




RESPONSIBILITIES:




Leverage Python and SQL to integrate and analyze data from internal and external systems that drive key business decisions throughout the organization
Govern, analyze, and own data that drives stakeholders’ perception of the organization, which involves diving in, addressing questions, and perform root cause analysis of issues that arise within the data
Develop ETL pipelines and data quality auditing systems using Airflow, Python, and SQL to create a cohesive, automated, and accurate data environment
Assist in requirements gathering, design, and development of complex data systems that collect, analyze, and measure data throughout all business units




BASIC QUALIFICATIONS:

2+ years of experience working in data engineering, business intelligence, or engineering
Experience analyzing and integrating data using Python and SQL to extract and transform data according to business rules and requirements
Extensive knowledge and experience working with large scale data warehouse, web APIs, and database platforms to integrate internal and external data sources
Attention to detail and the ability to think critically and solve problems using analytical and quantitative methodologies
Strong oral/written communication skills, specifically the ability to communicate and translate difficult analytical problems to stakeholders with minimal analytics background
Ability to work effectively in a high paced environment




PREFERRED QUALIFICATIONS

Bachelor’s Degree in a quantitative field such as Information Systems, Computer Science, Statistics, or Mathematics
Demonstrated ability to manage complex technical projects: work prioritization, planning, task delegation and hitting deadlines
Experience with programing/scripting languages and data science tools (Airflow, Python, Java, Spark)
Experience diving into data quality and data profiling analysis to ensure data consistency and accuracy across enterprise reporting
Experience with AWS tools and infrastructure to build and maintain a robust data warehouse

The safety and wellbeing of our employees and customers is a top priority. Fooda has a COVID-19 vaccination policy requiring all employees to be vaccinated against the disease. All hired candidates are required to submit proof of vaccination as a condition of employment. Fooda will consider accommodations for disability- or religious-based reasons.

Show more Show less"
2820374709,Data Engineer,VeeAR Projects Inc.,2021-12-03,United States,"Menlo Park, CA",,Contract,,"Job Description
Data Engineer, Client Responsibilities
Manage data warehouse plans for a business vertical or a group of business verticals
Build data expertise and own data quality for allocated areas of ownership
Design, build, optimize, launch and support new and existing data models and analytical solutions
Partner with internal stakeholders to understand business requirements, work with cross-functional data and products teams and build efficient and scalable data solutions
Conduct design and code reviews
Work with data infrastructure to triage infra issues and drive to resolution
Manage the delivery of high impact dashboards, tools and data visualizations

Minimum Qualifications
BS/B.Tech./M.Tech in Computer Science, Math or related field
5+ years of experience in the data warehouse space, custom ETL design, implementation and maintenance
5+ years of experience in SQL or similar languages, and development experience in Python
Experience with data architecture, data modeling, schema design and software development
Experience in leading data driven projects from definition through interpretation and execution
Experience with large data sets, Hadoop, and data visualization tools
Experience initiating and driving projects, and communicating data warehouse plans to internal clients/stakeholders

Preferred Qualifications
Experience working in support of diverse communities
Show more Show less"
2803449075,Jr. Data Engineer,IBM,2021-11-21,United States,"Lansing, MI",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

The position of the Data Engineer plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. The Data Engineer defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business. Develops applications on Big Data and Cognitive technologies including API development. Expected to have traditional Application Development background along with knowledge of Analytics libraries, open-source Natural Language Processing, statistical and big data computing libraries. Strong technical abilities to understand, design, write and debug complex code.

The successful candidates for these positions may be based anywhere in MICHIGAN and will work collaboratively with the Client Innovation Team. While this is not a fully remote role, work on-site at the IBM Client Innovation Center in Lansing MI is expected to be minimal with a focus on Team Meetings, Collaboration and Client Visits. It’s anticipated that a Michigan resource would typically spend an average 2-3 days/month on-site at the Center. Additionally, some travel is expected, and all candidates must be willing and able to travel to meet our client needs across the US. Travel is typically related to knowledge transfer and training at the client site (Monday thru Friday). You may need to travel up to 50% of the time post-Covid depending on individual project needs.

Required Technical and Professional Expertise


2 years experience with JavaScript, Java, or other object-oriented programming languages.
Hands-on experience and understanding of object-oriented programming, data structures, algorithms, profiling & optimization (stacks, queues, linked lists, hash tables, trees, arrays, common algorithms, iteration and recursion, etc.)
2 years coding challenge experiences including LeetCode and Hackerrank, etc.


Preferred Technical And Professional Expertise

Unless specified as a Required Skill, the following are additionally preferred but not required:


Experience with big data solutions such as Hadoop, MapReduce, Hive, Pig, Kafka, Storm etc. is a major plus.
Experience in Node.JS, Database, REST, Event Source, Web Sockets, HTML5, CSS3, RWD, JQuery is highly desirable.


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2826718079,Analytics Engineer,Acquia,2021-11-09,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Chase passion. Pursue wellness. Be the best part of our customers’ day. These are some of the core values we hold at Widen, and why we’ve repeatedly been voted one of Madison's Best Places to Work since 2015. Established in 1948, we build high-performing software that empowers organizations to create impactful, meaningful, and measurable brand experiences. Embracing innovation and change, we’ve evolved from a small engraving business to a global software company by putting our customers at the forefront of all we do. Headquartered in Madison, Wisconsin, USA, and London, UK, Widen is a family-owned business with over 70 years of growth driven by unparalleled service and fueled by a community of 660+ customers. Let's flourish, together.

Summary

The Analytics Engineer is a crucial, connective role on our data team that works with analysts, data engineers, and our internal operational teams. This position will gain an understanding of our current data landscape as well as our gaps and goals, and collaborate with others to build data-focused models and solutions that will scale with the growth of our business. The Analytics Engineer also evangelizes the use of data and data quality and hygiene when prioritizing a scalable, reliable, and usable set of data systems.

Essential Duties

Develop and maintain a deep understanding of Widen’s data sources and their purposes
Transform, enrich, and model raw data to enable analysis and visualization
Build and maintain highly performant and functional data models within our BI platform
Collaborate with data team members on data requests and analysis projects
Work with internal teams to understand analytics and metrics needs and to proactively identify and fill gaps in existing data collections
Build and maintain data quality tests and documentation with our data catalog
Advocate for improvements to data quality and performance
Assist in building and maintaining data acquisition tools and pipelines
Assist in creating and maintaining visualizations and dashboards for internal use
Prioritize diversity, equity, and inclusion in your every day work to create an environment of respect
Protect the confidentiality, integrity, and availability (CIA) of Widen and customer information held, in any form
Other duties, as assigned

Essential Qualifications

Advanced SQL experience
Strong data analysis skills and experience
Proficiency in one or more programming language (Python, Java, R etc)
Proficiency visualizing data in one or more BI platforms
Experience with one or more cloud-based data warehouse (e.g., Redshift, Snowflake)
Ability to communicate effectively with stakeholders to define needs and goals

Desired Qualifications

Experience using dbt
Python experience
Experience using a source code repository system (preferably Git/Github)
Experience writing automated data tests and software unit tests

Employees have the option to work remotely, from the Madison office, or a mix of both. Access to the office and other amenities are available to all employees — no matter their chosen work setup — to keep teams safe, healthy, and connected in the interim.

Widen is an equal opportunity (EEO) employer. We hire without regard to age, color, disability, gender (including gender identity), marital status, national origin, race, religion, sex, sexual orientation, veteran status, or any other status protected by applicable law.
Show more Show less"
2823968812,Data Analytics Engineer,Ookla,2021-11-07,United States,"Seattle, WA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","At Ookla, our mission is to help make the internet better, faster and more accessible for everyone. Globally, millions of users perform tests across the Speedtest and Downdetector ecosystem each day, which allows us to track internet performance and outages in real time.

We’re looking for a data analytics engineer to join our unique and highly-collaborative team. Your primary focus will be developing the tools and processes that enable data scientists and analysts to accurately, consistently, and reproducibly describe mobile and fixed internet performance in new and meaningful ways.

For this role, a strong understanding of R use, development, and deployment is necessary (tidyverse, shiny, plumber). Successful applicants will have an inquisitive nature, a creative approach to solving problems, excellent communication skills, and a strong drive for data advocacy. We’re especially interested in candidates who also have experience with broadband networking technologies, cloud computing, and developing reproducible software. We typically use tools like R, Redshift, Python, and Spark for our daily work.

We are people first, employees second at Ookla, and we know there is no one perfect path to any job. If you’re excited about the work we’re doing and think you would offer a creative new perspective, please apply whether or not your experience matches the job description. We strongly believe diversity of all kinds makes us better. We are an equal opportunity employer actively working to build an inclusive workforce at all levels of the company. [Read our latest diversity report here].

Responsibilities

Lead development of internal tools, packages, and documentation
Work closely with data engineers and data QA to ensure data quality
Mentor teammates and help them develop new skills


Requirements

R language expertise and experience building R packages and services (shiny, plumber)
SQL expertise, and experience building complex queries against large data sets
Experience with Python
Familiarity with data orchestration (Apache Airflow), data transformation/testing (dbt), and distributed processing (Apache Spark)
Proven history of exceptional customer service and advocacy
Experience with internet, cellular, and broadband technology and infrastructure is a plus


Benefits

People come first at Ookla. We offer competitive compensation, flexible schedules, transit passes, on- and off-site happy hours, team activities, lunch on Wednesdays and an office kitchen full of snacks. Our comprehensive benefits package includes 401(k) matching, unlimited paid vacation and sick time, ESPP options, health/dental insurance coverage and a stand-out parental leave. We make sure you have the best hardware, software and tools available for you to do your work, and we provide excellent flexibility for working remotely as time and responsibilities allow. Visit [our Built In Seattle page] for even more information.

Location

This is a remote/office based position which may be performed anywhere in the United States except for within the state of Colorado.
Show more Show less"
2825809726,Data Engineer | Data & AI,"Concurrency, Inc.",2021-12-03,United States,"Brookfield, WI",Information Technology,Full-time,IT Services and IT Consulting,"Who We Are

We are change agents. We are inspired technologists. We are unlike any other technology consulting firm. Our team fearlessly challenges the status quo, relentlessly pursues what’s next, and pushes the limits of what’s possible. A Microsoft Gold Partner and multiple-time Partner of the Year award recipient, Concurrency is renowned for its ability to turn unmatched technology expertise into client outcomes. Have we inspired the technologist in you? Come be a change agent at Concurrency.

Who We’re Looking For

We’re excited to add a Data Engineer to our Data & AI team. In this role, you’ll work with a team of customer-focused professionals who are committed to defining technical strategy, architecting, designing, and delivering end-to-end digital transformation. You’ll demonstrate strong technical competence and business acumen through engaging in senior-level technology decision-making discussions related to agility, business value, data warehousing, and cloud-oriented data solutions. You’ll empower other consultants by sharing subject matter expertise in large enterprise implementations, as well as overseeing the delivery of large, complex, and strategic projects for enterprise customers.

What You’ll Do

Lead requirements and design sessions with customer and internal teams
Author functional requirements and technical design documentation
Work with functional teams to plan project sprints, scope and resource allocation
Manage project milestones to ensure successful solution delivery and customer satisfaction
Research and evangelize modern data solutions and new technologies
Work with the solution team to help set standard architectures, processes, and best practices
Develop and maintain strong working relationships with key partners and vendors
Promote service offerings through blogs posts, industry groups, and speaking events


What You’ll Need

Bachelor's Degree in Computer Science, Information Technology, Business Analytics or Computer Engineering
3 years of experience providing Microsoft solutions, platforms or technologies to enterprise level customers
Eligible to work in the United States without sponsorship
1-3 years of experience with Azure Databricks, Azure Data Platform, Data Modeling (Tabular), Power BI, SQL Server and T-SQL Development


What Will Set You Apart

Azure Synapse experience
Machine Learning languages such as R or Python
IoT experience
Prior experience in a professional services organization
Spark experience
Strong technical documentation skills


Encouraging a healthy work/life balance and providing our colleagues great benefits are just part of what makes Concurrency a great place to work. Concurrency full-time employees receive complete and competitive benefits. We offer a collaborative work environment, competitive compensation, generous work/life opportunities and a comprehensive benefits package that includes paid time off plus holidays. In addition, all colleagues are eligible for a number of rewards and recognition programs, excellent training program and bonus opportunities.
Show more Show less"
2732474781,Data Engineer,Cloudflare,2021-12-03,United States,"Austin, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer and Network Security, and Internet Publishing","About Us

At Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world’s largest networks that powers approximately 25 million Internet properties, for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine’s Top Company Cultures list and ranked among the World’s Most Innovative Companies by Fast Company.

We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!

About The Team

The Business Intelligence team at Cloudflare is responsible for building a centralized cloud data lake and an analytics platform that enables our internal Business Partners and Product teams with actionable insights and also provides a 360 view of our business. Our goal is to democratize data, support Cloudflare’s critical business needs, provide reporting and analytics via self-service tools to fuel existing and new business critical initiatives.

About the role We are looking for an experienced Data Engineer to join our Austin team to scale our data platform and product insights initiatives by building self-service data products. You will work with a wide array of data sources to build integrated data pipelines that process billions of records each day and influence our critical business initiatives.

Success in this role comes from marrying a strong data engineering background with product and business acumen to deliver scalable data pipelines and analytics solutions that can enable advanced analytics via a self-service user interface.

What You'll Do

Design, implement and support end to end scalable data pipelines for multiple data products
Work closely with a cross-functional team of data scientists and analysts and internal stakeholders on strategic initiatives
Design backend database schemas and the APIs
Contribute in improving an evolving data platform for scalability, observability and reliability
Integrate internal web applications with other SaaS applications used by Go to market functions
Build rich data sets that drive innovation in data driven insights at scale within the company

Examples Of Desirable Skills, Knowledge And Experience

B.S. or M.S in Computer Science, Statistics, Mathematics, or other quantitative fields preferred
3+ years of industry experience in software engineering, data engineering, data science or related field with a track record of building scalable data pipelines and APIs
Strong command in writing advanced SQL queries
Solid understanding of big data technologies such as Spark, BigQuery, Kafka etc.
Hands-on programming experience with Python, Go or any JVM based programming language
Knowledge of data management fundamentals and data storage/computing principles
Experience in designing and integrating RESTful APIs
Strong communication skills

Bonus Points

Full stack software development experience, a strong plus
Experience with React JS is a plus
Familiarity with container based deployments such as Docker & Kubernetes
Familiarity with Google Cloud Platform or something similar

What Makes Cloudflare Special?

We’re not just a highly ambitious, large-scale technology company. We’re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.

Project Galileo : We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare’s enterprise customers--at no cost.

Athenian Project : We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.

Path Forward Partnership : Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.

1.1.1.1 : We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here’s the deal - we don’t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.

Sound like something you’d like to be a part of? We’d love to hear from you!

This position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.

Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA/Veterans/Disabled Employer.

Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.
Show more Show less"
2787820794,DevOps/ Big Data Engineer,M3,2021-11-10,United States,"Lawrenceville, GA",Information Technology,Full-time,Computer Software,"M3 - Accounting Software and Services for the Hospitality Industry




Who are we?

M3 is a Top 150 Workplaces winner named by the Atlanta Journal Constitution! Employee-owned, family-oriented, and a great place to grow your career. Our company-wide personal commitment to both clients and employees is simple: do the right thing and invest in long-term relationships. Together, we work to provide the highest standard of financial services and technology to deliver on our mission to drive hospitality company success. M3 helps make hospitality companies successful through technology that drives financial performance. Our software is the hotel accounting software used and trusted by the biggest names in the hospitality industry. We are looking for talented professionals to join our team!




We're located in beautiful, new buildings with Headquarters in Gwinnett County, GA just off I-85 and complete with an employee gym, bright, open work spaces and games in the break room.

Compensation and Benefits:

M3 offers a strong benefits package including 75% employer paid medical, dental and vision for the employee and family; life, long and term disability, and Long Term Care insurance that the company provides free of charge; 401k with a 6% match; three weeks paid time off; discretionary profit sharing; a great culture, competitive salary. We are a certified Drug Free Workplace and Equal Opportunity Employer.

Description Summary: This position will leverage Sisense to develop, create, and manage data models for our Insight product and internal business intelligence, as well as data analysis and dashboarding based on business requirements and in partnership with stakeholders. Duties typically include providing leadership & insights, developing analytical strategies, performing analytical support and/or modeling regarding a wide array of business initiatives. This job may require application of analytical, statistical modeling, and forecasting methods as well as assisting with development of the business intelligence infrastructure. This position will lead projects/virtual teams and mentor developers. Experience in a hospitality data is a plus.




Essential Duties:

The duties listed below are the essential functions of this position, and they may change as the needs of the company demand. All associates are expected to do what is necessary to get the work done and to cooperate fully with their supervisor’s requests for additional or altered duties.

Lead development efforts on BI data models, dashboarding, and data analysis for internal use and product teams
Collaborate with Business Intelligence Lead Engineer and other development teams to build and improve ETL services, data warehousing, data management, and BI data models
Analyze data and troubleshoot issues within BI platform tied across product information sources
Execute sophisticated quantitative analyses and advanced modeling to identify data trends and recommendations using hospitality data for internal usage, as well as customer facing reports for M3 website and tradeshow content
Technically support the BI product by monitoring and troubleshooting system performance issues Identify and resolving data reporting issues in a timely fashion
Assist in and participate with product lifecycle development and feedback to product teams
Assist in the development of the business intelligence infrastructure
Create and maintain appropriate documentation
Proactively seek ways to improve existing processes and procedures
Effectively manage multiple projects and priorities
Other duties as assigned




Education/Technical Requirements

1-3 years of experience in a data engineering or business intelligence discipline
Bachelor’s Degree in computer science, Engineering, or other STEM related area, Masters preferred
Experience with popular BI tools such as Sisense, Tableau, PowerBI, Grafana, etc
Advanced proficiency programming in SQL
Experience with cloud data services, such as Azure, AWS, Snowflake, etc
Experience writing code in one or more of the following languages:
T-SQL
.NET
PowerShell
Ansible
Javascript
Python
R




Professional Requirements

Ability to solve problems autonomously with ambiguous requirements
Experience coordinating and collaborating with technical talent
Strong communication skills; comfortable presenting to C level executives
Thrives under pressure and enjoys working in a fluid environment with competing deadlines
Must relate to other people beyond giving and receiving instructions: (a) get along with co-workers or peers without exhibiting behavioral extreme; (b) perform work activities requiring negotiating, instructing, supervising, persuading or speaking with others; and (c) respond openly and appropriately to feedback regarding performance from a supervisor
Frequently must follow written and oral instructions as well as complete routine tasks independently
Experience with organizational strategies, business operations, and end-user requirements to develop system designs
Applicants must be authorized to work in the US without requiring employer sponsorship currently or in the future. M3 does not offer H-1B sponsorship for this position.
Excellent communication, leadership, change management, and coaching skills to establish and maintain positive and productive working relationships
Extensive knowledge of business processes, strategic planning, and systems architecture; Hospitality industry experience is a plus
Highly organized, motivated and solution oriented
All staff members are to promote a positive and productive work environment by acting maturely and responsibly, satisfactorily performing his or her job responsibilities and conducting themselves in a professional, courteous and respectful manner




Physical Requirements:

Ability to sit and/or stand for extended periods
Ability to perform work on a computer for extended periods
Ability to travel in representing the company’s interests required
Ability to attend work and meetings with excellent attendance and punctuality
Ability to bend and lift up to 25 lbs.
Show more Show less"
2808114822,Data Engineer,Deckers Brands,2021-11-25,United States,"Los Angeles, CA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2812976552,Data Engineer,Moonpig,2021-10-31,United States,"Portland, OR",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Our Ways Of Working

We believe that we do our best work when we are together, but also appreciate that everyone works in different ways. That’s why we operate with three working models which look to define where and how our people work - Remote, Hybrid, Site/Office - based.

Although we believe the majority of our people will choose our hybrid working model (at least 2 days in the office each week), for some of our teams that don't require as much in-person connection and collaboration, we offer fully remote working (with paid travel to the Moonpig office up to 6 times per year). Remote roles are specified directly on our job adverts

Moonpig Group achieved ‘Unicorn’ status in one of the biggest tech IPOs of 2021, making the FTSE 250 index of leading companies listed on the London Stock Exchange with a market cap of £1.5 billion. We’re now growing the team to work towards an even more ambitious goal of reaching 25 million customers.

To help get us there, we’ll be developing some cool tech innovations. Two projects we’ll bring to life this year include augmented reality/video cards and pre-personalisation; the latter aiming to provide a richer browsing experience for our customers via the automatic translation of customer data into personalised cards and gifts across multiple galleries.

But the magic does not stop there. Our architecture is built for scale and flexibility which will allow us to quickly innovate and launch new propositions -- coupling that with the wealth of data we have on our customers, the sky's the limit in the world of experimenting with cutting edge ideas.

Moonpig is a hidden gem in terms of our culture. Check out our 4.7 rating on Glassdoor as well as info about our tech culture and benefits for a view on how great it is to work here!

We are looking to hire a Senior Data Engineer on our Data Platform Team. The Data Platform team’s mission is to ensure that the right data is available to the right people so that we leverage data to best serve our customers and continue to be a truly data driven organisation. This means we collaborate with other teams to capture their data requirements and find the best way to make that data available, on a secure, stable, single source of truth that is GDPR compliant. We enable other teams to leverage the data through reporting, analytics, ad-hoc queries and machine learning.

As data engineers, we contribute to the mission by building scalable and resilient systems that automate data flows including an in-house event ingestion platform, and pipelines that support the productionising of machine learning models for batch and live inference.

You'll be a good addition to the Data Platform team if you:

Have experience building cloud/serverless applications, using .NET and Python, either with AWS or a similar cloud suite.
Have experience working with Machine Learning tools, or at least a passionate interest in machine learning and willingness to pick it up.
Enjoy being part of an engineering team, working closely with people of different specialisms across the business.
Prefer a collaborative environment, sharing knowledge through collaboration, pair programming and constructive code review.
Are willing to challenge your own ideas; to try, fail, learn and repeat - and you encourage others to do the same.


Team Tech Stack

C# .NET
Python
AWS and Terraform
Machine Learning Ops tooling (AWS Sagemaker or any other ML platform)
Orchestration tooling (Airflow or any other orchestrator)
Git VCS and GitLab CI
Snowflake and DBT
What you'll be doing:

Join a team of software engineers to build and support a data platform that will enable fellow teams to leverage our data and technology to make the gifting experience effortless.
Collaborate with our data science team to refine and maintain a machine learning platform with a large focus on machine learning operations tooling.
Work in a serverless-first environment with a strong focus on asynchronous messaging and availability at scale.
Take ownership of your code, the infrastructure it sits on, the CI/CD pipelines that test and deploy it, and the production systems that monitor it.
Enjoy excellent career development opportunities backed by individual objectives and our engineering growth framework.
Contribute to our team’s technical direction and strategy.
Want to hear more?

Take a look at our Moonpig Attraction Deck where you can hear more about our awesome perks and benefits as well as a culture to boot.

We are committed to equal employment opportunity and value diversity regardless of race, colour, religion, sex, national origin, sexual orientation, age, marital status, pregnancy, maternity, disability, or gender identity.
Show more Show less"
2788609825,Data Engineer,Anblicks,2021-11-06,United States,"Dallas, TX",,Full-time,,"Required Skills/Expertise
""
• Analyze and understand data sources & APIs
• Design and Develop methods to connect & collect data from different data sources
• Design and Develop methods to filter/cleanse the data
• Design and Develop SQL , Hive queries, APIs to extract data from the store
• Work closely with data Scientists to ensure the source data is aggregated and cleansed
• Work with product managers to understand the business objectives
• Work with cloud and data architects to define robust architecture in cloud setup pipelines and work flows
• Work with DevOps to build automated data pipelines

Total Experience Required
• 4 <years <10 of relevant experience
• The candidate should have performed client facing roles and possess excellent communication skills

Business Domain knowledge: Finance & banking systems, Fraud, Payments

Required Technical Skills
• Big Data-Hadoop, NoSQL, Hive, Apache Spark
• Python
• Java & REST
• GIT and Version Control


Desirable Technical Skills
• Familiarity with HTTP and invoking web-APIs
• Exposure to machine learning engineering
• Exposure to NLP and text processing
• Experience with pipelines, job scheduling and workflow management



Personal Skills
Experienced in managing work with distributed teams
• Experience working in SCRUM methodology
• Proven sense of high accountability and self-drive to take on and see through big challenges
• Confident, takes ownership, willingness to get the job done
• Excellent verbal communications and cross group collaboration skills
""


Show more Show less"
2792738630,Data Engineer,Capital One,2021-11-13,United States,"Cambridge, MA",Information Technology and Engineering,Full-time,"Banking, Financial Services, and Investment Banking","314 Main Street (21020), United States of America, Cambridge, Massachusetts

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. What You’ll Do: Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance Basic Qualifications: Bachelor’s Degree At least 2 years of experience in application development At least 1 year of experience in big data technologies Preferred Qualifications: 3+ years of experience in application development including Python, SQL, Scala, or Java 1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud) 2+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL) 1+ years experience working on real-time data and streaming applications 1+ years of experience with NoSQL implementation (Mongo, Cassandra) 1+ years of data warehousing experience (Redshift or Snowflake) 2+ years of experience with UNIX/Linux including basic commands and shell scripting 1+ years of experience with Agile engineering practices At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Job Category - Engineering, Technology
Show more Show less"
2826953731,Data Engineer -RappiPay,Rappi,2021-11-09,United States,"Location, WV",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","YOUR NEXT STEP IS AT RAPPI!

Rappi is one of the first Latin American unicorns and a start-up that continues to focus on growing and making life easier for our users. As a company, we seek to continue improving the services we already offer, add more to our offer and continue expanding throughout the Latin American continent.

¡At Rappi we think big! We are building our financial ecosystem willing to become the biggest digital bank in Latin America. To accomplish this mission we need a world class team that delivers high quality financial products into the market.

Data is our biggest asset and we are building a truly data driven company.

We are hiring the most talented engineers in Latin America and we want you to join them. Working in Technology at Rappi Pay is not about fixing legacy systems. It is about building world-class products from the ground up that will be used by millions.

We are looking for a Data Engineer who will be responsible for building, improving and maintaining a scalable data pipeline infrastructure required for extraction, transformation, and loading of terabytes of data from thousands of sources to our analytics platform.

You will have the opportunity to apply cutting-edge technologies in large scale environment with a challenging rapid growth pace, taking ownership of both internal and external services, and applying all your skills to make an impact on the whole company.

You will be working with a skilled group of international tech specialists, on a high pressure hard-work environment.

Responsabilities

Work together with developers, tech leads and solution architects to build applications.
Improve existing structures by adding new functionalities or proposing technological updates so that as a result, the impact of your contribution is significant in the core of the business.
The result of your work will also allow you to improve the user experience on scalable and high availability platforms, contributing to the key differential of each business.
Build and maintain the ETLs from Production to the analytics platform.
Build and maintain Datalake / DW and Datamarts for the different use cases.
Make the right data accessible in the right way to the different groups of users.
Strive to get everything working on automatic ways.
Investigate and test new technologies that could improve our processes.
Provide a secure data environment to comply with regulations on different countries.
Must have

Computer science background/knowledge.
Advanced SQL understanding and implementation.
Advanced knowledge writing python code.
Advanced experience in AWS Data Toolset.
Advanced experience in Datalake / Datawarehouse / Datamarts technologies.
Advanced experience working with ETLs.
Experience working with CDC (Change Data Capture).
Experience working with streaming technologies (Kinesis / Kafka)
Experience working with Spark / EMR is a plus.
Experience on Snowflake Cloud Data Platform is a plus.
Understanding Data Catalog, Data Governance, Data Lineage.
Ability to communicate complicated technical problems to both technical and business audiences.
Rappi operates in more than 40 cities in 9 countries in Latin America. We have debit cards with VISA in Colombia, Mexico and Brasil and we will soon launch credit cards in Colombia, Mexico and Perú.

He leído y acepto la Autorización de Datos Personales de Rappi S.A.S

https://docs.google.com/document/d/e/2PACX-1vRFEkFojVd3AfFsARRsdZpiSjA_xQGK5Y7ZCBT3gw19MOdQVqH5nRAuSqyu3yZq2A/pub

Conforme a la Política de Tratamiento de Datos Personales

https://legal.rappi.com/colombia/politica-de-proteccion-y-tratamiento-de-datos-personales-rappi-s-a-s/

I have read and accept the Authorization of Personal Data from Rappi S.A.S

https://docs.google.com/document/d/e/2PACX-1vRFEkFojVd3AfFsARRsdZpiSjA_xQGK5Y7ZCBT3gw19MOdQVqH5nRAuSqyu3yZq2A/pub

In accordance with the Personal Data Treatment Policy

https://legal.rappi.com/colombia/autorizacion-de-tratamiento-de-datos-personales-rappitenderos-rappi-s-a-s/
Show more Show less"
2826031620,Data Engineer,Evio,2021-12-03,United States,United States ,,Full-time,,"We are looking for an experienced data engineer to help us build our analytics platform. This role is vital in supporting our clinical analytics team managing the data ETL process that will feed our real world evidence.




Job Specifics

 

In partnership with the clinical and technology teams, you will: 

Work with both internal and external stakeholders to create and maintain the data pipeline
Assemble large, complex data sets that meet functional / non-functional business requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies
Help to identify and implement analytics tools that utilize the data pipeline in support of business and partner demands
Work with stakeholders including the Clinical and Partner IT teams to assist with data-related technical issues and support their data infrastructure needs
Help to establish and manage the data security process




The skills and experience you bring to this role include:

5+ years of experience in a data engineering role
Bachelors Degree in Computer Science, Informatics, Information Systems or another quantitative field
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Practical experience programming in Python or similar tools for analysis and automation
Experience with end to end automation using cloud infrastructure (Azure, AWS etc.)
Experience with healthcare data (HL7, Claims, Rx) is preferred
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Strong analytic skills related to working with unstructured datasets
Build processes supporting data transformation, data structures, metadata, dependency and workload management
A successful history of manipulating, processing and extracting value from large disconnected datasets
Strong communication and organizational skills
Experience supporting and working with cross-functional teams in a dynamic environment




IMPORTANT: Along with your resume, please upload your answers to the following questions to accompany your application:

What makes you unique in 50 words or less?
Why health care in 50 words or less?
What excites you about joining the Evio team in 50 words or less?
Show more Show less"
2813145520,Cloud Data Engineer - remote,The Hartford,2021-10-31,United States,"Houston, TX",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

Responsibilities

The Hartford's Enterprise Data Organization is seeking a Data Engineer to support Customer Data Team. We are seeking a talented professional with a proven track record of engineering and operationalizing a next generation analytics solution suite using Cloud (AWS) and Big Data Technologies. Our ideal candidate will leverage deep technical expertise and strong communication skills to deliver both invest and maintenance projects within the Personal Lines portfolio. Responsibilities include but are not limited to:

Develop high quality, scalable software modules for next generation analytics solution suite
Prototype high impact innovations, catering to changing business needs, by leveraging new technologies (AWS – Cloud and Big Data)
Possesses functional knowledge and skills reflective of a competent practitioner with the ability to deliver on work of highest technical complexity
Migrate on-prem databases/data warehouses/applications to Cloud (AWS) using Big Data Distributed Processing technologies
Implement the disaster recovery plan to ensure that new systems promote uninterrupted systems operation
Coordinate activities with cross-functional IT unit stakeholders (e.g., database, operations, telecommunications, technical support, etc.)
Formulates logical statements of business problems and devises, tests and implements efficient, cost effective application program solutions (e.g., codes and/or reuses existing code through the use of program development software alternatives and/or integrates purchased solutions)
Prepares charts, tables and diagrams to assist in analyzing problems, utilizing various business, scientific, engineering and mathematical techniques. Analyzes existing system and programming logic to provide more efficient machine operations or to identify difficulties, and revises the logic and procedures involved as necessary

Qualifications

Bachelor’s degree with at least 4 years of applicable work experience.
2+ years ETL / Data Integration / Big Data / Cloud (AWS) Technologies experience
AWS / Big Data /Snowflake Technologies certification preferred
Knowledge of Talend, Unix/Linux Shell scripting, Autosys scheduling tool, Sub Version, version control Tools.
Some exposure to MS Sql Server and MSBI preferred
Strong data warehouse applications knowledge in financial/insurance domain
Knowledge of Big Data Distributed Processing (HDFS, Hive, Spark, PySpark), AWS, Data Analytical languages R, Python preferred.
Good programming skills in Java
Efficient scripting skills in languages like JavaScript, Python, PHP
Exposure in Agile and Kanban Methodologies

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$90,480 - $135,720

Benefits

Our company’s success is due to our employees’ dedication and passion for their work. They are our greatest asset. That’s why we are committed to offering employees and their families a comprehensive benefits package and award-winning well-being programs. By helping our employees achieve their full potential, we unlock our own. Visit https://www.thehartford.com/careers/benefits for details.

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

Data Engineer - GE08AE
Show more Show less"
2813004171,Data Engineer,Cookies,2021-11-29,United States,San Francisco Bay Area,Information Technology and Engineering,Full-time,Manufacturing and Alternative Medicine,"Data Engineer




Cookies, a globally recognized cannabis brand, is looking for a Data Engineer for a new cutting-edge and fully-remote team. Cookies offers trendsetting cannabis products that start with our indoor and outdoor farms and end up on your favorite dispensary’s retail shelves.




We’re looking for a Data Engineer who can jump in with both feet and help us select, develop, and deploy digital solutions that support all aspects of the Cookies vision and mission. This role will involve cross-functional requirements gathering, ideation, synthesis of those requirements into solutions, and then deployment of those solutions throughout Cookies and our network of partners, a constellation of vendors, and footprint of stores, sites, brands, and lines of business.







Major Areas of Responsibility:

Consistently design and produce high-quality SQL, Python, JavaScript, and code in other languages within the Cookies Platform for ETL and ELT work
Contribute during design and architecture discussions, and decisions critical to curating growth of data assets and IP as Cookies rapidly expands into new markets
Experience with data cleansing, transformation, and validation for data marts
Work cross-functionally with operations and marketing teams to evaluate requirements, ideate on solutions, and deploy those solutions to production with an emphasis on adoption
Skilled in writing unit tests, integration tests, end-to-end tests, and other QA code
On occasion, design & procure solutions for retail or supply chain circumstances, as or where requirements arise
Experience with relational and/or non-relational databases
Collaboration with Data Analysts to help solve systemic challenges leveraging algorithms and data structures.




You have:

Ability to operate under pressure and in a fast-paced environment
Passion for frontier hyper-growth industries, particularly legal cannabis
Strong RESTful API experience to manage and expand data pipelines.
Google Cloud familiarity: BigQuery, Cloud Spanner, Dataprep, Kubernetes, Protobuf
Excellent technical aptitude
Healthy curiosity for learning and sharing new things
Insatiable need to reach for the best and highest dreams possible
Prior work experience with prefect.io and Tableau is a plus
High School diploma or equivalent
CS degree (BS or MS) or 3-4 years relevant work experience as a professional engineer




Cookies is a fast-paced, dynamic environment. Looking for team members who are flexible, nimble and know how to get stuff done. We are a fun, driven, entrepreneurial group focused on culture, community, and quality. We’re an equal opportunity employer on the lookout for top-notch talent who truly wants to help us change the world.




This is a full-time position with the ability to work remotely, regardless of COVID! We strongly prefer candidates in the San Francisco, greater Bay Area, or Los Angeles areas.

Show more Show less"
2797871692,Big Data Engineer,Stefanini North America and APAC,2021-10-22,United States,"Dallas, TX",Engineering and Information Technology,Full-time,IT Services and IT Consulting,"Stefanini is looking for a Big Data Engineer (Mid-Level) in Dallas, TX

Required Skills

Experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc..)
At least 3 years of experience working with large data sets, streaming, experience working with distributed computing (Map Reduce, Hadoop, Hive, Apache Spark, Apache Kafka etc.).
Working knowledge of data structures, SQL, XML, JSON, Data visualization tools, Version Control Systems, Programming, and Unix/Linux shell scripting
Experience with AWS, GCP or Azure
Experience with RESTful API development, Familiarity with HTTP and invoking web-APIs
Equivalent education and/or experience may be substituted for any of the above requirements
Need local candidate to Dallas, TX

Qualifications

An associate degree, a bachelor's degree a plus
Certified Business Intelligence Professional (CBIP) or equivalent certification a plus
At least 4 years of experience in Data Engineering with SQL, Python
Experience with relational SQL and NoSQL databases
Show more Show less"
2803441996,Data Engineer,IBM,2021-11-21,United States,"Lansing, MI",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

The position of the Data Engineer plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. The Data Engineer defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business. Develops applications on Big Data and Cognitive technologies including API development. Expected to have traditional Application Development background along with knowledge of Analytics libraries, open-source Natural Language Processing, statistical and big data computing libraries. Strong technical abilities to understand, design, write and debug complex code.

The successful candidates for these positions may be based anywhere in MICHIGAN and will work collaboratively with the Client Innovation Team. While this is not a fully remote role, work on-site at the IBM Client Innovation Center in Lansing MI is expected to be minimal with a focus on Team Meetings, Collaboration and Client Visits. It’s anticipated that a Michigan resource would typically spend an average 2-3 days/month on-site at the Center. Additionally, some travel is expected, and all candidates must be willing and able to travel to meet our client needs across the US. Travel is typically related to knowledge transfer and training at the client site (Monday thru Friday). You may need to travel up to 50% of the time post-Covid depending on individual project needs.

Required Technical and Professional Expertise


2 years + experience with JavaScript, Java, or other object-oriented programming languages.
Hands-on experience and understanding of object-oriented programming, data structures, algorithms, profiling & optimization (stacks, queues, linked lists, hash tables, trees, arrays, common algorithms, iteration and recursion, etc.)
2 years + coding challenge experiences including LeetCode and Hackerrank, etc.


Preferred Technical And Professional Expertise

Unless specified as a Required Skill, the following are additionally preferred but not required:


Experience with big data solutions such as Hadoop, MapReduce, Hive, Pig, Kafka, Storm etc. is a major plus.
Experience in Node.JS, Database, REST, Event Source, Web Sockets, HTML5, CSS3, RWD, JQuery is highly desirable.


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2820813380,Data Engineer,Cognizant,2021-11-30,United States,"Tampa, FL",Information Technology,Full-time,IT Services and IT Consulting and Management Consulting,"Not Applicable

Qualification

Not Applicable

Responsibility

Not Applicable

Must Have Skills

Apache Hadoop

Employee Status : Full Time Employee

Shift : Day Job

Job Posting : Nov 30 2021

About Cognizant

Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.

Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.

Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.
Show more Show less"
2797275666,Big Data Engineer - Financial and Developer Services,Amazon,2021-11-18,United States,"Seattle, WA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Ever wondered how Amazon offers the Earth's biggest selection and still manages to offer lower prices every day to our customers? Our consumer business teams work with a massive array of selling partners and business financial performance metrics to expand selection and drive costs lower. Given the rapid growth of our business, this requires our category leaders, financial analysts, account managers, site merchandisers and vendor managers to quickly analyze vendors, merchants, categories and brands, diving deep into data showing business efficiency down to the unit sale level. The technology that enables this has huge visibility and impact and is critical to Amazon's continued profitability and growth.

Innovation

We're working on the future. If you are seeking an environment where you can drive innovation. If you want to apply state-of-the-art software technologies to solve real world problems. If you want the satisfaction of providing visible benefit to end-users in an iterative fast paced environment, this is your opportunity. The responsibilities of this role will be key in paving the future of Amazon Consumer and transforming how we do business.

Opportunity

You will be part of a team of creative, top-notch software developers to work hard, have fun, and make history. Software engineers at Amazon are more than just order takers; they see a problem and leverage innovative technology to address it. You will be working with very large data sets, well beyond the scalability limits of conventional relational databases. We're looking for people who innovate, love solving hard problems, and never take ""no"" for an answer.

Our team is within the Selling Partner Services organization and develops sophisticated tools for the Amazon Consumer businesses, supporting deep dive analysis, vendor negotiations and business planning towards enhancement at the bottom line. We also provide financial and operational reports to Amazon retail vendors worldwide.


Basic Qualifications

Bachelor’s degree or higher in an analytical area such as Computer Science, Physics, Mathematics, Statistics, Engineering or similar.
7+ years relevant professional experience in Data Engineering and Business Intelligence
7+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.
Strong knowledge of data warehousing concepts, including data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures, data modeling and performance tuning.
Advanced data analysis skills
Experience with AWS services including S3, Redshift, EMR
Knowledge of distributed systems as it pertains to data storage and computing
Ability to effectively communicate with both business and technical teams.

Preferred Qualifications

Experience on working with Big Data
Knowledge of Map Reduce, Spark and Presto
Experience providing technical leadership and mentoring other engineers for best practices on data engineering
Knowledge of software engineering best practices across the development life-cycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations


Company - Amazon.com Services LLC

Job ID: A1745728
Show more Show less"
2803432910,Data Engineer,Avance Consulting,2021-11-22,United States,"Irving, TX",,Full-time,,"1. 4 <years <10 of relevant experience with data engineering using Spark
2. Design and Develop methods to connect & collect data from different data sources using Spark, Kafka, Hive
3. Design and Develop methods to filter/cleanse the data
4. Design and Develop SQL , Hive queries, APIs to extract data from the store
5. Work closely with data Scientists to ensure the source data is aggregated and cleansed
6. Work with product managers to understand the business objectives
7. Work with cloud and data architects to define robust architecture in cloud setup pipelines and work flows
8. Work with DevOps to build automated data pipelines
9. Business Domain knowledge: Finance & banking systems, Fraud, Payments
10. Working with Business on storyboarding and requirement elicitation • Can do delivery presentation, getting Business approval/sign-off
11. Experience using Agile methodologies and Scrum • Work with other developers, designers, and test engineers to improve their skills and help deliver business outcomes
12. Ability to apply both technical and business knowledge while participating in the full lifecycle development process
13. Ability to interpret business requirements and logically think through to developing technical solutions
14. The candidate should have performed client facing roles and possess excellent communication skills
15. Analyze and understand data sources & APIs
Required Technical Skills
1. Big Data-Hadoop, Hive, Apache Spark
2. Python
Show more Show less"
2808116810,Data Engineer,Deckers Brands,2021-11-25,United States,"Boston, MA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2804139986,Data Engineer (Remote),The Hartford,2021-10-24,United States,"Hartford, CT",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

The Data Science Enablement team is committed to exploring new ways to use data and analytics to solve business problems. The team utilizes a wealth of data, both internal and external, and predictive analytics to enable accelerated access to advanced analytics and data-driven decision-making.

As a Data Engineer, you will be a key contributor to the team by partnering closely with expert resources to design, develop, and implement data assets for use throughout the Data Science organization. The role involves implementing and maintaining data pipelines, proficiency writing SQL queries and Python code, and the ability to discover and learn quickly through collaboration and curiosity. There is a need to think logically and structured as well as outside of the box to improve current processes and develop business acumen.

There will be a combination of team collaboration and self-led work efforts. This role involves interaction with data science partners as well as a wide range of business areas. We seek candidates with strong quantitative background and problem-solving skills. This position combines business and technical skills involving interaction with business customers, data science partners, internal and external data suppliers and information technology partners.

Responsibilities

This role can be 100% remote permanently.
Identify and validate internal and external data sources for availability and quality. Work with SME’s to describe and understand data lineage and suitability for a use case.
Create data assets, build data pipelines, and perform data analysis to ensure quality of data assets with Python.
Create summary statistics/reports from data warehouses, marts, and operational data stores.
Extract data from source systems and data warehouses, and deliver in a pre-defined format.
Work with data scientists to build data pipelines that leverage predictive models.
Produce code artifacts and documentation for reproducibility, preferably utilizing Github.
Collaborate closely with data scientists, business partners, data suppliers, and IT resources.
Work both self-directed and in a team environment with internal customers.
Communicate technical concepts regarding data to both data scientists and partners.

Minimum Requirements

You must have the technical skills to transform, manipulate and store data, the interpretative skills to relate data to the business processes that generates it, and the communication skills to document & disseminate information regarding the availability, quality, and other characteristics of the data to a diverse audience. These varied skills may be demonstrated through the following:

Must be authorized to work in the United States, now and in the future.
Experience accessing and retrieving data from disparate large data sources.
Understanding of data modeling concepts, data warehousing tools and databases (e.g. ETL, Big Data, ORACLE)
2+ years of experience using Python (Pandas, Numpy) for data analysis.
Exposure to Data Architecture in an enterprise environment.

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

Benefits

Our company’s success is due to our employees’ dedication and passion for their work. They are our greatest asset. That’s why we are committed to offering employees and their families a comprehensive benefits package and award-winning well-being programs. By helping our employees achieve their full potential, we unlock our own. Visit https://www.thehartford.com/careers/benefits for details.

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

Data Engineer - GE08AE
Show more Show less"
2820741603,Data Engineer,Level Agency,2021-12-03,United States,"Pittsburgh, PA",,Full-time,,"SALARY: $70 – 90K

Data Engineer

About You:

You are enthusiastic about taking the lead in developing successful, long-term testing strategies.
You thrive in a culture that is nimble, collaborative, analytical, and creative.
You have an interest in computer systems and coding languages while staying on top of the latest technologies.
Be a self-starter.
The instinct to automate simple tasks and save co-worker/client time.
Enjoy the challenge of discovering new technologies and finding ways to use them.

Does this sound like you? If so, Level Agency is currently looking for an experienced and results-driven Data Engineer to join our team, and we can’t wait to meet you!

 

The ideal candidate will have experience in building applications to connect different sources of information, programming and database/data warehouse management along with building highly responsive web applications that align with our business needs.

About the Position:

 

The Data Engineer will be part of the agency’s Operations Team, owning the technology products and processes. This includes developing and maintaining multiple automation jobs, data connections, web integrations, warehouse optimization, documentation, external product development, and testing each piece to report back on his or her findings. Other responsibilities include writing and testing code, debugging programs and integrating applications with third-party web services. The salary range for this position is $70 – 90K.

 

Success in this position is making sure the company is following the best practices and adapting with the rest of the world. Technology is constantly changing, and we need to make sure that Level Agency is going to grow with it. 

 

We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas. We require that you perform the job within the United States.

 

Your Impact:

·        Owning web integrations, providing best practices, and documentation.

·        Staying on top of the newest technologies and learning from different test models.

·        Analyzing different tests to identify the best practices for the company.

·        Management and maintenance of the data warehouse and connections that provide critical data for business decisions.

·        Act as a lead to identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, and providing more time for co-workers to make better decisions.

·        Creating programs that can recycled and used for multiple situations / clients.

·        Communicating with clients on what was successful and able to explain the losses.

·        Writing effective, scalable code

·        Build reusable code and libraries for future use

·        Automation of client and internal products

·        Dev-ops including system management, server setup and cloud-app setup

·        Developing back-end components to improve responsiveness and overall performance




Requirements:

Skills:

·        Experience programming and/or architecting a back-end language (JavaScript, Node.js, Ruby & Python)

·        Experience with non-relational & relational databases (SQL, MySQL, Postgres, NoSQL, Hadoop, MongoDB, etc.)

·        Understanding of how to work with specific API styles (REST/SOAP)

·        Familiarity with various tools such as AWS, Mesos or Docker

·        Creative and innovative approach to problem-solving

·        Familiarity with continuous-integration tools and patterns (Jenkins, Travis CI, etc.)

·        Ability to accurately estimate project hours.

·        An understanding of Agile best practices is a plus

 

Qualifications:

·        Bachelor’s in computer science (required)

·        3-5 years’ experience in Back-end Development.

·        2+ years in the data warehouse space.

·        2+ years writing SQL statements and optimization

 

Benefits:

·        Competitive compensation

·        Performance reviews every six months

·        Generous PTO policy

·        Ability to develop and refine skills with career advancement opportunities

·        Great medical benefits with the region's top plan

·        Simple IRA with 3% employer match contribution

·        Employee appreciation programs

·        Working with an awesome group of intelligent people!




 

The Company:

Change is the only constant in today’s marketing ecosystem, and it's happening FAST. Level Agency (www.level.agency) and its team of digital marketing scientists are experts at helping clients improve performance and acquire knowledge through its test, learn, and grow framework.

Test: Use design thinking principles to understand rapidly changing consumer challenges, formulate hypotheses, and develop creative prototypes.

Learn: Run experiments using lean methods that teach us more about our audiences and their preferences; measure results in real-time

Grow: Allocate additional marketing resources to exploit the new knowledge; tweak campaigns to be better every day; identify the next logical test; and run the cycle again.

Recently ranked #190 on the Inc. 500's Fastest-Growing Private U.S. Companies and one of Pittsburgh's Best Places to Work, Level Agency delivers powerful and comprehensive online solutions including multi-channel digital marketing, search engine optimization, lead generation, website development, ROI reporting, and much more.

Level Agency is an equal opportunity employer, a Military Friendly® partner, and we value diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

 

Show more Show less"
2766157505,Data Engineer,Recorded Future,2021-12-02,United States,"Boston, MA",Information Technology,Full-time,Computer Software and Computer and Network Security,"Recorded Future’s harvesting pipeline reads over 700,000 web sources and structured data feeds, and our real-time multilingual natural language processing technology takes that content from raw text to alerts and visualizations in minutes. You will join a team of motivated people working on a tough problem and help us shine a light into the dark corners of the internet.




What you’ll do as a Data Engineer:

Implement new techniques for extracting high fidelity information from our vast collection of structured and unstructured data.
Build, improve, and take ownership of key data pipelines.
Collaborate across teams to understand user needs and write the code to meet them.




What you’ll bring as a Data Engineer:

Python programming: You are comfortable writing scalable, resilient production-grade code in python.
Excellent communication: Your clarity of thought is always apparent in your crisp and articulate emails, Slack chats, phone calls, and in-person conversations.
Data skills: You are comfortable working with large, complex data structures. You love working with heterogeneous data to answer real human questions, and you know how to write the code that makes that happen.
Curiosity: You want to understand how the data you work with is used and get to know a new codebase.




Why should you join Recorded Future?

With over 600 employees, $140M ARR, 1,000 clients, and 50% year-over-year growth, Recorded Future is the world’s largest privately-held security intelligence company! Recorded Future employees (or “Futurists”), represent over 35 nationalities and embody our core values of being passionate, practicing inclusion, and acting ethically. Our dedication to empowering clients with intelligence to disrupt adversaries has earned us a 4.7-star user rating from Gartner and 8 of the top 10 Fortune 100 companies as clients.




We are committed to maintaining an environment that attracts and retains talent from a diverse range of experiences, backgrounds and lifestyles. By ensuring all feel included and respected for being unique and bringing their whole selves to work, Recorded Future is made a better place every day.




If you need any accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to our recruiting team at careers@recordedfuture.com




Recorded Future is an equal opportunity and affirmative action employer and we encourage candidates from all backgrounds to apply. Recorded Future does not discriminate based on race, religion, color, national origin, gender including pregnancy, sexual orientation, gender identity, age, marital status, veteran status, disability or any other characteristic protected by law.




Recorded Future will not discharge, discipline or in any other manner discriminate against any employee or applicant for employment because such employee or applicant has inquired about, discussed, or disclosed the compensation of the employee or applicant or another employee or applicant.

Show more Show less"
2817327708,Data Engineer,Averity,2021-12-01,United States,"New York, NY ",Information Technology and Engineering,Full-time,IT Services and IT Consulting and Marketing and Advertising,"Who Are We?

We are a Customer Data Platform seeking to transform the industry. We provide ways to extract specific customer behavior data for large and well-known brands. This allows our clients to increase their marketing efforts and profitability.

We are an established Startup backed by some serious Venture Capital and are growing quickly due to bringing on board more big name clients. We are national but our head office is located here in the Flatiron area in Manhattan.







What's The Job?

As a Hybrid-Remote Data Engineer on our team you will be problem solving, troubleshooting and engaging regularly with Customer teams and delivering on all technical requests. You will be working on creating ETL pipelines, ingest/export integrations, new product lines and orchestrating platform migrations. Also there is building different tools for automation and customer specific configurations.







What Skills Do You Need?

2 Years Work Experience in a Technical Role working with large datasets for ETL, Data Warehousing and Data Analytics
SQL
Python
AWS Experience
Client-facing Experience with External Clients gathering Data Requirements
Computer Science Degree







Compensation?

$85,000 - $110,000 base salary (based on work experience)
Generous vacation
Full Medical, Dental and Vision
401(K) Matching







What's in it for you?

This is a unique opportunity to work in a team of fun and smart people, where product meets customer needs and creates value. You get to work at a Startup in a brand new office at Madison Square Park in New York City.







We are big proponents of diversity, and encourage diverse applicants / candidates with diverse backgrounds to apply.

Show more Show less"
2818561590,PySpark Data Engineer,Insight Global,2021-11-29,United States,Atlanta Metropolitan Area,,Contract,," 

Must Haves:

3+ years Data Engineering experience
Experience/knowledge with the following cloud technologies: Data Bricks, Data Factory, Spark
Data warehouse development experience
Advanced SQL skills
Proficient with ETL processes
Python Development for Automation and development




Plusses:

Azure experience
Helm charts
Kubernetes
Terraform and Arm templates

 

Day-to-Day:

An Insight Global client is looking to add 4 PySpark Data Engineers to their team supporting the recent Azure platform initiative. The Data Engineer will be responsible for migrating the ETL processes and building out a Datawarehouse to support those processes. LexisNexis has a proprietary big data platform called HPCC, and they use ECL to develop within it. This role will be primarily about backend data development, writing complex SQL queries, multidimensional modeling, and using Python for automation/development. 80% of the day is heads down PySpark coding. The ideal candidate needs cloud experience, preferably with Azure. 

Show more Show less"
2819537581,Data Engineer - Marketing,Stitch Fix,2021-12-04,United States,United States,"Research, Analyst, and Information Technology",Full-time,"Apparel and Fashion, Internet Publishing, and Retail","About The Team

The data engineering team is a small, nimble group of data engineers that drive the company toward clean and informative data. As a member of the data engineering team, you’ll contribute toward a clear, concise data model to help power data science, ETLs and tools to make us efficient, as well as self-service data and tools to facilitate scalable decision-making. As a team, we are driven by the thrill of helping our colleagues use data with less friction, which ultimately increases the velocity at which the business can progress!

About The Role

Individual contributor position on the data engineering team, within our Algorithms organization, working with a team that focuses on our Marketing data infrastructure
You will build and own large additions to our data engineering framework, contributing to a code framework that centralizes ETL logic and definitions
You will help to define, build and maintain a clear, concise data model, especially focused on scalable analytics infrastructure
You will build scalable data engineering solutions & frameworks to solve business and data problems
You will be involved in the day-to-day operations of the team, including maintaining and improving our current tools & scripts and supporting data that powers our business
You will have autonomy to help shape the future of data engineering at Stitch Fix by bringing your ideas on improving and automating what we do and how we do it

You’re Excited About This Opportunity Because You Will...

You will work with a variety of cross functional partners from marketing analysts and data scientists as well as our third party vendors to deliver up-to-date metrics on our Marketing organization
You will focus on our marketing data infrastructure, optimization, and scalability
Be part of a fast-growing team which has high visibility across the organization
Contribute ideas and direct the team’s investment to impactful directions
Contribute to a culture of technical collaboration and scalable development

We Get Excited About Candidates Who Have…

3+ years of independent and significant project experience
Experience in building out data models and data engineering capabilities
Experience coding and designing extensible and reusable Python and SQL
Experience in working autonomously and taking ownership of projects.
Ability to think globally, devising and building solutions to meet many needs rather than completing individual projects or tasks
Strong prioritization skills with business impact in mind
Familiarity with using Spark to access an S3 data warehouse
Strong cross functional communication skills that help simplify and move complex problems forward with business partners

YOU’LL LOVE WORKING AT STITCH FIX BECAUSE…

We are a group of bright, kind and goal oriented people. You can be your authentic self here, and are empowered to encourage others to do the same!
We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation
We are a technologically and data-driven business
We are committed to our clients and connected through our vision of “Transforming the way people find what they love”
We love solving problems, thinking creatively and trying new things
We believe in autonomy & taking initiative
We are challenged, developed and have meaningful impact
We take what we do seriously. We don’t take ourselves seriously
We have a smart, experienced leadership team that wants to do it right and is open to new ideas
We offer competitive compensation packages and comprehensive health benefits
You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day

About Stitch Fix

At Stitch Fix, we’re about personal styling for everybody, and we believe in both a service and a workplace where you can be your best, most authentic self. We’re the first fashion retailer to combine technology and data science with the human instinct of a Stylist to deliver a deeply personalized shopping experience. This novel juxtaposition attracts a highly diverse group of talented people who are both thinkers and doers. All of this results in a simple, powerful offering to our customers and a successful, growing business serving millions of men, women, and kids. We believe we are only scratching the surface on our opportunity, and we’re looking for incredible people like you to help us carry on that trend.
Show more Show less"
2777276454,Data Engineer - Data Platform,Tesla,2021-10-09,United States,"Fremont, CA",Information Technology,Full-time,"Renewable Energy Semiconductor Manufacturing, Motor Vehicle Manufacturing, and Utilities","Tesla is looking for a talented data engineer with experience working with the highly transactional and scalable data platform. We are working on architecture to support analytics on Tesla’s complex business applications suite. With this architecture, our business users should be able to get “What”, “When” and “how” answered much faster and help them to take data driven decisions

Responsibilities

Build and manage Kafka based streaming data pipelines
Build and manage Airflow based ETLs
Monitor and improve performance of the pipelines
Develop storage layer (relational / non-relational) for hosting data for analytical queries
Work on fast pace projects to deliver innovative solutions for our business users

Requirements

Bachelor’s degree in computer science/software engineering or related fields with 3+ years of experience in data engineering
3+ years of experience working with Python, NodeJS
2+ years of experience working with Kafka based pipeline development
Strong knowledge of SQL is required
1+ year of hands-on experience with Apache Airflow
Ability to debug production issues using tools like Grafana, Splunk or server logs

Nice to have

Experience with distributed computing using Hadoop ecosystem, Spark, Presto.
Knowledge of Java, Scala
Knowledge of Kafka connect ecosystem
Experience with Docker, Kubernetes
Show more Show less"
2803147403,Data Engineer,2U,2021-11-17,United States,"Cambridge, MA",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","What We’re Looking For

We accept applications from remote employees in the following US states: CO, CT, ME, NH, NJ, NY and VT.

Data Engineering has built a best in class data platform leveraging tools such as snowflake, dbt_ and prefect. Now that the foundations have been laid the team is beginning to look toward what is next; and evolving our foundation to climb to the next rung of the analytics maturity model.

edX is looking to add a Data Engineer to set their vision on that next rung and to help us climb.

Your work will enable the Data group to evolve, automate and scale and impact edXers across the company as we keep the data flowing and enable edX to continue to mature as a data-driven organization - and achieve our potential to transform education for learners globally.

The Data Engineering (DE) team’s work lies at the foundation of all that edX does. The accurate, timely and usable data that DE provides to the organization drives business reporting and decision-making, product innovation, customer-facing data offerings and more.

Data Engineering works alongside data analysts and scientists, product engineering, and business stakeholders across the organization to provide the data platform and technical solutions that enable edX to drive value from its data. If you are looking to make an outsized impact on an organization, Data Engineering at edX is the place for you.

Responsibilities Include, But Are Not Limited To

Maintain and help improve Data Engineering’s best in class infrastructure
Be relentless in your distaste for toil; automating and removing processes and systems that are no longer serving their purpose
Build automation and tooling to help data move fast, we strive for idempotent, reproducible systems and results
Be data driven in your work, instrumenting the tools Data Engineering builds and tuning system performance
Rapidly diagnose and resolve faults with data services and pipelines as a member of an on-call rotation - ensuring the data flows throughout our ecosystem smoothly
Collaborate with peers in and out of the Data team to troubleshoot and propose and document solutions
Proactively communicate issues, status or roadblocks
Help optimize alerting, data processes and on-call rotations to reduce fatigue and improve efficiency of our operations

Things That Should Be In Your Background

Experience in a dev-ops or site reliability engineering role or
Experience building efficient data pipelines, performance tuning, and integrating disparate data sources and types, including high volume semi-structured and unstructured data (e.g., JSON, etc.)
Understanding of cloud-based data warehousing and ELT/ETL techniques and processes
Experience working in AWS systems
Experience working in Python
Collaborative and pragmatic, with and enthusiasm for learning and continuous improvement

Other Attributes That Will Help You In This Role

Experience with Snowflake and dbt_ (https://www.getdbt.com/)
Experience with pipeline data pipeline tools such as Prefect, Luigi or Airflow
Experience with or a desire to learn about Terraform and Kubernetes.
Experience master data management, data modeling and preparing data for analysis
Enthusiasm for Agile/Scrum processes

About EdX

edX is the education movement for restless learners. Together with our founding partners Harvard and MIT, we’ve brought together more than 38 million learners, the majority of top-ranked universities in the world, and industry-leading companies onto one online learning platform that supports learners at every stage. And we’re not stopping there—as a global nonprofit, we’re relentlessly pursuing our vision of a world where every learner can access education to unlock their potential, without the barriers of cost or location.

About 2U, Inc. (NASDAQ: TWOU)

2U is comprised of 3 lines of business: Graduate Degree Programs, Short Course, and Boot Camps. Going beyond traditional learning management systems, we use tech, people, and data to help top universities and enterprise organizations transform in the digital era—and eliminate the back row in higher ed. We support lifelong learning which means thinking beyond a single degree. It means finding ways for students to gain the skills they need to change careers, evolve their expertise, and meet the challenges of the changing world head-on. We help our partners fill those needs—developing new digital education technologies and offerings capable of supporting students at different points in their lives. Whether they need a simple refresher, to learn something new, or to change their career trajectories completely, our partners are there to help them succeed. Together with our partners, 2U has positively transformed the lives of more than 275,000 students and lifelong learners.

2U Diversity and Inclusion Statement

At 2U, we are committed to creating and sustaining a culture that embodies diverse walks of life, ideas, genders, ages, races, cultures, sexual orientations, abilities and other unique qualities of our employees. We strive to offer a workplace where every employee feels empowered by the ways in which we are different, as well as the ways in which we are the same.

Benefits & Culture

Working at 2U means working with individuals that are passionate and mission driven. We collaborate on tough problems to deliver the best outcomes for our partners, students, and each other. You will find team members working together in our open office spaces, gathered in the kitchen grabbing a snack, or taking a break in our game rooms.

2U Offers a Comprehensive Benefits Package

Medical, dental, and vision coverage
Life insurance, disability and 401(k)
Unlimited snacks and drinks
Generous paid leave policies including unlimited PTO
Additional time off benefits include: volunteer days, parental leave, and a company-wide winter break

In Colorado, the anticipated base salary for this role is $100,000.00 with potential bonus. Note: The final compensation for this position may consider factors including the geographic location where the work is performed (candidate’s assigned office) and prior work experience of the candidate.

To learn more, visit 2U.com. #NoBackRow

Note: The above statements are intended to describe the general nature and level of work performed by individuals assigned to this position, and are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required. All employees may be required to perform duties outside of their normal responsibilities from time to time, as needed.

2U is an equal opportunity employer that does not discriminate against applicants or employees and ensures equal employment opportunity for all persons regardless of their race, creed, color, religion, sex, sexual orientation, gender identity, pregnancy, national origin, age, marital status, disability, citizenship, military or veterans’ status, or any other classifications protected by applicable federal, state or local laws. 2U’s equal opportunity policy applies to all terms and conditions of employment, including but not limited to recruiting, hiring, training, promotion, job benefits and pay.
Show more Show less"
2805803862,Data Engineer,Brightloom,2021-11-19,United States,"Seattle, WA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","[This position may be based remotely. You must be able to work from home and align with Pacific time working hours as needed.]

The Role

Brightloom is creating an entirely new category of software-as-a-service for consumer brands -- the Customer Growth Platform. This first-of-its-kind platform enables automated digital engagement and personalized loyalty programs to transform customer experiences while delivering predictable and repeatable lifetime value growth for brands.

As a Data Engineer on our PRO team, you will leverage industry standard and leading edge Data Engineering tools and techniques to develop and improve all aspects of the data lifecycle. This role requires a detail-oriented individual who is invested in the customer journey to help ensure the best products are delivered to our customers. Along the way you will also contribute to our core product and platform capabilities and roadmaps to ensure the work you do can be re-used and available to our rapidly growing customer base.

What You'll Do

Drive Process Improvements. You will work with our Engineering and Data Onboarding teams to propose and improve data architectures that support our products.
Collaborate. Work across teams to understand how business decisions impact data pipeline needs.
Develop Solutions. Address operational efficiencies through improving performance, availability, orchestration, and throughput of data pipelines.
Model specialization. You'll become an expert on the inner workings of our models and help ensure the highest quality data is fed to our machine learning models.


About You

3+ years of experience, or equivalent demonstrated accomplishments in designing efficient and scalable data pipeline architectures.
BA/BS in a quantitative discipline such as Statistics, Mathematics, Data Science, or Computer Science
Demonstrated success working between disparate data systems, building using software engineering best practices (high test coverage, code reviews, test automation).
Comfortable with cloud services and technologies that support data storage, pipelines, manipulation, orchestration, and telemetry.
Proficiency in SQL, ETL, data warehousing, Python and PySpark.
Enjoy working in a fast-paced environment while learning new technologies.
Have experience in communicating with stakeholders of a diverse nature, including Sales and Customer Support.


Bonus Points

MA/MS preferred. Experience can be substituted for a degree if appropriate.
Experience supporting machine learning models in production.
Experience working with Databricks and Distributed Big Data Computing environments.
Passionate about working in the restaurant technology space.


About Us:

At Brightloom, we are working to create meaningful relationships between people and the brands they love. Our Customer Growth Platform (CGP) offers a first-of-its-kind SaaS approach to automated AI-driven, predictive personalization. Previously, these types of capabilities were exclusive to larger brands who have entire teams of people focused on marketing and customer analytics. The CGP is built upon proprietary models that show and tell brands what to do next, so they don't have to hire teams to build models, guess at rules, run experiments, and then interpret the results. The CGP models do this work, so the marketer doesn't have to. We're obsessed with taking something that's really hard, complicated, and expensive and turning it into a service that's simple and affordable for all consumer brands, not just industry leaders.

What We Offer:

Fun, creative and collaborative remote work environment
Wellness Wednesday- weekly afternoon of flex time to be offline/meeting free
Frequent remote and in-person events to keep you connected, including all company gatherings (fun, multi-day destination events) three times a year.
Competitive pay and equity/stock options
Health, Dental & Vision Insurance Coverage
Pet Insurance
Life Insurance, Short-Term Disability, Long-Term Disability
Phone/Internet Reimbursement
Home Office Refresh Reimbursement
Employee Assistance Program
Flexible Spending Account & Health Savings Account
Flexible Time Off + 14 company-paid holidays
401(k)


Building a diverse and inclusive workplace is a core tenet of our culture. Brightloom is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans status or any other characteristic protected by law.
Show more Show less"
2823997591,Data Engineer,Engage3,2021-12-02,United States,"Sacramento, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","As a Data Engineer at Engage3, you will be part of a technical team that architects, builds, maintains, scales, monitors, administrates and secures Engage3’s retail pricing platform. You will actively work in a multi-disciplinary fast-paced environment. Your ultimate goal is to create a solid, flexible, stable system that enables us to deliver best-in-class analytics products to retailers and brands in the face of massive growth.

This role requires a broad range of skills and abilities; you will be the functional lead, manage staff and do the work. Your primary responsibility is to enable data access, data processing and data products by architecting, maintaining, scaling, monitoring & securing.

ML production system (AWS, Azure, Python)
Data Warehouse (Snowflake)
ETL system & data pipelines
BI system (Tableau Online)
PostgreSQL Database

As a Qualified Applicant

You have 3-5 years of experience as a Data Engineer
You have planned, built & managed data infrastructures in a public cloud
You have strong experience with working with tools & platforms within the AWS ecosystem (EC2, S3, Aurora, Lambda, API Gateway, etc)
You have strong experience with working with tools & platforms within the Azure ecosystem
You have in-depth experience with PostgreSQL databases and Snowflake’s data warehouse
You have managed a business intelligence system
You have demonstrated experience of ETL developments
You are proficient in at least one programming language like Python, Scala and Java
You are comfortable with setting and meeting SLAs for data availability and quality
You have an understanding of Machine Learning / AI principles in data engineering
You are a mentor to your team & colleagues and have passion in sharing your knowledge
You’ve worked in an Agile environment. You thrive on iteration. You make opportunities to bring value sooner rather than later.
You value data-driven decisions. You are always looking for opportunities to quickly produce the right data to make decisions quickly. You keep cool under pressure.
You are a self-driven, highly motivated technologist who can work with a high degree of autonomy, is able to prioritize effectively and drive the data architecture vision.

Engage3 was founded by the creators of KhiMetrics (acquired by SAP), who are credited with inventing the retail price optimization space. Engage3’s leadership team is composed of former KhiMetrics, SAP, Revionics, dunnhumby, KSS Retail, and IBM/DemandTec executives.

Engage3’s Price Image Management SuiteTM helps retailers understand and manage their Price Image and align it with their sales and profitability objectives using predictive modeling. The suite includes Competitive Intelligence Management (CIM) - an AI-assisted, attribute-based, and data science-driven solution that provides accurate, granular competitive data (30 billion product pricing records collected annually in the U.S. and Canada) and like-item-linking visibility. CIM helps retailers reverse-engineer their competitors’ pricing and assortment strategies across channels, markets, and items. Also included in the suite is Price Image Optimization (PIO) - a next generation pricing solution that defines the impact of strategic pricing alternatives and unlocks pricing recommendations based on a retailer’s objectives for Price Image, sales, and profitability.

If you express interest in this role, please check your filtered emails in case our questionnaires get sent there. The email will come from Engage3-Breezy**.
Show more Show less"
2808119348,Data Engineer,Deckers Brands,2021-11-25,United States,"Dallas, TX",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2816360961,Data Engineer,Cygnus Professionals Inc.,2021-11-30,United States,"Fort Lauderdale, FL",,Contract,,"** 3-4 years’ Experience in Azure, ADF, Snowflake, Databricks and Experience in Dev Ops as well
Show more Show less"
2825066084,Data Engineer,ETalentNetwork,2021-12-02,United States,United States,,Contract,,"ONLY W2 ROLE.----
W2 ROLE
NO C2C ---------
Experience with GitLab or Jenkins
• Experience with Neo4j Graph databases
• Experience building data models
• Experience in building ETL workflows to cleanse, transform, and store data
• Experience building Tableau dashboard visualizations
• Experience with HANA, Oracle, MySQL
• Strong understanding of data virtualization
• Strong problem solving, conceptualization, and communication skills
• Demonstrates willingness to learn, self-starter, and dependable
Show more Show less"
2790494120,Data Engineer,Fooda,2021-10-14,United States,"Chicago, IL",Information Technology,Full-time,IT Services and IT Consulting and Food and Beverage Services,"Who We Are

We believe a workplace food program is something employees should love and look forward to every day. Powered by technology and a network of over 2,000 restaurants, Fooda feeds hungry people at work through our ongoing food programs located within companies and office buildings. Every day, each Fooda location is served by different restaurants that come onsite and serve fresh lunch from their chef’s unique menus. Fooda operates in over 20 major US cities and plans for continued expansion.

About The Team

Our Data Science & Analytics team is changing the way Fooda uses data. Do you want to get in on the ground floor of an analytics team at a high growth startup? The company has placed a huge strategic focus on building out our data science and analytics capabilities and you will be core to this growth. The team is responsible for all reporting & analytics for the company partnering closely with Product, Engineering, Sales, Marketing, Finance, and Operations to drive innovative analytic solutions.

Will you join us?

Position Opportunities And Responsibilities

As a Data Engineer, you will work on the Data Science and Analytics team to drive and evolve the analytics solutions and data systems at Fooda. You will contribute to analytics decision making, analysis, and data integration to enable Fooda to become a world-class data driven organization.

Responsibilities

Leverage Python and SQL to integrate and analyze data from internal and external systems that drive key business decisions throughout the organization
Govern, analyze, and own data that drives stakeholders’ perception of the organization, which involves diving in, addressing questions, and perform root cause analysis of issues that arise within the data
Develop ETL pipelines and data quality auditing systems using Airflow, Python, and SQL to create a cohesive, automated, and accurate data environment
Assist in requirements gathering, design, and development of complex data systems that collect, analyze, and measure data throughout all business units

Basic Qualifications

2+ years of experience working in data engineering, business intelligence, or engineering
Experience analyzing and integrating data using Python and SQL to extract and transform data according to business rules and requirements
Extensive knowledge and experience working with large scale data warehouse, web APIs, and database platforms to integrate internal and external data sources
Attention to detail and the ability to think critically and solve problems using analytical and quantitative methodologies
Strong oral/written communication skills, specifically the ability to communicate and translate difficult analytical problems to stakeholders with minimal analytics background
Ability to work effectively in a high paced environment

Preferred Qualifications

Bachelor’s Degree in a quantitative field such as Information Systems, Computer Science, Statistics, or Mathematics
Demonstrated ability to manage complex technical projects: work prioritization, planning, task delegation and hitting deadlines
Experience with programing/scripting languages and data science tools (Airflow, Python, Java, Spark)
Experience diving into data quality and data profiling analysis to ensure data consistency and accuracy across enterprise reporting
Experience with AWS tools and infrastructure to build and maintain a robust data warehouse

The safety and wellbeing of our employees and customers is a top priority. Fooda has a COVID-19 vaccination policy requiring all employees to be vaccinated against the disease. All hired candidates are required to submit proof of vaccination as a condition of employment. Fooda will consider accommodations for disability- or religious-based reasons.
Show more Show less"
2817127998,Data Engineer,SEI Novus,2021-12-02,United States,"Austin, Texas Metropolitan Area",,Full-time,,"Our Mission

Novus serves capital allocators and managers, helping them enrich and manage their data, extract actionable investment insights, and improve stakeholder communication via visualization and automation. We strive to be the center of the institutional investment ecosystem, where the world’s investors gather to manage their portfolios and engage with one another.

Over $120 trillion is invested annually on behalf pensions, endowments, sovereign funds, private investors, and family offices. Unfortunately, many of these institutions are using outdated and disconnected tools to manage their portfolios. Novus offers comprehensive solutions for multi-asset class portfolio. By providing a single platform that streamlines data processes, quantifies investment skill, uncovers bias, and helps investors plan more accurately, we are helping investors amplify their impact.




Our Values

We expect our team members to deliver on their responsibilities and understand how each and every component of our company works to generate our collective success. We hold ourselves and our colleagues accountable to the highest standards.

If the following sounds like you, we look forward to getting to know you—

You're looking to join a fast-paced team that will mentor and support you as you take on challenging projects.
You have a “team first” mentality and enjoy helping others achieve their own goals.
You understand that deadlines and goals – even if self-imposed – are what help businesses succeed.
You appreciate direct, unvarnished feedback – you know it will help you grow.
The thought of deploying code to production several times day excites you. You know it’s better to ""fail fast"" than to never ship at all.
You enjoy mastering your craft, but also love learning about technologies and tools outside your core expertise.
You don't take yourself too seriously and know the importance of bringing some levity to an otherwise tense situation.




What You’ll Do

As a Data Engineer, you will be help us build and iterate on our industry leading ETLs and Data Processing Frameworks. We are open to this person being based in Austin, NYC, or Zurich. You’ll be directly responsible for delivering a large project and will need to coordinate resources across several teams to accomplish your goals. You will:

Own the entire development lifecycle including writing of specification with the product team, architecture, work estimation, implementation, testing, releasing, and maintaining enterprise grade software.
Uphold high quality standards through technical guidance, leadership, and mentoring.
Apply industry best practices for database and ETL development.




Critical Skills / Abilities

3+ Years of ETL development or other enterprise data processing experience.
Excellent organization skills and an ability to self-organize.
Ability to architect complete data systems leveraging existing and novel technology.
Ability to exercise discretion and independent judgment within known contexts.
Have led multiple large-scale project from inception to completion.
Proficiency in SQL

Additional skills that we would love to see but are not required:

Proficiency in Scala
Kubernetes or a similar orchestration tool.
AWS or a similar public cloud.
Continuous Delivery using a build tool such as Bamboo.
Personal interest in finance
Knowledge on definitions and parameters of financial instruments like options, bonds, futures, and swaps.
Show more Show less"
2784782857,Data Engineer,CrowdStreet,2021-11-30,United States,"Austin, TX",Engineering and Information Technology,Full-time,Financial Services and Leasing Real Estate,"Data Engineer: BUILD SOMETHING MEANINGFUL




Role Summary:

The data team is committed to storing and curating all of the information we’ve collected, finding new and valuable data points to acquire, and stitching it all together for the business and our customers. As our newest data engineer, you’ll be a leader in acquiring, cleaning, transforming, and governing the data, and implementing processes and methods to improve our efficiency, reliability, and cost-effectiveness. From deciding on how to bring in a new data set, whether by API, S3 Bucket, or HTML page, to managing the frequency of its ingress, and testing its validity, this role will be an excellent opportunity to help grow this team within a rapidly expanding organization.




The Success You’ll Build: Primary Responsibilities and Impact

As a part of a rapidly growing data team, you will collaborate with data analysts and data scientists to acquire, transform and govern various data sets, and make them useful for deep analysis, modeling, and forecasting. You’ll build the transformations to turn raw data into something meaningful, to connect it to other data sets, as well as maintain and improve our governance layer in LookML. You’ll be working at all levels of the data warehouse stack, from processing raw files in S3, to accessing a variety of API endpoints, to transforming this data into the facts and dimensions in Snowflake.




You’ll also oversee the ingress of new data sets into Looker’s data layer, both creating your own models, and collaborating with our analysts to review pull requests and assist with adding new dimensions and measures to our expanding model.




Your focus in this role will include:

Identifying and acquiring new data, using integration tools, Python, and AWS services for automation.
Analysis and transformation of raw data into fact and dimension tables in Snowflake DB, using both dbt and Stitch.
Writing SQL to aggregate, associate, and stitch data sets together for our data scientists and analysts' consumption.
Managing Looker’s LookML layer, reviewing pull requests for changes and additions to the existing model.
Collaborating with data scientists and backend engineers to productize machine learning models.
Interfacing with engineering to track application database changes and additions, and incorporating new data points into the DW stack.
Finding ways to optimize performance, reduce compute costs and improve testing and data validation processes.




The tools you’ll use | Our Stack:

Snowflake
Stitch & dbt for ETL
Looker
AWS - DMS, Glue, EC2, ECS, Lambdas, S3
Python




The experience that will help you succeed:

You’ve spent at least 3 years working in a data warehouse stack, stitching and transforming various data sets, writing SQL, and creating great schemas for data scientists, data analysts, and business users. Other relevant experience may include:




Working with business stakeholders, product managers, and developers to build specifications for new data sets needed to enhance business processes.
Comfortable working with Looker, specifically managing, maintaining, and validating the LookML layer.
Understanding how to build data sets for both machine learning models and rich visualizations.
Familiar and comfortable creating, updating, and reviewing Python code leveraging for automating data ingress.
Capable of understanding and ultimately simplifying data from complex OLTP schemas into star and snowflake data warehouse schemas.
Comfortable working in a cloud-native AWS environment.

The What | Technical/Functional:




SQL: understanding existing SQL and writing new SQL for transformations, aggregations, and time-series analysis.
Operating and maintaining data warehouses, ideally Snowflake.
Ability to build automation to acquire and process raw data and bring it into Snowflake.
Managing and maintaining data governance and modeling layer, ideally LookML.




The How | Values:

Respect
Collaboration
Impact




Crowdstreet Benefits and Perks

BE HEALTHY, BE HAPPY

We support the health of our employees and families through our Medical, Dental, and Vision plans which include HSA and FSA options.




TAKE A BREAK

We offer a Flexible Time Off policy to encourage you to take a break when needed. Our policy also provides time off for you to volunteer and parental leave to support your growing family.




WORK WHERE YOU WORK BEST

We know that great work can happen anywhere which is why we offer a hybrid work model. Work from home, anywhere in the continental U.S., from one of our offices (Portland, OR or Austin, TX), or some combination of the two.




CROWDSTREET EQUITY

We provide stock option grants for all of our new employees to keep you connected to the ongoing success of our company.




HOW YOU WORK

We're providing all of our employees with a monthly stipend to use for your home office needs or support how you choose to commute to the office. Need something else to do your job? Our People Ops team can help!




BUILD YOUR CAREER

We supply a monthly stipend for your continuous learning and development. Is there a course you’ve always wanted to take? A certification you’ve wanted to achieve? A conference you’ve wanted to attend? Work with your manager to tee it up!




Working at CrowdStreet

CrowdStreet is the leading online marketplace for institutional-quality commercial real estate investment. Our customer, the individual investor, joins the CrowdStreet community to learn about and invest directly in private real estate offerings. Our mission is to deliver the best online real estate investing experience and make it easy for individual investors to diversify their portfolios.




CrowdStreet has been recognized as a leader in the commercial real estate and technology spaces. Recent accolades include:

Forbes Top 500 Best Startup Employer
Deloitte Technology Fast 500
2020 Top Places to Work, The Oregonian
2020 Oregon Technology Awards Accelerate Company of the Year
#5 for ""Fastest-Growing Private Companies in Oregon & SW Washington"" by the Portland Business Journal.




We are proud to support ‘Work Where You Work Best’ and are enthusiastically adding to our team throughout the US. We also offer two locations (AUS and PDX) for those who work best in an office.

At CrowdStreet, inclusion, equity, and diversity are critical in achieving our goals. Our differences in age, race, gender, nationality, sexual orientation, physical ability, thinking style and background bring a breadth of knowledge that makes us collectively smarter and better able to compete. We are committed to recruiting, developing, and advancing a diverse staff and engaging in the hard work that makes that possible.

Show more Show less"
2820774955,Data Engineer,Diamondpick,2021-12-03,United States,United States,,Contract,,"Title: AWS Data Engineer
Location: Remote
Hiring Mode: Contract

Responsibilities
• Primary objective is to increase collaboration and communication between engineering teams.
• Define interactions (Messages/events and batch data) between applications.
• Implement controlled vocabulary through standards adoption.
• Define Best Practices for holistic Data Management/Governance.
• Responsible and Accountable for managing schemas for both Intra-Domain and Inter-Domain messages and data.
• Own Logical, Physical and Communication Models.
Qualifications
• Bachelor’s degree in computer science or MIS related area required or equivalent experience
• Strong knowledge and understanding of distributed data warehouse concepts
• Experience with modelling for Snowflake, document DBs like Dynamo, Elastic Search indexes.
• Experience with working closely with product partners to define the data fabric.
• Willingness and ability to learn new tools and technologies required
• Excellent verbal and written communication skills
• Ability to work well in a team environment, meet deadlines, demonstrate good time management, and multi-task in a fast-paced project environment

Additional Qualifications Considered
• Banking and/or financial services experience desired, but not required
• Knowledge and ability with both relational and dimensional data models required
• Detailed-oriented with a proven history as a self-starter who can work independently with minimal supervision
• Strong oral presentation and written communication skills
• Outstanding organizational and effective time management skills
• Ability to obtain, analyze and synthesize information from multiple sources
• Excellent problem-solving, analytical and critical thinking skills
reach me on 302 330 7931
Show more Show less"
2826967479,Data Engineer,Radancy,2021-12-04,United States,"Thornton, IL",Information Technology,Full-time,Computer Software,"Radancy's Data Engineering team is seeking a motivated Data Engineer to build data products and services. The Data Engineering team works on data services across product organizations within Radancy and supports building a customer facing data visualization product. Team also supports an enterprise grade recruitment platform focusing on talent acquisition and job opportunity exploration. The team has extensive experience in ETL development, works with large scale data in real time, and collaborates with other engineering teams across the organization. Build and maintain ETL pipelines, Automated workflows, Data products and services, Reporting Suite etc. using latest technologies and tools i.e. Python, Docker, SQL Server, BigQuery, PostgreSQL, Airflow, Luigi, Tableau, ASP .NET, RabbitMQ, Kafka and many others Work with Cloud Computing Platforms (GCP/AWS), ETL Orchestration tools(Luigi/Airflow), and other advanced open-source technologies Data modeling, schema design, and SQL development Ingest and aggregate data from both internal and external data sources to build our world class datasets Develop and lead the testing and fixing of new or enhanced solutions for data products and reports, including automating ETL testing Collaborate with Product Owner and domain experts to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation Assist with the development and review of technical and end user documentation including ETL workflows, research, and data analysis Work with Product team to define data collection and engineering frameworks Build monitoring dashboards and automate data quality testing Own meaningful parts of our service, have an impact, grow with the company 3+ years of Python, SQL, and ETL development Experience with at least one - Client Facing Product or Services or Reporting suite Strong Understanding of ETL pipeline, data lakes and data warehouse development Exposure to at least one cloud computing platform (GCP/AWS/Azure), and cloud data warehouse (BigQuery/Redshift) Experience delivering applications that run in a containerized environment is a plus Basic knowledge of Machine Learning, ML Pipelines and tools is a plus Some experience with any of these is a plus - NLP, MLOps, DataOps, tensorflow/keras/pytorch Exposure to agile methodologies and particularly scrum Experience working with large datasets for several organizational units internally as well as externally is a huge plus Enthusiastic about working with and exploring new data sets Detail oriented, strong communicator, quick thinking and acting with minimal supervision Bachelor's degree in related area (Computer Science, Information Systems, Engineering) or an equivalent combination of education and experience Join the global leader in talent acquisition technologies that's committed to finding new ways to leverage software, strategy and creative to enhance our clients' employer brands - across every connection point. We're looking for unconventional thinkers. Relentless collaborators. And ferocious innovators. Talented individuals who are ready to work towards solutions that transform the way employers and job seekers connect. Radancy is an equal opportunity employer and welcomes all qualified applicants regardless of race, ethnicity, religion, gender, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. We actively work to create an inclusive environment where all of our employees can thrive.
Show more Show less"
2826964921,Data Engineer,Radancy,2021-12-04,United States,"Kenilworth, IL",Information Technology,Full-time,Computer Software,"Radancy's Data Engineering team is seeking a motivated Data Engineer to build data products and services. The Data Engineering team works on data services across product organizations within Radancy and supports building a customer facing data visualization product. Team also supports an enterprise grade recruitment platform focusing on talent acquisition and job opportunity exploration. The team has extensive experience in ETL development, works with large scale data in real time, and collaborates with other engineering teams across the organization. Build and maintain ETL pipelines, Automated workflows, Data products and services, Reporting Suite etc. using latest technologies and tools i.e. Python, Docker, SQL Server, BigQuery, PostgreSQL, Airflow, Luigi, Tableau, ASP .NET, RabbitMQ, Kafka and many others Work with Cloud Computing Platforms (GCP/AWS), ETL Orchestration tools(Luigi/Airflow), and other advanced open-source technologies Data modeling, schema design, and SQL development Ingest and aggregate data from both internal and external data sources to build our world class datasets Develop and lead the testing and fixing of new or enhanced solutions for data products and reports, including automating ETL testing Collaborate with Product Owner and domain experts to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation Assist with the development and review of technical and end user documentation including ETL workflows, research, and data analysis Work with Product team to define data collection and engineering frameworks Build monitoring dashboards and automate data quality testing Own meaningful parts of our service, have an impact, grow with the company 3+ years of Python, SQL, and ETL development Experience with at least one - Client Facing Product or Services or Reporting suite Strong Understanding of ETL pipeline, data lakes and data warehouse development Exposure to at least one cloud computing platform (GCP/AWS/Azure), and cloud data warehouse (BigQuery/Redshift) Experience delivering applications that run in a containerized environment is a plus Basic knowledge of Machine Learning, ML Pipelines and tools is a plus Some experience with any of these is a plus - NLP, MLOps, DataOps, tensorflow/keras/pytorch Exposure to agile methodologies and particularly scrum Experience working with large datasets for several organizational units internally as well as externally is a huge plus Enthusiastic about working with and exploring new data sets Detail oriented, strong communicator, quick thinking and acting with minimal supervision Bachelor's degree in related area (Computer Science, Information Systems, Engineering) or an equivalent combination of education and experience Join the global leader in talent acquisition technologies that's committed to finding new ways to leverage software, strategy and creative to enhance our clients' employer brands - across every connection point. We're looking for unconventional thinkers. Relentless collaborators. And ferocious innovators. Talented individuals who are ready to work towards solutions that transform the way employers and job seekers connect. Radancy is an equal opportunity employer and welcomes all qualified applicants regardless of race, ethnicity, religion, gender, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. We actively work to create an inclusive environment where all of our employees can thrive.
Show more Show less"
2826965859,Data Engineer,Radancy,2021-12-04,United States,"Northbrook, IL",Information Technology,Full-time,Computer Software,"Radancy's Data Engineering team is seeking a motivated Data Engineer to build data products and services. The Data Engineering team works on data services across product organizations within Radancy and supports building a customer facing data visualization product. Team also supports an enterprise grade recruitment platform focusing on talent acquisition and job opportunity exploration. The team has extensive experience in ETL development, works with large scale data in real time, and collaborates with other engineering teams across the organization. Build and maintain ETL pipelines, Automated workflows, Data products and services, Reporting Suite etc. using latest technologies and tools i.e. Python, Docker, SQL Server, BigQuery, PostgreSQL, Airflow, Luigi, Tableau, ASP .NET, RabbitMQ, Kafka and many others Work with Cloud Computing Platforms (GCP/AWS), ETL Orchestration tools(Luigi/Airflow), and other advanced open-source technologies Data modeling, schema design, and SQL development Ingest and aggregate data from both internal and external data sources to build our world class datasets Develop and lead the testing and fixing of new or enhanced solutions for data products and reports, including automating ETL testing Collaborate with Product Owner and domain experts to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation Assist with the development and review of technical and end user documentation including ETL workflows, research, and data analysis Work with Product team to define data collection and engineering frameworks Build monitoring dashboards and automate data quality testing Own meaningful parts of our service, have an impact, grow with the company 3+ years of Python, SQL, and ETL development Experience with at least one - Client Facing Product or Services or Reporting suite Strong Understanding of ETL pipeline, data lakes and data warehouse development Exposure to at least one cloud computing platform (GCP/AWS/Azure), and cloud data warehouse (BigQuery/Redshift) Experience delivering applications that run in a containerized environment is a plus Basic knowledge of Machine Learning, ML Pipelines and tools is a plus Some experience with any of these is a plus - NLP, MLOps, DataOps, tensorflow/keras/pytorch Exposure to agile methodologies and particularly scrum Experience working with large datasets for several organizational units internally as well as externally is a huge plus Enthusiastic about working with and exploring new data sets Detail oriented, strong communicator, quick thinking and acting with minimal supervision Bachelor's degree in related area (Computer Science, Information Systems, Engineering) or an equivalent combination of education and experience Join the global leader in talent acquisition technologies that's committed to finding new ways to leverage software, strategy and creative to enhance our clients' employer brands - across every connection point. We're looking for unconventional thinkers. Relentless collaborators. And ferocious innovators. Talented individuals who are ready to work towards solutions that transform the way employers and job seekers connect. Radancy is an equal opportunity employer and welcomes all qualified applicants regardless of race, ethnicity, religion, gender, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. We actively work to create an inclusive environment where all of our employees can thrive.
Show more Show less"
2818564412,"Big Data Engineer _ Austin, TX",TekAck Consulting LLC,2021-11-29,United States,"Austin, TX",Business Development,Full-time,Computer and Network Security,"Hi,

Hope you're doing well,

TekAck have the new role of AWS Big Data Engineer _ Austin, TX. Please share your resume if that works for you.

Big Data Engineer

2 Openings

FTE / Contract Both Options are fine.

Location Austin, TX (Remote Start)

Video Interview.

Job Description

Extensive experience setting up core data pipeline services.
Extensive experience with BigData, Hadoop, Spark, Java, AWS.
Modeling experience in Amazon Redshift, and establishing an API layer for data access within and across Virtual Private Cloud (VPC).
Strong in AWS native services , GLU, Redshift. understanding of Python, PySpark, Apache spark , someone who can provide strategic thinking
Hands on guy who has created ingestion pipeline , worked on applying business transformation.

Experience

Yrs. Of Experience.

AWS

BigData (Hadoop, Spark)

Redshift

Python

PySpark

Virtual Private Cloud

Thanks,

Arun Chauhan

Mobile: +1 484 290 1431

Email: arun.c@tekack.org
Show more Show less"
2804666853,Data Engineer,Visa,2021-11-23,United States,"Foster City, CA",Other,Full-time,"IT Services and IT Consulting, Financial Services, and Consumer Services","Company Description

As the world's leader in digital payments technology, Visa's mission is to connect the world through the most creative, reliable and secure payment network - enabling individuals, businesses, and economies to thrive. Our advanced global processing network, VisaNet, provides secure and reliable payments around the world, and is capable of handling more than 65,000 transaction messages a second. The company's dedication to innovation drives the rapid growth of connected commerce on any device, and fuels the dream of a cashless future for everyone, everywhere. As the world moves from analog to digital, Visa is applying our brand, products, people, network and scale to reshape the future of commerce.

At Visa, your individuality fits right in. Working here gives you an opportunity to impact the world, invest in your career growth, and be part of an inclusive and diverse workplace. We are a global team of disruptors, trailblazers, innovators and risk-takers who are helping drive economic growth in even the most remote parts of the world, creatively moving the industry forward, and doing meaningful work that brings financial literacy and digital commerce to millions of unbanked and underserved consumers.

You're an Individual. We're the team for you. Together, let's transform the way the world pays.

Job Description

To ensure that Visa’s payment technology is truly available to everyone, everywhere requires the success of our key bank or merchant partners and internal business units. The Global Data Science group supports these partners by using our outstandingly rich data set that spans more than 3 billion cards globally and collects more than 100 billion transactions in a single year. Our focus lies on building creative solutions that have an immediate impact on the business of our highly analytical partners. We work in complementary teams comprising members from Data Science and various groups at Visa. To support our rapidly growing group we are looking for Data Scientists who are equally passionate about the opportunity to use Visa’s rich data to seek important business problems. You will join one of the Data Science focus areas (e.g., banks, merchants & retailers, digital products, marketing) with an opportunity for rotation within Data Science to gain broad exposure to Visa’s business.

The position is based at Foster City, CA or our other offices in the U.S.

Essential Functions

Create automated data ingestion pipeline with Spark, Python or other tools and provide scalable data engineering solution for Visa Consulting and Analytics
Understand credit card portfolio profitability and develop financial allocation and forecasting models, e.g. calculate NPV, net profit margin using P&L data
Ensure issuer data accuracy, integrity and consistency. Develop self-service reporting tools with financial critical metrics and facilitate issuer consulting engagements including data exchange
Assist in analytics and communication of key financial revenue driver trends and performance
Drive in-depth analysis to help issuers increase cardholder usage and engagement, providing data driven insights and meaningful recommendations to improve cardholder activation and usage
Develop custom data models and algorithms to apply to data sets
Use predictive modeling to increase and optimize customer experiences, revenue generation, data insights, and other business outcomes
Be an out-of-the-box problem solver who is passionate about brainstorming innovative ways to use our outstanding data to answer business problems
Connect with clients to understand the challenges they face and convince them with data
Extract and understand data to form an opinion on how to best help our clients and derive relevant insights
Develop visualizations to make your sophisticated analyses accessible to a broad audience
Find opportunities to craft products out of analyses that are suitable for multiple clients
Assess the effectiveness and accuracy of new data sources and data gathering techniques
Qualifications

Basic Qualifications

2 years of work experience with a Bachelor’s Degree or an Advanced Degree (e.g. Masters, MBA, JD, MD, or PhD)

Preferred Qualifications

2+ years’ experience in data-based decision-making or quantitative analysis
Master’s degree in Statistics, Operations Research, Applied Mathematics, Economics, Data Science, Business Analytics, Computer Science, or a related technical field
Extracting and aggregating data from large data sets using SQL/Hive or Spark
Analyzing large data sets using programming languages such as Python, R, SQL and/or Spark
Generating and visualizing data-based insights in software such as Tableau
Presenting data-driven insights and conveying meaningful recommendations
Leading and coordinating work in Office software such as Word, Excel, PowerPoint and/or Teams
Building predictive and descriptive statistical models using machine learning tool kit, Jupyter notebooks, Python, and/or SAS
Data mining and statistical modeling (e.g., regression modeling, clustering techniques, decision trees, etc.)
Previous exposure to financial services, credit cards or merchant analytics is a plus, but not required
Additional InformationVisa has adopted a COVID-19 vaccination policy to safeguard the health and well-being of our employees and visitors. As a condition of employment, all employees based in the U.S. are required to be fully vaccinated for COVID-19, unless a reasonable accommodation is approved or as otherwise required by law.

Work Hours: Varies upon the needs of the department

Travel Requirements: This position requires travel 5-10% of the time.

Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.

Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.

Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.

Job Number: REF33778F
Show more Show less"
2799663963,Data Engineer,Equifax,2021-10-26,United States,"St Louis, MO",Analyst,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","The Data Engineer – will be responsible for designing and developing our data and data pipeline architecture for AI applications. The data engineer will support our Business Analysts, Architects and Data Scientists on data initiatives and will ensure optimal data delivery architecture is consistent through ongoing projects. The candidate must be self-directed and comfortable supporting the data needs of multiple business units, systems and products, in addition to having great communication skills to capture requirements and conduct statistical analysis to understand data context.  What You’ll Do
Create and maintain data pipelines using the Google Cloud Platform using the following tools: Google Dataflow, PubSub, BigQuery and Cloud Storage (or their equivalent in other platforms such as AWS, Azure or Hadoop). 
Work with data scientists in building and optimizing our AI solutions for greater functionality in our data systems
Build analytics tools that utilize the data pipeline to provide actionable insights into operational efficienciesIdentify, design and implement process improvements: optimize data delivery and automate manual processes
Maintain data integrity and regionalization by defining boundaries through multiple GCP zones 

We offer comprehensive compensation and healthcare packages, 401k matching, paid time off, and organizational growth potential through our online learning platform with guided career tracks.

If this sounds like somewhere you want to work, don’t delay, apply today - we’re looking for you!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.


Primary Location:


USA-St. Louis-2330 Ball


Function:


Function - Data and Analytics


Schedule:


Full time
Show more Show less"
2808118469,Data Engineer,Deckers Brands,2021-11-25,United States,"New York, NY",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2822299707,Data Engineer,JobsInLogistics.com,2021-12-01,United States,"Tampa, FL",Information Technology,Full-time,"Construction, Staffing and Recruiting, and Truck Transportation","About Penske


Job Description:

Most people know us for our big yellow trucks. But we're so much more than that. At Penske we have a 50-plus year history of leading the transportation and supply-chain industry, delivering world-class and award-winning technology solutions and the key to our success is our people.

We are experiencing rapid business growth and have added headcounts to IT teams across the organization to keep up with this expansion. Going into Winter 2021/2022, we are hiring immediately for full-time, long-term roles. At Penske you will ensure our technology solutions keep our company and our customers moving forward.


What You Will Be Doing

As a Penske Associate Data Engineer I you will develop your technical skills and business acumen by participating in the effort to develop, enhance, and support existing and new data systems. You will take direction from our database architects, as well as collaborate with our data analysts and data scientists to ensure optimal data delivery consistent throughout ongoing projects. Learning from our diverse team of data engineering experts, you will have the opportunity to influence our data and analytics roadmap by constant interactions with various business and technology teams.

This position can sit out of our corporate headquarters in Reading, PA or our IT Center in Tampa, FL.


Penske Responsibilities

Formulate and define system scope and objectives as well as preparing detailed specifications
Prepare software test plans
Provide production/technical support to end users
Conduct discussions and/or meetings with end users
Perform project leadership role to complete high-level and technical systems design for new and enhanced systems
Proficient in Data Modeling, analytics and data governance
Build and Support Analytical, Data Engineering, Data Modeling and Data warehouse projects


Penske Qualifications

Bachelor's Degree in Computer Science/Computer Engineering or equivalent years of software development experience required
1 years exposure to Data Engineering, Data Modeling, and Data Warehousing required
Basic knowledge of SQL variants required, such as PostgreSQL, MySQL, Oracle, SQL Server, or DB2
Basic knowledge of the full lifecycle development cycle in a large complex environment required Basic knowledge of data visualization tools like PowerBI, Qlikview, Tableau or other Reporting Tools is preferred
Basic knowledge of AWS, Pivotal Cloud Foundry, Spring Cloud Data Flow, Gemfire, GreenPlum is preferred - Experience working in an AGILE environment preferred
Ability to work in a team environment and seek guidance on tasks from senior developers and leads.
Regular, predictable, full attendance is an essential function of the job
Willingness to travel as necessary, work the required schedule, work at the specific location required, complete Penske employment application, submit to a background investigation (to include past employment, education, and criminal history) and drug screening are required.


Physical Requirements

The physical and mental demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
The associate will be required to: read; communicate verbally and/or in written form; remember and analyze certain information; and remember and understand certain instructions or guidelines.
While performing the duties of this job, the associate may be required to stand, walk, and sit. The associate is frequently required to use hands to touch, handle, and feel, and to reach with hands and arms. The associate must be able to occasionally lift and/or move up to 25lbs/12kg.
Specific vision abilities required by this job include close vision, distance vision, peripheral vision, depth perception and the ability to adjust focus.

Penske is an Equal Opportunity Employer.


About Penske Truck Leasing

Penske Truck Leasing Co., L.P., headquartered in Reading, Pennsylvania, is a partnership of Penske Corporation, Penske Automotive Group and Mitsui & Co., Ltd. A leading global transportation services provider, Penske operates a premier fleet of vehicles and serves its customers from locations in North America, South America, Europe, Australia, and Asia. Penske's product lines include full-service truck leasing, contract maintenance, commercial and consumer truck rentals, used truck sales, transportation and warehousing management and supply chain management solutions. Visit www.GoPenske.com to learn more. #DICE
Show more Show less"
2808114808,Data Engineer,Deckers Brands,2021-11-25,United States,"Houston, TX",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2801445269,Data Engineer - Python (652),Techstars,2021-11-16,United States,"Boulder, CO",Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","As a Data Engineer, Network at Techstars you will be part of a high performing team building innovative software solutions for entrepreneurs worldwide. Techstars already has one of the largest portfolios in early stage venture capital, with over 2,300 portfolio companies, a combined market cap of more than $193B, and 12 unicorns. In this role, you will build backend streaming data pipelines, integrations with third party SaaS applications, complex analytics features and app facing platform data APIs. You will take part in architecture and solution design and help optimize solution performance and reliability. As a result you will help Techstars attract 10x more founders, and contribute directly to scaling the Techstars footprint to serve more entrepreneurs than ever before.

Location: Remote, (Americas)

What you will do:

As part of a team of engineers working in an agile environment you will build and deploy quality data ingest, cleansing, analytics and ML solutions
Ensure that all data and software solutions are secure, performant, reliable, observable and testable
Work with team members in a collaborative manner
Continuously improve the quality of the products and solutions delivered


What you bring:

A passion for building data solutions
A deep appreciation for dev/ops
Experience working with distributed systems and cloud infrastructure
Data engineering experience with ETL, streaming, data pipelines, cleansing and mastery
Diverse experience with languages (ie. SQL, Python, Node, Scala)
Experience working with a variety of relational and non-relational database systems (ie Postgres, MongoDB, Redis)
Experience with cloud based data visualization technologies (ie. Looker, Domo, Airtable)
Experience working in an agile development environment
Excellent communication and collaboration skills, a desire to learn and teach


Nice to have:

Experience in financial/investment data
Experience developing with containerization technologies (Docker, Kubernetes etc.)


Compensation range: $95,000 - $110,000 + 10% Bonus

US Benefits

About Techstars

Techstars is the worldwide network that helps entrepreneurs succeed. Founded in 2006, Techstars began with three simple ideas - entrepreneurs create a better future for everyone, collaboration drives innovation and great ideas can come from anywhere. Now we are on a mission to enable every person on the planet to contribute to, and benefit from, the success of entrepreneurs. In addition to operating accelerator programs and venture capital funds, we do this by connecting startups, investors, corporations and cities to help build thriving startup communities. Techstars has invested in more than 2,300 companies with a combined market cap of more than $29B.

Techstars' mission is to help entrepreneurs succeed wherever they are in the world and whatever their background is. Regional accelerator programs all around the world are the cornerstone of the strategy. The investment approach is fundamentally driven by the worldwide network of managing directors, who interact with startup founders daily, guiding, mentoring and cultivating them along the journey. The scale of this reach results in a diversified strategy that provides investors with a uniquely qualified deal flow.

We help Techstars founders connect with other entrepreneurs, experts, mentors, alumni, investors, community leaders, and corporations to grow their companies.

www.techstars.com

Techstars is an affirmative action, equal opportunity employer and does not discriminate on the basis of race, sex, age, national origin, religion, physical or mental handicaps or disabilities, marital status, Veteran status, sexual orientation, gender identity nor any other basis prohibited by law.
Show more Show less"
2825128636,Data Engineer,ClearScale,2021-12-03,United States,"Atlanta, GA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","ClearScale is a leading cloud system integration company and AWS Premier Consulting Partner providing a wide range of cloud services including cloud consulting, architecture design, migration, automation, application development, and managed services.

We help Fortune 500 enterprises, mid-sized businesses, and startups in verticals like Healthcare, Education, Financial Services, Security, Media, and Technology succeed with ambitious, challenging, and unique cloud projects. We architect, develop, and launch innovative and sophisticated solutions using the best cutting-edge cloud technologies.

ClearScale is growing quickly and there is high demand for the services we provide. Clients come to us for our deep experience with Big Data, Containerization, Serverless Infrastructure, Microservices, IoT, Machine Learning, DevOps, and more.

ClearScale is looking for an experienced Data Engineer to participate in a custom data pipeline development project.

Responsibilities:

Migrate data located in a multitude of data stores, into the Data Lake
Orchestrate processes to ETL that data, slice it into the various data marts
Manage access to the data through Lake Formation
Build a data delivery pipeline to ingest a high volume of the real-time streams, detect anomalies, slice into the window analytics, put those results in the Elastic search system for the further dashboard consumption
Analyze, scope, and estimate tasks, identify technology stack and tools
Design and implement optimal architecture and migration plan
Develop new and re-architecture solution modules, re-design and re-factor program code
Specify the infrastructure and assist DevOps engineers with provisioning
Examine performance and advise necessary infrastructure changes
Communicate with the client on project-related issues
Collaborate with in-house and external development and analytical team


Basic Qualifications:
Hands-on experience designing efficient architectures for high-load enterprise-scale applications or ‘big data’ pipelines
Hands-on experience utilizing AWS data toolsets including but not limited to DMS, Glue, Data Brew, EMR, SCT
Practical experience in implementing big data architecture and pipelines
Hands-on experience with message queuing, stream processing, and highly scalable ‘big data’ stores
Advanced knowledge and experience working with SQL and NoSQL databases
Proven experience in re-design and re-architecting the large complex business applications
Strong self-management and self-organizational skills
Successful candidates should have experience with any of the following software/tools (not all required at the same time):
Python and PySpark - strong knowledge especially with developing Glue jobs
Big data tools: Kafka, Spark, Hadoop (HDFS3, YARN2, Tez, Hive, HBase)
Stream-processing systems: Kinesis Streaming, Spark-Streaming, Kafka Streams, Kinesis Analytics
AWS cloud services: EMR, RDS, MSK, Redshift, DocumentDB, Lambda
Message queue systems: ActiveMQ, RabbitMQ, AWS SQS
Federated identity services (SSO): Okta, AWS Cognito

Preferred Qualifications:

We are looking for a candidate with 5+ years of experience in Data, Cloud, or Software Engineer role, who has attained a degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field
Usage of HUDI with AWS Data Lakes
Graph databases development and optimization 3+ years
Neo4j, SPARQL, GREMLIN, TinkerPop, Pregel, Cypher, Graph Databases, Amazon Neptune, Knowledge Graphs
Valid AWS certificates would be a great plus


Powered by JazzHR

eUxhy1Q4QH
Show more Show less"
2792737755,Data Engineer,Capital One,2021-11-13,United States,"Chicago, IL",Information Technology and Engineering,Full-time,"Banking, Financial Services, and Investment Banking","77 West Wacker Dr (35012), United States of America, Chicago, Illinois

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You’ll Do

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies

Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems

Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake

Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community

Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment

Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications

Bachelor’s Degree

At least 2 years of experience in application development

At least 1 year of experience in big data technologies

Preferred Qualifications

3+ years of experience in application development including Python, SQL, Scala, or Java

1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)

2+ years experience with Distributed data or computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)

1+ years experience working on real-time data and streaming applications

1+ years of experience with NoSQL implementation (Mongo, Cassandra)

1+ years of data warehousing experience (Redshift or Snowflake)

2+ years of experience with UNIX Linux including basic commands and shell scripting

1+ years of experience with Agile engineering practices

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Job Category - Engineering, Technology
Show more Show less"
2819071096,Data Engineer,Progrexion,2021-11-05,United States,"San Francisco, CA",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Progrexion and its affiliated companies, Lexington Law and CreditRepair.com, comprise the nation’s largest consumer advocacy network and employ over 1,500 people at locations throughout the Wasatch Front and in Idaho. Progrexion offers a full range of services with an emphasis in on-line and direct response marketing. Our creativity and drive stem from our relaxed office vibe and our amazing team of over-achieving, wicked-talented experts (Facebook.com/Progrexion). If you have the creativity and drive to work in a fast paced, dynamic environment, have excellent attention to detail and problem solving skills, and want to work in a strong team environment; it may be time to think about Progrexion.

We are passionate about improving, monitoring and protecting our clients' credit reports. We level the financial playing field for our clients through credit report repair so they can realize their financial dreams. As reported in USA Today, an independent research group found that 79% of all credit files in America contain some errors. The credit bureaus track approximately 250 million credit files and process over 4.5 billion updates annually. If 79% of those reports with errors means that over 185 million Americans are in need of our service! That's opportunity!

The Marketing team is looking for an outstanding Data Engineer to join its growing Data team. This individual will play a central role in one of our organization’s most highly visible divisions, helping to build, and maintain the data warehouse to guide strategic decisions of c-level executives and shape the way that we serve our customers. The Data Engineer will report to the Marketing Data Systems Director.

The Data Engineer will work closely with their Director as well as the analytics team to clean, create, and evaluate data related to key business questions. To this end, most of your time will be spent working within SQL Server and MySQL databases. You will be involved in supporting the wide range of analyses carried out by our group.

Responsibilities

Design and build data warehouses to support the production reporting and analytics needs of the marketing team.
Ensure data quality and availability for ongoing analytics projects.
Develop and maintain a query library to support recurring data requests.
Carry out ad-hoc data extracts and analyses as needed.
Help implement and deliver long-term data warehouse and production reporting projects.

Qualifications

Experience in SQL and ETL development.
Knowledge of Python a plus.
Attention to detail and overarching curiosity are both essential.
Willingness to learn new techniques and programming languages.
Responsible and reliable; able to set and meet deadlines.

IND123
Show more Show less"
2804185309,Data Engineer,Stratpharma,2021-10-24,United States,"Austin, TX",Engineering,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","We are looking for an experienced data engineer to join our team. You will use various methods to transform raw data into useful data systems. For example, you’ll create algorithms and conduct statistical analysis. Overall, you’ll strive for efficiency by aligning data systems with business goals. To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources. Data engineer skills also include familiarity with several programming languages and knowledge of learning machine methods. If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you.

Responsibilities

Analyze and organize raw data
Build data systems and pipelines
Evaluate business needs and objectives
Interpret trends and patterns
Conduct complex data analysis and report on results
Prepare data for prescriptive and predictive modeling
Build algorithms and prototypes
Combine raw information from different sources
Explore ways to enhance data quality and reliability
Identify opportunities for data acquisition
Develop analytical tools and programs
Collaborate with data scientists and architects on several projects


Requirements

Previous experience as a data engineer or in a similar role
Technical expertise with data models, data mining, and segmentation techniques
Knowledge of programming languages (e.g. Java and Python)
Hands-on experience with SQL database design
Great numerical and analytical skills


Benefits

Retirement Plan (401k, IRA)
Paid Time Off (Vacation, Sick & Public Holidays)
Work From Home
Stock Option Plan
Health Care Plan (Medical, Dental & Vision)
Show more Show less"
2758757222,"Data Engineer, Core Growth",Snap Inc.,2021-12-03,United States,"Seattle, WA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Snap Inc. is a camera company. We believe that reinventing the camera represents our greatest opportunity to improve the way people live and communicate. Our products empower people to express themselves, live in the moment, learn about the world, and have fun together.

We’re looking for a Data Engineer to join the Core Growth product engineering organization. Working from one of our west coast offices in Santa Monica, CA, Mountain View, CA, or Seattle, WA, you’ll collaborate with Software Engineers, Data Scientists, and Product Managers to help Snapchat grow across the globe. The Core Growth team is Snap’s growth engineering platform and its mission is to grow our community by promoting real friendships while they feel safe to express themselves, live in the moment, learn about the world and have fun together. The team builds and operates key products for user acquisition, activation, discovery, and retention at Snap such as registration and onboarding, friend recommendations, search, sharing, notifications, among others. In this role, you will build the data infrastructure and tools that will deliver insights to broaden and deepen user engagement and improve product experience for our hundreds of millions of passionate users. You will have an opportunity to tackle large-scale engineering and product challenges while working alongside kind, smart, and creative colleagues. Come grab a front row seat to witness and influence how Snapchat grows to become the world's camera!

What You’ll Do

Define data models for instrumentation and reporting in partnership with Engineering, Data Science, and Product Management to support product analytics.
Build scalable aggregation pipelines to deliver performant datasets that can be consumed through surfaces such as Looker, Tableau, Superset, and Jupyter.
Drive data quality end-to-end from instrumentation to reporting. Build automated controls and processes to prevent and fix regressions.
Democratize data access amongst engineers, PMs, and scientists with well-documented and extensible pipelines and datasets.
Partner with Snap’s Data Governance and Insights teams to make high-quality datasets in the Growth domain available for external and partner reporting.

Knowledge, Skills & Abilities

Experience in building data pipelines to serve reporting needs
Experience owning all or part of a team roadmap
Experience with data visualization tools like Looker and Tableau
Ability to prioritize requests from multiple stakeholders in disparate domains
Ability to effectively communicate complex projects to non-technical stakeholders

Minimum Qualifications

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
3+ year experience in SQL or similar languages
3+ years development experience in at least one object-oriented or scripting language (Python, Java, Scala, etc), Python preferred
Experience in ETL / Data application development

Preferred Qualifications

Hands on experience with Google BigQuery
Experience using and sharing notebook solutions like Jupyter
Experience in version control systems such as Git
Data architecture and warehousing experience
Experience with Airflow and Druid
Show more Show less"
2816172853,Technology Engineer (Data Engineer),PNC,2021-11-16,United States,"Chicago, IL",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Banking, and Financial Services","Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. We work together each day to foster an inclusive workplace culture where all of our employees feel respected, valued and have an opportunity to contribute to the company’s success.

As a Technology Engineer (Data Engineer) for PNC's Security Analytics Hub, you will have the opportunity to work fully remote. Our team focuses on producing data driven insights into multiple areas of risk facing the bank, including cybersecurity and physical security.

Day To Day Responsibilities

Acquire/map datasets that align with our business partner needs
Develop algorithms that shape data into useful and actionable information
Build, test, and maintain database pipeline architectures
Collaborate with management to understand and meet company objectives
Form new data validation methodologies and data analysis tools
Ensure continued compliance with data security policies and governance

Technical Qualifications

Education: BS/BA in technical discipline
5+ years of Python development
5+ years of experience with development/decomposition of complex SQL (RDMS Platforms)
3+ years of experience with test-driven development. Continuous Integration/ Development (e.g. GIT, Jenkins, Maven)
3+ years with CRON/Shell Scripting
Experience with utilization of REST API and/or EDPI
Hands on experience with project management tools such as JIRA, Confluence
Ability to work with end users (BI analysts, data scientists, etc.) to solve technical issues
Experience working in an Agile Team construct
Extensive knowledge of databases, data warehouses, systems integrations, and data flows is mandatory for this role.
Additionally, candidates should be well-versed in data architecture, data development, with a proven history of providing effective data solutions.

Required Skills To Be Considered For This Role

Coding: Proficiency in coding languages is essential to this role. Common programming languages used by the team include SQL, Python.
Relational and non-relational databases: You should be familiar with both relational and non-relational databases, and how they work (Teradata, Oracle, etc).
ETL (extract, transform, and load) systems: Moving data from databases and other sources into a single repository, like a data warehouse.
Data storage knowledge: As solutions are designed, when to use a data lake versus a data warehouse, for example.
Automation and scripting. Candidate should be able to write scripts to automate repetitive tasks (e.g. Cron jobs, Linux, shell scripting).
Big data tools: Understanding of Hadoop, MongoDB, and Kafka helpful, but not required.
Data security: Securely managing and storing data to protect it from loss or theft per PNC guidelines.

Job Description

Leverages technical knowledge and industry experience to design, build and maintain technology solutions. Assists with selecting appropriate platforms, integrates and configures solutions.
Develops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.
May provide consultation on common issues and best practices for junior staff.
Provides a systematic analysis on client requirements within the traceability framework and resolves any functional problems encountered.
Ensures quality of project deliverables while maintaining compliance with relevant standards and processes.

PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:

Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.

Competencies

Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.

Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.

Effectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.

Emerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.

Industry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.

IT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).

IT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.

Planning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.

Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Work Experience

Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

Education

Bachelors

Additional Job Description

COMPENSATION

Base Salary

$55,000 to $142,600

Role

Placement within the compensation range is based on the specific role and the following factors

Where a person is paid in the compensation range is aligned to their experience and skills.

– Lower in range –Building skills and experience in the job

– Within the range–Experience and skills align with proficiency in the role

– Higher in range –Experience and skills add value above typical requirements of the role

– Compensation Range may vary based on Geographic Location

INCENTIVE

Role is incentive eligible with the payment based upon company, business and individual performance.

Benefits

PNC offers employees a comprehensive range of benefits to help meet your needs now and in the future. Depending on your eligibility, options for full-time employees include medical/prescription drug coverage (with a Health Savings Account feature); dental and vision options; employee and spouse/child life insurance; short- and long-term disability protection; maternity and parental leave; paid holidays, vacation days and occasional absence time; 401(k), pension and stock purchase plans; dependent care reimbursement account; back-up child/elder care; adoption assistance; educational assistance and a robust wellness program with financial incentives. To learn more about these and other programs, including benefits for part-time employees, visit pncbenefits.com > New to PNC.

Disability Accommodations Statement

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.

The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO)

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.

California Residents

Refer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.
Show more Show less"
2808118456,Data Engineer,Deckers Brands,2021-11-25,United States,"Oakland, CA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2777988399,Big Data Engineer - PySpark,"Logic20/20, Inc.",2021-12-01,United States,"Seattle, WA",Information Technology,Full-time,Management Consulting,"This position is a remote opportunity.




In a nutshell...

Our Advanced Analytics team is looking for a PySpark Data Engineer to design and develop a scalable data processing infrastructure for our client in the utilities industry. You’ll work closely with our team of analysts, TPMs, and data scientists to enable data-driven decision making and build solutions that have a real-world impact on public safety, customer experience, and environmental protection.




At the same time, you’ll be joining a five-time Best Company to Work For, where super-smart, talented people come together to do outstanding work—and have a heck of a lot of fun while they’re at it. Because we’re a consulting shop with a diverse clientele, you can count on a steady stream of opportunities to work with cutting-edge technologies and different types of data on projects that make a real difference.




About you

You’re the perfect person for the job if you’re a big-data engineering ninja with …

A nose for uncovering business needs and pain points in partnership with executive management
A talent for communicating engineering concepts to non-techy business stakeholders
A passion for building large-scale machine learning pipelines
A knack for developing and iterating solutions at record speed




What you’ll be doing

Joining forces with internal and external teams to understand the client’s business needs
Designing and developing a scalable data processing infrastructure
Helping the client better understand their core needs, with a keen awareness of technical limitations.




Your qualifications

Strong understanding of high-performance ETL development with Python
5+ years of data engineering, 3+ years of PySpark
Data engineering implementation experience with some of the following technologies: Python, Spark and PySpark, Spark SQL
Advanced engineering skills with Python
Comfortable working with very large data
Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule
Strong communication and interpersonal skills
Ability to work both independently and as part of a team
Work across teams to solve technical roadblocks for our customers.
An undergraduate degree in technology or business is required




We'd be super impressed if you had...

Experience building data and computational systems that support machine learning
Knowledge of AWS services
Experience with modern software delivery practices, including source control, testing, continuous delivery
Experience delivering product with Agile methodologies
Experience with streaming data in Spark




About Logic20/20

Logic20/20 is one of Seattle’s fastest-growing consulting firms. We hire remarkable people to create simple, efficient solutions for complex problems.

Although we make it look like magic, our success is due to our approach (methodical and structured) and the people we hire (smart, motivated, and team-oriented). Together, these enable us to consistently exceed client expectations—and our reputation is growing.

For the past five years, we’ve placed in the top ten of Seattle Business magazine’s “Best Companies to Work For.” From engaged leadership and wide-ranging benefits to career mentorship and diverse internal opportunities, we pride ourselves on being one of the best companies to work with and work for.




We hire people that are self-motivated, comfortable conceiving strategies on the fly, and enjoy working individually and as part of a team. Our work is high-energy and demanding, but new hires will quickly feel at home among colleagues as friendly and focused as they are. We bring our best to every opportunity, driving change in industries across the West Coast. Join us and you can, too.

“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Director, Advanced Analytics




#LI-REMOTE

Show more Show less"
2799402264,Data Engineer 1,Dexcom,2021-11-18,United States,"San Diego, CA",Information Technology,Full-time,Medical Equipment,"Position Summary

We are seeking an entry level Data Engineer for our Data Engineers team within our R&D Data Platform function. In this role, you will help to design, develop, implement, oversee and adapt application interfaces. This role will entail 75% of hands-on development of daily activities and work collaboratively across functions.

Essential Duties & Responsibilities

Work with our Data Architect to build robust data pipelines for our Enterprise Environment via Java in a virtualized environment
Execute on technical requirements and document new ones when needed
Manage code via Github/Bamboo and work tasks within JIRA
Participate in on-call rotation for data pipeline support in a GCP environment
Support QA; diagnosing and resolving bugs
Participate in ongoing peer reviews and apply best practices for testing and deployment in an agile environment
Understanding the technical architecture of internally developed applications
Protect the confidentiality and security of client data
May take direction from another Engineer for related projects/activities.

Required Qualifications

Bachelor's degree in Computer Science, Information Systems, Mathematics or Engineering from an accredited academic university, or an equivalent combination of education and experience
Demonstrated experience and ability to develop in Java
Demonstrated experience supporting a Data pipeline Production environment
Knowledge of traditional programming and software development methodologies
Proven ability to learn new tools and technology
Demonstrated ability to work in a fast paced and changing environment with short deadlines, interruptions, and multiple tasks/projects occurring at once

Preferred Qualifications: (Optional, otherwise delete section)

Experience with Cloud (GCP/AWS) infrastructure deployments – application resource management in GCP environment(s)
Experience with GCP services (Dataflow/PubSub/Airflow/Spanner)
Experience with traditional data pipeline applications (Kafka/Spark/Casandra)

Functional Description

Establishes database management systems, standards, guidelines and quality assurance for database deliverables, such as conceptual design, logical database, capacity planning, external data interface specification, data loading plan, data maintenance plan and security policy. Documents and communicates database design. Evaluates and installs database management systems. Codes complex programs and derives logical processes on technical platforms. Builds windows, screens and reports. Assists in the design of user interface and business application prototypes. Participates in quality assurance and develops test application code in client server environment. Provides expertise in devising, negotiating and defending the tables and fields provided in the database. Adapts business requirements, developed by modeling/development staff and systems engineers, and develops the data, database specifications, and table and element attributes for an application.

Functional/Business Knowledge

Applies basic technical understanding with the knowledge to develop process and design experiments. Possesses theoretical knowledge, but is learning the industry and requirements of applied science. Understands organizational and functional processes and policies.

Scope

Demonstrates potential for technical proficiency. Works on problems of basic scope in which analysis of situation or data requires a review of data factors. Exercises judgment within defined procedures and practices to determine appropriate action.

Judgement

Follows standard practices and procedures in analyzing situations or data from which answers can be readily obtained.
Normally receives instructions on all work and work output it supervised.

Experience and Education

Typically requires a Bachelors degree in a technical discipline, and a minimum of 0-2 years related experience.

Workplace Type

The Workplace Type for this role is Flex. Based on the nature of your position you will be working onsite approximately 2-3 days per week from collaborative space and hoteling desks at our Dexcom sites. You will need to be located within commuting distance (typically 75 miles/120km) of your assigned Dexcom site.
Show more Show less"
2791845069,Data Engineer,IBM,2021-11-12,United States,"Phoenix, AZ",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $63,300 to $172,500 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2816537571,Data Engineer,Egen,2021-12-02,United States,"Naperville, IL",,Full-time,,"Egen is a data engineering and cloud modernization firm helping industry-leading companies achieve digital breakthroughs and deliver for the future, today. We are catalysts for change who create digital breakthroughs at warp speed. Our team of cloud and data engineering experts are trusted by top clients in pursuit of the extraordinary. An Inc. 5000 Fastest Growing Company 7 times, and recently recognized on the Crain’s Chicago Business Fast 50 list, Egen has also been recognized as a great place to work 3 times.




Our Data Platform Engineering teams build scalable data pipelines using Python and AWS, GCP, or Azure. The pipelines we build typically integrate with technologies such as Kafka, Storm, and Elasticsearch. We are working on a continuous deployment pipeline that leverages rapid on-demand releases. Our developers work in an agile process to efficiently deliver high value applications and product packages.




As a Data Platform Engineer, you will architect and implement cloud-native data pipelines and infrastructure to enable analytics and machine learning on rich datasets.




Required Experience:

Minimum of Bachelor’s Degree or its equivalent in Computer Science, Computer Information Systems, Information Technology and Management, Electrical Engineering or a related field.
You know what it takes to build and run resilient data pipelines in production and have experience implementing ETL/ELT to load a multi-terabyte enterprise data warehouse.
You have implemented analytics applications using multiple database technologies, such as relational, multidimensional (OLAP), key-value, document, or graph.
You value the importance of defining data contracts, and have experience writing specifications including REST APIs.
You write code to transform data between data models and formats, preferably in Python (Spark or PySpark is a bonus).
You've worked in agile environments and are comfortable iterating quickly.

Nice to have's (but not required):

Experience moving trained machine learning models into production data pipelines.
Expert knowledge of relational database modeling concepts, SQL skills, proficiency in query performance tuning, and desire to share knowledge with others.
Experience building cloud-native applications and supporting technologies / patterns / practices including: AWS/GCP/Azure, Docker, CI/CD, DevOps, and microservices.




Show more Show less"
2812059887,Data Engineer,Lockheed Martin,2021-10-30,United States,"Orlando, FL",Information Technology,Full-time,"IT Services and IT Consulting, Construction, and Computer Software","COVID-19 continues to significantly impact our employees, families and communities. With employee health and safety as our top priority, and as a federal contractor, Lockheed Martin is taking action to address the increased risk and uncertainty COVID variants pose in the workplace and ensuring we meet our commitments to national security.

As directed by Executive Order 14042: Ensuring Adequate COVID Safety Protocols for Federal Contractors, all current and newly hired employees, in the United States, are required to be fully vaccinated by January 18, 2022.

Description:The Data Engineer delivers full-stack data solutions across the entire data processing pipeline. This relies on systems engineering principles to design and implement solutions that span the data lifecycle to: collect, ingest, process, store, persist, access, and deliver data at scale and at speed. It includes knowledge of local, distributed, and cloud-based technologies; data virtualization and smart caching; and all security and authentication mechanisms required to protect the data.

Responsibilities

Build data pipelines that clean, transform, and aggregate unorganized data into databases or data sources that are ready for analysis
Design and implement data solutions by defining functional capabilities, security, back-up, and recovery specifications
Work through all stages of a data solution lifecycle, e.g., analyze / profile data, create conceptual, logical and physical data model designs, architect and design ETL, reporting and analytics
Maintain data systems performance by identifying and resolving production and application development problems; calculating optimum values for parameters; evaluating, integrating, and installing new releases
Define standards, best practices, and certification processes for data objects
Conduct performance tuning and optimization of data processing and storage
Write complex queries that can scale to meet requirements
Verification/validation that data solutions and/or system performance meets requirements
Document data definitions, dictionaries, and architectures
Define how data will be collected, what data will be needed, constraints to be considered

Basic Qualifications

Systems Engineering experience to include systems design, requirements, analysis, and management of complex systems over their lifecycles
Experience in design or development of enterprise data solutions, applications, and integrations
Knowledge of modern enterprise data architectures, design patterns, and data toolsets and the ability to apply them
Proficiency in data modeling techniques and understanding of normalization
Has software engineering experience
Strong problem solving, conceptualization, and communication skills
Degree in Computer Science, Systems Engineering, or related field

Desired Skills

Data APIs
Database systems (SQL and NO SQL)
Data modeling
Extraction, Transformation and Load (ETL) tools
Data Visualization Tools (Tableau, SSRS)
Database architecture
Languages: SQL, Python, XML, Shell Scripting

Job.Qualifications

BASIC QUALIFICATIONS:

Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.

As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.

Experience Level

Experienced Professional
Show more Show less"
2817330259,Data Engineer,Averity,2021-12-01,United States,United States ,Engineering and Information Technology,Full-time,Marketing and Advertising,"How would you like to be a Senior Data Engineer at a leading company who is a recent unicorn valued at $1.4 Billion in the AdTech space? Our mission is to deliver the best software and data solutions that enable advertisers to accurately measure and optimize their digital portfolios. The sky here is the limit with plenty of room for growth, competitive salary, and endless perks.




What's The Job?

As a Senior Data Engineer, you will be working cross functionally with several teams to create the future of Data in regard to measurement platforms. The role involves a modern tech stack, including Python, SQL, Spark, Kafka, Airflow, and Hive.




Who Are We?

We are a leading software and data company in the Measurement and Optimization for Advertisement space. We are overhauling the AdTech space, focusing on bringing together all sorts of audiences across different media platforms. Our goals are to increase ROI for advertisers and publishers while improving the consumer viewing experience.




What Skills Do You Need?

Experience building data pipelines and working with Big Data
Python, SQL
Spark, Databricks, Airflow, Hive
Bachelors in Computer Science or related field




Compensation:

$150,000 - $200,000 Base Salary
Full Benefits Package
401(k)
Fully Remote
Other perks




What's In It For You?

Here is the chance to join a fast growing tech team at a leading startup with the opportunity for accelerated growth paths, a competitive salary, and countless perks. We promote a fully remote environment and provide the option for those who like being on site to work from or NYC or LA offices! If you're looking to explore a new vertical where the potential is endless, look no further.

Show more Show less"
2758754329,Data Engineer,Snap Inc.,2021-12-03,United States,"Mountain View, CA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Snap Inc. is a camera company. We believe that reinventing the camera represents our greatest opportunity to improve the way people live and communicate. Our products empower people to express themselves, live in the moment, learn about the world, and have fun together.

We’re looking for a Data Engineer on our Analytics Engineering team! Working from one of our west coast offices in Santa Monica, CA, Mountain View, CA, or Seattle, WA, you’ll collaborate with teams across the organization (engineering, finance, sales, marketing, and strategy) to build pipelines and systems to deliver the data necessary for making the right decision in the moment. Our team strives to improve decision quality across the company by ensuring metrics are trustworthy, discoverable, and easily consumable.
What you’ll do:
Work closely with stakeholders in engineering, finance, sales, marketing, strategy, and governance to make high quality datasets available to consumers in a timely manner
Develop data pipelines adhering with privacy and governance principles
Become familiar with our data consumption portals and their capabilities
Build expertise and ownership of data quality for supported domains
Establish and implement data quality standards and controls
Build tooling and implement systems to overcome limitations of the data consumption portals when appropriate
Drive adoption of the data sets you’ve produced
Knowledge, Skills & Abilities:
Experience in building data pipelines to serve reporting needs
Experience owning all or part of a team roadmap
Ability to prioritize requests from multiple stakeholders in disparate domains
Ability to effectively communicate complex projects to non-technical stakeholders
Minimum Qualifications:
BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
3+ year experience in SQL or similar languages
3+ years development experience in at least one object-oriented or scripting language (Python, Java, Scala, etc)
Experience in ETL / Data application development
Preferred Qualifications:
Hands on experience with Google BigQuery
Experience in version control systems such as Git
Data architecture and warehousing experience
Experience leading a small team of data or software engineers
Experience with Airflow

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at accommodations-ext@snap.com .

_________________________________________________________________________________________________

For more information on what to include when writing your job description, please check out this resource: OFCCP | Job Description Template Details .
Show more Show less"
2820811441,Data Engineer,Cognizant,2021-11-30,United States,"Tampa, FL",Information Technology,Full-time,IT Services and IT Consulting and Management Consulting,"Not Applicable

Qualification

Not Applicable

Responsibility

Not Applicable

Must Have Skills

Apache Hadoop

Employee Status : Full Time Employee

Shift : Day Job

Job Posting : Nov 30 2021

About Cognizant

Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.

Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.

Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.
Show more Show less"
2818825609,Data Engineer - AWS,Tiger Analytics,2021-12-03,United States,"Dallas, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Management Consulting","Description

Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for multiple Fortune 500 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best global analytics consulting team in the world.

The Data Engineer will be responsible for architecting, designing, and implementing advanced analytics capabilities. The right candidate will have broad skills in database design, be comfortable dealing with large and complex data sets, have experience building self-service dashboards, be comfortable using visualization tools, and be able to apply your skills to generate insights that help solve business challenges. We are looking for someone who can bring their vision to the table and implement positive change in taking the company's data analytics to the next level.

Requirements

Bachelor’s degree in Computer Science or similar field
3+ years of experience in a Data Engineer role
Strong experience with advanced SQL
Experience with AWS cloud services: EC2, EMR, Athena
Experience with scripting languages: Python, Java, Scala, etc.
Experience extracting/querying/joining large data sets at scale
A desire to work in a collaborative, intellectually curious environment
Strong communication and organizational skills

Benefits

This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.
Show more Show less"
2808117856,Data Engineer,Deckers Brands,2021-11-25,United States,"Santa Barbara, CA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2817848660,Data Engineer,IBM,2021-11-29,United States,"Monroe, LA",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

tTtThe IBM Client Innovation Center in Baton Rouge is expanding and has immediate opportunities for experienced forward-thinking Data Engineer with a passion for growth and innovation. The success of IBM is in your hands as you transform vital business needs into innovation solutions to drive growth for our clients. Our clients are some of the world’s leading companies and you will be part of challenging projects to build and support technical solutions for their needs You will have access to the latest education, tools and technology, and a limitless career path with the world’s technology leader. Come to IBM and make a global impact!

The position of the Data Engineer plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. The Data Engineer defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business. Develops applications on Big Data and Cognitive technologies including API development. Expected to have traditional Application Development background along with knowledge of Analytics libraries, open-source Natural Language Processing, statistical and big data computing libraries. Strong technical abilities to understand, design, write and debug complex code.

The role of the Data Engineer is to work directly with the client using Pyspark,Scala, Hadoop, Hive and Postgre SQL. The Data Analyst must possess an understanding of the relational databases. The Data Engineer must also possess the skills to effectively collaborate with the client Subject Matter Experts (SMEs) to provide necessary solutions.

The successful candidates for this position will become members of our Client Innovation Team. You will work closely across the CIC network to delight our customers with leading edge solutions with a keen focus on quality and client satisfaction. In addition to strong collaboration across the team, you will be virtually integrated into our deep learning and knowledge program as well as employee engagement across NA. All resources in our CIC network may be requested to travel depending on specific client project needs. US Travel is typically related to knowledge transfer and client relationship building at the client site, as well as subsequent travel for key milestones or project initiatives. Travel is generally no more than 50% of the time. Preferred Locations: Lake Charles & New Orleans LA; Mobile AL; Pensacola FL; Gulfport, Hattiesburg, Jackson & Oxford MS; Beaumont & Galveston TX.

This position requires relocation to Louisiana within 30 days of the office reopening. This position requires up to 50% travel. This is not a permanent work from home position.

sprgg21

Required Technical and Professional Expertise

Minimum 3 Years Relevant Experience

Should have a strong knowledge on Pyspark, Scala, Hadoop,Hive and/or Postgre SQL

Preferred Technical And Professional Expertise

Unless specified as a Required Skill, the following are additionally preferred but not required:


Experience with big data solutions such as Hadoop, MapReduce, Hive, Pig, Kafka, Storm etc. is a major plus.


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2780070382,Data Engineer II,Mastercard,2021-11-21,United States,"Arlington, VA",Information Technology,Full-time,"IT Services and IT Consulting, Internet Publishing, and Financial Services","Our Purpose

We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.

Job Title

Data Engineer II

Role Description

The Data Engineer II will participate on data management aspects of client engagements to deliver Test & Learn and other D&S delivery solutions, as well as contribute to and foster a high-performance collaborative workplace. A Data Engineer II will:

Independently execute projects through design, implementation, automation, and maintenance of large-scale enterprise ETL processes for a global client base
Develop repeatable and scalable code that processes client data in an automated and efficient manner to ensure data availability in the platform is as real-time as possible.
Act as an expert data resource within the team
Manage the process of data delivery on teams by overseeing other Data Engineers and Analysts to deliver on-time, accurate, high-value, robust data solutions across multiple clients, solutions, and industry sectors
Build trust-based working relationships with peers and clients across local and global teams
Implement best practices and collaborate in the design of effective streamlined processes for a complex global solutions group
Leverage industry best practices including proper use of source control, code reviews, data validation and testing
Enhance big data pipelines using SQL, SSIS, Powershell and related technologies to address complex technical challenges and seamless communication with several cloud storage technologies
Leverage new SQL Server features such as Columnstore Indexes, In-Memory OLTP, Incremental statistics, Trace Flags, SQL CLR functions, window aggregate functions, and parallel computing algorithms to reduce the processing time of multi-billion row data sets
Contribute to the automation capabilities of the team. Implement techniques to optimize and routinize repeatable tasks for Test & Learn data setup
Comply with and uphold all Mastercard internal policies and external regulations


Minimum Job Requirements

Bachelor's degree in a quantitative field (e.g., Computer Science, Statistics, Econometrics, Engineering, Mathematics, Operations Research). Master's degree preferred
Excellent English quantitative, technical, and communication (oral/written) skills; is an excellent listener
Expertise and hands-on experience with RDBMS technologies, preferably with Microsoft SQL Server, the SSIS Stack and .Net
Proficiency with at least one scripting language (Powershell, Python)
Proven self-motivated leader with experience working in multiple teams spread across several geographies
Demonstrated excellent skills in the ability to innovate, think critically and disaggregate problems. Able to provide oversight, validation and quality control to own and team work product
Skilled at balancing multiple projects and differing project priorities
Flexible to work with global offices across several time zones


Relevant Fields Of Educational Study

Computer Science, Statistics, Econometrics, Engineering, Mathematics, Operations Research

Due to COVID-19, most of our employees are working from home. We’ve implemented a virtual hiring process and continue to interview candidates by phone or video and are onboarding new hires remotely. We value the safety of each member of our community because we know we’re all in this together.

Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.

If you require accommodations or assistance to complete the online application process, please contact reasonable.accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.

Corporate Security Responsibility

All Activities Involving Access To Mastercard Assets, Information, And Networks Comes With An Inherent Risk To The Organization And Therefore, It Is Expected That The Successful Candidate For This Position Must

Every person working for, or on behalf of, Mastercard is responsible for information security.

Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
Show more Show less"
2805949108,Sr. Big Data Engineer (Analytics),App Annie,2021-12-03,United States,"San Francisco, CA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","*YOU CAN WORK REMOTELY FROM ANY LOCATION AS LONG AS YOU ARE LOCATED IN PST/PDT OR MST TIME ZONE




Something about us

App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. More than 1,300 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business. We are a global company, headquartered in San Francisco but as a “remote” first company, we care about your results and not your location.

Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.




What can you tell your friends when they ask you what you do?




I am an experienced Big Data engineer who can create innovative new products in the analytics and data space. I participate in the development that creates the world's #1 app stores analytics service. Together with my team I build out new product features and applications using agile methodologies and open source technologies. I work directly with Product Managers, Software Architects, and I am on the front lines of coding new and exciting analytics and data mining products. I love what I do and excited to join an entrepreneurial company with a start-­up culture!




You will be responsible for and take pride in….

As a Big Data Engineer, you will be in charge of our data analysis projects and to build clean, robust and maintainable data processing program that can support these projects on huge amount of data, this includes:

Able to design and implement complex product components based on requirements with possible technical solutions.
Write data analysis and statistics programs using Pyspark with a commitment to maintaining high quality work while being confident in dealing with data mining challenges.
Discover any feasible new technologies lying in the Big Data ecosystem, share them to team with your professional perspectives.
Get up to speed in the machine learning domain, implementing analysis components in a distributed computing environment with instruction from Data Scientists.
Be comfortable conducting detailed discussions with Data Scientists regarding specific questions related to specific data models.
You should be a strong problem solver with proven experience in big data.

You should recognize yourself in the following…

Master's degree in Math or Computer Science and at least 2+ years of experience in Big Data Engineering.
Hands-on experience and deep knowledge of Hadoop ecosystem.
Knowledge and experience with PySpark, Mapreduce, HDFS, Linux, Storm, Kafka.
Proficient with programming in Python, experience in Pandas, Sklearn or Other data science and data analysis toolset is a big plus.
Having a background of data mining and machine learning domain, familiar with common algorithms and libs is a plus.
Passion for cloud computing (AWS in particular) and distributed systems.
You must be a great problem solver with the ability to dive deeply into complex problems and emerge with clear and pragmatic solutions.
Good communication, and cooperation globally.




This is what we offer…

We provide a $1,000 (country equivalent) WFH allowance to set you up for remote work success.
Remote working from anywhere in PST time zone! We are not office centric anymore and never will be.
90-days global passport. Work from anywhere in the world for 90 days a year!
Internet allowance for stable internet connection, so your video does not freeze on Zoom.
Flexible working days. We love to meet, but if you need to get your kids behind school-zoom, need to leave early to get to your band repetition or gym classes, do your thing.
Paid leave, so long as you promise to come back!
Health and dental benefits.
An international team of talented and engaged people from different cultural backgrounds and locations.
Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!
Unlimited access to online learning platform Udemy to help you develop your skills.
Virtual initiatives and events to keep you connected with your colleagues.
Generous Employee Referral Program. Up to $10,000 for specific roles.




Yes, I want this job!

Show more Show less"
2819407743,Data Engineer,Robin Healthcare,2021-11-30,United States,"Phoenix, AZ",Information Technology,Full-time,"Computer Software, Financial Services, and Hospitals and Health Care","Robin Healthcare is a tech-healthcare startup with a mission to transform our healthcare system from its very core: the doctor-patient encounter. We marry medical scribing with the Robin Assistant™, our proprietary smart device, to help streamline documentation, coding, and other administrative tasks in the background of natural patient care.

Why:

The purpose of this role in the short term is to prototype and build out the data sets, reports, KPIs and dashboards to operate Robin's business on the new Assist platform, with an explicit goal to democratize Robin's most widely-used data for teams outside the Data Science & Analytics group to consume. In the longer-term, this role will be responsible for analysis, insights, reports, and actionable recommendations for the most challenging business problems at Robin. This role will also provide strong technical guidance to other data analysts in the Data Science & Analytics group.

What You'll Be Doing:

Use data, logic, and intuition to improve business outcomes through analysis, insights, reports, and actionable recommendations
Develop democratized dashboards, data sets, and KPIs that empower less technical owners and operators across the business to make data-driven business decisions
Design durable and forward-looking data models and data sets for the Data Science & Analytics group to develop on and provide technical direction to other analysts
Partner with Product Management, Engineering, and Creative to condense feedback from users & customers, explore & experiment to (in)validate hypotheses, and measure the outcomes of product initiatives
Partner with Client Success and account managers to build creative tools and insights to increase provider and practice satisfaction, grow revenue, and communicate performance to our customers
Partner with Operations, Talent Acquisition, and Content to create diagnostic metrics and reveal opportunities to increase the satisfaction, efficiency, and performance of our scribe population


What You'll Bring:

Adept at distilling complicated analytical concepts to broad audiences and influencing decision making through compelling data narratives
Experience building clean visualizations and performant dashboards using Jupyter, Tableau, Looker, or similar software
Experience writing performant code in BigQuery SQL
Expert programming skills in one or more general purpose languages (Python, R, Scala, etc.)
Experience with statistical and machine learning methods to build descriptive and predictive models
Familiarity writing production ETL using data technologies that allow analysis of large amounts of data (Spark, Hadoop, Hive, Presto, etc)
Familiarity with a variety of business domains and their common data and analytics needs


Graduate-level degree or equivalent proven experience in a quantitative field such as mathematics, statistics, engineering or natural sciences

What We Offer

Amazing Mission - Break new ground in a stable, well-funded company and fix a broken healthcare system
Barrier Free Culture- No Micro-Management!! We Remove Bureaucracy and Empower Our People
Decide How and When You Work
100% Remote Work Environment OR WeWork Space Of Your Choice
Your Choice of Laptop (PC or Mac) and Home Office Setup Stipend
Flexible Schedule- Build Your Work Around Your Life
Generous Stock Options
Unlimited Vacation Time (Must Take At Least 2 Weeks and Shut Off Your Phone)
Great Benefits - Medical, Dental, Vision, Life, Disability, 401k, etc.
Paid Family Leave (Up To 16 Weeks)
Investment Into Your Career With Resourcing For Education And Development
Close, Fun, And Engaging Community
Work With Brilliant, Hard-Working, Caring People Daily
Netflix Watch Parties, Pilates/Yoga classes, Clubs & Social Events


Equal Opportunity Employer: Successful applicants must be eligible to work in the US (visa sponsorship is not provided at this time) and must be able to pass a pre-employment background test. Robin Healthcare is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

To request reasonable accommodation or if you need assistance to complete the job application, contact hiring@robinhealthcare.com
Show more Show less"
2818856809,Data Engineer,Personal Capital,2021-12-03,United States,United States,Information Technology,Full-time,Computer Software and Financial Services,"About The Job:




You will work with the Data and Analytics team to design, develop, test, and implement highly scalable data pipelines to facilitate data mining, analysis, reporting, operating performance, and integration of disparate systems.




You will create complex classifiers, predictive models and other machine learning techniques to provide insights and integrate analytic data with our applications. As a member of this team, you’ll collaborate with Data Architects, Data Scientists, Business Analysts and stakeholders to maximize the utilization of our rich set of data.




Requirements:

A Bachelor of Science degree in Computer Science or equivalent.
Two or more years experience with production level Java (preferred) or Python programming.
One or more years of experience writing complex SQL statements.
Exposure to building and maintaining Data Warehouse or Data Lake (preferably in Amazon Redshift).
Exposure to writing API code that interfaces with external systems and is processed through an ETL pipeline.
Exposure to ETL processes including dimensionalization, star and snowflake schema designs.
Experience with statistical analysis and tools such as R and/or Python.
Experience with data analytic visualization tools.
Exposure to machine learning techniques and classifier algorithms.

Show more Show less"
2816513506,Jr. Data Engineer,Wipro,2021-12-02,United States,"Seattle, WA",Engineering and Information Technology,Full-time,IT Services and IT Consulting,"· 3+ years of progressive responsibilities in one or more of the following areas: ETL/DAG design and implementation, data warehouse design and implementation, SQL and NoSQL query writing and tuning, and a bachelor’s degree; or 5+ years of the same experience without a bachelor’s degree

What are some preferred/nice to have skills the manager is looking for?

· 2+ years’ hands-on experience implementing and deploying modern data pipeline solutions including: Python, Airflow or similar tools, data design for warehousing, reporting, and transactional databases

· Experience with advertising terminology, reporting, and standards

· Familiarity with GCP, AWS or other cloud platforms

· Knowledge of and working experience with open-source software and cloud infrastructure components

· Agile development practical experience

· Experience using version control systems such as Subversion or Git
Show more Show less"
2807414487,Data Engineer,DoorDash,2021-11-25,United States,"San Francisco, CA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Data is at the foundation of DoorDash success. The Data Engineering team builds database solutions for various use cases including reporting, product analytics, marketing optimization and financial reporting. By implementing dashboards, data structures, and data warehouse architecture; this team serves as the foundation for decision-making at DoorDash.

DoorDash is looking for a Data Engineer to be a technical powerhouse to help us scale our data infrastructure, dashboards and tools to meet growing business needs.

What You Will Do

Work with business partners and stakeholders to understand data/reporting requirements
Work with engineering, product teams and 3rd parties to collect required data
Design, develop and implement large scale, high volume, high performance data models and pipelines for Data Lake and Data Warehouse.
Develop and implement data quality checks, conduct QA and implement monitoring routines.
Build and implement ETL frameworks to improve code quality and reliability
Build and enforce common design patterns to increase code maintainability
Manage reliability and scaling of portfolio of pipelines and data marts
Document new and existing models, solutions, and implementations
Mentor and coach team members to improve their designs and solutions

Qualifications

Hiring at various job and qualification levels.

10+ years of professional experience
7+ years experience working in data engineering, business intelligence, or a similar role
Proficiency in programming languages such as Python/Java
3+ years of experience in ETL orchestration and workflow management tools like Airflow, flink, Oozie and Azkaban using AWS/GCP
Expert in Database fundamentals, SQL and distributed computing
3+ years of experience with the Distributed data/similar ecosystem (Spark, Hive, Druid, Presto) and streaming technologies such as kafka/Flink.
Experience working with Snowflake, Redshift, PostgreSQL and/or other DBMS platforms
Excellent communication skills and experience working with technical and non-technical teams
Knowledge of reporting tools such as Tableau, superset and Looker
Comfortable working in fast paced environment, self starter and self organizing
Ability to think strategically, analyze and interpret market and consumer information

Why You’ll Love Working at DoorDash

We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies.
We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day.
We are learners - We’re not afraid to dig in and uncover the truth, even if it’s scary or inconvenient. Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute.
We are customer obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility.
We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.
We offer great compensation packages and comprehensive health benefits.

About DoorDash

DoorDash is a technology company that connects customers with their favorite local and national businesses in all 50 US states, Canada, and Australia. Founded in 2013, DoorDash empowers merchants to grow their businesses by offering on-demand delivery, data-driven insights, and better in-store efficiency, providing delightful experiences from door to door. By building the last-mile delivery infrastructure for local cities, DoorDash is bringing communities closer, one doorstep at a time. Read more on the DoorDash Engineering blog or www.doordash.com.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.
Show more Show less"
2816170960,Technology Engineer (Data Engineer),PNC,2021-11-16,United States,"Houston, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Banking, and Financial Services","Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. We work together each day to foster an inclusive workplace culture where all of our employees feel respected, valued and have an opportunity to contribute to the company’s success.

As a Technology Engineer (Data Engineer) for PNC's Security Analytics Hub, you will have the opportunity to work fully remote. Our team focuses on producing data driven insights into multiple areas of risk facing the bank, including cybersecurity and physical security.

Day To Day Responsibilities

Acquire/map datasets that align with our business partner needs
Develop algorithms that shape data into useful and actionable information
Build, test, and maintain database pipeline architectures
Collaborate with management to understand and meet company objectives
Form new data validation methodologies and data analysis tools
Ensure continued compliance with data security policies and governance

Technical Qualifications

Education: BS/BA in technical discipline
5+ years of Python development
5+ years of experience with development/decomposition of complex SQL (RDMS Platforms)
3+ years of experience with test-driven development. Continuous Integration/ Development (e.g. GIT, Jenkins, Maven)
3+ years with CRON/Shell Scripting
Experience with utilization of REST API and/or EDPI
Hands on experience with project management tools such as JIRA, Confluence
Ability to work with end users (BI analysts, data scientists, etc.) to solve technical issues
Experience working in an Agile Team construct
Extensive knowledge of databases, data warehouses, systems integrations, and data flows is mandatory for this role.
Additionally, candidates should be well-versed in data architecture, data development, with a proven history of providing effective data solutions.

Required Skills To Be Considered For This Role

Coding: Proficiency in coding languages is essential to this role. Common programming languages used by the team include SQL, Python.
Relational and non-relational databases: You should be familiar with both relational and non-relational databases, and how they work (Teradata, Oracle, etc).
ETL (extract, transform, and load) systems: Moving data from databases and other sources into a single repository, like a data warehouse.
Data storage knowledge: As solutions are designed, when to use a data lake versus a data warehouse, for example.
Automation and scripting. Candidate should be able to write scripts to automate repetitive tasks (e.g. Cron jobs, Linux, shell scripting).
Big data tools: Understanding of Hadoop, MongoDB, and Kafka helpful, but not required.
Data security: Securely managing and storing data to protect it from loss or theft per PNC guidelines.

Job Description

Leverages technical knowledge and industry experience to design, build and maintain technology solutions. Assists with selecting appropriate platforms, integrates and configures solutions.
Develops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.
May provide consultation on common issues and best practices for junior staff.
Provides a systematic analysis on client requirements within the traceability framework and resolves any functional problems encountered.
Ensures quality of project deliverables while maintaining compliance with relevant standards and processes.

PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:

Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.

Competencies

Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.

Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.

Effectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.

Emerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.

Industry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.

IT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).

IT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.

Planning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.

Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Work Experience

Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

Education

Bachelors

Additional Job Description

COMPENSATION

Base Salary

$55,000 to $142,600

Role

Placement within the compensation range is based on the specific role and the following factors

Where a person is paid in the compensation range is aligned to their experience and skills.

– Lower in range –Building skills and experience in the job

– Within the range–Experience and skills align with proficiency in the role

– Higher in range –Experience and skills add value above typical requirements of the role

– Compensation Range may vary based on Geographic Location

INCENTIVE

Role is incentive eligible with the payment based upon company, business and individual performance.

Benefits

PNC offers employees a comprehensive range of benefits to help meet your needs now and in the future. Depending on your eligibility, options for full-time employees include medical/prescription drug coverage (with a Health Savings Account feature); dental and vision options; employee and spouse/child life insurance; short- and long-term disability protection; maternity and parental leave; paid holidays, vacation days and occasional absence time; 401(k), pension and stock purchase plans; dependent care reimbursement account; back-up child/elder care; adoption assistance; educational assistance and a robust wellness program with financial incentives. To learn more about these and other programs, including benefits for part-time employees, visit pncbenefits.com > New to PNC.

Disability Accommodations Statement

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.

The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO)

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.

California Residents

Refer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.
Show more Show less"
2826047433,Data Engineer (Remote),Mattermost,2021-12-03,United States,"Tampa, FL",Information Technology,Full-time,Computer Software,"Mattermost is an open source platform for secure collaboration across the entire software development lifecycle. Hundreds of thousands of developers around the globe trust Mattermost to increase their productivity by bringing together team communication, task and project management, and workflow orchestration into a unified platform for agile software development.

Founded in 2016, Mattermost’s open source platform powers over 800,000 workspaces worldwide with the support of over 4,000 contributors from across the developer community. The company serves over 800 customers, including European Parliament, NASA, Nasdaq, Samsung, SAP, United States Air Force and Wealthfront, and is backed by world-class investors including Battery Ventures, Redpoint, S28 Capital, YC Continuity. To learn more, visit www.mattermost.com .

We value high impact work, ownership, self-awareness and being focused on customer success. If these values match who you are, we hope you'll learn more about working at Mattermost and apply!

Mattermost is a data-driven organization, and we are looking for a best-in-class Data Analytics Engineer to operate, maintain and enhance our internal self-service data warehouse. You will be responsible for managing our Snowflake data warehouse, building and maintaining ETL and data ingestion processes, and providing assistance to other teams within the company who input data into the warehouse and carry out analytics with the data it holds.

Responsibilities

Design, deploy, own and maintain best-in-class data infrastructure (Snowflake, Airflow, dbt, EKS, etc.)
Manage the development and operation of high-volume data pipelines to enable the business to make data-driven decisions.
Partner with the Analytics team to build data models that are actionable for the business
Drive strategic and architectural decisions around the evolution of our data warehouse and pipelines.
Write complex SQL queries and ETL pipelines.
Collaborate with Product and Engineering teams to ensure that new products and features are instrumented to capture product usage data/telemetry
Provide assistance to other teams within the company supplying data to the warehouse or consuming it for analytics.
Design schemas and guide usage of the data warehouse to maintain it as a high quality source of insights.

Required Background/Skills

3+ years experience as a Data Engineer
3+ years experience using Python
Strong SQL SkillsExperience building and managing a data lake in an enterprise setting
Experience applying Software Engineering best practices to Data Analytics, including CI/CD, version control, infrastructure as code, etc.
Experience in Schema Design, Data Modelling and Metadata management
Comfortable working with a variety of different tools and scripting languages and flexible in your choice of key technologies in the data analytics stack.
Ability to work independently in a small, globally-distributed remote team.
Strong written and verbal communication skills and a proven ability to work with engineers, data analysts and non-technical stakeholders across all departments of an organization.

Nice To Haves

Experience developing software and scripts in Go and Javascript.
Experience with Snowflake, Apache Airflow, dbt and Rudderstack.
Experience with data visualisation tools such as Looker.
Experience working in open source communities.

We Are Currently Hiring Staff In These Countries/regions

Mattermost is a remote-first company with staff living and working across the globe.

Australia - Brazil - Canada - Chile - Finland - Georgia - Germany - Greece - India - Ireland - Mauritius - Mexico - Pakistan - Philippines - Poland - South Africa - Turkey - Ukraine - Uganda - United Kingdom - United States

We are constantly working towards adding more countries/regions to this list, but first we need to make sure we are compliant with local laws and regulations, which takes time.

Mattermost is made up of people from a wide variety of backgrounds and lifestyles. We embrace diversity and invite applications from people from all walks of life. We don't discriminate against staff or applicants based on gender identity or expression, sexual orientation, race, religion, age, national origin, citizenship, disability, pregnancy status, veteran status, or any other differences. Also, if you have a disability, please let us know if there's any way we can make the interview process better for you; we're happy to accommodate!
Show more Show less"
2818594812,Data Engineer,Accenture Federal Services,2021-11-29,United States,United States,"Consulting, Information Technology, and Management",Full-time,IT Services and IT Consulting,"Federal Data Engineer

Organization: Accenture Federal Services




You are:

A Data Engineering pro—someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You’re passionate about digital technology, and you take pride in making a tangible difference. Complex issues don’t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy. As part of our AI & Technology group, you will lead cloud technology innovation for our clients through robust delivery of world-class data platforms. There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing cloud data landscape.




The work:

You will be part of a highly collaborative and growing network of cloud data experts, who are taking on today’s biggest, most complex business challenges using the latest data technologies and partnering with the largest cloud providers. You will be designing and building Big Data and real-time analytics solutions using industry standard technologies and work with data architects to make sure Big Data solutions align with technology direction. You will have an opportunity to work in roles such as Cloud Data Engineer, Data Modeler or Data Architect covering all aspects of Data including Data Management, Data Governance and Cloud Data Migration. We will nurture your talent in an inclusive culture that values diversity. Come grow your career in Technology at Accenture!




What you need:

Hands-on technical experience implementing or supporting Data Engineer Technology solutions
Experience with using cloud native services on one or more Cloud Platforms (GCP, Azure and/or AWS)
Experience with gathering and processing raw data and translating analyses
Experience with designing and implementing relational databases for storage and processing
Experience with working directly with teams to integrate data processing and business objectives
One more thing, this role requires US Citizenship (No Dual Citizens)




Bonus Points:

Experience with Open-source technologies such as Spark, Kafka, Presto, Hive, Cassandra, Hadoop
Experience with SQL and NOSQL databases to organize the collection, processing, and storing of data from different sources
Experience with Architecting and building scalable data platforms
Experience with Java, Scala, and/or Python programming languages
Show more Show less"
2792166356,Data Engineer (remote),Skylight,2021-10-16,United States,"Washington, DC",Consulting,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Skylight is at the forefront of a civic movement to reinvent how the government serves the public in a digital world.

We’re looking for a Data Engineer to join our talented team of technologists in driving this movement forward.

You’ll be a key part of our small, but rapidly growing team, which consists of former Presidential Innovation Fellows, founders of 18F, and members of the U.S. Digital Service.

We work in small, fast, agile teams to create exceptional customer experiences and enduring solutions out of the government’s most complex design and technology challenges. The work is challenging, but highly rewarding.

Requirements

What you’ll do:

Investigate, change, and modernize existing data systems, and build new ones, if necessary
Design and build data pipelines that transform data into usable formats
Write code to ensure the performance and reliability of data extraction and processing
Analyze systems to identify technical debt, instability, unreliability, and other opportunities for improvement, and design, document, and communicate solutions
Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
Select and use the right tools, frameworks, languages, and technologies for the job, with a preference for open-source solutions
Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
Represent Skylight's culture of delivery when interacting with government stakeholders and other contractors


What we’re looking for:

In-depth knowledge of computer science
Experience as a backend engineer or data engineer
Expertise programming in languages such as Python or Java
Expertise with relational databases such as PostgreSQL
Expertise creating and consuming APIs
Excellent knowledge of relational and non-relational database systems
Proven ability to apply good software engineering principles and practices
Ability to select and use the right tools for the job, particularly open-source solutions
Ability to communicate clearly to technical and non-technical audiences
Experience working within a multidisciplinary, agile team format
A mindset and work approach that aligns with our core values
Ability to travel from time to time (when it's safe)


Benefits

We focus on supporting you in a variety of ways:

Competitive salary
Medical insurance, dental insurance, vision insurance
Short-term and long-term disability insurance
Life and AD&D insurance
Dependent care FSA, healthcare FSA, health savings account
Dollar-for-dollar 401(k) match up to 10% of your salary
Flexible paid-time-off policy (minimum of 29 days), which covers any type of leave (such as holiday, sick, and vacation) that you need or want to take
Minimum of 9 weeks paid time off for all eligible new birth, adoption, or foster parents
Performance rewards, including annual salary increase, annual performance bonus, spot bonuses, and stock options
Business development / sales bonuses
Referral bonuses
Annual $2,000 allowance for professional development
Annual $750 allowance for tech-related purchases
Annual swag budget of $50 to display your Skylight pride with some merchandise (hoodies, hats, and more)
Dollar-for-dollar charity donation matching, up to $500 per year
Access up to $1,000 before payday to cover emergency expenses
Remote-friendly work environment
An environment that empowers you to unleash your superpowers for public good


We participate in E-Verify and upon hire, will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.

We're an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, sex, sexual orientation, gender identity or expression, religion, age, pregnancy, disability, work-related injury, covered veteran status, political ideology, marital status, or any other factor that the law protects from employment discrimination.
Show more Show less"
2824595102,Data Engineer,Enexus Global Inc.,2021-12-02,United States,United States,,Contract,,"Hi,
I am looking for a Data engineer
Exp: 6+
Skills: Pyspark, AWS, SQL, data bricks
Visas: USC, GC, H1B, H4 EAD, GC-EAD
Remote 100%
The candidate should be comfortable to work with the implementation partner
You can also reach me at rjassi@enexusglobal.com

Show more Show less"
2803597960,Data Engineer,EXL,2021-11-17,United States,"Hartford, CT",Information Technology,Full-time,IT Services and IT Consulting,"Hartford, CT, USA Req #1349

Tuesday, August 3, 2021

Overview

EXL (NASDAQ: EXLS) is a leading operations management and analytics company that designs and enables agile, customer-centric operating models to help clients improve their revenue growth and profitability. Our delivery model provides market-leading business outcomes using EXL’s proprietary Business EXLerator Framework™, cutting-edge analytics, digital transformation and domain expertise. At EXL, we look deeper to help companies improve global operations, enhance data-driven insights, increase customer satisfaction, and manage risk and compliance. EXL serves the insurance, healthcare, banking and financial services, utilities, travel, transportation and logistics industries. Headquartered in New York, New York, EXL has more than 32,000 professionals in locations throughout the United States, Europe, Asia (primarily India and Philippines), South America, Australia and South Africa. For more information, visit www.exlservice.com.

EXL is hiring a Data Engineer for its Data and Analytics business. This position is based out of our Hartford, CT office.

Required Skills

Knowledge in building data pipelines using SQL and Python.

Desired Skills

Logical thinking, problem-solving, knowledge in statistical theories and analysis with excellent communication.

Job Description

Coordinate with data scientists, product managers and business leaders to understand data needs and deliver on those needs
Define technical roadmap and drive key technology decisions with senior technology stakeholders
Build the infrastructure for optimal extraction, transformation and loading data from a wide variety of data sources using big data technologies
Work on pipeline creation, data ingestion, storage, wrangling, cataloguing, quality, security features
Automate jobs (ingestion & pipelines), notifications and reports
Prioritize to manage ad-hoc requests in parallel with ongoing sprints

What We Offer

EXL Health offers an exciting, fast-paced and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. From your very first day, you get an opportunity to work closely with highly experienced, world-class Healthcare consultants.
You can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth
We provide guidance/coaching to every employee through our mentoring program wherein every junior level employee is assigned a senior level professional as advisors.
The sky is the limit for our team members. The unique experiences gathered at EXL Health sets the stage for further growth and development in our company and beyond.

EEO/Minorities/Females/Vets/Disabilities

Please be aware that EXL requires all employees to be vaccinated for COVID-19. This position will require the successful candidate to obtain and show proof of a vaccination. EXL is an equal opportunity employer, and will provide reasonable accommodation to those individuals who are unable to be vaccinated consistent with federal, state, and local law.

Other details

Pay Type Salary
Required Education Bachelor’s Degree

Apply Now
Show more Show less"
2797769414,Data Engineer,"REsurety, Inc.",2021-10-19,United States,"Boston, MA",Information Technology,Full-time,"Renewable Energy Semiconductor Manufacturing, Computer Software, and Financial Services","Company Overview

REsurety is the leading analytics company empowering the clean energy economy. Operating at the intersection of weather, power markets, and financial modeling, we enable the industry’s decision-makers to thrive through best-in-class value and risk intelligence, and the tools to act on it. Our data and software products offer unprecedented insight into the financial performance and environmental impact of clean energy projects. Our risk-transfer products enable renewable energy buyers, sellers, and financiers to manage the risk inherent to generating power from an intermittent fuel source: the weather. Our clients include clean energy investors, advisors, developers, and buyers.

With 7,000 MW contracted and many of the clean energy industry’s leaders as clients, we are a small team with a big impact! Our culture is open and collaborative. We expect excellence from our team members and reward it with high ownership and flexibility. If you’re a high-achiever with a passion for clean energy, we want to hear from you.

Company Values & Principles:

At REsurety, we value the skills of execution, creativity & ownership, commercial focus, and teamwork, and we help and encourage all team members to develop these skills while at REsurety.

Our values also shape our culture and act as the foundation for our principles. Like all great companies, we strive to hire the best and are committed to building a diverse, inclusive company where team members feel engaged, valued, and supported. What is special about REsurety, though, is how much we:

Share information openly, broadly, and deliberately with each other;
Encourage ownership by all team members;
Provide continuous, constructive feedback; and
Empower all team members to bring their full, authentic self to work.


Position Overview:

As a Data Engineer on the Infrastructure team, you will work closely with the product team and other engineers to build and maintain a data warehouse designed to fuel the Analytics Engine of the Clean Energy Economy. You will be working on cloud infrastructure building and maintaining data extract, transform and load for our internal stakeholders.

Key Responsibilities:

Building and maintaining a data warehouse
Monitoring ETL processes to ensure accurate up-to-date data
Integrating/aligning serverless cloud architecture components
Assisting analytic and engineering teams to build and maintain data pipelines
Mentor/coach other engineers to bring your expertise to the wider team


Required Experience & Qualifications:

Scripting language - Python/R (preferred)
SQL
Cloud architecture/tools
Docker containers
Git
Willingness to take on hard problems and suggest and then implement solutions


Preferred Qualifications:

Experience with Snowflake
Capability to diagram system architecture
AWS CLI, BOTO3, Azure CLI, Terraform, etc.
Familiarity with or interest in wholesale electricity markets


Benefits:

Unlimited Paid Time Off Policy & Flexible Working Hours
Hybrid Work: Onsite Monday, Tuesday, Thursday, remote Wednesday and Friday
Medical Insurance
Dental Benefits
Health Savings Account (HSA)
401(k)
Stock Options
12 Weeks Paid Parental Leave
Fitness Reimbursement
Blue Bikes Gold Membership
Pre-Tax Transportation Deduction
Professional Development Stipend


REsurety, Inc. is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, gender identity, sexual orientation or any other characteristic protected by law.

Powered by JazzHR

KicMW8i13D
Show more Show less"
2814291802,Data Engineer,SEI Novus,2021-11-30,United States,"New York, NY",,Full-time,,"Our Mission

Novus serves capital allocators and managers, helping them enrich and manage their data, extract actionable investment insights, and improve stakeholder communication via visualization and automation. We strive to be the center of the institutional investment ecosystem, where the world’s investors gather to manage their portfolios and engage with one another.

Over $120 trillion is invested annually on behalf pensions, endowments, sovereign funds, private investors, and family offices. Unfortunately, many of these institutions are using outdated and disconnected tools to manage their portfolios. Novus offers comprehensive solutions for multi-asset class portfolio. By providing a single platform that streamlines data processes, quantifies investment skill, uncovers bias, and helps investors plan more accurately, we are helping investors amplify their impact.




Our Values

We expect our team members to deliver on their responsibilities and understand how each and every component of our company works to generate our collective success. We hold ourselves and our colleagues accountable to the highest standards.

If the following sounds like you, we look forward to getting to know you—

You're looking to join a fast-paced team that will mentor and support you as you take on challenging projects.
You have a “team first” mentality and enjoy helping others achieve their own goals.
You understand that deadlines and goals – even if self-imposed – are what help businesses succeed.
You appreciate direct, unvarnished feedback – you know it will help you grow.
The thought of deploying code to production several times day excites you. You know it’s better to ""fail fast"" than to never ship at all.
You enjoy mastering your craft, but also love learning about technologies and tools outside your core expertise.
You don't take yourself too seriously and know the importance of bringing some levity to an otherwise tense situation.




What You’ll Do

As a Data Engineer, you will be help us build and iterate on our industry leading ETLs and Data Processing Frameworks. We are open to this person being based in Austin, NYC, or Zurich. You’ll be directly responsible for delivering a large project and will need to coordinate resources across several teams to accomplish your goals. You will:

Own the entire development lifecycle including writing of specification with the product team, architecture, work estimation, implementation, testing, releasing, and maintaining enterprise grade software.
Uphold high quality standards through technical guidance, leadership, and mentoring.
Apply industry best practices for database and ETL development.




Critical Skills / Abilities

3+ Years of ETL development or other enterprise data processing experience.
Excellent organization skills and an ability to self-organize.
Ability to architect complete data systems leveraging existing and novel technology.
Ability to exercise discretion and independent judgment within known contexts.
Have led multiple large-scale project from inception to completion.
Proficiency in SQL

Additional skills that we would love to see but are not required:

Proficiency in Scala
Kubernetes or a similar orchestration tool.
AWS or a similar public cloud.
Continuous Delivery using a build tool such as Bamboo.
Personal interest in finance
Knowledge on definitions and parameters of financial instruments like options, bonds, futures, and swaps.
Show more Show less"
2826888696,Data Engineer,Lockheed Martin,2021-11-17,United States,"Bethesda, MD",Information Technology,Full-time,Defense and Space Manufacturing,"This is an exciting virtual opportunity that will encourage collaboration and teamwork! This role will offer a 4x10 schedule (4-day work weeks) and is eligible for amazing benefits to include, but not limited to 401k, health/dental/vision benefits, paid vacation and more! Read below and apply today!

Join the Lockheed Martin EBDT organization that is driven by speed, agility, and technical innovation. We are seeking an individual who is passionate, resourceful, and tactical to work side-by-side in a dynamic team of IT professionals that drives continuous results. This is an exciting opportunity to work as a trusted team member in assisting with the development of effective solutions to the IT organization!

The Lockheed Martin CDAO (Chief Data and Analytics Office) team is seeking a high energy team member with a strong working knowledge in Data Virtualization. In this role you will be part of the CDAO team consisting of colleagues possessing varying skill sets including; front-end and back-end developers, data scientists, machine learning / AI specialists, product managers, and other data engineers. The selected candidate will focus on Data Virtualization but will be included as part of a broader range of projects across the CDAO portfolio. The team is focused on exploiting small, innovative and agile teams to rapidly iterate and mature solutions from prototypes to deployment for utilization across the Lockheed Martin enterprise.

The selected candidate will focus on…

Analyze and resolve technical issues that come up during development and co-ordinate within various environments for monitoring and troubleshooting.
Work with product owners and customers to understand the relevant test cases
Develop and utilize tools to continuously monitor infrastructure and data
Develop and implement automated regression test plans.

MUST BE U.S. CITIZEN
Show more Show less"
2825813715,Data Engineer | Data & AI,"Concurrency, Inc.",2021-12-03,United States,"Minneapolis, MN",Information Technology,Full-time,IT Services and IT Consulting,"Who We Are

We are change agents. We are inspired technologists. We are unlike any other technology consulting firm. Our team fearlessly challenges the status quo, relentlessly pursues what’s next, and pushes the limits of what’s possible. A Microsoft Gold Partner and multiple-time Partner of the Year award recipient, Concurrency is renowned for its ability to turn unmatched technology expertise into client outcomes. Have we inspired the technologist in you? Come be a change agent at Concurrency.

Who We’re Looking For

We’re excited to add a Data Engineer to our Data & AI team. In this role, you’ll work with a team of customer-focused professionals who are committed to defining technical strategy, architecting, designing, and delivering end-to-end digital transformation. You’ll demonstrate strong technical competence and business acumen through engaging in senior-level technology decision-making discussions related to agility, business value, data warehousing, and cloud-oriented data solutions. You’ll empower other consultants by sharing subject matter expertise in large enterprise implementations, as well as overseeing the delivery of large, complex, and strategic projects for enterprise customers.

What You’ll Do

Lead requirements and design sessions with customer and internal teams
Author functional requirements and technical design documentation
Work with functional teams to plan project sprints, scope, and resource allocation
Manage project milestones to ensure successful solution delivery and customer satisfaction
Research and evangelize modern data solutions and new technologies
Work with the solution team to help set standard architectures, processes, and best practices
Develop and maintain strong working relationships with key partners and vendors
Promote service offerings through blogs posts, industry groups, and speaking events


What You’ll Need

Bachelor's Degree in Computer Science, Information Technology, Business Analytics or Computer Engineering
3 years of experience providing Microsoft solutions, platforms, or technologies to enterprise-level customers
Eligible to work in the United States without sponsorship
1-3 years of experience with Azure Databricks, Azure Data Platform, Data Modeling (Tabular), Power BI, SQL Server, and T-SQL Development


What Will Set You Apart

Azure Synapse experience
Machine Learning languages such as R or Python
IoT experience
Prior experience in a professional services organization
Spark experience
Strong technical documentation skills


Encouraging a healthy work/life balance and providing our colleagues great benefits are just part of what makes Concurrency a great place to work. Concurrency full-time employees receive complete and competitive benefits. We offer a collaborative work environment, competitive compensation, generous work/life opportunities and a comprehensive benefits package that includes paid time off plus holidays. In addition, all colleagues are eligible for a number of rewards and recognition programs, excellent training program and bonus opportunities.
Show more Show less"
2792740211,Data Engineer,Capital One,2021-11-13,United States,"Chicago, IL",Information Technology and Engineering,Full-time,"Banking, Financial Services, and Investment Banking","77 West Wacker Dr (35012), United States of America, Chicago, Illinois

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You’ll Do

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies

Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems

Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake

Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community

Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment

Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications

Bachelor’s Degree

At least 2 years of experience in application development

At least 1 year of experience in big data technologies

Preferred Qualifications

3+ years of experience in application development including Python, SQL, Scala, or Java

1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)

2+ years experience with Distributed data or computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)

1+ years experience working on real-time data and streaming applications

1+ years of experience with NoSQL implementation (Mongo, Cassandra)

1+ years of data warehousing experience (Redshift or Snowflake)

2+ years of experience with UNIX Linux including basic commands and shell scripting

1+ years of experience with Agile engineering practices

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Job Category - Engineering, Technology
Show more Show less"
2814740769,Data Engineer,chelsoftusa,2021-12-01,United States,United States,,Contract,,"Data Engineer on the Data Integration team your primary focus is to design and build durable data pipelines. You will be working on data integration processes to enable our growing Business Intelligence and Data Science teams. You will work both on-premise and in the cloud with a focus on modernizing our data pipelines and integration strategy to increase data accuracy and availability, lower support cost, and increase speed to shelf. We are looking for people who can be great individual contributors who are also open to pair programming and have a willingness to learn and work with new technologies. 

KEY RESPONSIBILITIES

·        Build performant and scalable data pipelines

·        Create, monitor, and maintain data pipelines

·        Ensures new and existing code meets company standards for readability, testability, automation, documentation and performance

·        Pair with other team members to increase efficiency and collaboration

·        Continually bring features from conception to production, leveraging a DevOps mindset

·        Integrate with both existing legacy systems and new modern systems

·        Provide after hours on-call support on a rotational basis

KNOWLEDGE, SKILLS AND EXPERIENCE

·        Proficient with SQL

·        Experience designing, modeling, and implementing snowflake, star, and relational data models.

·        Experience using ETL/ELT tools (e.g. SSIS, Informatica) and best practices

·        Ability to independently troubleshoot issues, think critically, and clearly communicate findings/recommendations

·        Experience using workflow management/orchestration tools (Airflow) 

 

Show more Show less"
2798295729,Data Engineer,"EDO, Inc.",2021-10-19,United States,"Los Angeles, CA",Information Technology,Full-time,"Marketing and Advertising, Online Media, and Computer Software","Role can be in any of EDO's office locations: New York, Los Angeles, San Francisco. Role is also open to full remote.

Who We Are

EDO was founded in 2015 to transform how data is used within the Media, Entertainment, and Advertising industry. Today, EDO is the leading data and analytics company for TV mid-funnel measurement and attribution. Customers include Disney, NBCU, Toyota,, and WarnerMedia. EDO's premier product offering Ad EnGage focuses on national linear TV; we are expanding our platform to cover the newest and fastest-growing segment of advertising with convergent TV (i.e. streaming) by developing new data sources and analytical techniques to measure the new ways ads are being bought, sold, and shown to consumers.

Before EDO, advertisers could only rely on their first party data and limited partnership opportunities. Advertisers would rely on survey based methodologies that would poll a small number of people on their attitude towards the brand. With EDO, advertisers are able to get full coverage of their campaigns and their competitive campaigns. All with no set up cost. Plus, EDO's outcome measurement is rooted in behavioral outcomes such as search which is much more correlated with economic outcomes than attitudes and the best KPI you can use to perform in-flight optimization. Marketers use this data to optimize their media plans and creatives.

About The Role

As a Data Engineer at EDO, you will join a team of talented Data Engineers working closely with Data Scientists to develop our next generation data pipeline. Our complex and challenging data pipeline combines multiple sources of advertising occurrence data and metadata with our own proprietary engagement data in real time to generate the mid-funnel engagement data which our clients rely on to make critical business decisions about their advertising strategy. You will have the opportunity to learn and work on cutting edge technologies related to big data and real time streaming.

About You

2+ years data engineering experience
Working knowledge pertaining to relational databases (MySQL, Postgres, etc), cloud data services (AWS), and data warehousing tools (Redshift, Snowflake, etc).
Production experience working with modern ETL data pipeline tools. You will work with the team to decide and utilize the appropriate tools for our data pipeline. (Spark, Kafka, Airflow, RabbitMQ, Kiba, Luigi, etc.).
Proficiency with a scripting language such as Ruby or Python and proficiency with another language such as Scala, Java.
Self-driven individuals who take ownership of their work
Ability to build products quickly and efficiently
Strong understanding of software engineering practices and principles
Previous industry experience working with TV or other advertising data is a huge plus


Benefits

Supportive, collaborative team and work that has immediate, clear impacts
Early-stage equity and competitive salary
Unlimited PTO along with trust and support to use it
Medical, dental, and vision insurance
Wellness Stipend - movie tickets, fitness discounts, commuter subsidies, meals and snacks
Show more Show less"
2814799194,Data Engineer,DICK'S Sporting Goods,2021-12-01,United States,"Pittsburgh, PA",Information Technology,Full-time,Retail,"At Dicks Sporting Goods, we create the future of sport driven by powerful data products and platforms that serve our Athletes and Teammates.




We are looking for a Data Engineer who wants to be a part of a team responsible for implementing all ad campaigns (display, search, videos) across all online platforms. Responsibilities include but are not limited to developing appropriate data pipelines to support trafficking, QA, yield optimization, and providing campaign reports and analysis to support the digital media operations teams.




What you will bring:

Robust data ingestion and transformation experience in a serverless-friendly scripting language
Expert at digital media data – including tagging, measurement, analysis, forecasting, and reporting
3+ years experience with AdTech tools – ad servers, data management platforms, and demand-side platforms
3+ years experience with data for MarTech tools – content management systems, digital asset management systems, and customer data platforms
3+ years of digital analytics platforms – e.g. Adobe Analytics, Google Analytics, Snowplow, etc.
Experience in audience segmentation
Proficiency in version control systems (e.g. Git) and release automation (e.g. Terraform, Ansible)
A good grip of data structures, relationships, integration patterns, and algorithms.
3+ years of experience being close to the business and delivering value through it as part of a team
Working knowledge of ""Big Data"" solutions such as Hadoop, NoSQL, MapReduce, etc. preferred
Some experience applying security and privacy to how you manage data.
A grasp of the importance of common data platform patterns and how they relate like data lakes, data modeling, data lineage, data fidelity, data transformation, etc.




Job Duties & Responsibilities

Work as part of a team-building the data ingestion, products, pipelines, and tooling supporting our data products driving merchandising, supply chain, pricing, and product development initiatives.
Work with stakeholders including the product, data, and architecture teams to assist with data-related technical issues and support their data infrastructure needs.
Provide proactive design, operational support, and governance for privacy and security policy for data
Bachelor's Degree in Computer Science, Software Engineering, Information Systems or Information Technology or related field required, or equivalent experience
3 – 5 years of experience in Data Engineering, Data Modeling, Digital Media, FaceBook API, Google Marketing Cloud API
Experience with consuming, transformation, and persisting large volume, high-velocity data from various sources
Proficient with SQL
Proficient with object-oriented programming and scripting languages (Python, Java, etc..)
Experience with relational databases (Oracle, SQL Server, etc..) as well as NoSQL database technologies (MongoDB, BigTable, Cassandra, etc..)
Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores (Kafka, Pub/Sub)
Proficiency with digital media measurement methodologies – CPM, CPA, etc. Conversion funnels, audience segmentation, clickstream analytics
Experience with continuous integration/continuous delivery (CI/CD) pipelines (Jenkins, Concourse, Azure DevOps)
Experience with Agile Development and Agile Deployment tools and versioning using Git or similar tools
Proficient in Linux/Unix environments

Show more Show less"
2824276678,Data Engineer,K2 Partnering Solutions,2021-12-02,United States,United States,,Contract,,"Looking for a Data Engineer to be able to build tools themselves with Python, or write SQL from the ground up. They prefer those who are able to write SQL by hand and create tools/automation scripts themselves.




Strong SQL is a must!




Role is contract with the opportunity to go full time.

Show more Show less"
2814409971,Data Engineer,Byline Bank,2021-11-30,United States,"Chicago, IL",Information Technology,Full-time,Banking and Financial Services,"At Byline Bank, we’re not like the other guys. We don’t pretend to know you. We’re in the neighborhoods where you live, work and hangout. And we’re always available—in-person, online, or on your mobile app. Experience banking the way it should be. Let’s write the next chapter of your story, together.




Byline is seeking a Data engineer to work on ByLine’s Data and Salesforce environment, Financial services cloud, NCino, Marketing cloud and Reporting. This person will also need to demonstrate knowledge of integration between on prem and cloud systems, object-oriented design and engineering efforts to improve user’s adaption of Salesforce platform for their daily use.




Areas of responsibility:

Meet business to determine functional and technical requirements.
Take lead in application design life cycle and support.
Be hands on in creating demos, proof of concept and solution wireframe.
Utilize best practices, for requirements gathering, bugs and back log management of tickets.
Provide technical assistance, end user support and documentation.
Act as point of contact for Salesforce platform issues and tickets.




Technical requirements:

Proven technical experience in Salesforce/Force.com development for 3-5 years.
Technical knowledge of Salesforce CRM and other similar cloud-based solutions like Oracle, SAP, Dynamics.
Direct work experience related to development, configuration and testing with Financial data, reporting and Fintech vendor services.
SSRS or Business Objects experience is required to create reports for end user.
Hands of use of Apex, Lightening components, Triggers, Workflow, process builder in Salesforce.
Demonstrated experience with SQL, TSQL, SSIS, relational databases and other ETL integration products.
Experience with web services (Rest, SOAP, JSON and XML)
Hands on experience with PowerBI or SSRS and Salesforce Reports and dashboard
Understand agile concepts and willingness to support ITIL process.
Salesforce certification preferred.
FIS or FServe Financial system background preferred.




PHYSICAL DEMANDS/WORK ENVIRONMENT: Usual office environment with frequent sitting, walking, and standing, and occasional climbing, stooping, kneeling, crouching, crawling, and balancing. Frequent use of eye, hand, and finger coordination enabling the use of office equipment. Oral and auditory capacity enabling interpersonal communication as well as communication through automated devices.

Show more Show less"
2707842798,Data Engineer,Coda,2021-12-03,United States,United States,Information Technology,Full-time,Computer Software,"About Coda

Coda started with an observation: In a world full of applications, why do documents and spreadsheets still run everything? And why haven't they been meaningfully updated in over 50 years? Coda is a new doc that's familiar and flexible like the documents you're used to, but comes with building blocks you can combine to create docs as powerful as apps. It's a big product with an even bigger mission. And we need your help to spread the word! We're backed by some of the Valley's leading venture capitalists, and have assembled a world-class team across offices in San Francisco, Mountain View, and Seattle, and remote employees all over the US. In fact, all our jobs are open in any location across the US. Here's a quick overview of what we do.

About The Role

As a data engineer you will help design, source and build foundational data sets to power deep product analytics, experimentation, and business warehouses.

Your work will unlock insights allowing our team to execute with speed and confidence. Your data sets and pipelines will allow us to tailor the product experience based on our customers' needs and behaviors, while simultaneously empowering our marketing and sales teams to reach and engage our users.

As a member of Coda's engineering team, you will operate as a software engineer and work broadly across the entire product, servers, infrastructure and data stack. You'll work with a stellar team of passionate, experienced engineers, data scientists, designers, and product managers who have been instrumental in building some of the most widely-used technology products in the world, including YouTube, Google Drive/Docs, Amazon AWS, Pinterest, and Microsoft Azure.

If you are data curious, excited about designing data sets and pipelines, producing insights and shining a light on the business through data, we'd love to hear from you! You have the opportunity to have an outsized impact on the future direction of data within Coda.

Our current stack consists of server infrastructure running on Kubernetes in Amazon AWS, Snowflake for warehousing, Apache Airflow for orchestration, Mode Analytics for dashboarding, Python and SQL for datapipelines. We believe in using the best tool for the job in hand, and don't shy away from solving hard problems!

In This Role You Will

Building robust, efficient ETL pipelines from different sources (S3, Relational Databases, external systems) to Snowflake with Apache Airflow.
Developing dashboards, company wide datasets that power product analytics, revenue, experimentation, and data oriented product features.
Gathering and understanding internal data requirements, working in the team to achieve high-quality data ingestion and build systems that can process the data and transform the data, providing ad-hoc access to large data-sets.
Building pipelines that deliver your datasets into external tools such as Intercom and Salesforce.
Building expertise around Coda's data and helping grow this data gene among Codans.
Developing and evangelizing event schemas and logging patterns across the entire engineering team to power product analytics. Doing this with an eye towards security and compliance (such as GDPR, and CCPA).

You may be a great fit for this role if:

Bachelor's degree or equivalent experience in a technical focused discipline such as computer science, engineering or math.
You have worked with SQL and data warehousing systems such as Snowflake, Oracle, Redshift, Teradata, SQL Server, etc.
Experience with workflow management technologies such as Airflow, Luigi, SSIS, etc.
Experience providing technical leadership and mentor other engineers for the best practices on data design.

How we care for our Codans!

Some Of Our Benefits Include

Starting on your first day of employment, Coda offers a wide range of benefits and perks that support eligible employees and their family members.

Medical, Dental, Vision and Life Insurance
401k
Optional Remote or in-office work
Commuter Benefits
Cell & Internet Subsidy
Lunch Subsidy
Fitness Subsidy
Parental Leave
Annual Educational Stipend

At Coda, we are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants. We do not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. Coda believes that diversity and inclusion among our teammates is critical to our success as a company, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool.
Show more Show less"
2822383106,Data Engineer,NEXT Music,2021-12-01,United States,United States,Information Technology and Engineering,Full-time,"Musicians, Internet Publishing, and Entertainment","NEXT Music is a music start-up co-founded by Tim Westergren, co-founder of Pandora

We’ve created a live streaming platform, Sessions, and we are redefining the future of fan communities and the way musicians connect with their fans. Rising Artists use Sessions to develop a fanbase and earn a living through performance while Headliner Artists like Why Don’t We, Zac Brown Band, and Mike Epps partner with us to develop exclusive fan communities and produce incredible live streaming performances.




We are seeking our first Data Engineer to own our new stack

You will be working closely with other engineers, directly with the CTO, and collaborating with our Data Analytics team. We have a legacy data stack, using in-house tools and AWS Redshift. We are migrating to our new Snowflake-powered stack, revamping our data pipelines, building out a fresh dbt project.




We need an experienced Data Engineer to coordinate with Software Engineers to build out those pipelines. To own our dbt project, defining our standards and processes as we roll out the new stack across the company.




Things we value

Experience building data pipelines and modeling (with SQL, dbt)
Software Engineering mindset, applied to Data
Broad knowledge of the wider Data Engineering/Analytics industry
Show more Show less"
2754973135,Data Engineer,Twitch,2021-12-01,United States,"San Francisco, CA",Information Technology,Full-time,Internet Publishing,"About Us

Launched in 2011, Twitch is a global community that comes together each day to create multiplayer entertainment: unique, live, unpredictable experiences created by the interactions of millions. We bring the joy of co-op to everything, from casual gaming to world-class esports to anime marathons, music, and art streams. Twitch also hosts TwitchCon, where we bring everyone together to celebrate, learn, and grow their personal interests and passions. We’re always live at Twitch. Stay up to date on all things Twitch on LinkedIn , Twitter and on our Blog .

About The Role

Data is central to Twitch's decision-making process, and data engineers operate at the forefront of this by creating datasets that inspires analysis across all of Twitch. You will shape the way that our performance is measured, defining how we transform our data, and scaling analytics methods and tools to support our growing business, leading the way for high-quality, high velocity decisions.

We're looking for an experienced data engineer to join our central analytics team, which is focused on empowering staff throughout Twitch to use and trust our data. Your responsibilities may range from developing and enhancing our data warehouse which act as sources of truth across the company, driving data quality across product departments and teams, building self-service business intelligence infrastructure for analysts, and connecting into data interfaces that allow everyone in Twitch to discover and analyze the data. In the process, you will work with technical and non-technical staff members throughout the company, and will report to the Director of Central Analytics.

This position can also be located in Irvine, CA; Seattle, WA; New York, NY; and Salt Lake City, UT and remote.

You Will

Define and own team level data architecture for trusted, governed, dimensionally-modeled repository of data that enables Twitch staff to quickly and reliably answer their questions.
Keep existing data sources fresh against data quality issues, design data quality assurance framework and improve the processes for developing new ones raising the level of quality expected from our work.
Conduct unit, integration, and system tests on our data sources to validate data against source systems, and optimize performance to improve query speed and reduce cost.
Improve search, discovery and literacy: Create exploration and visualization interfaces in our BI tools and promote the use of these sources across the company through training programs.
Improve business and engineering team processes via data architecture, engineering, test, and operational excellence best practices. Make enhancements that improve data processes.
You Have:

3+ years of experience in data engineering, software engineering, or other related roles.
3+ years in relational database concepts with a solid knowledge of star schema, SQL, SQL Tuning, OLAP, Big Data technologies
3+ years of experience maintaining data pipelines from multiple data sources, in collaboration with diverse partners.
Experience with best practices for development including query optimization, version control, code reviews, and documentation.
Experience working with Amazon Webservices, S3, EMR, or Redshift
Experience in coding languages like Python/Java/Scala
Passion for games and the gaming industry is a great bonus!
Perks

Medical, Dental, Vision & Disability Insurance
401(k), Maternity & Parental Leave
Flexible PTO
Amazon Employee Discount
Monthly Contribution & Discounts for Wellness Related Activities & Programs (e.g., gym memberships, off-site massages),
Free Snacks & Beverages

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

The pay range for this position in Colorado is $90,450.-150,750 yr; however, base pay offered may vary depending on job-related knowledge, skills, and experience. A sign-on bonus and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. You should apply via Amazon's internal or external careers site.

We are an equal opportunity employer and value diversity at Twitch. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Show more Show less"
2824203978,Data Engineer,Insight Global,2021-12-02,United States,Des Moines Metropolitan Area,,Full-time,,"MUST BE W2- CLIENT DOES NOT SPONSOR

Must Haves:
• Bachelor's degree plus 8+ years related work experience or a Master's in related field plus 4+ years related work experience
• Ability to work directly with data and datastores through programming language such as SQL, Python, Java, .NET, etc.
• Experience building/operating systems for data extraction, ingestion, and processing of large data sets
• Experience building data products incrementally and integrating and managing datasets from multiple sources
• Ability to collaborate with global teams
• Must be able to effectively communicate strategies and designs to all levels of the company
• Experience working with cloud platforms (AWS or AZURE) and surrounding ecosystems
• Experience with Data Visualization- PowerBI
• Solid leadership and presentation skills required

Plus:
• Cloud data warehousing to support a range of personas and use cases (date engineers, data science, investment teams)
• Data catalog/search engine/query mechanism to facilitate finding and graphing available data vendors/data points


Day-to-Day:
Insight Global is looking for a talented Data Engineer for a Fortune 1000 Financial company in Des Moines, IA. This person will be responsible for but not limited to the following: Ability to work directly with data and datastores through programming language such as SQL, Python, Java, .NET, etc, build out operating systems for data extraction, ingestion, and processing large data sets. Lastly, Experience building data products incrementally and integrating and managing datasets from multiple sources. This person will be working Globally with people in Mexico, Chile, Hong Kong, Malaysia, Indonesia, Thailand, Brazil and India. Travel would be be included at about 15% of the year (twice yearly at most).


Show more Show less"
2756101988,Data Engineer,Cognite,2021-10-14,United States,"Houston, TX",Information Technology,Full-time,IT Services and IT Consulting,"Do you see how data can be used, modeled and visualized in new ways to improve decisions in industrial engineering, but you experience that the tools and data availability is insufficient to create impact? If you want to change that, and take part in forming what the future of the industry will look like you should join our Cognite and become a part of the team responsible for delivering Cognite’s cutting edge industry solutions to our customers!

As a Data Engineer, located in Houston, TX, you will design, develop and implement data infrastructure and best-in-class pipelines that collect, connect, centralize and curate data from various internal and external data sources. You will ensure that architectures support the needs of the business, and recommend ways to improve data reliability, efficiency. You are an experienced engineer with a passion for software development, hands-on in designing, implementing, and delivering features for flagship products.

What You'll Do

Partner with Solution Architects to understand client requirements and define queries with subject matter experts
Develop custom extractors using backend technologies and languages i.e Python, Spark, Rest APIs
Customize existing extractors i.e. database extractor using SQL, event streaming using Kafka and deploy using Docker
Create custom data models for data discovery, mapping, and cleansing
Collaborate with product development to turn customer needs into potential product offerings
Prototype data visualization and dashboards

Who You Are

3+ years of experience in a Data intense role
Experience in O&G, Power & Utilities and/or Manufacturing is required
BS or MS degree in computer science or related field
Loves to code, passion for coding, and enjoys sharing that knowledge with others
Strong understanding of data analysis or data science
Experience working with data technologies, such as: ETL, SQL, Python
Ability to work on both internal and external client-facing projects and communicate with key stakeholders
Ability to travel onsite to meet with and engage with clients -- we don’t build solutions in isolation.
Role based in Houston, TX or (Austin, TX w/ travel to Houston)

What Makes Us Great

An opportunity to make an impact on the industrial future and be part of disruptive and groundbreaking global projects
High level of autonomy, ability to influence decisions and to learn from mistakes
Work along side a driven, engaging team with in-depth software expertise and industry experience
Opportunity to join Together@Cognite for social, community, and diversity initiatives
Focus on agility and speed, openness, togetherness, impact, and obligation to speak up
Join a team that truly lives their values and brings their whole selves to Cognite --> watch some of our Cognite Voices Katrine Tjølsen , Petter Reistad .

Perks & Benefits

Competitive Compensation + 401(k) with employer matching
Health, Dental, Vision & Disability Coverages with premiums fully covered for employees and all dependents
Unlimited PTO + flexibility to enjoy it
Paid Parental Leave Program
Learning & Development Stipends
Global Mobility & Exchange Program
Company Paid Friday Lunch via DoorDash + Fully Stocked Fridges in the offices

Cognite is a global industrial SaaS company that was established with one clear vision: to rapidly empower industrial companies with contextualized, trustworthy, and accessible data to help drive the full-scale digital transformation of asset-heavy industries around the world. Our core Industrial DataOps platform, Cognite Data Fusion™, enables industrial data and domain users to collaborate quickly and safely to develop, operationalize, and scale industrial AI solutions and applications to deliver both profitability and sustainability. Visit us at www.cognite.com and follow us on Twitter @CogniteData or LinkedIn: https://www.linkedin.com/company/cognitedata

Equal Opportunity

Cognite is committed to creating a diverse and inclusive environment at work and is proud to be an equal opportunity employer. All qualified applicants will receive the same level of consideration for employment; everyone we hire will receive the same level of consideration for training, compensation, and promotion.

We ask for gender as part of our application because we want to ensure equal assessment in the recruitment process. Your answer will help us reach this commitment! However, the question about gender is optional and your choice not to answer will not affect the assessment of your application in any way.
Show more Show less"
2801227352,Big Data Engineer,RAPS Consulting Inc,2021-11-16,United States,"New York, NY",Information Technology,Contract,Staffing and Recruiting,"Description

Hadoop/Big data implementation experience 3+ years

Java, J2ee 8+ years +

Oracle PL/SQL(definitely required) 8+ years +

PL SQL Tuning 8+ years +

Development in Unix, Linux Env 5 years +

Must have Basel III & Accounting implementation experience

Ability to utilize programming methodologies and languages

Efficient coding i.e. adhering to coding standards, procedures and techniques

Effective analysis of new and existing applications and platforms

Clear communication and documentation of technical specifications
Show more Show less"
2808114858,Data Engineer,Deckers Brands,2021-11-25,United States,"Plano, TX",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2818873594,Data Engineer,Farmers Insurance,2021-11-08,United States,United States,Information Technology,Full-time,"Insurance, Financial Services, and Consumer Services","We are Farmers!

Join a team of diverse professionals at Farmers to acquire skills on the job and apply your learned knowledge to future roles at Farmers. Farmers Insurance also offers extensive training opportunities through the award winning University of Farmers named by Training magazine amongst top 10 corporate training units in the world.

Job Summary

Provides expertise in the design and functionality of business applications; Understands business processes and products and how best they can be supported by the application systems; Creates and validates the detailed technical designs to ensure alignment with business requirements; Develops and performs quality checks on project deliverables; Creates and validates estimates for new application functionality; Performs impact analysis of application changes across various components, holding an end-to-end view of the system; Specifies / recommends integration and testing criteria; Supports the implementation activities as well as troubleshoots application/system/environmental issues, as required.

Essential Job Functions

Use MS SQL SSIS to build ETL process to create new business functionalities as well to solve business problems: Respond to new requests for reports/data understanding business objectives and processes; review and refine technical requirements/User Stories; and communicate estimated hours and timeline to complete; Extract data directly from relational databases (e.g. DB2, SQL Server), data warehouses, or other data stores using SQL; Ability to create manual as well as automated data exports/reports; and Support application unit testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. Work productively on assigned tasks; Collaborate effectively with other team members; Demonstrate accountability to management and business for hours spent on assigned tasks; and diligently strive to deliver value.

Physical Actions

Essentially sedentary work consisting of occasional walking, standing, and lifting/carrying 10 lbs. maximum

Functional ability of seeing, hearing and speaking
Ability to type proficiently

Physical Environment

Work in a climate-controlled office, with occasional travel by car or airplane.

Education Requirements

High school diploma or equivalent required. Bachelor’s degree preferred, in Information Systems or related field.

Preferred Skills And Abilities

Work within structure of SAFe Agile team on the successful delivery of Business Intelligence projects, enhancements, and defects. Independently lead and deliver new projects and enhancements. Collaborate with Agile team members to understand functional and technical requirements. Prepare estimates based on high-level requirements and assumptions. Translate functional requirements into technical specifications for ETL development; develop source-to-target mappings and actively manage Development, Unit Testing and Implementation efforts. Troubleshoot production defects, perform root cause analysis and provide guidance to team on the fixes.

Experience in developing ETL and reporting applications using Microsoft SQL Server (strongly preferred), or Informatica or similar ETL technologies.
Experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process on MS SQL Server or DB2 or similar DB platform.
Experience with Python and unstructured data manipulation is a plus.
Experience working in an Agile Environment is a plus.
Good knowledge of business intelligence best practices, processes, and methodologies.
Good programming experience in writing Stored Procedures, Queries, Views, User Defined Functions, and Common Table Expressions using SQL or T-SQL.
Highly committed, motivated, enthusiastic and a natural team player.
Good interpersonal and communication skills (both verbal and written) and ability to interact with and effectively address concerns.
Good prioritization, time management, analytical, and organization skills.
Experienced in facilitating in-person and remote meetings with business & IT.
Experienced in effective management of multiple competing and frequently changing assignments and priorities.

Experience Requirements

2+ years experience with data extraction, manipulation and presentation in usable format.

Special Skill Requirement

Experience with Python and unstructured data manipulation is a plus.

Benefits

Farmers offers a competitive salary commensurate with experience, qualifications and location
CO Only: The pay range for this job being performed in CO would be $72,000 - 96,000
Bonus Opportunity (based on Company and Individual Performance)
401(k)
Medical
Dental
Vision
Health Savings and Flexible Spending Accounts
Life Insurance
Paid Time Off
Paid Parental Leave
Tuition Assistance
For more information, review “What we offer” on https://www.farmers.com/careers/

Job Location(s): US - CA - WdlndHills-6301, US - RW - Remote Work - Farmers, US - TX - Remote, US - OK - OklaCty-Memrl, US - CA - WdlndHills-6303, US - KS - Kansas City, US - MI - Caledonia KM2, US - OH - Indpdc-4500

Salary Grade: Grade 35

Hiring Manager: Matthew S Woods

Want to learn more about our culture & opportunities? Check out farmers.com/careers and be sure to follow us on Instagram and LinkedIn!
Show more Show less"
2786089934,"Data Engineer (SQL, AWS)",Travelers,2021-11-04,United States,"Hartford, CT",Information Technology,Full-time,"Law Practice, Legal Services, and Insurance","Company Summary

Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Target Openings

1

Job Description Summary

Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.

This position may be based 100% remotely or in one of our offices.

Primary Job Duties & Responsibilities

Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.

Minimum Qualifications

Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.

Education, Work Experience, & Knowledge

Bachelor’s Degree in STEM related field or equivalent
Six years of related experience
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.

Job Specific Technical Skills & Competencies

Experience working with AWS.
Experience working with SQL.
Experience working with Snowflake databases is preferred.
The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.

Employment Practices

Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.

To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
Show more Show less"
2808117732,Data Engineer,Deckers Brands,2021-11-25,United States,"San Francisco, CA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2826246026,Data Engineer,Altice USA,2021-12-03,United States,"Long Island, KS",Information Technology,Full-time,"IT Services and IT Consulting, Telecommunications, and Financial Services","Job ID: 2021-27912

Location:

1 Court Square, Long Island City, NY

Altice USA is a cutting-edge communications, media, and tech company. We connect people to what matters most to them; texting with friends, advertising that resonates, or binge watching their favorite show. Our differentiated approach centers around technologies that push the envelope and deliver the ultimate customer experience. We're building a workforce that attracts and retains the best talent, not only to meet the needs of our customers, but that also reflects the diverse communities we serve. We're not the only ones who have seen it; we've recently been recognized by Forbes as one of America's Best Employers as well as by the Human Rights Campaign, DiversityInc Magazine, and Cablefax for our diversity & inclusion program.

a4 Advertising, Altice Advanced Advertising & Analytics, is a data and advertising business that delivers multiscreen campaigns for small businesses, local, regional, national, political, and multicultural advertisers and their agencies. a4 Advertising 's coverage includes the Optimum and Suddenlink markets and also spans nationwide, offering 50M authenticated U.S. Household IP Addresses and 15M Households with viewership data collected across 201 DMAs. With services that deliver Linear, OTT, Programmatic, Mobile AdMessenger, and Social Media video and display ad solutions, a4 Advertising can help businesses and brands of all sizes reach their target audience. a4 Advertising also provides unique programming and inventory opportunities through our owned networks: News 12 & News 12 New York, Cheddar News and i24 NEWS.

Responsibilities

We seek a Data Engineer to understand our business workflows and our technology. The Data Engineer roll will be a key member of the Data Solutions team pipeline infrastructure, data warehouse, and analytical developer interfaces. You will work closely with Data Strategy, Product Management, Application Development and the Software Engineering teams. You will be a direct partner with business stakeholders and will serve a central engineering role as we support and extend our existing data warehouse and infrastructure capabilities, designing solutions and coding new features for users and business stakeholders.

Required Tasks and Duties:
Work with Data Solutions Manager to distill technical requirements
Collaborate with data engineers and data warehouse in building automated batch implementations and integrating them into architecture
Design and implement data pipelines, data structures and ETL processes per business requirements
Utilize deep SQL knowledge to answer any architectural or data related questions
Proven handling of PII standard practices and obfuscation of data as needed
Proven experience in monitoring dataflows and underlying systems

Qualifications

Bachelor's /Master's Degree in Computer Science/Computer Engineering/Information Science/Mathematics or related field or equivalent job experience. (Graduate degree in related field preferred)
2+ years relevant working experience
2+ years of experience as a Python Developer and adept at reading, writing, troubleshooting, and understanding Python language
Strong SQL programming skills, data structure in relational databases, data manipulation and transformation knowledge required
2+ year experience with cloud environments and server management. Experience working in Big Query and Google Cloud Server environments a plus
Experience with multi-billion record datasets
Experience scripting and deploying ETL jobs, cron jobs and code changes. Fluency with Airflow and/or Data Flow preferred.
Experience with data security and PII data handling best practices
Excellent communication and presentation skills with the ability to translate business objectives into technical requirements and communicate with various teams and stakeholders
Team oriented and collaborative approach with a demonstrated aptitude and willingness to learn new methods and tools
Experience with data visualization tools and coding a plus
Ideal candidates have experience working in Media, Television or Digital Marketing

Altice USA is an Equal Opportunity Employer committed to recruiting, hiring and promoting qualified people of all backgrounds regardless of gender, race, color, creed, national origin, religion, age, marital status, pregnancy, physical or mental disability, sexual orientation, gender identity, military or veteran status, or any other basis protected by federal, state, or local law.

Altice USA, Inc. collects personal information about its applicants for employment that may include personal identifiers, professional or employment related information, photos, education information and/or protected classifications under federal and state law. This information is collected for employment purposes, including identification, work authorization, FCRA-compliant background screening, human resource administration and compliance with federal, state and local law.

Requirements of this position include demonstration of either full vaccination status against COVID-19 or company-provided weekly COVID-19 testing.
Show more Show less"
2758753412,"Data Engineer, Core Growth",Snap Inc.,2021-12-03,United States,"Los Angeles, CA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Snap Inc. is a camera company. We believe that reinventing the camera represents our greatest opportunity to improve the way people live and communicate. Our products empower people to express themselves, live in the moment, learn about the world, and have fun together.

We’re looking for a Data Engineer to join the Core Growth product engineering organization. Working from one of our west coast offices in Santa Monica, CA, Mountain View, CA, or Seattle, WA, you’ll collaborate with Software Engineers, Data Scientists, and Product Managers to help Snapchat grow across the globe. The Core Growth team is Snap’s growth engineering platform and its mission is to grow our community by promoting real friendships while they feel safe to express themselves, live in the moment, learn about the world and have fun together. The team builds and operates key products for user acquisition, activation, discovery, and retention at Snap such as registration and onboarding, friend recommendations, search, sharing, notifications, among others. In this role, you will build the data infrastructure and tools that will deliver insights to broaden and deepen user engagement and improve product experience for our hundreds of millions of passionate users. You will have an opportunity to tackle large-scale engineering and product challenges while working alongside kind, smart, and creative colleagues. Come grab a front row seat to witness and influence how Snapchat grows to become the world's camera!

What You’ll Do

Define data models for instrumentation and reporting in partnership with Engineering, Data Science, and Product Management to support product analytics.
Build scalable aggregation pipelines to deliver performant datasets that can be consumed through surfaces such as Looker, Tableau, Superset, and Jupyter.
Drive data quality end-to-end from instrumentation to reporting. Build automated controls and processes to prevent and fix regressions.
Democratize data access amongst engineers, PMs, and scientists with well-documented and extensible pipelines and datasets.
Partner with Snap’s Data Governance and Insights teams to make high-quality datasets in the Growth domain available for external and partner reporting.

Knowledge, Skills & Abilities

Experience in building data pipelines to serve reporting needs
Experience owning all or part of a team roadmap
Experience with data visualization tools like Looker and Tableau
Ability to prioritize requests from multiple stakeholders in disparate domains
Ability to effectively communicate complex projects to non-technical stakeholders

Minimum Qualifications

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
3+ year experience in SQL or similar languages
3+ years development experience in at least one object-oriented or scripting language (Python, Java, Scala, etc), Python preferred
Experience in ETL / Data application development

Preferred Qualifications

Hands on experience with Google BigQuery
Experience using and sharing notebook solutions like Jupyter
Experience in version control systems such as Git
Data architecture and warehousing experience
Experience with Airflow and Druid
Show more Show less"
2808117693,Data Engineer,Deckers Brands,2021-11-25,United States,"McKinney, TX",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2789628249,Data Engineer,Zoom,2021-12-03,United States,"Austin, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2812353191,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"Boston, MA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2560366337,Big Data Engineer,"DIVERSANT, LLC",2021-05-25,United States,"Charlotte, NC",Engineering and Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Financial Services","We have an immediate need for a Senior Big Data Engineer with our client in the Financial Services Industry. This is a 12 month contract opportunity with long-term potential and is located in Charlotte, NC.  Please review the below job description and contact me ASAP.
The right candidate would have to be extremely comfortable in a linux/unix environment with the ability to wear several hats as a polyglot developers as well as dev ops for the lower lane environments when required.
Hadoop experience or exposure to the Apache Java stack or relevant technologies is a must, a successful candidate would be to work independently and or in a global team setting depending on the deliverables.
Ability to troubleshoot the applications from a high-level.
Ability to tell the difference between an application problem vs a hardware problem vs. a network problem.
Ability to work independently.
Ability to learn on the fly.
Show more Show less"
2803597961,Data Engineer,EXL,2021-11-17,United States,"Hartford, CT",Information Technology,Full-time,IT Services and IT Consulting,"Hartford, CT, USA Req #1350

Tuesday, August 3, 2021

Overview

EXL (NASDAQ: EXLS) is a leading operations management and analytics company that designs and enables agile, customer-centric operating models to help clients improve their revenue growth and profitability. Our delivery model provides market-leading business outcomes using EXL’s proprietary Business EXLerator Framework™, cutting-edge analytics, digital transformation and domain expertise. At EXL, we look deeper to help companies improve global operations, enhance data-driven insights, increase customer satisfaction, and manage risk and compliance. EXL serves the insurance, healthcare, banking and financial services, utilities, travel, transportation and logistics industries. Headquartered in New York, New York, EXL has more than 32,000 professionals in locations throughout the United States, Europe, Asia (primarily India and Philippines), South America, Australia and South Africa. For more information, visit www.exlservice.com.

EXL is hiring a Data Engineer for its Data and Analytics business. This position is based out of our Hartford, CT office.

Required Skills

Knowledge in building data pipelines using SQL, Hive and Python.

Desired Skills

Logical thinking, problem-solving, knowledge in statistical theories and analysis.

Job Description

Coordinate with data scientists, product managers and business leaders to understand data needs and deliver on those needs
Define technical roadmap and drive key technology decisions with senior technology stakeholders
Build the infrastructure for optimal extraction, transformation and loading data from a wide variety of data sources using big data technologies
Work on pipeline creation, data ingestion, storage, wrangling, cataloguing, quality, security features
Automate jobs (ingestion & pipelines), notifications and reports
Prioritize to manage ad-hoc requests in parallel with ongoing sprints

What We Offer

EXL Health offers an exciting, fast-paced and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. From your very first day, you get an opportunity to work closely with highly experienced, world-class Healthcare consultants.
You can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth
We provide guidance/coaching to every employee through our mentoring program wherein every junior level employee is assigned a senior level professional as advisors.
The sky is the limit for our team members. The unique experiences gathered at EXL Health sets the stage for further growth and development in our company and beyond.

EEO/Minorities/Females/Vets/Disabilities

Please be aware that EXL requires all employees to be vaccinated for COVID-19. This position will require the successful candidate to obtain and show proof of a vaccination. EXL is an equal opportunity employer, and will provide reasonable accommodation to those individuals who are unable to be vaccinated consistent with federal, state, and local law.

Other details

Pay Type Salary
Required Education Bachelor’s Degree

Apply Now
Show more Show less"
2790167212,Data Engineer,American Signature Inc.,2021-11-12,United States,"Columbus, Ohio Metropolitan Area",,Full-time,,"DATA ENGINEER
POSITION DESCRIPTION

The Source+
At The Source+, we help people save money so they can live better. This mission serves as the foundation for every decision we make to create the future of retail, from responsible sourcing to sustainability – and everything in between.

Position Overview
The Source+ Data Engineer works on data services across product organizations within The Source+ Group and supports building both the internal and external customer facing data products. The Data Engineer supports an enterprise grade platform focusing on seed to sale cannabis cultivation, wholesale and retail development and sales. You will have extensive experience in ETL development, works with large scale data in real time, and cross collaborate with other teams across the organization.

Position Responsibilities
The responsibilities of the position include:
• Build and maintain ETL pipelines utilizing Python that connect 1st and 3rd party data
• Work with Cloud Computing Platforms and other open-source technologies – in particular, Microsoft Azure.
• Conduct data modeling, schema design, and SQL development
• Ingest and aggregate data from both internal and external data sources to build our datasets
• Develop and lead the testing and fixing of new or enhanced solutions for data products and reports, including automating ETL testing
• Manage multiple layers of SQL processing to convert the data from raw, staging to production BI views, which includes a lot of optimization code to provide failsafe’s and efficient response times for users.
• Collaborate with Product Owner and domain experts to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
• Assist with the development and review of technical and end user documentation including ETL workflows, research, and data analysis
• Work with Product team to define data collection and engineering frameworks
• Build monitoring dashboards and automate data quality testing
• Responsible for daily integrity checks, performing deployments and releases
• Own meaningful parts of our service, have an impact, grow with the company
• Other duties as assigned.

Supervisory Responsibilities
• No

Desired Qualifications
• 3+ years of Python, SQL, and ETL development
• Bachelors or master’s degree in computer science or other related field
• Product / reporting suite experience
• Exposure to front end development: HTML, JavaScript, jQuery, Angular or similar libraries
• Exposure / familiarity with Microsoft Azure / Google Cloud Platform / Amazon Redshift
• Microsoft experience preferred
• Enthusiastic about working with and exploring new data sets
• Detail oriented and strong communicator
• Adaptable - Change before you have to.

Show more Show less"
2813964417,Data Engineer - Site Reliability,Morgan Stanley,2021-11-22,United States,"Alpharetta, GA","Project Management, Analyst, and Engineering",Full-time,"Financial Services, Investment Banking, and Investment Management","Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. Morgan Stanley can provide a superior foundation for building a professional career - a place for people to learn, to achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.

Technology works as a strategic partner with Morgan Stanley business units and the world's leading technology companies to redefine how we do business in ever more global, complex, and dynamic financial markets. Morgan Stanley's sizeable investment in technology results in quantitative trading systems, cutting-edge modeling and simulation software, comprehensive risk and security systems, and robust client-relationship capabilities, plus the worldwide infrastructure that forms the backbone of these systems and tools. Our insights, our applications and infrastructure give a competitive edge to clients' businesses—and to our own.

The Data Engineering group, RTOI is responsible for design and support for continuous data streams from disparte sources into a variety of targets. Includes design and development of applications to consolidate data from various sources (Internal + External), integration and enrichment with other sources of data with central repositories, applications to manage data flows between heterogeneous sources and applications to uniformly distribute data for downstream consumption. Working in a highly collaborative and dynamic environment to engineer, develop and integrate a variety of systems and applications through multiple environments.

Tasks Include, But Are Not Limited To

Design and support Data pipeline initiatives
System design, site reliability, administration and performance tuning. Engineer optimizations and solutions for real time streaming applications.
Ensure performance, availability and scalability of data solutions including Kafka and Elastic Search (ELK)

Skills

Strong Unix / Linux skills
Apache Kafka
Elastic stack
Working knowledge of scripting languages (e..g, Shell + python)
Understand continuous data stream concepts
Working knowledge of XML
Strong troubleshooting skills
Database (eg: SQL, Sybase, DB2)
Team oriented and can work well within a global collaborative model
Be comfortable expressing your ideas in meetings, design sessions, etc.
Good analytical and problem solving skills that are coupled with strong communication
Self-sufficient and show ability to lead given the opportunity

Posting Date

Nov 23, 2021

Primary Location

Americas-United States of America-Georgia-Alpharetta

Education Level

Bachelor's Degree

Job

Engineering

Employment Type

Full Time

Job Level

Associate
Show more Show less"
2797979742,Data Engineer (Remote Available),Kohl's,2021-11-13,United States,"Menomonee Falls, WI",Information Technology,Full-time,Retail,"Data Engineer - Remote Available

Help us transform a 50 year company that is modernizing and in hyper growth mode! We are changing the ways customers purchase online, shop in store, and get work done at our distribution and credit centers. You will play a visionary role, creating the solutions and seeing it come to life! We can play well to your strengths and help you develop areas in which you wish to grow or learn more about. Come build your resume with Kohl’s!

Work where you like.

We mean it! Your work can be done 100% remotely permanently. If you prefer to work in a physical building we offer relocation to our Milwaukee, WI or Milpitas, CA offices. And we have a strong internal Developer community and technology to support team collaboration across the US.

Who are we?

We are a fast- paced team with an emphasis on iterative development and constant collaboration. We believe pair programming makes us stronger, faster, and smarter. We practice and teach an approach to software engineering that applies across industries and organizations, so you’ll experience all types of teams, products, and technologies. And we believe that working fast doesn't mean working overtime-- taking time to relax, recharge and refocus keeps our pace sustainable.

What we believe.

Working at Kohls means you get better at what you already do well. We set up regular retrospectives to figure out what we’re doing wrong so we can fix it, and what we’re doing right so we can improve on it. We consistently practice Test Driven Development, and we believe that methodical, steady, relentless forward momentum drives consistent results. Growing and developing your skills is encouraged and supported.

Responsible For

Collaboration through frequent pair programming
Regular retrospectives to figure out what is being done wrong so it can be fixed, and what is being done right so the team can improve on it.
Test Driven Development.

The Ideal Candidate Will Have
Strong knowledge building development practices like CI/CD, Test Automation and cloud deployments
Knowledge of build management tools such as Jenkins or Maven
Demonstrated understanding of source control systems such as GIT
Database Design experience including either SQL, PL/SQL
Implementing ETL process with Big Data Technologies
Required: Spark, Python, Scala
Preferred: MapReduce, Pig, Hive, Kafka, Sqoop, Airflow and Flume
Experience in designing and creating automation workflows and execution
Experience and/or interest in Test Driven Development (TDD) and agile methodologies
Strong communication skills and interest in a pair-programming environment
Passion for growing your skills, tackling interesting work and complex problems
Experience deploying to cloud environments a plus
2+ years of relevant work experience

req# : R205920


Show more Show less"
2807405322,Data Engineer,PlayStation,2021-11-25,United States,"San Diego, CA",Information Technology,Full-time,"Computer Software, Consumer Services, and Entertainment","PlayStation isn’t just the Best Place to Play —it’s also the Best Place to Work. We’ve thrilled gamers since 1994, when we launched the original PlayStation. Today, we’re recognized as a global leader in interactive and digital entertainment. The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation.

Data Engineer

PlayStation, San Diego Studio

Are you an experienced developer with a passion for games? Are you a baseball fan? Would you enjoy supporting the development efforts of games used by passionate loyalists around the world? Does a career opportunity influencing the most successful gaming platform of all time interest you?

We seek a Data Engineer to provide insights and analysis of gameplay and user behavior. Here, you will ensure necessary data is being recorded, validate and maintain a large data pipeline, mine large quantities of data, and build new data infrastructures as needed. You would be tasked to deliver actionable insights used to grow our studio culture. If this is you, please apply!

Responsibilities

Develop efficient and easy to read code primarily using cloud based services
Partition and bucket large datasets for quick access
Help scale and maintain AWS infrastructure to account for growing volume of data
Develop highly efficient systems to retrieve, maintain and analyze in game and customer data
Work with Data Scientists to automate and optimize code to production quality
Perform ETL tasks and maintenance
Maintain and test data integrity to ensure accuracy and timeliness
Define and iterate on development of analytics infrastructure for pre-production and post-production titles

Qualifications

Min. 2 years’ experience with large complex data sets
Professional experience working with Python and SQL
Big Data Experience working in AWS (ex: Glue, S3, Athena) or Azure
Professional level interpersonal and communication skill (email, phone, face to face)
Ability to turn difficult and complex problems into elegant and efficient solutions
A multi-functional teammate
Bachelor's degree from an accredited institution

Pluses

Command-line experience
Knowledge of Data Science packages for cloud machine learning platforms
Database management experience
Programming in C#, C++, or other object-oriented language
Experience validating data emission from a live product
Understand the rules of the sport of baseball
Passion for video games

Sony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to race, color, religion, gender, pregnancy, national origin, ancestry, citizenship, age, legally protected physical or mental disability, covered veteran status, status in the U.S. uniformed services, sexual orientation, marital status, genetic information or membership in any other legally protected category.

Reasonable Accommodation Notice Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.

We strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond.

We sincerely appreciate the time and effort you spent in contacting us and we thank you for your interest in PlayStation.

PRIVACY NOTICE TO SIE LLC’S JOB APPLICANTS

This Privacy Notice explains what personal information we at Sony Interactive Entertainment LLC collect from you, and why we collect it and use it. This Notice covers our practices regarding the personal information of all applicants to our job positions. Please review it carefully.

Categories of personal information we collect from you

Generally, We Obtain This Information Through Our Recruiting Team

We collect personal information about you throughout the recruiting process, in particular the following categories.

Identification and contact information
Direct identifiers such as your first and last name.
Indirect identifiers such as a government ID, your Social Security, work permit or passport #.
Contact information such as your email address, mailing address, telephone number.
Other information about you or that can be associated with you such as:
Sensitive/Protected Data. During the recruitment process, you may (voluntarily) provide us with your ethnicity, gender, military service information, or physical or mental health information, as well as your national origin and citizenship.
Professional or job position-related information , including your past professional experience, references; background verification; talent management and assessment; information regarding any conflicts of interests; and the terms and conditions of your job offer.
Non-public education information , including information about your education records, such as grades and transcripts.

Show more Show less"
2804267221,ENTRY LEVEL BIG DATA ENGINEER,"RIT Solutions, Inc.",2021-10-24,United States,"Dallas, TX",Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Financial Services","Duration: 24+ month

Visa: Any except H1B

Description

JOB TITLE: Software Implementation Consultant

MUST HAVE SKILLS (Most Important)

""Must know Teradata and knowledge of Big Data Technology

""Experience in UNIX Shell Scripting is a must.

""Working knowledge of databases (Teradata) and Advance SQL (Structured Query Language).

""4 Years Hands of experience on Teradata Utilities (Bteq/Mload/TPT/QG/FastExport) ""General operational expertise such as good troubleshooting skills, understanding of system's capacity, bottlenecks, data anomalies.

""1/2 Years Hands of experience on HIVE/Spark/HSQL/OOZIE

""Experience in Design and build of the infrastructure for data extraction, preparation, and loading of data from a variety of sources using technology such as Non -SQL and Big data. ""Experience in Building data and analytics tools that will offer deeper insight into the pipeline, allowing for critical discoveries surrounding key performance indicators and customer activity

""Must be agile for greater efficiency across all of our company data systems.

""Experience Initiating and participating in projects in the area of prediction, optimization, and processes using advanced statistical/mathematical approaches, in the enterprise environment

""Experience in Identifying valuable data sources and automate collection processes ""Experience in Undertaking and preprocessing of structured and unstructured data ""Experience in Analyzing large amounts of information to Client trends and patterns

Desired Skills

""The ability to analyze, model and interpret data.

""Problem-solving skills.

""A methodical and logical approach.

""The ability to plan work and meet deadlines

""Accuracy and attention to detail

Job Duties

""Candidate needs to accomplish an end-to-end build of the pipeline and data harmonization component to enable insight generation for executives and channels to take proactive action on time.

""Design, develop, and implement software based on requirements.

""Troubleshoot production issues and coordinate with the support team for code deployment.

""Collaborate with team members to follow processes, procedures, and data security.

""Diligently teaming with the infrastructure, network, database, application, and business intelligence teams to guarantee high data quality and availability.
Show more Show less"
2824866343,Data Engineer,CVS Health,2021-12-02,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Financial Services, and Hospitals and Health Care","Job Description

We are looking for a Data Engineer with strong programming skills to join our team working on large scale clinical data science projects.

As a Data Engineer you will, assist in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and address project delivery needs. You will collaborate with data science team members and help to productionalize machine learning models, optimize pipelines, and scale AI projects.

Responsibilities Include:

Collaborate with data engineering and data science team members and to help develop, optimize, and support major AI / ML projects as they scale.
Collaborate with business and other related project stakeholders and translate business requirements into viable technical specifications for viable solutions.
Write ETL (Extract / Transform / Load) processes, design database systems, and develop tools for analytic processing and operations.
Lead portions of initiatives with guidance and direction
Collaborate with team members and stakeholders to transform data and integrate algorithms and models into automated processes.
Use knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines.
Use programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systems.
Build data marts and data models to support clients and other internal customers.
Integrate data from a variety of sources, assuring data quality and accessibility standards.
Apply an understanding of business context, needs, priorities to accomplish your work.
Use expertise, judgment and precedents to resolve moderately complex problems.


Required Qualifications


2+ years of hands-on experience with programming languages
Strong programming skills in Python required. Familiarity with other programming languages (Java, C, etc) expected.
Solid fundamental programming knowledge/education most critical overall.
Shell/Bash skills required. Unix/Linux understanding required.
Strong SQL and ETL skills required.
HQL/Hadoop/Hive experience desired (major plus).
Machine learning experience desired (major plus)
Ability to understand complex systems and solve challenging analytical problems.


COVID Requirements

COVID-19 Vaccination Requirement

CVS Health requires its Colleagues in certain positions to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, pregnancy, or religious belief that prevents them from being vaccinated.

If you are vaccinated, you are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status within the first 10 days of your employment. For the two COVID-19 shot regimen, you will be required to provide proof of your second COVID-19 shot within the first 45 days of your employment. Failure to provide timely proof of your COVID-19 vaccination status will result in the termination of your employment with CVS Health.
If you are unable to be fully vaccinated due to disability, medical condition, pregnancy, or religious belief, you will be required to apply for a reasonable accommodation within the first 10 days of your employment in order to remain employed with CVS Health. As a part of this process, you will be required to provide information or documentation about the reason you cannot be vaccinated. If your request for an accommodation is not approved, then your employment may be terminated.

Preferred Qualifications


Spark, Java, and Scala skills are a plus as is familiarity with big data infrastructures, tools, workflows.
Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment.
Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources.
Strong collaboration and communication skills within and across teams.
Experience building data transformation and processing solutions.
Knowledge of large-scale search applications and building high volume data pipelines.

Education

Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline

Master’s degree or PhD preferred

Business Overview

At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.
Show more Show less"
2798966140,Data Engineer,OPTX,2021-11-14,United States,"Las Vegas, NV",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Gambling Facilities and Casinos","Overview

We are looking for a Data Engineer to design and build a robust set of tools and pipelines to support data analytics efforts. You’ll manage and optimize our core infrastructure by creating and maintaining data pipelines. You will work with other engineers and analysts from to design, implement, and maintain a data ecosystem that delivers actionable insights to make key business decisions. You have technical chops but can also work independently to prioritize issues, work within ambiguity, and manage conflicting deadlines. You are creative, data-driven, results-oriented, and eager to help us solve data problems of varying complexities.

Location: Las Vegas, NV | Remote

Responsibilities

Collaborate with Analysts, Program Managers, and other Data Engineers across teams to understand the workforce management ecosystem, identify corresponding data needs, come up with technical proposals, and influence these partners on opportunities for improvement.
Develop, launch and maintain team data pipelines.
Build framework for auditing, error logging and master data management for your pipelines.
Identify, investigate and solve data quality issues and make sure the data is secured and reliable.
Design, develop and provide technical support for tooling integrations.
Support on-call shift as needed to support the team.
Continuously improve the existing pipeline and process infrastructure to meet evolving business needs.

Minimum Qualification

Experience in the data warehouse space.
Experience in custom ETL design, implementation and maintenance.
Experience with object-oriented programming languages.
Experience with schema design and dimensional data modeling.
Experience in writing SQL statements.
Experience analyzing data to identify deliverables, gaps and inconsistencies.
Experience managing and communicating data warehouse plans to internal clients.

Preferred Qualification

Experience with more than one coding language, preferably C#, Java or Python.
Experience with designing and implementing real-time pipelines.
Experience with data quality monitoring and anomaly/outlier detection.
Experience with SQL performance tuning and E2E process optimization.
Experience with SSIS, Talend or Airflow.
BS in CE/EE/CSE or computational sciences.

OPTX is a SAAS casino data platform focused on core and artificial intelligence functionality in the areas of slots, marketing, and player development.
Show more Show less"
2822310039,Data Engineer,TrueSkilla,2021-12-01,United States,United States,,Full-time,,"Hello,

How are you?

Urgent requirement on Data Engineer

Remote Position

Full Time Position




Role: Data Engineer

Key Responsibilities:

• Create data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.

• Help Marketing organization to become a 100% data-driven organization by building a next generation data platform that brings accurate and timely data to the Marketers

• Validate Data Engineering business data elements, organizational and business intelligence architecture designs for engineering functional areas from Dashboards, Data Lakes, Data Operations, ML - AI, and upstream/downstream intake and output processes

• Work with client teams, and other client stakeholders to implement continued design, development and optimization of the marketing data pipelines & data prep infrastructure built on cutting-edge cloud technologies.

• Develop and implement a roadmap to advance marketing and eCommerce analytics

• Build relationships with clients to better understand their business, and to enable them to better understand how to use analytics to drive their business

• Deploy workflow orchestration and demonstrate expertise in data modelling, ETL development, and data warehousing

• Develop automation processes, and best practices execute projects, & Ensure business needs are being met. Troubleshoots business and production issues.

Qualification:

BE / B. Tech/Master’s in Computer science/Information Tech/Business Analytics/ Statistics

Experience:

3-5 years of relevant experience in consulting through data and professional services

2+ years of experience in data engineering and data science with a track record of manipulating, processing, and extracting value from large datasets

Technical/Domain:

Experience building and managing data pipelines and repositories in cloud environments such as Google Cloud, Microsoft Azure or AWS

Experience extracting/cleansing data and generating insights from large transactional data sets using Spark SQL, SQL, Python, and PySpark on cloud

Experience with optimizing Spark pipelines on Dataproc, Databricks or similar technologies

Experience in Airflow is a preferred.

Show more Show less"
2801225416,Big Data Engineer,RAPS Consulting Inc,2021-11-16,United States,"Raleigh, NC",Information Technology,Contract,Staffing and Recruiting,"Description

Hadoop/Big data implementation experience 3+ years

Java, J2ee 8+ years +

Oracle PL/SQL(definitely required) 8+ years +

PL SQL Tuning 8+ years +

Development in Unix, Linux Env 5 years +

Must have Basel III & Accounting implementation experience

Ability to utilize programming methodologies and languages

Efficient coding i.e. adhering to coding standards, procedures and techniques

Effective analysis of new and existing applications and platforms

Clear communication and documentation of technical specifications
Show more Show less"
2787852455,Data Engineer,Cinemark,2021-11-10,United States,"Plano, TX",Information Technology,Full-time,Entertainment,"Headquartered in Plano, TX, Cinemark Holdings, Inc. is a leader in the motion picture exhibition industry with 500+ theatres in the U.S. and Latin America.




Join Our Team!




Do you enjoy working together as a team to accomplish major goals? Join Cinemark to utilize and expand your skills! We are dedicated to making the movie experience memorable, “One Guest at a time.” Our world class talent creates a warm and friendly culture through shared values.




What is a Data Engineer?

The Data Engineer will be responsible for development, implementation, testing, documentation and maintenance of BI and analytics platforms. Will implement data ingestion routines using best practices in data modeling, ETL/ELT processes leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI or other query tools. Produce comprehensive, usable dataset documentation and metadata. Work with internal customers to solve, implement and lead through the deployment of technical solutions for their business needs.




A Day in the Life of a Data Engineer:




Develops and maintains scalable data pipelines and builds out new integrations to support continuing increases in data volume and complexity
Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization
Implements processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it
Writes unit/integration tests, contributes to engineering wiki, and documents work
Automate manual processes and optimize data delivery
Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues
Designs data integrations and data quality framework
Understands and enforces data quality and governance standards like data lineage and traceability
Contributes to data strategy in support of data and data architecture scalability and ability to meet business needs




What You Will Need to Have:

Bachelor’s Degree in Computer Science, Engineering, Math or related field is required Master's degree is preferred
3+ years of experience, specializing in BI solution development
3+ years of SQL experience (No-SQL experience is a plus)
2+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients
Experience designing, building, and maintaining data processing systems
Experience in interpretation of business needs from requests, and rapidly implement effective technical solutions
3+ years of work experience in data management disciplines including data integration, data modeling, optimization, and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks
Strong experience with popular database programming languages including SQL, PL/SQL and others for relational databases
Experience sourcing data via a variety of sources like REST web services, MS SQL Server
Experience using software version control tools (Git, Azure DevOps, Subversion, etc.)
Advanced level of SQL and query performance tuning techniques for Data Integration and Consumption
Solid understanding of BI and analytics landscape, preferable in large-scale development environments
Experience with or knowledge of Agile Software Development methodologies
Background in Cloud Data Warehousing principles and Data Modeling preferred
Strong aptitude for learning new technologies and analytics techniques
Communication skills and ability to develop and present solutions to all levels of management
Must be able to interact effectively and patiently with customers especially while under pressure
The ability to work on multiple projects/tasks simultaneously to meet project deadlines for self and others as required
Ability to establish and maintain positive working relationships with other employees.
Strong analytical and problem-solving skills, with strict attention to accuracy and detail, and the ability to evolve data into knowledge
Passion for delivering highly available, robust BI solutions
Knowledge of best practices and IT operations in an always-up, always-available service




DISCLAIMER: This job description is not an exhaustive list of all responsibilities, duties, skills, efforts, requirements or working conditions associated with the job. While this is intended to be an accurate reflection of the current job, management reserves the right to revise the job or to require that other or different tasks be performed as assigned.




Cinemark USA, Inc. is an Equal Opportunity Employer

Show more Show less"
2817337189,"AVP, Big data Engineer (R2183746)",Citi,2021-11-06,United States,"Tampa, FL",Engineering and Information Technology,Contract,"Banking, Financial Services, and Investment Banking","Job Id: 21358918

Application Development Senior Programmer Analyst with responsibilities that include:
Design & implementation of scalable & fault tolerant ETL Pipelines on BigData Platform to store & process terabytes of contract information’s from upstream sources with high availability
Actively work on performance tuning techniques through understanding Spark DAG’s on data structures on both Relational & BigData Platforms giving high performance to both ETL & Reporting Components
Create mock-ups and proof of concept from business requirements when necessary
Performs ad-hoc data research & analysis, provide written summaries of results for non-technical business users
Working with the onsite development team and providing necessary overlap coverage to ensure smooth transition and communication between offshore and onsite
Work closely with multiple teams(Business Analyst, ETL, DB team, Infra, Support, etc )
Work collaboratively in a small, cross-functional Global Team

Job Qualifications:

4 + years of application/software development
3 + Years of hands-on experience on BigData Technologies like Apache Spark , Hive, Hadoop is must
3+ years experience with JAVA(Core Java, J2EE, Spring Boot Restful Services), Python, Web services (REST, SOAP), XML, Java Script, Micro services, SOA etc
3+ years experience with ETL technologies like AbInitio, Talend etc
Experience with developing frameworks and utility services including logging/monitoring
Strong technical knowledge of Apache Spark, Hive, SQL and Hadoop ecosystem
Knowledge of Scala, Java & Python programming language. Hands-on experience on any two languages are mandatory
Experience delivering high quality software following continuous delivery and using code quality tools (JIRA, GitHub, Jenkin, Sonar, etc.).
Experience creating large-scale, multi-tiered, distributed applications with Hadoop and Spark
Comfortable in Windows and Linux environments.
Comfortable with different data storage solutions such as RDMBS(Oracle), Hive, HBase, Impala etc.
Experience with API development and use of data formats is a plus
Knowledge on NOSQL Databases like MongoDB, Hbase, Cassandra etc is aplus.
Working experience with Financial application / Finance processes
Experience with vendor products like Tableau, Arcadia, Paxata, KNIME is a plus
Ability to work independently, multi-task, and take ownership of various analyses or reviews
Has to be results-oriented, willing and able to take ownership of engagements
should have strong analytical skills

Education:

Bachelor’s degree/University degree or equivalent experience

This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.

As a bank with a brain and a soul, Citi creates economic value that is systemically responsible and in our clients’ best interests. As a financial institution that touches every region of the world and every sector that shapes your daily life, our Enterprise Operations & Technology teams are charged with a mission that rivals any large tech company. Our technology solutions are the foundations of everything we do. We keep the bank safe and provide the technical tools our workers need to be successful. We design our digital architecture and ensure our platforms provide a first-class customer experience. Our operations teams manage risk, resources, and program management. We focus on enterprise resiliency and business continuity. We develop, coordinate, and execute strategic operational plans. Essentially, Enterprise Operations & Technology re-engineers client and partner processes to deliver excellence through secure, reliable, and controlled services.

Global Functions Technology is a diverse organization comprised of more than 15,000 talented professionals with some of the brightest minds – all working together to realize Citi’s Vision of growth and economic progress. As a group, we partner with the Finance, Risk, Compliance, and Human Resources teams to drive the delivery of innovative technology solutions using common data, analytics, and platforms. Our technology operates in real-time environments, capturing and managing market, transaction, and accounting data, as well as the data from millions of customers daily. Our solutions cover all products and geographies in which Citi does business. We are the backbone for reporting across the bank, satisfying our regulatory commitments, enabling our businesses to be nimbler and helping to safeguard customer assets through highly effective controls.

Our commitment to diversity includes a workforce that represents the clients we serve globally from all walks of life, backgrounds, and origins. We foster an environment where the best people want to work. We value and demand respect for others, promote individuals based on merit, and ensure opportunities for personal development are widely available to all. Ideal candidates are innovators with well-rounded backgrounds who bring their authentic selves to work and complement our culture of delivering results with pride. If you are a problem solver who seeks passion in your work, come join us. We’ll enable growth and progress together.

-------------------------------------------------

Job Family Group:

Technology

-------------------------------------------------

Job Family:

Applications Development

------------------------------------------------------

Time Type:

Full time

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting


Show more Show less"
2825322562,Data Engineer,Hitachi Vantara,2021-12-03,United States,"Houston, TX",Information Technology,Full-time,"IT Services and IT Consulting, Human Resources, and Management Consulting","The Team

At Hitachi Vantara’s Digital Insights practice, we help our clients by building technology solutions that addresses business challenges and improve business outcomes with data-driven insights. As we continue expand our big data team, we are looking for data engineers who are passionate about technology and want to build a career working on the latest technology platforms.

As a Part Of This Team, You Will

Work with our clients to gather requirements and develop scalable data solutions
Use cloud services to integrate different data sources and develop data lakes
Provide recommendations to optimize data pipelines and data warehouse queries

Required Skills

Bachelor’s degree in computer science, MIS related area, or equivalent experience
Ability to work well in a team environment, meet deadlines, demonstrate good time management, and multi-task in a fast-paced project environment
Experience developing data pipelines (EMR/Glue) in AWS cloud
3+ years of experience with Apache Spark (Python or Scala)
Familiarity with basic Linux commands and writing Shell scripts
1+ years of experience working on Snowflake and proficient with SQL”.
Strong understanding of data warehousing concepts and dimensional modeling
Willingness and ability to learn new tools and technologies
Excellent verbal and written communication skills

Preferred Skills

Experience developing stream processing jobs and familiarity with Kafka
NoSQL databases – MongoDB, Cassandra, DynamoDB, HBase, Neo4j, etc.

Our Company

Hitachi Vantara is part of the Global Hitachi family. We balance innovation with an open, friendly culture and the backing of a long-established parent company, known for its ethical reputation. We guide customers from what’s now to what’s next by unlocking the value of their data and applications to solve their digital challenges, achieving outcomes that benefit both business and society.

Our people are our biggest asset, they drive our innovation advantage and we strive to offer a flexible and collaborative workplace where they can thrive. Diversity of thought is welcomed and our employee base is represented by several active Employee Resource Group communities. We offer industry leading benefits packages (flexible working, generous pension and private healthcare) and promote a creative and inclusive culture. If driving real change gives you a sense of pride and you are passionate about powering social good, we’d love to hear from you.

Our Values

We strive to create an inclusive environment for all and are open to considering home working, compressed/flexible hours and flexible arrangements. Get in touch with us to explore how we might be able to accommodate your specific needs.

With Japanese Roots Going Back Over 100 Years, Our Culture Is Founded On The Values Of Our Parent Company Expressed As The Hitachi Spirit

We are proud to say we are an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Wa – Harmony, Trust, Respect

Makoto – Sincerity, Fairness, Honesty, Integrity

Kaitakusha-Seishin – Pioneering Spirit, Challenge
Show more Show less"
2792738616,Data Engineer,Capital One,2021-11-13,United States,"Plano, TX",Information Technology and Engineering,Full-time,"Banking, Financial Services, and Investment Banking","Locations: TX - Plano, United States of America, Plano, Texas

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You’ll Do

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies

Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems

Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake

Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community

Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment

Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications

Bachelor’s Degree

At least 2 years of experience in application development

At least 1 year of experience in big data technologies

Preferred Qualifications

3+ years of experience in application development including Python, SQL, Scala, or Java

1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)

2+ years experience with Distributed data computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)

1+ years experience working on real-time data and streaming applications

1+ years of experience with NoSQL implementation (Mongo, Cassandra)

1+ years of data warehousing experience (Redshift or Snowflake)

2+ years of experience with UNIX Linux including basic commands and shell scripting

1+ years of experience with Agile engineering practices

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Job Category - Engineering, Technology
Show more Show less"
2808117689,Data Engineer,Deckers Brands,2021-11-25,United States,"Portland, OR",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2796492273,Data Engineer,Quantexa,2021-10-18,United States,"Boston, MA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Description

Founded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 5 years, 350+ employees later we still believe that today. We connect the dots within our Customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data.

Due to the continuous success and high demand from our Customers, we are looking for Graduates to kick start their career by joining our Quantexa family.

What does a Graduate role at Quantexa look like?

Our Big Data Graduate role is designed for you to develop your technical skill set, think creatively and be a real problem solver of major issues our clients are facing today. If you are someone who likes to think outside the box, holds a real passion for data and is open to new ideas, you’ll find a Qmmunity that recognises your needs to be a creative innovator and embrace it.

You will work on big data projects where you will have exposure to data science, data engineer and DevOps methods, whilst learning to be comfortable dealing with both internal and external stakeholders. In a typical Quantexa project, you’ll work with high volume data, helping our top clients solve business problems in the area of fraud, compliance and financial crime. You’ll be working closely with Data Scientists, Data Engineers, Business Analysts, Technical Leads, Project Managers and Solutions Architects, using entity resolution to generate networks and apply a scoring framework to identify risks. At Quantexa everyone is following the same goal of meeting our client’s expectations and delivering a first-class service.

What training is provided, and technology will you use?

We want our graduates to learn the latest leading technologies and being the huge fans of functional programming that we are, your first 3 months will consist of going through our dedicated training academy. You’ll have exposure to learning Scala, which is our primary language here at Quantexa, so you are confident and comfortable using our platform. Part of this exciting journey will also have you exposed to other big data tools such as Spark and Hadoop with our platform being hosted on Google cloud (GCP). You will learn how to create entities and networks and loading data using Elasticsearch in the Quantexa interface. You’ll be required to generate a solution using our explorer in a world leading big data tool set. This training is heavily self-paced learning giving you the flexibility to add to the task and complete with set timings.

Following completion of the academy you will be working on multiple projects. You can expect to work with different lead experts who share their love of big data to deliver the best for our clients.

Requirements

What do I need to have?

We are looking for enthusiastic individuals who share a love of ‘big data’ and have a numerate degree in either Mathematics, Physics, Computer Science, IT/Technology.
Must be a graduate already or expecting to graduate in a STEM subject
A passion and the desire to learn and code in Scala using multiple big data tool sets.
Hold problem solving skills and enthusiasm to pick up a broad set of tasks.
Experience in Python, Java, Scala, R or similar technologies is desirable.
Passion and drive to grow within one of the UK’s fastest scale ups.
Willingness to travel within the UK and Europe.


Benefits

Why join Quantexa?

We know that just having an excellent glass door rating isn’t enough, so we’ve put together a competitive package as a way of saying thank you for all your hard work!

Competitive Salary
Company Bonus
Excellent private healthcare, Dental and Optic coverage, Life assurance, LTD and STD coverage
401k where we’ll match up to 5%
Online training customized to your personal preferences
Generous annual leave
Amazing working environment - Ranging from regular social events, free beverages and a very good location right by south station in Boston.
Show more Show less"
2817114540,"DevOps Engineer, Data",Housecall Pro,2021-12-02,United States,United States,Engineering,Full-time,Computer Software,"Why Housecall Pro?

You’ll get to do work that creates value, with a team that values what you create. We’re a mission-driven company dedicated to changing the lives of service professionals with a leadership team that truly invests in their employees’ careers. We also offer:

A generous benefits program that supports the whole you with medical, dental, vision, life, disability, and 401(k)
Paid holidays and unlimited paid time off
Equity in a rapidly growing startup backed by top-tier VCs
Monthly tech reimbursements
A culture built on innovation that values big ideas, no matter where they come from







As a DevOps Engineer, Data at Housecall Pro you’ll design, build and grow our data engine. You are passionate about data-driven approaches and cloud infrastructure. You enjoy exploring large data sets and get excited about learning new technologies and learning in a collaborative environment. You are skilled in deploying software and relish the opportunity to help developers work more efficiently. You have experience in data warehousing and working with relational databases for the purpose of building data solutions for analytics and data science.




Our Analytics team is extraordinary. We are empathetic, hard working and focused on easy data and information access. We are the ""insights engine"" of Housecall Pro, helping HCP and the HCP service professionals to operate and to grow our businesses.




What you’ll be doing

Manage cloud resources using Infrastructure-as-Code techniques (e.g. Terraform)
Build out best practices around monitoring, testing, alerting
Apply SDLC techniques to the deployment of data systems
Measure & optimize infrastructure costs
Orchestrate movement and transformation of data using SQL and Python tooling




Qualifications

Strong knowledge of data-relevant AWS services such as RDS, S3, EMR, Kinesis, DynamoDB, and Lambda (or equivalents from GCP or Azure)
Solid understanding of the software development lifecycle, and CI/CD tools and practices
Experience running containerized workloads in production, especially batch workloads
Familiarity with modern MPP-columnar data warehouse platforms such as Redshift, Snowflake, Greenplum, ClickHouse (we use Snowflake)
Familiarity with DAG-oriented workflow tools such as Luigi, Airflow, Prefect
Some experience with SQL & Python
Ability and willingness to learn
Familiarity with Spark and the Hadoop ecosystem is a bonus
BS in Computer Science, Information Technology or related field, or equivalent experience




Founded in 2013, Housecall Pro helps home service professionals thrive by giving them the tools to work simpler and grow smarter across all aspects of their business. Our core SaaS software platform helps Pros with scheduling, dispatching, job management, invoicing, payment processing, marketing, and more. We’ve raised over $50M in venture capital funding to date, and have over 400 ambitious, impact-driven, genuinely fun-loving employees in San Diego, San Francisco, Denver, and all over the world.




Housecall Pro celebrates diversity and we are committed to creating an inclusive environment for all employees with equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. Housecall Pro is an equal opportunity employer; committed to an environment free from discrimination, harassment, and retaliation.

Show more Show less"
2826222933,Data Engineer,CloudRay,2021-12-03,United States,"Clearwater, FL",Information Technology,Contract,"Computer Networking Products, Computer and Network Security, and Telecommunications","Hello Team,

Rek

Data Engineer

Clearwater, FL

6 Months C2H

Client: GalaxE Solutions

Visa: GC/GC EAD/USC/H4 EAD

Rate: $50 - $52/hr. on W2 All Inclusive.

Candidate resumes should be no longer than 6 pages.
visa/EAD candidates (besides GC EADs and Asylee EADs) must be presently authorized to work in the US until at least 2022 to be considered.
Show more Show less"
2682952785,Big Data Engineer,FinTech LLC,2021-08-18,United States,"Beaverton, OR",Engineering and Information Technology,Full-time,"Appliances, Electrical, and Electronics Manufacturing, Manufacturing, and Retail","Responsibilities:



Develop and extend a recently started data platform to support big data pipelines in the consumer data space
Drive/remain responsible for development of end-to-end for specific components
Contribute to project discussions, collaborate directly with architect team and present results to key stakeholders
Design, build and continuously enhance the project codebase
Act as an onsite-timezone force multiplier for a distributed team of engineers and managers
Write detailed design documentation, present decisions and motivate these
Work inside a team of industry experts on the cutting edge Big Data technologies to develop solutions for deployment at massive scale
Design data infrastructure with privacy and security being cross-cutting concerns
Set coding and deployment best practices

Requirements:



+6 years experience designing and coding platform solutions for Big Data pipelines
+3 years of experience working with event-messaging systems - Kafka is a big plus
+2 years coded and deploying services running on Kubernetes
Python and Spark knowledge is required
Experience working with AWS
Experience with enterprise data warehouse
Strong understanding of the challenges in building end-to-end big data pipelines for a large variety of use-cases at scale
Strong communication skills
Show more Show less"
2818867587,"100% REMOTE Data Engineer (Python, Node, SQL, ETL)",Robert Half Technology,2021-12-03,United States,"New Jersey, United States ",Information Technology,Full-time,Computer Software,"Title: Data Engineer

Location: 100% REMOTE but company is based out of Teaneck, NJ

Salary: $80-$110k annually plus benefits, etc (Based on Experience)

Industry: Software / Technology




** They are looking for a minimum of 2 years of experience **




Job Description:




Responsibilities:

Develop, maintain, and improve ETL pipelines servicing multiple data source loading
Optimize ML pipelines for efficient training and inference workflows
Collaborate across multiple functions for building clean and easy-to-manage data infrastructures
Develop customer facing APIs for data consumption and modeling
Contribute to companies software development and implement innovative ideas to software application



Qualifications:

Bachelor’s degree in Computer Science or equivalent
2+ years experience in developing ETL pipelines, data warehousing
2+ years experience in scripting language (Python, NodeJS)
2+ years experience in SQL (Mysql, Redshift)
Experience with AWS services including S3, EC2, RDS, Lambda, Glue
Nice to have: familiar with data science tech stack (pandas, numpy, scikit-learn)
Show more Show less"
2792734965,Data Engineer,Capital One,2021-11-13,United States,"Plano, TX",Information Technology and Engineering,Full-time,"Banking, Financial Services, and Investment Banking","Locations: TX - Plano, United States of America, Plano, Texas

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You’ll Do

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies

Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems

Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake

Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community

Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment

Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications

Bachelor’s Degree

At least 2 years of experience in application development

At least 1 year of experience in big data technologies

Preferred Qualifications

3+ years of experience in application development including Python, SQL, Scala, or Java

1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)

2+ years experience with Distributed data or computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)

1+ years experience working on real-time data and streaming applications

1+ years of experience with NoSQL implementation (Mongo, Cassandra)

1+ years of data warehousing experience (Redshift or Snowflake)

2+ years of experience with UNIX Linux including basic commands and shell scripting

1+ years of experience with Agile engineering practices

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Job Category - Engineering, Technology
Show more Show less"
2817902755,Data Engineer,Kestra Financial,2021-11-04,United States,"Austin, TX",Information Technology,Full-time,"Computer Software, Insurance, and Financial Services","We are looking for passionate data engineers to join our growing Data and Analytics team. Join this exciting journey in modernizing our Advisor solutions to the next-generation cloud platform. You will be responsible for working in a cross-functional team to expand, optimize, and improve overall data quality and set up next-generation data orchestration using modern cloud tools and technologies. As a cloud Data Engineer, you will be designing and building secure and resilient architectures, with the goal of providing actionable insights to our Advisors for them to optimize their business.

ESSENTIAL DUTIES AND RESPONSIBILITIES:

Design and develop data pipelines to extract data from a wide variety of data sources using Azure, Snowflake Cloud, and cloud-native technologies.
Build a data model to get actionable insights from data, operational efficiency, and other key business performance metrics.
Design and manage inbound and outbound data processes and monitoring. Work with the data provider to bring in new feed into our data eco-system.
Enjoy working in Agile as part of a scrum team and deliver high quality product incrementally in an interactive manner.
Write Test Driven Development based code to meet overall data quality standards as defined by the users.
Automate the data testing processes and integrate them with monitoring systems.
Collaborate with the Application Engineering team, DBA, Infrastructure, and Project Management Office.
Analyze existing systems (including legacy) and data sets to help Business Analysts define the functional and non-functional requirements.
Meet with the business users, assist with data-related technical issues, and support their data infrastructure needs.


KNOWLEDGE, SKILLS, AND/OR ABILITIES:

Background in working with Azure Cloud Services: Data Factory, SQL database, Functions, Data Lake, Databricks, Logic Apps, and Azure Automation.
Fluent in object-oriented and functional script language: Python, Scala, and C#.
Advanced working knowledge of SQL Server database - writing advanced SQL script, profiling, and optimization.
Working knowledge of Business Intelligence tools: Microsoft Integration Services, Reporting Services, and Analysis Services, as well as PowerBI.
Experience with other Big Data tools such as Spark, Snowflake, and Kafka
Experience in creating and using APIs
Preference for background in Financial Services, ideally in the Wealth Management/Independent Broker Dealer/RIA industry


SUPERVISORY RESPONSIBILITIES: None

EDUCATION AND/OR EXPERIENCE:

Bachelors/Masters in Computer Science, MIS/Information Management, Engineering or related field


CERTIFICATES, LICENSES, REGISTRATION: None

PHYSICAL DEMAND: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Ability to sit at a computer for long periods of time in office environment well lit.
Ability to lift up to 20 pounds.
Position is located in the Austin, TX office. Must be able to work in the office during scheduled work hours.


OTHER DUTIES: Please note this job description is not designed to cover or contain a complete comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.

Benefits

Full health, vision, dental. 401(k) plans along with a host of voluntary plans such as car insurance, legal services and more.

DISCLOSURE

By applying to a job at Kestra Financial, Inc., you are agreeing to the following statements:

You acknowledge that if hired, Kestra Financial, Inc. may, obtain and use background information concerning your credit, character, general reputation, personal characteristics, work habits, performance and experience for evaluation for your potential employment.
It is the policy of Kestra Financial to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, sex, sexual orientation, gender, identity or expression, age, disability, marital status, citizenship, national origin, genetic information, or any other characteristic protected by law. Kestra Financial prohibits any such discrimination or harassment.


Powered by JazzHR

FfJyiHw9JK
Show more Show less"
2805519937,Data Engineer - Remote,The Hartford,2021-10-25,United States,"Houston, TX",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

Join a fast-paced and talented Agile Scrum team to unlock Data Capabilities for The Hartford. You will have an opportunity to participate in the entire software development lifecycle process in support of continuous DATA delivery, while growing your knowledge with emerging technologies. We use the latest DATA technologies, software engineering practices, Agile delivery framework, and are passionate about technology and building well architected and innovative solutions that drive optimal business value generation. This cutting edge and forward focused team presents the opportunity for collaboration, self-organization within the Scrum Team and visibility as we focus on continuous Business data delivery.

What’s in it for you?

Experience deeper understanding of Data analysis, Emerging technologies and Development practices.
Collaboration with a high-performing, forward-focused team, Product Owner(s) and Business stakeholder(s) engagement.
Opportunity to expand your communication, analytical, interpersonal, and organization capabilities.
Experience working in a fast paced environment – driving business outcomes in Agile ways of working.
Enable and influence the timely and successful delivery of business data capabilities and/or technology objectives.
Enhance your entrepreneurial mindset – network opportunity and influencing outcomes.
Appreciation and opportunity to learn and support rapid software construction and deployment using a mix of technologies.
Supporting environment that fosters can-do attitude and opportunity for growth and advancement based on consistent demonstrative performance.
Optimize business value by leveraging your DATA experience and depth.
Be part of a Scrum Team – driving work independently or collaboratively towards achieving business outcomes.
Experience in working with IT offshore vendor partners.
Ability to collaborate daily alongside our senior investment professionals to develop technology driven solutions which will deliver a competitive advantage to EDO.
Strong ability to estimate project tasks and to deliver upon committed dates. Ability to develop and maintain systems according to a defined set of standards.
Act as a mentor for colleagues.

Qualifications

Bachelor degree with at least 4 years of applicable work experience.
Desired educational experience include, but are not limited to: Computer Science, Engineering, IT, Management Information Systems, Data Analytics, Applied Mathematics, and Business.
Experience with prior Data Engineer/ETL competencies and prior experience with successful enablement of Data Delivery initiatives.
Understanding of current and emerging IT products, services, processes and methodologies.
Experience in the following disciplines is required: SQL, Oracle, PL/SQL, Talend (or similar ETL Technology), Autosys, data warehousing architecture, and data modeling
Certifications in the following is preferred(not mandatory) - AWS Cloud practitioner

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$90,480 - $135,720

Benefits

Our company’s success is due to our employees’ dedication and passion for their work. They are our greatest asset. That’s why we are committed to offering employees and their families a comprehensive benefits package and award-winning well-being programs. By helping our employees achieve their full potential, we unlock our own. Visit https://www.thehartford.com/careers/benefits for details.

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

Data Engineer - GE08AE
Show more Show less"
2822265180,Data Engineer,Insight Global,2021-12-01,United States,"Irvine, CA",,Full-time,,"Must Haves:

3+ years of experience as a data engineer or similar
2+ years of experience with AWS or 1+ year with AWS and 1+ with azure
Extensive experience working on AWS data solutions; pyspark, python, etc
Experience within data engineering or data warehousing, data modeling
Experience working with large volumes of data
Excellent understanding of how a large environment operates

Plusses:

Experience with languages such as: Typescript, node, scripting experience, java, c#
Previous work experience at a large firm in the financial services industry




Day to day:

A large financial services firm in Irvine, CA is looking for a Data Engineer to join their team. You will be joining a team of 6 engineers focused on retirement planning for smaller sized companies and high net worth individuals. You will partner with the tech lead to design and implement a data warehouse app. In doing so, you will collaborate across multiple teams to gather data. The data team is focusing on “liberating the data,” and this candidate must have the knowledge and vision to make data more accessible and available. There is a big opportunity come in and influence how the team builds things, and there will be opportunities to help with refactoring, rearchitecting and rebuilding from scratch. This position will be a hybrid role, so this person must be local to a Capital Group office in Irvine or Los Angeles, CA. This position will be a 6-month contract to hire.

Show more Show less"
2758753385,Data Engineer,Snap Inc.,2021-12-03,United States,"Los Angeles, CA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Snap Inc. is a camera company. We believe that reinventing the camera represents our greatest opportunity to improve the way people live and communicate. Our products empower people to express themselves, live in the moment, learn about the world, and have fun together.

We’re looking for a Data Engineer on our Analytics Engineering team! Working from one of our west coast offices in Santa Monica, CA, Mountain View, CA, or Seattle, WA, you’ll collaborate with teams across the organization (engineering, finance, sales, marketing, and strategy) to build pipelines and systems to deliver the data necessary for making the right decision in the moment. Our team strives to improve decision quality across the company by ensuring metrics are trustworthy, discoverable, and easily consumable.
What you’ll do:
Work closely with stakeholders in engineering, finance, sales, marketing, strategy, and governance to make high quality datasets available to consumers in a timely manner
Develop data pipelines adhering with privacy and governance principles
Become familiar with our data consumption portals and their capabilities
Build expertise and ownership of data quality for supported domains
Establish and implement data quality standards and controls
Build tooling and implement systems to overcome limitations of the data consumption portals when appropriate
Drive adoption of the data sets you’ve produced
Knowledge, Skills & Abilities:
Experience in building data pipelines to serve reporting needs
Experience owning all or part of a team roadmap
Ability to prioritize requests from multiple stakeholders in disparate domains
Ability to effectively communicate complex projects to non-technical stakeholders
Minimum Qualifications:
BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
3+ year experience in SQL or similar languages
3+ years development experience in at least one object-oriented or scripting language (Python, Java, Scala, etc)
Experience in ETL / Data application development
Preferred Qualifications:
Hands on experience with Google BigQuery
Experience in version control systems such as Git
Data architecture and warehousing experience
Experience leading a small team of data or software engineers
Experience with Airflow

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at accommodations-ext@snap.com .

_________________________________________________________________________________________________

For more information on what to include when writing your job description, please check out this resource: OFCCP | Job Description Template Details .
Show more Show less"
2818356599,Data Engineer,Deloitte Consulting,2021-12-01,United States,"Philadelphia, PA",Information Technology,Full-time,Management Consulting,"Are you an experienced, passionate pioneer in technology? A system’s professional who wants to work in a collaborative environment. As an experienced Data Engineer, you will have the ability to share new ideas and collaborate on projects as a consultant without the extensive demands of travel. If so, consider an opportunity with Deloitte under our Project Delivery Talent Model. Project Delivery Model (PDM) is a talent model that is tailored specifically for long-term, onsite client service delivery. PDM practitioners are local to project locations, minimizing extensive travel, and provides you with a full career path within the firm.

Work you’ll do/Responsibilities

This team member will support the Citizen Development Experience and the advancement of analytics for the Investment Business community. This candidate will be responsible to help support the development, configuration, and enablement of SageMaker features for adoption and use by the business community. Other work in this role will include using Python support to advanced analytics. Additional responsibilities of this role will support general use of AI/ML workflow for business clients.




The Team

The US Systems Engineering Offering delivers large scale software applications and integrated systems and assists its clients with architecture design, assessment and optimization, and definition. The practice aims at developing service-oriented architecture (SOA) and other integration solutions to enable information sharing and management between business partners and disparate processes and systems. It would focus on key client issues that impact the core business by delivering operational value, driving down the cost of quality, and enhancing technology innovation.

Qualifications

Required

Experience with AI/ML
Experience with SageMaker Studio
Experience with Python
Experience with AWS query including EMR cluster, Athena.

Travel up to 20% annually

Limited immigration sponsorship may be available.

Preferred

Knowledge of Financial and Investment domain also desirable but will consider all AI/ML candidates for this role.

Recruiter tips

We want job seekers exploring opportunities at Deloitte to feel prepared and confident. To help you with your interview, we suggest that you do your research: know some background about the organization and the business area you’re applying to. Check out recruiting tips from Deloitte professionals.




Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you.

Our people and culture

Our diverse, equitable, and inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our client most complex challenges. This makes Deloitte one of the most rewarding places to work. Learn more about our inclusive culture.

Professional development

From entry-level employees to senior leaders, we believe there’s always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.

As used in this posting, ""Deloitte"" means Deloitte Consulting LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Deloitte will consider for employment all qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local laws. See notices of various ban-the-box laws where available.

Show more Show less"
2798045925,Data Engineer,Expedia Group,2021-10-24,United States,"Chicago, IL",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Travel Arrangements","What You’ll Do

Design, build, and support scalable and durable data solutions that can enable self-service consumption use cases using cloud based technologies in an agile manner
Support Expedia Group’s product and business teams’ specific data needs on a global scale
Close partnership with internal partners from engineering, product, and business
Write clean, efficient and thoroughly tested code
Be part of an agile team that is continuously learning and improving
Develop scalable and highly-performant distributed systems with everything this entails (availability, monitoring, resiliency)
Work with our business partners to flesh out and deliver on requirements in an agile manner
Evolve development standards and practices
Take architectural ownership for various critical components and systems
Proactive problem-solving at the organization level
Communicate and document solutions and design decisions
Build bridges between technical teams to enable valuable collaborations
Promote good development methodologies via code reviews, great software design, brown bags or tech talks
Provide support to both internal and external team members where necessary
Evaluate and recommend tools, technologies and efficient processes

Who You Are

Bachelor’s or Master’s Degree in Computer Science or Engineering or related experience required
Experience building data pipelines with data from event streams, NoSQL, APIs etc. using distributed data frameworks
Experience in batch processing (using Spark) and stream processing required
Professional development experience in Scala/Java required
Experience with different aspects of data systems including database design, data modeling, performance optimization, SQL etc.
Understanding and experience in Kafka, Kubernetes, Spring, AWS, Hive, Docker a huge plus
Strong communication skills (able to explain concepts to non-technical audiences as well as peers)
Self-starter who is highly organized, communicative, quick learner, and team-oriented

Why Join Us: Expedia Group recognizes our success is dependent on the success of our people. We are a global travel platform, made up of the most knowledgeable, passionate, and creative people in our business. Our brands recognize the power of travel to break down barriers and bring the world within reach – that responsibility inspires us to be the place where exceptional people want to do their best work, and to provide them the tools to do so. Whether you’re applying to work in engineering or customer support, marketing or lodging supply, at Expedia Group we act as one team, working towards a common goal; to bring the world within reach. We relentlessly strive for better, but not at the cost of the customer. We act with humility and optimism, respecting ideas big and small. We value diversity and voices of all volumes. We are a global organization but keep our feet on the ground so we can act fast and stay simple. Our teams also have the chance to give back on a local level and make a difference through our corporate social responsibility program, Expedia Cares. If you have a hunger to make a difference with one of the most loved brands in the world and to work in the dynamic travel industry, this is the job for you. Our family of travel brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Egencia®, trivago®, Vrbo®, Orbitz®, Travelocity®, Wotif®, ebookers®, CheapTickets®, Hotwire®, Expedia® Media Solutions, CarRentals.com™, Expedia Local Expert®, Expedia Cruises™ and SilverRail Technologies, Inc. For more information, visit www.expediagroup.com

About Expedia Group

Expedia Group (NASDAQ: EXPE) powers travel for everyone, everywhere through our global platform. Driven by the core belief that travel is a force for good, we help people experience the world in new ways and build lasting connections. We provide industry-leading technology solutions to fuel partner growth and success, while facilitating memorable experiences for travelers. Expedia Group's family of brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Vrbo®, Egencia®, trivago®, Orbitz®, Travelocity®, Hotwire®, Wotif®, ebookers®, CheapTickets®, Expedia Group™ Media Solutions, Expedia Local Expert®, CarRentals.com™, and Expedia Cruises™.

© 2021 Expedia, Inc. All rights reserved. Trademarks and logos are the property of their respective owners. CST: 2029030-50

Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. This employer participates in E-Verify. The employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization.
Show more Show less"
2785402836,Data Engineer,McKinsey & Company,2021-11-27,United States,"Atlanta, GA","Consulting, Research, and Strategy/Planning",Full-time,Management Consulting,"Qualifications

Bachelor's degree in information systems, computer science, engineering or similar field; mathematics or statistics background is a plus
Proficient in SQL and knowledge of data science languages like R and Python
Experience building and optimizing data pipelines integrating multiple sources building required infrastructure for optimal extraction, transformation and loading of data from various data sources using for example AWS, Snowflake’s Datalake and SQL technologies
Solid understanding of data modeling, design patterns and data processing best practices
Skilled user of BI and visualizations software like Tableau, Power BI, Alteryx or similar
Strong analytical and problem-solving skills paired with the ability to develop creative and efficient solutions; tolerance in dealing with bad quality data
Distinct customer focus and quality mindset

What You'll Do

You will be responsible for data integration and process automation to analyze CRM data.

In this role, you will work closely with the Personalization analytics manager to develop standard reporting as well as develop data pipelines for complex analytical models. You will learn about a landscape of data sources and tools that enable the client development and relationship building efforts of the firm and receive access to large pools of data. You will make the data digestible and create dashboards and metrics for further analysis. You will create customized outputs as needed by stakeholders and you will also prepare data sources and pipelines to support a number of predictive models and recommendation engines that you will develop together with a data scientist.

Who You'll Work With

You will be based in our Atlanta, Chicago, Miramar, New York or Philadelphia office as part of our Personalization analytics team. You will help create innovative analytics for our global client development operations. You will be part of a newly created team which is directly supporting senior leaders of the firm and you will build solutions from scratch applying your own creativity to the process with ample opportunity to experiment with the data.

The Personalization analytics team create insights from CRM data and the client development funnel to improve decision making in client development operations, enable customization of outreach campaigns and tracking/predicting engagement of new clients. We provide insights to individual partners for intelligent relationship management based on trigger events and contact status changes.
Show more Show less"
2824590659,Data Engineer,Tackle-Consulting,2021-12-02,United States,United States,,Contract,,"ROLE- DATA ENGINEER

LOCATION- REMOTE NEED TO SUPPORT IN PST HRS

SKILLS -SPARK, JAVA / SCALA (MANDATORY)




RESOURCE REQUIREMENT:

Senior Developer with 7+ Years of exp in BigData, AWS, Vertica Data Engineer with 5+ Years of with Big

Engineer will work on migration of Vertica to AWS Leverage existing Intuit Migration Vertica to AWS framework (Just FYI)

MUST HAVE SKILL:

Moderate Expertise in BigData, Spark, SparkSQL, AWS skills S3, Lambda, EMR, Redshift

Candidate should have excellent understanding of SQL, DW concepts

GOOD TO HAVE :Experience in Vertica (Not Mandatory)

Show more Show less"
2815128717,Big Data Engineer,Jobot,2021-11-26,United States,"Nashville, TN",Engineering and Information Technology,Full-time,IT Services and IT Consulting and Computer Software,"Spark Engineer needed at industry leading healthcare analytics software company! 100% Remote

This Jobot Job is hosted by Mike Williams

Are you a fit? Easy Apply now by clicking the ""Apply"" button and sending us your resume.

A Bit About Us

Founded nearly 15 years ago, our goal is to protect consumers and companies nationwide from overpriced, low-quality healthcare. Using industry-leading objective price and quality data and claims-driven ROI reporting, Our intuitive online healthcare shopping solution provides 7,000+ employers and members with an easy-to-use benefits solution that increases movement to high-value care, driving savings and rapid ROI, and provides greater price predictability.



Why join us?


Competitive base salary and overall compensation package
401 K with generous company match
Full benefits Medical, Dental, Vision
Generous PTO, vacation, sick, and holiday schedule
Life Insurance coverage

Job Details

100% Remote.

We are looking for a Senior Software Engineer you will clean, transform, and analyze vast amounts of raw data from various systems using Spark to provide ready-to-use data for our analysts and external clients. You will be able to work within an agile development process and be comfortable writing code in a continuous integration environment. Finally, you will be a subject matter expert on big data processing and mentor our teams on data engineering best practices.

Manage queries against multi-billion row datasets
Effectively use source control systems such as Git
Deep understanding of distributed systems

You should know some of the following

Apache HDFS/Spark cluster
(Scala, Java, Python, .NET, R)
Hive Metastore
SQL database
SQL Server, T-SQL etc.
Azure / AWS / Google Cloud

Interested in hearing more? Easy Apply now by clicking the ""Apply"" button.


Show more Show less"
2817127872,Data Engineer,Takashi USA LLC,2021-12-02,United States,United States,,Contract,,"A minimum of 6 years of experience designing and implementing software solutions for complex problems.
Must have industry experience with building and deploying ML-based solutions

You are familiar with monitoring and deployment tools and platforms, such as Docker, Kubernetes, Terraform, AWS Services.

You have experience with designing, building, and maintaining production-grade machine learning pipelines and models.

You have working experience of classical machine learning/deep learning models, and libraries like Scikit-learn, Pytorch, TensorFlow, Light GBM, Keras.

Experience building ML infrastructure, with an eye towards software engineering.

Experience with Spark or Hadoop and database schema design for ML pipelines.

Strong coding experience (e.g. Python, SQL, open-source ML packages).
Show more Show less"
2808116737,Data Engineer,Deckers Brands,2021-11-25,United States,"Sacramento, CA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2504922650,Data Engineer,Ribbon,2021-12-04,United States,United States,Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","Who are we?

Ribbon is a first of its kind real estate technology company transforming the real estate transaction by delivering certainty, transparency and joy to the home buying process. Consumers and realtors deserve a better experience, and we have designed an open platform that welcomes everyone in the ecosystem to participate.

As members of the Ribbon team, we live out our mission every day through our core values:

Set New Standards. Our mission requires a new way forward. We start from first-principles to be different, creative and bold. Big or small, we create new norms.

Build Together. We are one team, one mission, creating vibrant communities of belonging. We unite in our passion and collaborate with optimism, integrity and trust.

Learn, Teach, Grow. In service of delivering a world class experience, we actively learn from our community, educate others, and celebrate the victories and struggles that come along the way.

Engineering Team

We believe that software can be a driving force in making home ownership achievable, and we're looking to build a team of passionate and talented engineers to make that dream possible for more families. At Ribbon we place a strong emphasis on start-to-finish ownership, collaboration, and inclusivity.

How You'd Be Making Home Ownership Achievable

This role has tremendous impact across many products at Ribbon that modernize the home buying process and make it fair for all
Maintain and improve Ribbon’s ETL pipeline which supports everything we do - our consumer facing web application, product analytics, sales enablement, etc.
Brainstorm and build out new data projects. We are just scratching the surface of how we can use data to help our customers. Whoever is in this role will have the freedom to explore new opportunities for the business.

Who You Are

You are passionate about building robust and reliable data pipelines
You value inclusivity and collaboration as much as writing good, clean code
You make the effort to design and write code that is scalable, performant, and easy for your teammates to build upon and maintain
You care about growing those around you

Our stack

Here are some of the tools you'd be using to help us build the future of real estate. If you've never used these specific tools before but are interested in working with them, please apply!

Data: Python, Scala, Spark, Snowflake, EMR, Kafka, Airflow, Yarn, Terraform Cloud
Ops: Docker, AWS, Postgres

What You Will Do

Ship code and help others build with velocity and quality
Maintain and improve our ETL pipeline
Identify new business opportunities within data engineering for the company
Lead our data engineering function and build the team around you
Bring at least 5 years of practical experience and extensive knowledge with data engineering to the team

What We Offer

Health, dental, and vision insurance
Flexible, unlimited vacation
Fully paid parental leave
Regular team lunches
Health + wellness stipend
Company-sponsored TalkSpace membership
401(k)
Commuter benefits
FSA + HSA
Learning + development stipend
Meaningful equity in the company

Even if you don’t meet all the requirements, we encourage you to apply! If you’d be excited to show up for work each day, we’d be excited to have you on our team.

Here at Ribbon we’re not scared of differences. It’s how we break new ground. As we scale and we help families from every walk of life, the team we build must be reflective of the diversity that we serve. Together, we’ve built and will continue to grow, a diverse and inclusive culture where everyone has a seat at the table and the space to be their most authentic self. Ribbon is an Equal Opportunity Employer and we support, celebrate, and cherish all the things that make our teammates who they are.
Show more Show less"
2825832028,Data Engineer,Modis,2021-12-03,United States,"Malvern, PA",Information Technology,Contract,IT Services and IT Consulting,"AWS Data Engineer

$64/hr




Sr. Data Engineer with experience in GLUE ETL & Redshift

Job Description: Provides and trains others inexpert level data solutions by using software to process, store, and serve data to others. Tests data quality and optimizes data availability. Ensures that data pipelines are scalable, repeatable, and secure. Leads, instructs, and mentors less experienced Data Engineers in providing the deepest dive analytical skillset on a variety of internal and external data. Contributes to strategic planning and aligns end-to-end processes with cross-departmental and cross-divisional goals.

Core Responsibilities

1. Writes the most complex ETL (Extract / Transform / Load) processes, designs database systems, and develops tools for real-time and offline analytic processing.

2. Troubleshoots software and processes for data consistency and integrity. Leads the integration of highly complex and large scale data from a variety of sources for business partners to generate insight and make decisions.

3. Translates business specifications into design specifications and code. Establishes analytical rigor and methods for writing complex programs, ad hoc queries, and reports. Ensures that all code is well structured, includes sufficient documentation, and is easy to maintain and reuse.

4. Partners with internal clients and leaders to gain an expert understanding of highly strategic, high risk business functions and informational needs. Contributes to strategic planning for Data Engineering at Vanguard. Works closely with other technical and data analytics experts across the business to implement data solutions.

5. Leads all phases of solution development. Explains technical considerations at related meetings, including those with internal clients and less experienced team members.

6. Assesses data quality and tests code thoroughly for accuracy of intended purpose. Acts as the highest point of escalation for data analysis and serves as a technical consultant for the client.

7. Educates and develops junior data engineers on the team while applying quality control to their work and increasing their knowledge in specialized Data Engineering techniques and processes. Leads data engineering standards and contributes expertise to other data expert teams

8. Tests and implements highly complex new software releases through regression testing. Identifies issues and engages with vendors to resolve and elevate software into production.

9. Participates in special projects and performs other duties as assigned.

Qualifications

Ten years of data analytics, programming, database administration, or data management experience.

Undergraduate degree or equivalent combination of training and experience. Graduate degree preferred.




If you are interested in this position then please click APPLY NOW. For other available opportunities at Modis go to www.modis.com. If you have questions about the position, please contact Akriti Mangalam at akriti.mangalam@modis.com or call at 346 561 8455




Equal Opportunity Employer Minorities/Women/Veterans/Disabled

Show more Show less"
2600122678,Big Data Engineer,Amazon Web Services (AWS),2021-12-04,United States,"Seattle, WA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

AWS World Wide Revenue Ops is seeking a Big Data Engineer to join our Business Performance Management team, building a new Sales Revenue data solution. Our vision is to collect and process billions of usage and billing transactions every single day and relate it to the largest data feed supported by Salesforce.com. We apply business logic to transform to this raw data to generate the daily and monthly Sales Revenue utilized for daily and monthly AWS Sales Revenue reporting and the processing of quarterly Sales Commissions for AWS Sales on Incentive plans.

We are truly leading the way to disrupt the big data industry. We are accomplishing this vision by bringing to bear Big Data technologies like Elastic Map Reduce (EMR) in addition to data warehouse technologies like Spectrum to build a data platform capable of scaling with the ever-increasing volume of data produced by AWS services.

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build ETL to ingest the data into the data lake. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

Location: This role open to these locations: Seattle & Dallas. Relocation offered from within the US to any of these locations.

Inclusive Team Culture

Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have twelve employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance

Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.


Basic Qualifications

This position requires a Bachelor's Degree in Computer Science or a related technical field, and 5+ years of meaningful employment experience.
5+ years of work experience with ETL, Data Modeling, and Data Architecture.
Expert-level skills in writing and optimizing SQL.
Experience with Big Data technologies such as Hive/Spark.
Proficiency in one of the scripting languages - python, ruby, linux or similar.
Experience operating very large data warehouses or data lakes.

Preferred Qualifications

Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
Experience with building data pipelines and applications to stream and process datasets at low latency.
Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
Knowledge of Engineering and Operational Excellence using standard methodologies.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role

/*AWS WWRO Galaxi Data Platform*/

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon Web Services, Inc.

Job ID: A1589014
Show more Show less"
2826070316,Data Engineer - Machine Learning - Remote Optional,"Goldstone Partners, Inc.",2021-12-03,United States,Denver Metropolitan Area ,Information Technology,Full-time,Computer Software,"GeoVisual Analytics is changing the way crops are cared for in the US and around the world. Using routine monitoring of fields with drones, in-field scouting, and satellites, we’re applying our NASA-funded ML algorithms to analyze crop maturity, health, and predicted yields, helping farmers to dramatically reduce production uncertainties and increase profits. We’re headquartered conveniently between Boulder and Denver with a beautiful view of the front range right outside our window. We’re growing and looking for a few committed professionals to help us scale. If you love the concept of combining drone-gathered imagery with Data Science then we might be your next great adventure.




Our Values: Team Accountability, Social Impact, Intellectual Growth




As a member of the GeoVisual team, your role is critical in building tools that consume and transform data sets into readily available information for analysis by the team. You understand the fundamentals of statistical methods that underlie machine learning and relish the opportunity to put them into practice. Engineering data pipelines and visualizations that shed light on the complexities of our research is your passion. You have an entrepreneurial spirit and the idea of using data to help the world grow healthy food and protect its natural resources excites you. If you are ready for your next challenge – let’s talk!




Your Values: Social Impact, Optimization, Intellectual Curiosity




Spend your days:

Creating and maintaining data pipe architecture optimizing ML data delivery to analyze growth and predict yields using drone, satellite, and weather data
Leveraging historical and real-time data that will allow informed labor and equipment scheduling
Productionizing models into UI for visualization to leveraging data
Designing, constructing, installing, testing, and maintaining highly scalable data pipelines
Getting involved in developing the creative vision, design, development, and delivery of some amazing remote sensing solutions




What you’ll bring to the table:

Undergraduate degree in Math or Engineering – Advanced degree preferred
At least 3 years of experience as a data engineer using Python and PyTorch
Demonstrated comprehensive experience with data modeling and data visualization – bonus points for GIS or Geo-Positioning exposure
High proficiency with AWS infrastructure
Knowledge of deep learning modeling techniques and trends, especially CNN based model architectures for computer vision applications
Ability to build processes that support data transformation, data structures, metadata, dependency, and workload management
Comfortable working within an Agile framework
Creative, articulate, and competent communication style – you deliver your messages clearly, concisely, and confidently
Strong interest in continuous learning and keeping up with emerging ML trends
You have worked in a small company so you know what it means to shift priorities and wear many hats
Desire to contribute to a team who is doing great things for humanity




Our team members enjoy:

Salary $90 - $115k plus benefits
An engaged, committed team of thought leaders to hang out with every day
The opportunity to get in on the ground floor and help build a truly impactful company




Goldstone Partners is helping this scrappy, and talented team find focused professionals who want to help improve crop yield for the global population. Principals only please. Applications welcome from US Citizens and Green Card Holders. 




Please submit a resume for consideration.

Show more Show less"
2801104663,Data Engineer,Prenosis,2021-11-19,United States,United States,,Full-time,,"About Prenosis

Prenosis is a health tech innovator devoted to ushering in a new era of precision diagnostics in acute care using artificial intelligence. Its ImmunixTM precision diagnostics platform leverages machine learning algorithms trained on deep biological data and broad clinical data to more holistically capture and illuminate the complex health states of patients. Its proprietary NOSISTM dataset is the largest and fastest growing hybrid biomarker-clinical dataset for sepsis care.




Be a core member of a tight knit team that is changing the world with a revolutionary homegrown dataset! Play a leadership role in a company that doesn’t just consume healthcare data, but contributes by generating much cleaner and more powerful data!




About the Position

Your responsibilities at Prenosis would entail the following:

Evangelize data best-practices throughout the company
Build and manage a robust and scalable data pipeline including ingestion, validation, standardization, and label generation.
Decide on data pipeline architecture and tools.
Build internal tools to empower data scientists to manage and use the data pipeline.
Work closely with data scientist and product engineers to understand the data pipeline requirements.
Make sure data is available and accessible for data science and machine learning.
If desired, help set up our MLOps process, infrastructure, and tools.




Requirements:

Degree in computer science, software engineering, math, or similar
3+ years full time experience building software
1+ years of data engineering experience
Experience diagnosing pipeline bottlenecks and tuning databases for performance
Experience with one or more data pipeline orchestration tools (e.g. Apache Airflow)
Experience with distributed computing frameworks (e.g. Apache Spark)
Experience architecting big data pipelines and building data models
Good devops best-practices
Experience working with medical data (e.g. FHIR) would be a plus.
Experience at startups would be a plus




Prenosis is an equal opportunity employer that does not discriminate against any employee or applicant for employment because of race, color, religion, sex, national origin, ancestry, disability, age or marital status.

Show more Show less"
2810867558,Data Engineer (REMOTE),TransLoc,2021-11-24,United States,"Austin, TX",Engineering,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","All About Us:

At TransLoc, we believe that public transit is central to the future of mobility. Made up of the three most-trusted companies in transit technology (TransLoc, Ride Systems and DoubleMap), today's TransLoc delivers a one-stop-shop for transit providers seeking transit orchestration solutions. Recognized by Fast Company for our innovative technology, our intelligent transportation software portfolio includes flexible demand response, fixed route systems, and planning services, providing software and services for more than 1500 transit providers worldwide. Our fixed route and on-demand systems have powered more than 600 million annual rides, helping transit users reach jobs, schools, healthcare and other important destinations in an equitable and accessible way. If being part of an organization bridging the chasm between today’s needs and tomorrow’s demands is important to you, we want to hear from you today!

Why you should join us:

At TransLoc, we constantly strive to create an atmosphere that allows our employees (TransLocians) to do their best work. We are committed to keeping TransLocians happy, healthy, motivated, focused and creative. We’ve designed our top-notch benefits program with these goals in mind. In a nutshell, we’ve built a place where we truly love working, and we think you’ll love it too! We have offices in Raleigh-Durham, North Carolina, Indianapolis, Indiana and Morgan, Utah. However, we can hire remotely in: Alabama, Arizona, Florida, Indiana, Kansas, Michigan, North Carolina, Pennsylvania, Texas and Utah.

Our Values:

People First - Rise Up - Play To Win - Do The Right Thing - Pursuit of Knowledge

Summary:

As a Data Engineer you will be a part of a growing team within TransLoc that focuses on putting data at the core of everything that we do. Responsible for the design, development and upkeep of data structures, the Data Engineer will be in a prime spot to have significant impacts to the daily business of the company.

Requirements

Essential Functions:

Develop, design, construct, test, and maintain optimal data architecture/structures to meet the needs of TransLoc both current and future
Stay up-to-date on, and implement, industry best practices concerning the proper handling of data and applicable data regulations
Identify ways to improve data reliability, efficiency, and quality
Align architecture/structure with business requirements
Work with other team members and customers to identify/develop value-add solutions
Prepare data for predictive and prescriptive modeling
Enthusiastically cultivate a culture of making sound decisions based on data
Evaluate, analyze, and implement business intelligence solutions to further enhance the company’s decision-making process
Execute additional duties as assigned


Knowledge, Skills and Abilities:

Extensive knowledge of data warehousing tools, patterns, and processes
Experience consuming web-based APIs
Ability to work with various data formats including JSON, XML, delimited, and fixed-width formatted data
Advanced knowledge of data privacy standards and best practices
Proficiency with languages (SQL, Python, Go Lang, R)
Experience with Messaging Patterns and Events propagation (Pub-Sub, Kafka, RabbitMQ)
Experience with CI/CD pipelines using Jenkins
Experience with source Control using Git
Experience with SQL Databases (SQL Server, Postgres, MySql)
Experience with NoSQL database (Cassandra, MongoDB)
Experience with data warehouse platforms (Snowflake, RedShift, BigQuery)
Experience with Looker is a plus
ETL design and coding using one or more tools (AWS services, Spark, Glue ETL)
Google Cloud Platform experience strongly preferred


Minimum Qualifications:

3+ years experience in a similar role with similar duties
Degree in Computer Science, IT, or similar field; Advanced degree preferred


Benefits

TransLoc cares about its employees as much as we care about equitable and accessible mobility. We work hard, play hard (hello unlimited time off), and want our employees to know they are valued. That’s why we offer competitive compensation packages, generous benefits, including dental, vision, 100% employer-paid medical coverage for employees as well as generous contributions towards spousal and dependent coverage, and Pick Your Perk a $2,400/yr stipend to be used any way you’d like (seriously, ANY way you’d like!). In the market for a new vehicle? Take advantage of our Ford discount program! TransLoc also offers a strong 401k retirement matching plan, and a progressive work environment.

TransLoc is made up of people from a wide variety of backgrounds and lifestyles. We embrace diversity and invite applications from people of all walks of life. TransLoc is an equal opportunity employer. We are committed to EEO for all employees and to providing our people with a harassment and discrimination free environment. All decisions at TransLoc, are based on business need, individual qualifications, and job requirements without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. We will not tolerate discrimination or harassment based on any of these characteristics. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform the essential functions of this position. Also, if you have a disability, please let us know if there is any way we can make the interview process better for you; we’re happy to accommodate!

Recruiting Agencies, Please Note:

TransLoc will not accept unsolicited assistance from recruiting/search agencies for this employment opportunity. Please, no phone calls or emails. All resumes submitted by recruiting or search agencies to any employee at TransLoc via email, the Internet or in any form and/or method without a valid written search/recruitment agreement in place for this position will be deemed the sole property of TransLoc. No fee will be paid in the event the candidate is hired by TransLoc as a result of the referral or through other means.
Show more Show less"
2814263150,"Data Engineer (SQL, Power BI)",Mindtree,2021-11-30,United States,"Seattle, WA",Information Technology,Full-time,IT Services and IT Consulting,"The ideal candidate will use their passion for data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users. 

 

SKILLS




Experienced in designing facts and dimensions required for a scenario.
Perform Data Profiling, Data Analysis, Data Modelling
Excellent understanding of Microsoft SQL Server and related technologies
Exposure to Azure non-relational data solutions such as Azure Cosmos DB
Knowledge in Azure, Azure SQL, SQL Data Warehouse, Data Lake Analytics/Store, HDInsight
Basic understanding of Azure storage solutions such as Azure Storage, Azure Storage Disks, and Azure Files
Basic understanding of Azure solutions outside of the Azure storage and data platforms
Good understanding of data security and governance standards
Microsoft Finance Domain experience
Show more Show less"
2812354049,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"Seattle, WA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2793877545,Spark Data Engineer,Computomic,2021-11-15,United States,United States,,Contract,,"As a Data Engineer on our team you will have the opportunity to shape the future big data landscape at leading Fortune 500 organizations and cutting-edge startups. You will work on customer engagements to solve big data problems using leading cloud platforms such as AWS/Azure/GCP, Apache Spark and the Databricks platform.




The skills you will bring:

Certified and have deep knowledge of one or more popular cloud platforms (AWS, Azure, GCP). Strong abilities to provide a firm point of view on core cloud platform capabilities, security, and best practices
Hands-on technical experience, building production grade data pipelines with Apache Spark and/or Databricks
Experience building pipelines with CICD capabilities and strong knowledge of Apache Spark and/or Databricks Internals
Ability to identify, debug bottlenecks and significantly optimize slow running data pipelines
Proficient in Python (preferable) or Scala. Good understanding of design principles in Object Oriented and Functional programming techniques
Experience migrating applications from legacy Hadoop or Datawarehouse’s to the cloud running Apache Spark or Databricks a huge plus
Databricks technical certifications, knowledge of the lake house architecture, highly desirable




Other nice to have skills:

You will bring very strong consulting skills, are customer focused and know how to navigate through tough project situations
You are highly motivated, creative in your approach to technical problems and know how to leverage both internal and external networks
You spend a significant amount of time to keep your technical skills updated and are constantly looking for the next big challenge
You will bring both broad and deep knowledge in Data Engineering and/or Data Science, and have the ability to architect a solution by mapping a customer business problem to an end-to-end solution.
You are resourceful and confident under pressure




This position is available for both Contract and Full Time role. We offer great compensation and opportunity to work on cool technologies and great projects!




Are you passionate about this opportunity, but worried that you don’t have 100% of the experience we’re looking for? We still want to hear from you! Apply online and let us know why you would make a great addition to the Computomic team.




Please note that we will NOT offer any new Visa sponsorship at this time. We can transfer H1s.

Show more Show less"
2814739794,Big Data Software Engineer (Early Career),Apple,2021-12-01,United States,"Austin, TX",Engineering and Information Technology,Full-time,Computers and Electronics,"
Summary

Imagine what you could do here! At Apple, great ideas have a way of becoming great products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish! This position is in the Big Data Engineering team that manages various innovative open source technologies in Streaming, Data Science and Big Data Analytics areas, including Kafka, Hadoop, Spark and AI/ML.


What are we expecting? The most creative software engineers! You should have BS or MS in CS with strong Computer Science fundamentals, strong programming and problem solving skills. The ideal candidate will bring a lot of energy and initiative and will be ready to learn and explore new innovative technologies.


Key Qualifications

Experience in a professional programming position

Solid understanding of core Java programming, performance, multi-threading, garbage collection

Strong education in Computer Science, Software Engineering, Algorithms, Operating Systems, Networking, etc.

Experience with Python and/or Go development highly desirable

Experience with public clouds (GCP & AWS) highly desirable

Knowledge of deployments in Kubernetes containers highly desirable

Experience and knowledge in Big Data Technologies such as Hadoop, Spark, etc. is highly desirable


Description

Apple's Big Data Engineering team is looking for a highly motivated, thorough, individual with excellent written and oral skills who is not afraid to think outside the box and question assumptions. In this role, you will be part of a fast growing, cohesive team with many exciting responsibilities related to Big Data, including:

Build a Big Data Cloud Platform

Setup of Kafka brokers, Kafka MirrorMakers and Kafka Zookeeper on hosts including a combination of bare metal systems, VMs and Containers.

Setup of Hadoop clusters with related technologies on hosts including a combination of bare metal systems, VMs and Containers.

Develop scalable, robust systems that will be highly adaptable to changing business needs.

Define/develop Big Data technologies, platforms and applications

Architect, improve, and scale applications to the next level.

Collaborate with application owners, developers and project managers.

Recommend and deploy tools and processes to enable rapid development, deployment and operations of big data solutions.

Be a specialist for application teams faced with architectural decisions or technical problems, such as scaling and tuning.


Education & Experience

BS or MS in Computer Science or equivalent


Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other legally protected characteristics. If you’d like more information about your EEO rights as an applicant, please click here. Apple will not discriminate or retaliate against applicants who inquire about, disclose, or discuss their compensation or that of other applicants. For more information, please click here.


Apple will consider for employment all qualified applicants with criminal histories in a manner consistent with applicable law. If you are applying for a position in San Francisco, please click here.


Apple participates in the E-Verify program in certain locations as required by law. Learn more.


Apple is committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Learn more.


Apple is a drug-free workplace. Learn more.


Role Number: 200295463


Show more Show less"
2809599734,Data Engineer (Remote),Huxley,2021-11-22,United States,"Boston, MA",Information Technology and Other,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Data Engineer | Boston, MA | $100K - $160K



I'm working with a fast-paced, blockchain-native tech company looking to bring on a Data Engineer. As a Data Engineer, you'll work to build a robust, scalable cloud data infrastructure in AWS.



What You'll Do:



Build out internal data collection framework to support rapidly growing analytics business
Work directly with the Director of Data Operations and Head of Data
Define and implement the data ingestion strategy
Build out data pipelines
Own ETL processes

What We're Seeking:



Strong OO Programming experience with Python
SQL experience
Proven knowledge of ETL and data integration
Experience analyzing data sets
Strong passion for modern tech and willingness to learn new skills
Experience writing and maintaining data pipelines
Excellent verbal and communication skills

Nice to have:



Experience with Cloud Technologies (AWS preferred)
Experience with data pipeline tools (Airflow, Luigi)
Exposure to big data technologies (Spark, Hive, Hadoop)










EOE Statement: Specialist Staffing Group is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.













To find out more about Huxley please visit www.huxley.com



Show more Show less"
2812342967,Big Data Engineer,LGZ New Media,2021-10-31,United States,"Portland, OR",Information Technology,Contract,IT Services and IT Consulting,"Role: Big Data Engineer

Location: Portland, OR

Type of Employment: Contract

Job Description

Design & develop batch and complex event processing applications.
Design and develop Spark Streaming jobs to consume data from Messaging queues (like Kafka) and persist in HDFS/HBASE/Hive.
Design and develop text parsers (XML and JSON).
Design data models in HBase to store non-relational data such as XML JSON etc.
Design and develop access layer in Phoenix for HBase tables.
Performance tune Batch and Streaming applications to meet the required SLAs.
Design and develop ETL jobs to load data into Hive using Java/Python/HiveQL.
Design and develop ETL jobs to process data in Spark and load it into Hive/HBase.
Develop Sqoop jobs to load data from relational databases into HDFS/Hive.
Support Production activities
Show more Show less"
2803958702,Data Engineer,Olive,2021-11-23,United States,"Chicago, IL",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Hospitals and Health Care","Description

Olive is healthcare’s first intelligent digital workforce and has been successfully deployed at numerous healthcare systems across the country. Olive helps streamline and automate the most high-volume, repetitive tasks so healthcare professionals can concentrate on their patients and solve healthcare’s most challenging problems. Olive’s promise to her customers is that she finds out where she can make an impact, onboards quickly, shows up to work everyday, does her job extremely well, and gets smarter over time.

As part of the Data Engineering team, you have proven strengths in software development and a keen desire to understand and work with data. Your work will be instrumental in enabling the rest of Olive to access and draw insights from our data. This team’s primary objective is to work with clinicians and analysts to define what “clean clinical data” means, and programmatically implement processes to provide it. This includes everything from data mapping to ML augmentation, and from orchestrated pipelines to manually curated QA checks.

Why work with us?

We are a fast growing organization, which is utilizing cutting edge technology in order to reinvent the industry. You will be exposed to interesting and challenging projects, where you will be able to satisfy our ever growing desire for reliable, meaningful data, provided to the consumers at rapid scale.

Together with you, our team will build brand new data models, choose and integrate new infrastructure components, and tackle uncountable unknown-unknowns to help Olive become recognized as the thought leader in analytics across industries.

Responsibilities

Build for change. Design and develop flexible and scalable software frameworks to solve immediate and foreseeable problems.
Maintain high standards. Implement Data Engineering and Software Engineering best practices.
Keep learning! Evaluate new technologies and services whenever applicable.
Be part of a professional team. Be friendly and engaged in code reviews, strategy sessions, and retros.

Requirements
3+ years of experience as a Data Engineer, or Software Engineering working with data
Strong understanding of data pipelines (scalability and performance)
Mastery of complex data manipulation, beyond simple ELT.
Experience supporting both technical and business teams
Expert skills in:
Python (pandas in particular)
SQL
Git / version control
Advanced skills in:
Prefect, Airflow or similar orchestration tools
Docker

Preferred Skills
Experience working with one or more of the following technology/concepts:
Kubernetes
DBT
AWS (Glue, Lambda, S3, RDS, etc)
Linux
CI/CD
Data warehousing (Redshift)
Experience in data modeling, specifically building relationally and dimensionally to support analytics
Nice to have:Experience supporting Machine Learning, and/or incorporating ML into data pipelines

Background in Healthcare (clinical and claims)
Show more Show less"
2818948281,Data Engineer,Hungryroot,2021-11-04,United States,United States,Information Technology,Full-time,Food and Beverage Services,"Who We Are

Hungryroot is your personal grocer, powered by AI and the belief that food deeply impacts your daily life. You tell us a little about yourself, and we use proprietary predictive technology to deliver groceries and recipes that best suit your individual needs and goals. We also assist with meal planning and nutritional support, helping you save time, save money, shop sustainably, and eat what makes you feel your best.

We are a distributed team built on top talent from over 10 states across the U.S. While we have an office in NYC, we support employees creating “offices” wherever they are. We believe in fostering team connection and collaboration across all of our “offices” - so don’t expect to be online at 6 am to make a meeting if you’re on the West coast. Expect to attend regular team building events, and to be able to work from the beach every once in a while. Expect to be treated like an owner who cares about our common goal, not someone who has to clock in and out of work.

Hungryroot is more than doubling in revenue year-over-year and rapidly growing - this is why we need you!

What You’ll Do

We’re looking for a highly motivated, problem-solving Data Engineer who is excited to play an integral role in our rapidly growing Technology team. At Hungryroot, we experiment, iterate, learn, and repeat. Most importantly, we build things people love. As a member of the Technology team, you will be responsible for helping to deliver the best data solution and tooling to support all data needs across the company. The ideal candidate is obsessed with data modeling, data accuracy, and overall system performance.

How You’ll Make an Impact:

Maintain and extend our data warehouse in order to support various data needs from our internal teams.
Design and iterate on data modeling to achieve a great balance between simplicity and robustness.
Design, build and maintain ETL pipelines between various data sources and our analytics vendors.
Monitor the operation of our data pipelines and reporting services, troubleshoot any failures and deploy fixes in a timely manner.
Collaborate with other functional group leaders to develop solutions to support growing business needs.


Why We Need You:

3+ years of fully independent project experience with significant contributions.
3+ years of experience working with relational databases and writing SQL.
Experience with data warehouse and ETL pipelines.
Experience with AWS Redshift is preferred.
Experience with Python is preferred.
Experience with a CDP such as Segment or mParticle is welcome.
A solid understanding of general database concepts, schema design, performance tuning.
Always motivated and resourceful. Able to take ownership for your tasks and see features through from start to finish.
Collaborate well with teammates and be positive and constructive in communication.
Be proactive. Think slightly ahead instead of remaining reactive to foreseeable problems.
Strive to be transparent and candid. Do not intentionally hide mistakes or blame others, instead find ways to prevent future mistakes.


Perks & Benefits

Remote Work Optional: Work from home, work from our NYC office, work from anywhere, you decide!
Competitive compensation + comprehensive Medical, Dental, and Vision benefits
Unlimited vacation policy
Monthly Hungryroot credit
Universal paid parental leave
401k
Commuter benefits
A working environment filled with passionate, happy, smart people!


Hungryroot is built on the values of being proactive, positive, and transparent in all that we do. Our mission to help make healthy eating easy, accessible, and joyful is better served by a diverse workplace.

We are a proud Equal Opportunity Employer committed to building an inclusive workplace. We have zero-tolerance for harassment or discrimination. We do not discriminate on the basis of race, religion, ethnicity, national origin, gender identity, gender expression, sexual orientation, age, marital status, veteran status, or disability.


Show more Show less"
2721104967,Senior Big Data Software Engineer,Zillow,2021-11-22,United States,"Washington, United States",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Financial Services","About The Team

Zillow is disrupting real estate by empowering people to unlock life's next chapter! The Zillow Data Engineering team supports multiple lines of business and is responsible for implementing, operating and improving data pipelines and creating data sets to empower Zillow Group brands and customers. We achieve this goal by building and deploying highly scalable data pipelines, adhering to software/data engineering best practices and ensuring the quality of our data to the delight of our consumers.

About The Role

In this role, you will evangelize and build Data Products for customer, property and business-specific data to simplify critical ML and Analytics products, like the Zestimate and pricing of Zillow-owned homes, to enrich the customer experience, and simplify marketing operations. You will partner with other data engineering teams and platform teams within AI to lead the architecture, implementation, and operations of big data pipelines and tools for building high-quality data marts.

As a Member Of This Team, You Will

Architect, design, build, implement and support data pipelines/products to serve ML and Analytical use cases
Collaborate with product managers, engineers, data scientists, and analysts on mission-critical property data needs to build world-class datasets
Identify opportunities to evangelize and support existing data processes
Contribute back to common tooling/infrastructure to enable self-service tooling to expedite customer onboarding

This role has been categorized as a Remote position. “Remote” employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.

In Colorado, the standard pay range for this role is $154,000.00 - $246,000.00 Annually. This range is specific to Colorado and may not be applicable to other locations.

Who you are

5+ years software development experience with very high proficiency in Python or Scala or Java.
Led the design/implementation of config driven, scalable, reliable services and workflows/pipelines using EMR, Kafka, Spark, Hive, Airflow or equivalents.
Experienced in establishing and promoting high standards in pipeline monitoring, data validation, testing, etc.
You have deep experience in applying automation to data engineering (DataOps).
Passionate about data engineering / analytics and distributed systems.
Excellent interpersonal skills and passionate about collaborating across organizational boundaries.
Comfortable distilling informal customer requirements into problem definitions, resolving ambiguity and balancing challenging objectives.
Passionate about mentorship, and coaching/onboarding/leading teammates.
A degree in Computer Science or a related technical field; or equivalent work experience
Here at Zillow - we value the experience and perspective of candidates with non-traditional backgrounds. We encourage you to apply if you have transferable skills or related experiences.

In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location.

Get to know us

Zillow is reimagining real estate to make it easier to unlock life’s next chapter.

As the most-visited real estate website in the United States, Zillow® and its affiliates offer customers an on-demand experience for selling, buying, renting or financing with transparency and nearly seamless end-to-end service. Millions of people visit Zillow and its affiliate sites every month to start their home search, and now they can rely on Zillow to help them finish it — and no matter what job you're in, you will play a critical role in making this vision a reality.

At Zillow, we're powered by our innovative and inclusive work culture, where everyone has the flexibility, support and resources to do the best work of their careers. Our efforts to streamline the real estate transaction is supported by our passion to redefine the employee experience, a deep-rooted culture of innovation, a fundamental commitment to Equity and Belonging, and world-class benefits. But don't just take our word for it. Read our reviews on Glassdoor and recent recognition from multiple organizations, including: Fortune’s 100 Best Companies to Work For® List 2021 Bloomberg Gender-Equality Index 2021, Human Rights Campaign (HRC) Corporate Equity Index and HRC’s Best Place to Work for LGBTQ Equality 2021, Fortune Best Workplaces for Technology 2020, Fortune Best Workplaces for Millennials 2020, Fortune Best Workplaces for Parents 2020, and the Deloitte Technology Fast 500.

Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com.

Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.
Show more Show less"
2804326744,Data Acquisition / Data Engineer,Resultid,2021-11-18,United States,San Francisco Bay Area,,Part-time,,"Who We Are




Resultid is an AI-Powered Business Intelligence platform that extracts the value in data to inform investment decisions, faster. We do predictive analytics on technology and R&D data using cutting edge machine learning and natural language process techniques to connect the scientific data to business insights.




As a Techstars portfolio company and Boston 2020 graduate, we are a dedicated group of skilled contributors with the confidence to adapt as a team of continuous learners. Our team loves working together, tackling and solving new challenges, and helping each other learn. We encourage ownership and autonomy in your work to drive rapid development and growth.




We are a remote first company and are adding a Data Acquisition / Data Engineer to our North American distributed team.




Who You Are

You have an interest in data engineering and gathering and organizing data. You are responsible, self-driven, and a good communicator. You will have the ability to lead the data acquisition projects for Resultid so being organized will be an important skill as well. You have an interest in solving technical problems and working with others to develop the best solution for the task.




Responsibilities

Find the best data sources available based on input from business team / customers
Ex. If we need company finance data, find the sources we can obtain the data from, and assess how we need to get it (paid api, data scraping etc.)
Work with the data scraping team to develop the schema for inputting the data into the database
Work with the data scraping team to resolve issues or requirements that may come up when working on the data sources (apply for api access, figuring out best time to run scrapers on that data source)
Document data schema, data intake schedule etc.
Manage progress of data on a kanban board
Managing hand off of data once in ETL pipeline, to developers to implement the data into our current platform / applications




Qualifications

Experience or degree in Computer Science, Data Science,  Information Science
Ability to research and understand data sources and formats (apis, csv, json, bulk data files etc.)
Familiarity with SQL, Elasticsearch, and able to learn some graph database knowledge
Ability to communicate with developers and write documentation




Preferred Experience

Able to help with data-driven tools development when required. Some data-driven tools development experience would be great!
Some Big data experience is required. Exposure to tools like Kafka, Spark etc.
Experience with AWS




Show more Show less"
2777964427,Data Engineer,PlayStation,2021-11-25,United States,"San Diego, CA",Information Technology,Full-time,"Computer Software, Consumer Services, and Entertainment","PlayStation isn’t just the Best Place to Play —it’s also the Best Place to Work. We’ve thrilled gamers since 1994, when we launched the original PlayStation. Today, we’re recognized as a global leader in interactive and digital entertainment. The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation.

PlayStation isn’t just the Best Place to Play —it’s also the Best Place to Work. We’ve thrilled gamers since 1994, when we launched the original PlayStation. Today, we’re recognized as a global leader in interactive and digital entertainment. The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation.

Passionate about working on critical initiatives that allow for creativity and room for growth? At PlayStation, we use a variety of the most groundbreaking tools and deal with enormous amounts of data. Are you a strong believer in using data and technologies to drive the best business decisions? If so, read on…

Sony Interactive Entertainment’s (SIE) Global Payments Fraud and Decision Science Teams are the guardians of both customer trust and purchase success for PlayStation and the PlayStation® Network (PSN). We provide innovative solutions to support every element of the network, various platform services, customer service teams, a diverse developer community, and more.

As a Data Engineer of the GPFD DS (Data Solutions) team, you be using a wide array of skills and tools to support the teams in the department and outside of the department. The mission of fighting fraud daily can involve anything from short term (a few weeks) to long term projects (6+ months). Our responsibility is to provide data, dashboards, reports and systems for the teams to do their daily jobs. We have lots of challenges, things change, and we get to be creative as we tackle problems and build solutions.

Responsibilities

Engineer data pipelines and provide automated solutions for GPFD teams
Monitor systems, create alerts, dashboards, charts/reports and alerts delivery
Document processes, architecture of systems/data flows, project plans, using the agile methodology
Create training materials/presentations and present slides to a wide variety of audiences, from highly technical peers to executive management
Mentor team members, share workloads, enable team growth
Participate in hiring, interviewing, developing tests, reviewing (pre-screening) candidates
Demonstrate an outstanding work ethic
Find issues and appropriately and expertly raise tickets within/without the team
Solve sophisticated problems through highly creative methods
Use cloud technologies to provide robust solutions and learn new tools/systems as they emerge
Demonstrate a passion for protecting Sony and its customers
Requirements:

BS Degree in Engineering, Computer Science or equivalent experience.
5+ years of experience in database development, programming, design, and analysis.
Solid experience with data and databases
Familiarity with common files formats - csv, xml, json, avro
SQL skills - writing, reading, tuning, debugging
Data table design skills – DDL & DML
Understanding SQL execution
Demonstrable understanding of coding and scripting languages - Java, Python, JavaScript, bash, batch files
General knowledge in Linux, Unix Administration and Windows Administration
File ownership and permissions, file/data transfer methods
Users, access/authentication, and encryption/ssh
Experience with automation, configuration management, enterprise schedulers
Preferred Skills:

Big Data- Snowflake, DynamoDB, Oracle, Hadoop, Athena, EMR
Reporting/BI Tools – Tableau/Splunk/Datadog
Basic Knowledge of Payments Processing and CNP (Card Not Present) Fraud
Streams – Kinesis/Kafka/ActiveMQ
Cloud- Common Services, AMIs, instances, automation, storage (Packer/Ansible/Chef/Puppet), Docker etc.

Sony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to race, color, religion, gender, pregnancy, national origin, ancestry, citizenship, age, legally protected physical or mental disability, covered veteran status, status in the U.S. uniformed services, sexual orientation, marital status, genetic information or membership in any other legally protected category.

Reasonable Accommodation Notice Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.

We strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond.

We sincerely appreciate the time and effort you spent in contacting us and we thank you for your interest in PlayStation.

PRIVACY NOTICE TO SIE LLC’S JOB APPLICANTS

This Privacy Notice explains what personal information we at Sony Interactive Entertainment LLC collect from you, and why we collect it and use it. This Notice covers our practices regarding the personal information of all applicants to our job positions. Please review it carefully.

Categories of personal information we collect from you

Generally, We Obtain This Information Through Our Recruiting Team

We collect personal information about you throughout the recruiting process, in particular the following categories.

Identification and contact information
Direct identifiers such as your first and last name.
Indirect identifiers such as a government ID, your Social Security, work permit or passport #.
Contact information such as your email address, mailing address, telephone number.
Other information about you or that can be associated with you such as:
Sensitive/Protected Data. During the recruitment process, you may (voluntarily) provide us with your ethnicity, gender, military service information, or physical or mental health information, as well as your national origin and citizenship.
Professional or job position-related information , including your past professional experience, references; background verification; talent management and assessment; information regarding any conflicts of interests; and the terms and conditions of your job offer.
Non-public education information , including information about your education records, such as grades and transcripts.

Show more Show less"
2814042679,Data Engineer,UserTesting,2021-11-01,United States,"San Francisco, CA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","About UserTesting

What makes the difference between a product that's engaging, compelling, and easy to use and one that's frustrating, broken, and complicated? The answer is user experience. Here at UserTesting, our mission is to help our customers create great experiences. We enable every organization to deliver the best customer experience powered by human insight. UserTesting enables every organization to deliver the best customer experience powered by human insight. With UserTesting’s on-demand Human Insight Platform, companies across industries make accurate customer-first decisions at every level, at the speed business demands. With UserTesting, product teams, marketers, digital, and customer experience executives, designers and UX researchers confidently and quickly create the right experiences for all target audiences, increasing brand loyalty and revenue.

UserTesting will continuously invest in your education with a reserved and generous budget and the tools necessary to do the job the right way. We also provide unlimited paid time off.

Job Description

We are seeking Data Engineers who will be a part of a team that’s building a new Enterprise Data Warehouse (EDW). The Data Engineer will be responsible for connecting and extracting from various source systems to consolidate information within the EDW. Willingness to adapt, are passionate about reusability and dynamism, are the key attributes for this role. Candidates should demonstrate the ability to manage competing priorities across multiple efforts at varying stages within the development lifecycle. Comfortable in a complex data environment and understanding of data structures.

Specific Responsibilities

Manage and Create Data Pipelines into the EDW
Analyze the issues such data load problems, transformation/translation problems etc.
Participate in analysis of bugs
Identifying edge case scenarios.
Ability to Prioritize multiple tasks effectively and deliver the results in a timely manner

Requirements

3+ years of experience with Java, Python, or other programming languages
3+ years experience with SQL
2+ years of experience with JSON, SOAP or REST API
2+ years experience in cloud database technology, preferably Snowflake
2+ years experience with AWS, Azure, or GCP
Previous experience working in an Agile development environment preferred, but not necessary
Knowledge of JIRA, Confluence, or similar tracking and management tools.
Fivetran experience a bonus
DBT development experience a bonus
Undergraduate degree Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Graduate degree preferred.

Why You’ll Love Working For UserTesting

We’re honored to be named 2020 Inc. Best Workplace, and named to Deloitte’s Technology Fast 500 List, among a variety of other awards. Joining UserTesting means being part of a passionate team focused on transforming the way companies learn about their users.

Founded in 2007 and backed by Accel and OpenView, User Testing is headquartered in San Francisco with offices in Atlanta and Edinburgh.

To learn more about our team, culture, and customers, check out our careers page, company blog, and press/awards. Besides a great work environment and the opportunity to change the world we’re also growing fast — join us!
Show more Show less"
2825160041,Data Engineer (Consulting Services),Lovelytics,2021-12-03,United States,"Arlington, VA",Information Technology,Full-time,IT Services and IT Consulting,"Lovelytics is seeking an entry-level data engineer to deliver strategic engagements related to SQL, Tableau, and other analytics solutions.

The Data Engineering Consultant will primarily focus on participating and eventually leading engagements with clients related to data warehousing, ETL development, data integrations, and data modeling. Additionally, the individual will be expected to create deliverables for clients using Tableau Software.

Role Location: Arlington, VA (we function in a highly flexible work environment with the opportunity to work remote)

Primary Job Responsibilities

Fill the role of data engineer for client engagements focused on developing data warehouses, optimizing back-end performance, and integrating data sources to systems.
Work hand-in-hand with senior data engineering team members to increase your skillset and deliver engagements successfully.
Gather requirements from clients and develop creative and effective technical solutions
Manage projects to ensure project milestones are reached within the given timeline and budget allocated
Extract insights from data provided by clients and provide visually appealing and high-performing reports and dashboards
Support other team members on projects, which can oftentimes mean wearing many different hats
Troubleshooting data issues on the fly with prospects and clients


Our Ideal Candidates Skills And Experiences

B.S. in Computer Science or equivalent
Strong working experience with SQL
An understanding of business information systems, focusing on database architecture, data modeling, data analysis, and application integration.
Excellent communication skills
Working knowledge of data warehousing concepts
Familiarity with Tableau Software or other business intelligence tools
Hands-on” knowledge with application development, data warehousing platforms and databases (Oracle, SQL Server, Redshift, Snowflake, Postgres, BigQuery), application software SDLC and business reporting/analytics
Familiarity with developing strategies for ETL (IE. Alteryx, Informatica, Databricks, SSIS, Azure Data Factory, Matillion, Talend, Fivetran)


What We Promise You

Exciting projects with great clients in varying departments and verticals across the world
The ability to work closely with experienced data engineers and quickly grow and expand your skillset
The ability to work closely with all sizes of companies, ranging from Fortune 100 to small local businesses
A workplace where you are encouraged to challenge the status quo and develop new technologies, methodologies, and processes
A diverse team consisting of data gurus, experience seekers, and entrepreneurial minds that are always pushing to be better


Living the Lovelytics Values

You have a positive attitude coupled with excellent communication skills
Your entrepreneurial spirit pushes you to find creative client and internal solutions
You are motivated by providing superior solutions and disrupting the status quo
You are not afraid to voice your ideas about improving methodologies and processes
You thrive in the excitement of a fast-growing company


Some Of Our Benefits

Unlimited paid time off with an annual minimum amount of days employees must use
401K with Matching
Casual work environment
Transportation benefits, including Arlington Bike Share subscription and pre-tax travel reimbursements
Medical, dental, life, and other insurance coverages
Paid parental leave (up to 8 weeks)
Frequent out-of-office company outings
Quarterly company bonuses based on company performance


Powered by JazzHR

lEQg9Ysiji
Show more Show less"
2798295730,Data Engineer,"EDO, Inc.",2021-10-19,United States,"San Francisco, CA",Information Technology,Full-time,"Marketing and Advertising, Online Media, and Computer Software","Role can be in any of EDO's office locations: New York, Los Angeles, San Francisco. Role is also open to full remote.

Who We Are

EDO was founded in 2015 to transform how data is used within the Media, Entertainment, and Advertising industry. Today, EDO is the leading data and analytics company for TV mid-funnel measurement and attribution. Customers include Disney, NBCU, Toyota,, and WarnerMedia. EDO's premier product offering Ad EnGage focuses on national linear TV; we are expanding our platform to cover the newest and fastest-growing segment of advertising with convergent TV (i.e. streaming) by developing new data sources and analytical techniques to measure the new ways ads are being bought, sold, and shown to consumers.

Before EDO, advertisers could only rely on their first party data and limited partnership opportunities. Advertisers would rely on survey based methodologies that would poll a small number of people on their attitude towards the brand. With EDO, advertisers are able to get full coverage of their campaigns and their competitive campaigns. All with no set up cost. Plus, EDO's outcome measurement is rooted in behavioral outcomes such as search which is much more correlated with economic outcomes than attitudes and the best KPI you can use to perform in-flight optimization. Marketers use this data to optimize their media plans and creatives.

About The Role

As a Data Engineer at EDO, you will join a team of talented Data Engineers working closely with Data Scientists to develop our next generation data pipeline. Our complex and challenging data pipeline combines multiple sources of advertising occurrence data and metadata with our own proprietary engagement data in real time to generate the mid-funnel engagement data which our clients rely on to make critical business decisions about their advertising strategy. You will have the opportunity to learn and work on cutting edge technologies related to big data and real time streaming.

About You

2+ years data engineering experience
Working knowledge pertaining to relational databases (MySQL, Postgres, etc), cloud data services (AWS), and data warehousing tools (Redshift, Snowflake, etc).
Production experience working with modern ETL data pipeline tools. You will work with the team to decide and utilize the appropriate tools for our data pipeline. (Spark, Kafka, Airflow, RabbitMQ, Kiba, Luigi, etc.).
Proficiency with a scripting language such as Ruby or Python and proficiency with another language such as Scala, Java.
Self-driven individuals who take ownership of their work
Ability to build products quickly and efficiently
Strong understanding of software engineering practices and principles
Previous industry experience working with TV or other advertising data is a huge plus


Benefits

Supportive, collaborative team and work that has immediate, clear impacts
Early-stage equity and competitive salary
Unlimited PTO along with trust and support to use it
Medical, dental, and vision insurance
Wellness Stipend - movie tickets, fitness discounts, commuter subsidies, meals and snacks
Show more Show less"
2825345190,Data Engineer,"JPC Partners, LLC",2021-12-03,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","This Role Will Be Responsible For

Our client is looking for a Data Engineer that will support the multiple and simultaneous projects to load data into the data warehouse and make it available for reporting.

Creating the process to receive data files from FinTech Partners
Load data files into the staging tables in the data warehouse
Load the data into the fact and dimension tables in the data warehouse and integrate it with other loan data
Specialized Skills / Experience:

Oracle experience
Talend experience
In depth knowledge of data warehousing and ETL processes
5-7 years of experience as a data engineer
5-7 years of writing complex SQL code
5-7 years of working in an environment that follows an agile development process
3-5 years developing Talend jobs
Critical Thinker with a strong ability to troubleshoot and resolve issues
Good communication – verbal and written - with the ability to coordinate and communicate between data warehouse and reporting teams
Strong work ethic with a sense of ownership, accountability and urgency
Ability to balance an attention to detail with meeting deadlines
Nice to Haves:

Snowflake experience
Experience working in financial services, preferably banking
Solution Architecture
Data Architecture
Show more Show less"
2788363271,Big Data Engineer,Alignment Healthcare,2021-10-17,United States,"Orange, CA",Engineering and Information Technology,Full-time,"Insurance, Wellness and Fitness Services, and Hospitals and Health Care","Job Number: 3202

Position Title: Data Engineer

External Description

Data Engineer

Alignment Healthcare was founded with a mission to revolutionize health care with a serving heart culture. Through its unique integrated care delivery models, deep physician partnerships and use of proprietary technologies, Alignment is committed to transforming health care one person at a time.

By becoming a part of the Alignment Healthcare team, you will provide members with the quality of care they truly need and deserve. We believe that great work comes from people who are inspired to be their best. We have built a team of talented and experienced people who are passionate about transforming the lives of the seniors we serve. In this fast-growing company, you will find ample room for growth and innovation alongside the Alignment community.

Position Summary

Alignment Healthcare is a data and technology driven healthcare company focused partnering with health systems, health plans and provider groups to provide care delivery that is preventive, convenient, coordinated, and that results in improved clinical outcomes for seniors.

We are experiencing rapid growth (backed by top private equity firms), our Data Services and BI team is looking for the best and brightest leaders. Data drives the way we make decisions. We love our customers and understanding them better makes it possible to provide the best clinical outcome and care experience.

This position will play a key role in building and operating a cloud-based data platform and its pipelines using big data technologies.

As a Data Engineer, you will develop a new data engineering platform that leverage a new cloud architecture, and will extend or migrate our existing data pipelines to this architecture as needed. You will also be assisting with integrating the SQL data warehouse platform as our primary processing platform to create the curated enterprise data model for the company to leverage. You will be part of a team building the next generation data platform and to drive the adoption of new technologies and new practices in existing implementations. You will be responsible for designing and implementing the complex ETL pipelines in cloud data platform and other solutions to support the rapidly growing and dynamic business demand for data, and use it to deliver the data as service which will have an immediate influence on day-to-day decision making.

General Duties/Responsibilities

(May include but are not limited to)

Interfacing with business customers, gathering requirements and developing new datasets in data platform
Building and migrating the complex ETL/EDI pipelines from on premise system to cloud and Hadoop/Spark to make the system grow elastically
Identifying the data quality issues to address them immediately to provide great user experience
Extracting and combining data from various heterogeneous data sources
Designing, implementing and supporting a platform that can provide ad-hoc access to large datasets
Modelling data and metadata to support machine learning and AI

Minimum Requirements

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Minimum Experience:
3+ years relevant experience in cloud based data engineering.
Demonstrated ability in data modeling, ETL development, EDI Development and data warehousing.
Data Warehousing Experience with SQL Server, Oracle, Redshift, Teradata, etc.
Experience with Big Data Technologies (NoSQL databases, Hadoop, Hive, Hbase, Pig, Spark, Elasticsearch etc.)
Experience in using Python, .net, Java and/or other data engineering languages
Knowledge and experience of SQL Server and SSIS.
Experience with X12(837,834,278) and HL7 transactions
Education/Licensure:
Bachelors or Masters in Computer Science, Engineering, Mathematics, Statistics, or related field
Other:
Excellent communication, analytical and collaborative problem-solving skills
Requires Spark and Scala
Building and migrating the complex ETL/EDI pipelines from on premise system to cloud and Hadoop/Spark to make the system grow elastically
Preferred
Healthcare domain and data experience
Healthcare EDI experience is a plus
API development experience is a plus
Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
Experience building data products incrementally and integrating and managing datasets from multiple sources
Experience leading large-scale data warehousing and analytics projects, including using Azure or AWS technologies – SQL Server, Redshift, S3, EC2, Data-pipeline, Data Lake, Data Factory and other big data technologies
Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space
Linux/UNIX including to process large data sets.
Experience with Azure, AWS or GCP is a plus
Microsoft Azure Certification is a plus
Demonstrable track record dealing well with ambiguity, prioritizing needs, and delivering results in an agile, dynamic startup environment
Problem solving skills and Ability to meet deadlines are a must
Microsoft Azure Certification is a plus
Python and Java are a plus,
Experience with X12(837,834,278) and HL7 transactions preferred
Work Environment
The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Essential Physical Functions

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

While performing the duties of this job, the employee is regularly required to talk or hear. The employee regularly is required to stand, walk, sit, use hand to finger, handle or feel objects, tools, or controls; and reach with hands and arms.
The employee frequently lifts and/or moves up to 10 pounds. Specific vision abilities required by this job include close vision and the ability to adjust focus.

City: Orange

State: California

Location City: Orange

Location State: California

Community / Marketing Title: Big Data Engineer

Company Profile

Alignment Healthcare was founded with a mission to revolutionize health care with a serving heart culture. Through its unique integrated care delivery models, deep physician partnerships and use of proprietary technologies, Alignment is committed to transforming health care one person at a time.

By becoming a part of the Alignment Healthcare team, you will provide members with the quality of care they truly need and deserve. We believe that great work comes from people who are inspired to be their best. We have built a team of talented and experienced people who are passionate about transforming the lives of the seniors we serve. In this fast-growing company, you will find ample room for growth and innovation alongside the Alignment community.

EEO Employer Verbiage

On August 17, 2021, Alignment implemented a policy requiring all new hires to receive the COVID-19 vaccine. Proof of vaccination will be required as a condition of employment subject to applicable laws concerning exemptions/accommodations. This policy is part of Alignment’s ongoing efforts to ensure the safety and well-being of our staff and community, and to support public health efforts.

Alignment Healthcare, LLC is proud to practice Equal Employment Opportunity and Affirmative Action. We are looking for diversity in qualified candidates for employment: Minority/Female/Disable/Protected Veteran.

If you require any reasonable accommodation under the Americans with Disabilities Act (ADA) in completing the online application, interviewing, completing any pre-employment testing or otherwise participating in the employee selection process, please contact careers@ahcusa.com.
Show more Show less"
2825184147,Backend/Data Engineer,Mediaocean,2021-12-03,United States,"Seattle, WA",Information Technology,Full-time,Computer Software,"Job Description

What You Will Do:

As a Backend Software Engineer on the Mediaocean team, you will be responsible for helping craft the future of our offerings - from the database layers to the APIs that surface our data and functionality to our users. A little about our team: we've built a large Python Flask application that is supported by an array of smaller services, and are in the process of adding further robustness to our systems by doubling down on service-based architecture. We integrate with a myriad of third-party APIs which require a rigorous attention to detail and creative solutions to ensure we handle all situations gracefully. We also design and build data engineering pipelines that enable large volumes of data to go through layers of ETL processing and analysis.

Responsibilities Will Include

Have autonomy to work on what matters and have an impact immediately
Build, test and ship well-engineered features and enhancements
Design, support, maintain and upgrade highly performant and tested APIs and internal services using tools like Python, Celery, Kubernetes, MySQL, Postgre, Mongo, Redis, AWS Redshift
Articulate a long-term vision for maintaining and scaling our systems
Work with other engineers, product managers, designers and company leadership to turn our vision into a concrete roadmap every quarter and to help develop an amazing experience for our agency & brand customers.

Who You Are

3+ years of experience in software engineering with strong sense of computer science fundamentals
You demonstrate strong critical thinking ability, such as you have a Computer Science degree, or prior work experience (in a technical role, or otherwise), went to a coding school, or you are self-taught, or some combination of the above
Proficiency in Python
Relational Databases - Postgre, MySql
NoSQL Databases - Mongo
Experience handling large amounts of data, building warehousing pipelines
Experience with large scale data warehousing tech like AWS Redshift is a plus

Why Mediaocean?

Full healthcare benefits (PPO & CDHP medical plans, dental, and vision) & 401k
New parents are offered six weeks paid leave
Open PTO; vacation/sick/religious observances/philanthropy opportunities
Professional development opportunities within our Learning & Development programs
Belong@Mediaocean affinity based groups of colleagues to create community
All of these benefits/perks are effective on the date of hire

We would hate to miss out on your application because you do not meet every requirement – transferrable skills and education will also be considered, so please do not hesitate to apply!

Mediaocean recognizes our true strength and value shine when all our team members feel there is space in the conversation for their voices, thoughts, ideas, perspectives, and concerns. Mediaocean is committed to being an equal opportunity employer, and we consider all applicants regardless of their age, race, color, gender, sexual orientation, ethnicity, religion, national origin, disability, or veteran status.
Show more Show less"
2779754529,Data Engineer - Observability,Citi,2021-10-05,United States,"Irving, TX",Information Technology,Full-time,"Banking, Financial Services, and Investment Banking","Job Id: 21274428

Role Description: The Observability organization at Citi is responsible to provide full stack observability solutions (metrics, events, logs, traces) to infrastructure, security, and applications SRE, operations and development teams covering over 10,000 application instances.

The observability solutions utilize products like Splunk, Elasticsearch, Grafana / Prometheus, AppDynamics, NOI, and ITM6 hosted on Linux machines. These products are managed using a robust ansible based deployment model. We are looking for a data engineer to join the team with experience in data modelling, analyzing enterprise inventory technical reference data as well as granular telemetry and an appetite for architecting common data model that can be adopted by any product and solution.

This is a senior level, hands-on position responsible for a variety of data engineering activities.

Responsibilities:

Create and maintain optimal data model and data pipeline for enterprise observability solution
Provide SRE teams with automation opportunities based on data analysis
Collaborate in building event co-relations and grouping policies based on event data and reducing tickets for application and infrastructure teams
Architect and design a common data model, standard metadata taxonomy, data pipeline and curation of data for complex enterprise observability solutions covering infrastructure, system, and security logs and metrics
Architect and implement measurement criteria in the data pipeline for completeness, timeliness, and accuracy of data
Build processes and policies supporting data transformation, data structures, metadata, dependency, and data dictionary across the pipeline
Utilize Citi’s data analytics tools like Grafana and become the data analytics SME to harness available technical asset inventory data to gain insights, improve data quality and increase self-service

Qualifications:

3+ years of experience as a Data Engineer
Technical expertise required in big data and cloud technologies – Kafka, spark, Hadoop, Hive, HDFS, Cloudera.
ERD – entity relationship diagrams
Experience with Lucene or DSL based on JSON, Splunk SPL, relational SQL and NoSQL databases, including Oracle, Postgres, Mongo or Cassandra.
Experience building and optimizing large data volumes in data pipelines and architecture and data sets using Kafka, ELK and Splunk
Experience with Data connectivity methodologies such as APIs (Rest/Soap), ODBC/JDBC, HTTP web hooks, JSON, etc.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores
Experience supporting and working with cross-functional teams in a dynamic environment
Excellent teamwork and proactive attitude
Experience with Python, Java, Golang, or Scala

Good to have Skills:

Experience with Grafana, ELK and Splunk will be a plus
Experience in Machine learning, Data Scientist to predict event, fatal issues in applications and infrastructure will be a plus

Education:

Bachelor’s degree/University degree or equivalent experience in Computer Science, Statistics, Information Systems, or another quantitative field
Master’s degree is a plus

-------------------------------------------------

Job Family Group:

Technology

-------------------------------------------------

Job Family:

Data Architecture

------------------------------------------------------

Time Type:

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting

Effective November 1, 2021, Citi requires that all successful applicants for positions located in the United States or Puerto Rico be fully vaccinated against COVID-19 as a condition of employment and provide proof of such vaccination prior to commencement of employment.


Show more Show less"
2817190373,"Data Engineer with Python, Azure, and Tableau",Motion Recruitment,2021-12-03,United States,"Los Angeles, CA",Information Technology,Full-time,Staffing and Recruiting,"Job Description

This company is one of the largest retail corporations in the entire planet and is looking for a Data Engineer! They have about 11,700 stores, operate under 59 different names in 28 different countries. If you have the below tech stack, don't miss out on applying to this well known and established retail chains in the nation.

Required Skills & Experience

4+ years
Python
Azure
Synapse
Tableau or PowerBI
The Offer

Competitive Salary: Up to $80/hr DOE

You Will Receive The Following Benefits

Medical Insurance & Health Savings Account (HSA)
Pre-tax Commuter Benefit

Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.

Posted By: Sophia Gutteridge
Show more Show less"
2600125559,Big Data Engineer,Amazon Web Services (AWS),2021-11-13,United States,"Dallas, TX","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

AWS World Wide Revenue Ops is seeking a Big Data Engineer to join our Business Performance Management team, building a new Sales Revenue data solution. Our vision is to collect and process billions of usage and billing transactions every single day and relate it to the largest data feed supported by Salesforce.com. We apply business logic to transform to this raw data to generate the daily and monthly Sales Revenue utilized for daily and monthly AWS Sales Revenue reporting and the processing of quarterly Sales Commissions for AWS Sales on Incentive plans.

We are truly leading the way to disrupt the big data industry. We are accomplishing this vision by bringing to bear Big Data technologies like Elastic Map Reduce (EMR) in addition to data warehouse technologies like Spectrum to build a data platform capable of scaling with the ever-increasing volume of data produced by AWS services.

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build ETL to ingest the data into the data lake. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

Location: This role open to these locations: Seattle & Dallas. Relocation offered from within the US to any of these locations.

Inclusive Team Culture
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have twelve employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.


Basic Qualifications

This position requires a Bachelor's Degree in Computer Science or a related technical field, and 5+ years of meaningful employment experience.
5+ years of work experience with ETL, Data Modeling, and Data Architecture.
Expert-level skills in writing and optimizing SQL.
Experience with Big Data technologies such as Hive/Spark.
Proficiency in one of the scripting languages - python, ruby, linux or similar.
Experience operating very large data warehouses or data lakes.

Preferred Qualifications

Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
Experience with building data pipelines and applications to stream and process datasets at low latency.
Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
Knowledge of Engineering and Operational Excellence using standard methodologies.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role

/*AWS WWRO Galaxi Data Platform*/

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon Web Services, Inc.
Job ID: A1589013
Show more Show less"
2818279010,Data Engineer,Brilliant.org,2021-11-04,United States,"San Francisco, CA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","About Brilliant

Brilliant is a tight-knit team of scientists, educators, engineers, designers, storytellers, and illustrators who are redesigning education at scale.

We believe that math and science are fascinating and beautiful, but that the tools widely used to teach it are dry and ineffective. Brilliant makes learning STEM fun, through problem solving and interactive explorations – from foundational math and science to cutting-edge computer science and professional topics.

Brilliant helps over 9 million students, professionals, and lifelong learners around the world cultivate problem solving skills, build intuition, and master concepts rather than memorize them. To understand more about our approach, see our learning principles.

You can see all open roles and learn more about our team culture on our Careers page and Engineering Page.

Application Note

We're always excited to welcome and encourage anyone from non-traditional backgrounds to apply, so please, don't sweat the requirements lists too much! It's important to note that including a cover letter which details your interest in Brilliant and why you feel you'd be a great fit for this position will be required to be considered.

The Role

We are a team of fun, motivated, and experienced entrepreneurs who are working to make a huge impact in education. As a Data Engineer, you will design, develop, and maintain our data warehouse and pipelines, as well as assist analysts with report creation and maintenance.

You’ll work closely with engineers and analysts to evolve our data infrastructure to the next level, whilst working with and deploying cutting edge tools and technologies.

Initially this role will sit within our Engineering organisation, although as the team grows there will be a dedicated Data org where this role will be situated. This is an exciting opportunity to help define the culture of data within Brilliant.

Interactive education is in its infancy; we have really only scratched the surface of what is possible with computer-based pedagogy. Our work helps people across Brilliant teach topics from vector calculus to neural networks in an interactive way. Come build the future of interactive learning with us!

Your responsibilities

Create and maintain data pipelines and ETLs (principally in DBT)
Inform and evolve our event tracking architecture and infrastructure
Consolidate our data destination management, both internally and externally
Work with analysts and engineers to maintain and improve our data model
Assist analysts with complex data gathering and reporting
Who are you?

You have previous experience as a data engineer or in a similar role
You are an expert with data models, data mining, and segmentation techniques
You are a SQL master
You have experience with Python, or a similar language
Our Engineering Team

Our engineers are extraordinary programmers without big egos. We love to share knowledge and support each other. We work together as an interdependent team to accomplish a common goal, and we know how to get things done. We maintain high personal standards, and possess an ongoing, voluntary, and self-motivated pursuit of knowledge.

Why join Brilliant?

Brilliant has a mission you can get behind. We’re a company that’s helping to bring learners from all over the world together and create a platform on which they can excel, learn, and contribute.

We Also Offer

Competitive compensation
Medical, dental, and vision benefits – we pay 100% of the premiums
Equipment budget for computer and peripherals
Free lunch
Weekly happy hour
Flexible vacation time
Fully-stocked pantry and refrigerator with snacks and drinks
Sponsorship for conferences and professional development
A stimulating work environment and a chance to change the world

Our CCPA Privacy Notice can be found here.
Show more Show less"
2792738623,Data Engineer,Capital One,2021-11-13,United States,"Plano, TX",Information Technology and Engineering,Full-time,"Banking, Financial Services, and Investment Banking","Locations: TX - Plano, United States of America, Plano, Texas

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You’ll Do

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies

Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems

Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake

Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community

Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment

Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications

Bachelor’s Degree

At least 2 years of experience in application development

At least 1 year of experience in big data technologies

Preferred Qualifications

3+ years of experience in application development including Python, SQL, Scala, or Java

1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)

2+ years experience with Distributed data computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)

1+ years experience working on real-time data and streaming applications

1+ years of experience with NoSQL implementation (Mongo, Cassandra)

1+ years of data warehousing experience (Redshift or Snowflake)

2+ years of experience with UNIX Linux including basic commands and shell scripting

1+ years of experience with Agile engineering practices

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Job Category - Engineering, Technology
Show more Show less"
2808117702,Data Engineer,Deckers Brands,2021-11-25,United States,"San Diego, CA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2693144317,Data Engineer,Bath & Body Works,2021-11-20,United States,"Columbus, OH",Project Management and Information Technology,Full-time,Manufacturing and Retail,"Overview
Description
This position is within Data Services Team, responsible for data engineering processes supporting Analytics and Reporting solution for Bath & Body Works. This individual will be part of a team to design and build data pipelines into our data platforms that meets business requirements and SLA. This individual will also be help execute strategic roadmap to a cloud data platform.
Responsibilities

Support Data Engineering team in designing and building effective and efficient data pipelines for ingestion for analytics and reporting.
Identify opportunities and build solutions to optimize data processing, improve data quality and reduce failures.
Support operational reporting to Leadership Team

Qualifications
Qualifications
5 - 7 years of experience progressively in the following areas of Data Engineering:
Designing, building pipelines and supporting data platform across Datawarehouse such Teradata or Big Data platforms Hadoop(Mapr, Cloudera) or Cloud Data Platform like Snowflake, BigQuery
Scripting experience using Python or R or Perl
Supporting software on Linux Platform
Utilizing CI/CD Platform.
Reporting Tools like MicroStrategy, Tableau, Power BI
Preferred skills:
ETL Tool Experience – Talend, IBM Datastage, Informatic, Abinito
Experience working with messaging systems like Kafka, JMS
Experience working with REST API
Strong communication skills as this role will need to collaborate with both teams across the organization boundaries and report out progress in terms of key initiatives.

Education

Bachelor’s Degree or equivalent work experience in information technology

An equal opportunity employer, we do not discriminate in hiring or terms and conditions of employment because of an individual’s race, color, religion, gender, gender identity, national origin, citizenship, age, disability, sexual orientation, pregnancy, genetic information, marital status or any other protected category recognized by state, federal or local laws. We only hires individuals authorized for employment in the United States.
Category: Information Technology
Show more Show less"
2813062044,Data Engineer,Egen,2021-11-30,United States,"Naperville, IL",,Full-time,,"Egen is a data engineering and cloud modernization firm helping industry-leading companies achieve digital breakthroughs and deliver for the future, today. We are catalysts for change who create digital breakthroughs at warp speed. Our team of cloud and data engineering experts are trusted by top clients in pursuit of the extraordinary. An Inc. 5000 Fastest Growing Company 7 times, and recently recognized on the Crain’s Chicago Business Fast 50 list, Egen has also been recognized as a great place to work 3 times.




Our Data Platform Engineering teams build scalable data pipelines using Python and AWS, GCP, or Azure. The pipelines we build typically integrate with technologies such as Kafka, Storm, and Elasticsearch. We are working on a continuous deployment pipeline that leverages rapid on-demand releases. Our developers work in an agile process to efficiently deliver high value applications and product packages.




As a Data Platform Engineer, you will architect and implement cloud-native data pipelines and infrastructure to enable analytics and machine learning on rich datasets.




Required Experience:

Minimum of Bachelor’s Degree or its equivalent in Computer Science, Computer Information Systems, Information Technology and Management, Electrical Engineering or a related field.
You know what it takes to build and run resilient data pipelines in production and have experience implementing ETL/ELT to load a multi-terabyte enterprise data warehouse.
You have implemented analytics applications using multiple database technologies, such as relational, multidimensional (OLAP), key-value, document, or graph.
You value the importance of defining data contracts, and have experience writing specifications including REST APIs.
You write code to transform data between data models and formats, preferably in Python (Spark or PySpark is a bonus).
You've worked in agile environments and are comfortable iterating quickly.

Nice to have's (but not required):

Experience moving trained machine learning models into production data pipelines.
Expert knowledge of relational database modeling concepts, SQL skills, proficiency in query performance tuning, and desire to share knowledge with others.
Experience building cloud-native applications and supporting technologies / patterns / practices including: AWS/GCP/Azure, Docker, CI/CD, DevOps, and microservices.




Show more Show less"
2814270673,Data Engineer,Quadrant Resource,2021-11-30,United States,United States,,Contract,,"urgently Looking for Data Engineers

• 3+ years of PySpark programming experience around building data pipelines is mandatory
• Strong skills in Python Programming with focus around data pipeline activities.
• Data Bricks or DataProc knowledge/experience will be a plus.
• Strong SQL Experience.
• Apache Airflow Experience is good to have.
• Snowflake is a plus.
• CI/CD Experience with Jenkins Pipelines, Code Coverage, Scans etc. preferred.
Show more Show less"
2819112413,Data Engineer,inspHIRE Talent Solutions,2021-12-02,United States,Atlanta Metropolitan Area,Information Technology,Full-time,Staffing and Recruiting,"Data Engineer




Are you seeking the freedom to creatively solve interesting problems while also engineering something that genuinely makes a difference? Join the company that is bringing technological advancement to the logistics industry. Reporting to Director of Data Science, Engineering and Analytics, you will be joining a newly formed team of data professionals tasked with optimizing and preparing current state data platforms in preparation for design/architecture of future state advanced analytics and AI/ML platforms that drive customer value.




The ideal candidate will possess strong background in Data Engineering development technologies & experience with cloud-based resources. The candidate must possess excellent written and verbal communication skills with the ability to collaborate effectively with domain experts and technical experts on the team.This role will be responsible for both team collaboration as well as project initiative ownership and leadership.

 

RESPONSIBILITIES:

Understand the business data needs, both current and future to help deliver and guide a data strategy
Set and ensure proper adherence to strategic and tactical patterns
Set technical direction for obtaining and implementing technology
Help evaluate current and future staffing needs
Drive the creation of new standards and best practices as technology evolves; communicate and drive adoption across the company
Drive creation of new data capabilities and offerings

 

REQUIRED SKILLS/QUALIFICATIONS:

Bachelor’s Degree in a technical field (statistics, mathematics, science, accounting, finance) or related field
Cloud data experience. Storage, compute, movement orchestration, reporting (Azure Preferred)
Full data stack experience
Traditional and modern data warehousing expertise
RDBMS expertise
Experience in data lake patterns and process
Excellent interpersonal and communication skills (written and verbal)

 

PREFERRED SKILLS:

Azure data experience
Data Bricks
Azure Data Factory
Columnstore experience
MPP platform experience
PowerBi or Tableau 
Azure advanced analytics experience – ML/AI

 

About or Client:

Atlanta based with multiple US locations, our client delivers value and scale to their manufacturing, retail and distribution customers and partners via innovative end-to-end supply chain cloud based technology products and solutions.

Show more Show less"
2819519230,"Software Engineer, Data Infrastructure",DoorDash,2021-12-04,United States,"Seattle, WA",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Come help us build the world's most reliable on-demand, logistics engine for delivery! We're bringing on experienced engineers to help us further our 24x7, global infrastructure system that powers DoorDash’s three-sided marketplace of consumers, merchants, and dashers.

The Data Infrastructure team manages DoorDash's massive database and makes data accessible for teams driving decision making, machine learning, and experimentation. The team is relatively small, so there's an opportunity for impact where you can help grow the team and shape the roadmap for data infrastructure at DoorDash.

What You’ll Do

Work on our data pipeline, ETL systems, and real-time data
Come up with solutions for scaling data infrastructure
Help all departments of the company have access to our data
Collaborate in a dynamic startup environment
Improve logistics by taking on cutting-edge, technical problems

What We're Looking For

B.S., M.S., or PhD. in Computer Science or equivalent
5+ years of experience with CS fundamental concepts and OOP languages like Java and Python
Experience working with databases (e.g. SQL) and data infrastructure
Experience in big data technology like Presto, Snowflake, Hadoop, Airflow, Kafka
A passion for analyzing data to inform decisions
Experience improving efficiency, scalability, and stability of system resources

Why You’ll Love Working at DoorDash

We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies.
We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day.
We are learners - We’re not afraid to dig in and uncover the truth, even if it’s scary or inconvenient. Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute.
We are customer-obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility.
We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.
We offer great compensation packages and comprehensive health benefits.

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly and always learn and reiterate to support merchants, Dashers and the communities we serve. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods. Read more on the DoorDash website, the DoorDash blog, the DoorDash Engineering blog, and the DoorDash Careers page.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. Our leaders seek the truth and welcome big, hairy, audacious questions. We are grounded in our company values, and we make intentional decisions that are both logical and display empathy for our range of users—from Dashers to Merchants to Customers.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

Pursuant to the Colorado Fair Pay Act, the base salary range in Colorado for this position is $136,000 - $182,750, plus opportunities for equity and commission. Compensation in other geographies may vary. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

If you need any accommodations, please inform your recruiting contact upon initial connection.


Show more Show less"
2810031919,Data Engineer,StockX,2021-11-01,United States,United States,Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","Help shape the next generation of ecommerce for the next generation of consumer.

As a Data Engineer, you will be empowered to leverage data to drive amazing customer experiences and business results. You will own the end to end development of data engineering solutions to support analytical needs of the business. The ideal candidate will be passionate about working with disparate datasets and be someone who loves to bring data together to answer business questions at speed. You should have deep expertise in the creation and management of datasets and the proven ability to translate the data into meaningful insights through collaboration with analysts, data scientists and business stakeholders.

Responsibilities

Design and build mission critical data pipelines with a highly scalable distributed systems architecture - including data ingestion (streaming, events and batch), data integration, data curation

Help continually improve ongoing reporting and analysis processes, simplifying self-service support for business stakeholders

Automation of end to end data pipeline with metadata, data quality checks and audits

Optimize the data pipelines to support BI and ML use cases

Support mission critical applications and near real time data needs from the data platform

Capture and publish metadata and new data to subscribed users

Work collaboratively with business analysts, product managers, data scientists as well as business partners and actively participate in design thinking session

Participate in design and code reviews

Qualifications

3+ years’ experience years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets

1+ years' of experience in programming language like Python, Scala

1+ years' experience building with AWS or other cloud environments

Strong familiarity with batch processing and workflow tools such as AirFlow, NiFi

Strong business mindset with customer obsession; ability to collaborate with business partners to identify needs and opportunities for improved data management and delivery

BS/BA degree in Computer Science, Physics, Mathematics, Statistics or other Engineering disciplines

Nice To Have

Masters in Computer Science, Physics, Mathematics, Statistics or other Engineering disciplines

Experience with data visualization tools such as Tableau, Looker, PowerBI

About Us

Our global platform offers unprecedented access to current culture while our data-driven, bid-ask model provides buyers with the real-time visibility to know they’re getting a fair price. And, unlike other ecommerce sites, StockX hand-checks every purchase (20,000+ daily trades) at one of our regional authentication centers.

StockX’s special formula has rocketed the company to a multibillion dollar valuation, with 10M+ lifetime trades on the platform—more than half of those coming in the last year. And we’re just getting started.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. This job description is intended to convey information essential to understanding the scope of the job and the general nature and level of work performed by job holders within this job. However, this job description is not intended to be an exhaustive list of qualifications, skills, efforts, duties, responsibilities or working conditions associated with the position. StockX reserves the right to amend this job description at any time.
Show more Show less"
2801723310,Data Engineer,PLANOLY,2021-11-16,United States,"Austin, TX",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","PLANOLY is the industry-leading social marketing platform trusted by over 5 million users to visually plan, schedule and measure performance across Instagram and Pinterest. PLANOLY is beautifully crafted to be simple, clean and easy to use. PLANOLY believes firmly in inclusivity and is thrilled to pave the way for brands, businesses and individuals of all backgrounds to carry out their digital marketing strategies seamlessly.



 



PLANOLY is looking for a thoughtful, well-rounded Data Engineer to join a rapidly growing startup and work on building data pipelines, tools and analytics services that help power business decisions. Our software platform that small businesses, influencers, agencies, and marketing firms use daily gives us an incredibly rich and diverse dataset that we need to collect, transform, and analyze in order to improve effectiveness of our products as well as impact business decisions. You will have the opportunity to take a leading role in our data initiatives and help solve some challenging problems in the social media marketing space. 



 



Tools We Use



Google BigQuery
Google Data Studio
dbt
SQL
Amazon Web Services
Google Cloud

What You Will Do



Data Modeling / Architecting via designing data models and implementing appropriate abstractions for immediate requirements.
Data infrastructure management including coding and maintaining cloud-based data pipelines and third-party data integrations.
Monitor the quality of data and information, report on results, identify, and recommend system application changes required to improve the quality of data in all applications.  Take on responsibility for the health and reliability of the data infrastructure.
Design, implement and manage large data sets for our group of products to identify usable information.
Work directly with data analysts to understand business questions and design data infrastructure to support those needs.
Collaborate closely and autonomously with a small team of engineers, designers and cross-functional users to implement solutions.

Who You Are



Bachelor’s degree in Computer Science, Business Administration, Finance, STEM field, or 3+ years of relevant work experience.
Expert-level experience writing SQL queries and creating SQL based data models.  Experience with dbt a plus.
Experienced in managing data pipelines in cloud-based infrastructure such as Amazon Web Services. Experience with serverless technology such as Lambda preferred.
Experience coding services and systems using OOP languages or commonly used languages like Python or NodeJS.  
Able to work within a software development lifecycle process and following agile methodologies.
Knowledge of common software development tools such as git and 
Ability to collaborate with other engineers, QA, and non technical people.
Experience architecting and maintaining large-scale data warehousing solutions (Redshift, Big Query, etc) and ETL techniques.
Proficiency in Microsoft Excel.
Excellent attention to detail with strong written/verbal communication skills.
Ability to QA and troubleshoot large data sets.
Ability to work on green field projects with relatively minimal guidance.

Who We Are



We are social media experts and first and foremost users of our tools to enhance our social media strategies. PLANOLY is built by influencers for influencers.
We’re growing super fast and have been profitable since inception.
We offer an open work environment where highly motivated engineers take full ownership of the products and help steer the firm.
We are a huge advocate of work-life balance, which is seen in our open vacation and work-from-any-coffee-shops policies.
We’ll provide you with lunch, snacks, drinks, and regular team outings.

 



** This role is not eligible for an employment visa.**



U.S. Equal Employment Opportunity/Affirmative Action Information



PLANOLY is proud to be an equal opportunity employer and will consider all qualified individuals seeking employment without regards to race, color, creed, religion, gender, gender identity, national origin, citizenship, age, sex, marital status, ancestry, physical or mental disability, veteran status, sexual orientation, or any other protected classification.

Show more Show less"
2816172861,Technology Engineer (Data Engineer),PNC,2021-11-16,United States,"New York, NY",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Banking, and Financial Services","Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. We work together each day to foster an inclusive workplace culture where all of our employees feel respected, valued and have an opportunity to contribute to the company’s success.

As a Technology Engineer (Data Engineer) for PNC's Security Analytics Hub, you will have the opportunity to work fully remote. Our team focuses on producing data driven insights into multiple areas of risk facing the bank, including cybersecurity and physical security.

Day To Day Responsibilities

Acquire/map datasets that align with our business partner needs
Develop algorithms that shape data into useful and actionable information
Build, test, and maintain database pipeline architectures
Collaborate with management to understand and meet company objectives
Form new data validation methodologies and data analysis tools
Ensure continued compliance with data security policies and governance

Technical Qualifications

Education: BS/BA in technical discipline
5+ years of Python development
5+ years of experience with development/decomposition of complex SQL (RDMS Platforms)
3+ years of experience with test-driven development. Continuous Integration/ Development (e.g. GIT, Jenkins, Maven)
3+ years with CRON/Shell Scripting
Experience with utilization of REST API and/or EDPI
Hands on experience with project management tools such as JIRA, Confluence
Ability to work with end users (BI analysts, data scientists, etc.) to solve technical issues
Experience working in an Agile Team construct
Extensive knowledge of databases, data warehouses, systems integrations, and data flows is mandatory for this role.
Additionally, candidates should be well-versed in data architecture, data development, with a proven history of providing effective data solutions.

Required Skills To Be Considered For This Role

Coding: Proficiency in coding languages is essential to this role. Common programming languages used by the team include SQL, Python.
Relational and non-relational databases: You should be familiar with both relational and non-relational databases, and how they work (Teradata, Oracle, etc).
ETL (extract, transform, and load) systems: Moving data from databases and other sources into a single repository, like a data warehouse.
Data storage knowledge: As solutions are designed, when to use a data lake versus a data warehouse, for example.
Automation and scripting. Candidate should be able to write scripts to automate repetitive tasks (e.g. Cron jobs, Linux, shell scripting).
Big data tools: Understanding of Hadoop, MongoDB, and Kafka helpful, but not required.
Data security: Securely managing and storing data to protect it from loss or theft per PNC guidelines.

Job Description

Leverages technical knowledge and industry experience to design, build and maintain technology solutions. Assists with selecting appropriate platforms, integrates and configures solutions.
Develops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.
May provide consultation on common issues and best practices for junior staff.
Provides a systematic analysis on client requirements within the traceability framework and resolves any functional problems encountered.
Ensures quality of project deliverables while maintaining compliance with relevant standards and processes.

PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:

Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.

Competencies

Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.

Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.

Effectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.

Emerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.

Industry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.

IT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).

IT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.

Planning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.

Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Work Experience

Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

Education

Bachelors

Additional Job Description

COMPENSATION

Base Salary

$55,000 to $142,600

Role

Placement within the compensation range is based on the specific role and the following factors

Where a person is paid in the compensation range is aligned to their experience and skills.

– Lower in range –Building skills and experience in the job

– Within the range–Experience and skills align with proficiency in the role

– Higher in range –Experience and skills add value above typical requirements of the role

– Compensation Range may vary based on Geographic Location

INCENTIVE

Role is incentive eligible with the payment based upon company, business and individual performance.

Benefits

PNC offers employees a comprehensive range of benefits to help meet your needs now and in the future. Depending on your eligibility, options for full-time employees include medical/prescription drug coverage (with a Health Savings Account feature); dental and vision options; employee and spouse/child life insurance; short- and long-term disability protection; maternity and parental leave; paid holidays, vacation days and occasional absence time; 401(k), pension and stock purchase plans; dependent care reimbursement account; back-up child/elder care; adoption assistance; educational assistance and a robust wellness program with financial incentives. To learn more about these and other programs, including benefits for part-time employees, visit pncbenefits.com > New to PNC.

Disability Accommodations Statement

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.

The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO)

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.

California Residents

Refer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.
Show more Show less"
2812348748,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"Las Vegas, NV",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2781243858,Data Engineer,Centene Corporation,2021-10-11,United States,"Tampa, FL",Information Technology,Full-time,Insurance and Hospitals and Health Care,"You could be the one who changes everything for our 24 million members. Centene is transforming the health of our communities, one person at a time. As a diversified, multi-national Fortune 50 and rapidly growing organization, our mission is fueled by exceptional talent. To support our rapid growth, we are building our East Coast headquarters and innovation hub here in Charlotte.

About Us

We are revolutionizing the world of healthcare through digital transformation and building a world-class software engineering practice. Our high caliber team delivers leading edge technology and drives innovation to solve complex business challenges. Using collective innovation we are turning visions into action and challenging what is possible to support the healthcare of 1 in 15 individuals.

About You

You are a highly collaborative, strategic risk-taker driven to make a difference and change the face of healthcare. You thrive in a supportive, result-oriented community and are committed to the relentless pursuit of continuous growth. You are highly agile, excel in fast-paced environments and willing to push outside your comfort zone. You are ready to find your purpose at work

The Role

We are transforming technology and creating a digital evolution that will empower Centene to better serve our members. The Data Engineer will provide the Health Plan Systems with a platform for real-time stream processing by performing application and production support to help ensure the availability of streaming services and the continuous flow of data.

As Data Engineer you will

Contribute to the development and maintenance of real-time processing applications
Contribute to the creation and maintenance of optimal data pipeline architectures
Conduct maintenance and support for core infrastructure health, system upgrades, monitoring, CI/CD and logging
Research streaming best practices and proper stream architecture
Collaborate with team members to better understand existing data requirements and validation rules
Analyze trends in data sets and contribute to the development of algorithms in order to improve upon the usefulness of raw data

Our Comprehensive Benefits Package

Flexible work solutions including remote options, hybrid work schedules and dress flexibility
Competitive pay
Paid Time Off including paid holidays
Health insurance coverage for you and dependents
401(k) and stock purchase plans
Tuition reimbursement and best-in-class training and development

Additionally, You Will Bring
Education/Experience Computer Science, Computer Engineering, Software Engineering, related field or equivalent experience.
Master’s degree in Computer Science or Computer Engineering preferred.
2+ years of experience in Computer Engineering, Software Development, System Administration, Linux Administration.
Experience with the following programs/platforms is preferred
Oracle, ETL, Oracle Datawarehouse, Informatica, PowerCenter, Greenplum, Snowflake, Talend and AWS

Centene is an equal opportunity employer that is committed to diversity, and values the ways in which we are different. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other characteristic protected by applicable law.
Show more Show less"
2812775470,Data Engineer,Nortek Consulting Inc,2021-11-29,United States,United States,,Full-time,,"5 years of experience in a Data Engineer role.

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), and working familiarity with a variety of databases.

Technical Skills

Source Code Control (e.g., Git, Subversion).

Open-Source Frameworks (Apache Spark, Hadoop, etc.).

Strong design and coding skills (e.g., Python, Scala, JavaScript).

Experience with reporting/visualization tools

Comfortable working with global stakeholders, internally and externally.

Experience with SQL-based technologies

Experience with Restful API developments.

Experience with AWS Services

Show more Show less"
2805163481,Data Engineer,Charles Schwab,2021-10-29,United States,"Westlake, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Your Opportunity

Would you like to be part of a new team chartered to build the next generation data & analytics platform supporting Schwab Technology Services? The STS Data Enablement Team in Data and Rep Technology (DaRT) is looking for a Data Engineer that will help develop and enable the strategic use of STS data assets.

Our ideal candidate is enthusiastic about learning new and existing technologies in order to deliver exceptional software solutions. You need to have proven critical thinking skills and a laser focus on pragmatic problem solving. We require strong ethics, critical thinking skills, and the ability to partner with and influence business people and technologists across the organization. You should have strong backgrounds in both data architecture and data engineering, along with a passion for learning new data integration techniques.

What you are good at

Collaborating directly with business and technology stakeholders to define future-state business capabilities & requirements, and translating those into transitional and target state data architectures
Analyzing the current technology environment to detect critical deficiencies, and recommend solutions for improvement
Designing, implementing, and maintaining data warehouses and near real-time data pipelines via the practical application of existing and new data engineering techniques
Developing continuous integration and continuous deployment pipelines for data solutions that include automated unit & integration testing
Mentoring, motivating, and supporting the team to achieve organizational objectives and goals
Advocating for agile practices to increase delivery throughput
Ensuring consistency with published development, coding and testing standards

What you have

3+ years of experience designing, building, and supporting near real-time data pipelines and analytical solutions using Hadoop, Teradata, MS SQL Server, Talend, Informatica, and/or SSIS
2+ years of experience working on agile teams delivering data solutions
2+ years of experience building data pipelines and interfaces with object oriented languages (.Net, Java, Python)
1+ years of experience modeling star schema data warehouses using the Kimball dimensional modeling techniques
1+ years of experience delivering solutions on public cloud platforms (Google Cloud preferred)
Basic understanding of at least one IT Management frameworks such as ITIL or COBiT
Experience writing automated unit, integration, and acceptance tests for data interfaces & data pipelines
Ability to quickly learn & become proficient with new technologies
Exceptional interpersonal skills, including teamwork, communication, and negotiation

Why work for us?

Own Your Tomorrow embodies everything we do! We are committed to helping our employees ignite their potential and achieve their dreams. Our employees get to play a central role in reinventing a multi-trillion-dollar industry, creating a better, more modern way to build and manage wealth.

Benefits: A competitive and flexible package designed to empower you for today and tomorrow. We offer a competitive and flexible package designed to help you make the most of your life at work and at home—today and in the future. Explore further.

Schwab is committed to building a diverse and inclusive workplace where everyone feels valued. As an Equal Opportunity Employer, our policy is to provide equal employment opportunities to all employees and applicants without regard to any status that is protected by law. Please click here to see the policy.

Schwab is an affirmative action employer, focused on advancing women, racial and ethnic minorities, veterans, and individuals with disabilities in the workplace. If you have a disability and require reasonable accommodations in the application process, contact Human Resources at applicantaccessibility@schwab.com or call 800-275-1281.

TD Ameritrade, a subsidiary of Charles Schwab, is an Equal Opportunity Employer. At TD Ameritrade we believe People Matter. We value diversity and believe that it goes beyond all protected classes, thoughts, ideas, and perspectives.
Show more Show less"
2816170951,Technology Engineer (Data Engineer),PNC,2021-11-16,United States,"Charlotte, NC",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Banking, and Financial Services","Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. We work together each day to foster an inclusive workplace culture where all of our employees feel respected, valued and have an opportunity to contribute to the company’s success.

As a Technology Engineer (Data Engineer) for PNC's Security Analytics Hub, you will have the opportunity to work fully remote. Our team focuses on producing data driven insights into multiple areas of risk facing the bank, including cybersecurity and physical security.

Day To Day Responsibilities

Acquire/map datasets that align with our business partner needs
Develop algorithms that shape data into useful and actionable information
Build, test, and maintain database pipeline architectures
Collaborate with management to understand and meet company objectives
Form new data validation methodologies and data analysis tools
Ensure continued compliance with data security policies and governance

Technical Qualifications

Education: BS/BA in technical discipline
5+ years of Python development
5+ years of experience with development/decomposition of complex SQL (RDMS Platforms)
3+ years of experience with test-driven development. Continuous Integration/ Development (e.g. GIT, Jenkins, Maven)
3+ years with CRON/Shell Scripting
Experience with utilization of REST API and/or EDPI
Hands on experience with project management tools such as JIRA, Confluence
Ability to work with end users (BI analysts, data scientists, etc.) to solve technical issues
Experience working in an Agile Team construct
Extensive knowledge of databases, data warehouses, systems integrations, and data flows is mandatory for this role.
Additionally, candidates should be well-versed in data architecture, data development, with a proven history of providing effective data solutions.

Required Skills To Be Considered For This Role

Coding: Proficiency in coding languages is essential to this role. Common programming languages used by the team include SQL, Python.
Relational and non-relational databases: You should be familiar with both relational and non-relational databases, and how they work (Teradata, Oracle, etc).
ETL (extract, transform, and load) systems: Moving data from databases and other sources into a single repository, like a data warehouse.
Data storage knowledge: As solutions are designed, when to use a data lake versus a data warehouse, for example.
Automation and scripting. Candidate should be able to write scripts to automate repetitive tasks (e.g. Cron jobs, Linux, shell scripting).
Big data tools: Understanding of Hadoop, MongoDB, and Kafka helpful, but not required.
Data security: Securely managing and storing data to protect it from loss or theft per PNC guidelines.

Job Description

Leverages technical knowledge and industry experience to design, build and maintain technology solutions. Assists with selecting appropriate platforms, integrates and configures solutions.
Develops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.
May provide consultation on common issues and best practices for junior staff.
Provides a systematic analysis on client requirements within the traceability framework and resolves any functional problems encountered.
Ensures quality of project deliverables while maintaining compliance with relevant standards and processes.

PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:

Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.

Competencies

Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.

Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.

Effectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.

Emerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.

Industry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.

IT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).

IT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.

Planning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.

Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Work Experience

Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

Education

Bachelors

Additional Job Description

COMPENSATION

Base Salary

$55,000 to $142,600

Role

Placement within the compensation range is based on the specific role and the following factors

Where a person is paid in the compensation range is aligned to their experience and skills.

– Lower in range –Building skills and experience in the job

– Within the range–Experience and skills align with proficiency in the role

– Higher in range –Experience and skills add value above typical requirements of the role

– Compensation Range may vary based on Geographic Location

INCENTIVE

Role is incentive eligible with the payment based upon company, business and individual performance.

Benefits

PNC offers employees a comprehensive range of benefits to help meet your needs now and in the future. Depending on your eligibility, options for full-time employees include medical/prescription drug coverage (with a Health Savings Account feature); dental and vision options; employee and spouse/child life insurance; short- and long-term disability protection; maternity and parental leave; paid holidays, vacation days and occasional absence time; 401(k), pension and stock purchase plans; dependent care reimbursement account; back-up child/elder care; adoption assistance; educational assistance and a robust wellness program with financial incentives. To learn more about these and other programs, including benefits for part-time employees, visit pncbenefits.com > New to PNC.

Disability Accommodations Statement

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.

The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO)

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.

California Residents

Refer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.
Show more Show less"
2821524995,Data Engineer,Peraton,2021-12-04,United States,"Washington, DC",Engineering,Full-time,Civil Engineering,"US CITIZENSHIP REQUIRED FOR THIS POSITION: No

RELOCATION ASSISTANCE: No relocation assistance available

CLEARANCE TYPE: Confidential

TRAVEL: No

Description

Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the worlds leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our 22,000 employees do the cant be done, solving the most daunting challenges facing our customers.

Peraton is looking for Database Engineer to support our customer in Washington, DC. The ideal candidate designs, develops, builds, analyzes, evaluates and installs database management systems to include database modeling and design, relational database architecture, metadata and repository creation and configuration management. Uses data mapping, data mining and data transformational analysis tools to design and develop databases. Determines data storage and optimum storage requirements. Prepares system requirements, source analysis and process analyses and design throughout the database implementation.

Basic Qualifications

Bachelor's degree in a STEM discipline, preferably in Computer Science or Computer Engineering with at least 5 years of relevant experience.

We are an Equal Opportunity/Affirmative Action Employer. We consider applicants without regard to race, color, religion, age, national origin, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, marital status, veteran status, disability, genetic information, citizenship status, or membership in any other group protected by federal, state, or local law.
Show more Show less"
2600122680,Big Data Engineer,Amazon Web Services (AWS),2021-12-04,United States,"Seattle, WA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

AWS World Wide Revenue Ops is seeking a Big Data Engineer to join our Business Performance Management team, building a new Sales Revenue data solution. Our vision is to collect and process billions of usage and billing transactions every single day and relate it to the largest data feed supported by Salesforce.com. We apply business logic to transform to this raw data to generate the daily and monthly Sales Revenue utilized for daily and monthly AWS Sales Revenue reporting and the processing of quarterly Sales Commissions for AWS Sales on Incentive plans.

We are truly leading the way to disrupt the big data industry. We are accomplishing this vision by bringing to bear Big Data technologies like Elastic Map Reduce (EMR) in addition to data warehouse technologies like Spectrum to build a data platform capable of scaling with the ever-increasing volume of data produced by AWS services.

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build ETL to ingest the data into the data lake. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

Location: This role open to these locations: Seattle & Dallas. Relocation offered from within the US to any of these locations.

Inclusive Team Culture
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have twelve employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.


Basic Qualifications

This position requires a Bachelor's Degree in Computer Science or a related technical field, and 5+ years of meaningful employment experience.
5+ years of work experience with ETL, Data Modeling, and Data Architecture.
Expert-level skills in writing and optimizing SQL.
Experience with Big Data technologies such as Hive/Spark.
Proficiency in one of the scripting languages - python, ruby, linux or similar.
Experience operating very large data warehouses or data lakes.

Preferred Qualifications

Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
Experience with building data pipelines and applications to stream and process datasets at low latency.
Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
Knowledge of Engineering and Operational Excellence using standard methodologies.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role

/*AWS WWRO Galaxi Data Platform*/

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon Web Services, Inc.
Job ID: A1589015
Show more Show less"
2826937364,Data Engineer,Amber People HR,2021-12-04,United States,"New York, NY",Information Technology,Full-time,Human Resources,"New York

$140,000 - $150,000

My client is looking for a first-class Data Engineer to join their team analytics team. You’ll be responsible for all things data: building out our streaming and batch ETL pipelines, curating and anonymizing data that’s being generated from various sources, designing and building the data warehouse, and so on.

We’ll expect you to have an in-depth knowledge of distributed systems and data flows. Combined with an understanding of business intelligence and performance requirements, you’ll breathe life into Attentive data and help make it an invaluable part of the platform and business.

If you are a self-starter, excited about building a culture around data-driven decisions, motivated by making an impact, and pushing the boundaries of your knowledge, you will excel here and do great things!

The Role

Design, implement, and maintain an ever-growingETL pipeline using state-of-the-art technology
Use best practices and standards for managing large collections of data for analytics
Discover and integrate new heterogeneous data sources
Work closely with data analysts, data scientists, and product managers enabling them to provide insight into key performance metrics of the business
Help to improve data reliability, efficiency, and quality

Your Qualifications

4+ years of experience designing and developing a data warehouse on a distributed database platform, such as Snowflake or Redshift
Experience designing, developing, and maintaining high-throughput and low-latency ETL pipelines
Experience with data modelling, data access, and data storage techniques
Experience with big data tools such as Apache Spark
Proficient in SQL and Python
Proficient with at least one RDBMS (MySQL or Postgres preferred)
Successfully implemented data pipelines in the public cloud, especially Amazon Web Services
Strong analytical and interpersonal skills
Enthusiastic, highly motivated and ability to learn quick

Benefits & Perks

Robust health benefits packages including access to a 401k and various medical, dental and vision plans, and $100/month fitness reimbursement
Full support for remote work during COVID-19
Daily lunch delivery credit and other goodies sent to home
Regular company-wide social events (even virtually!)
Generous annual education stipend toward job-related external learning opportunities
An extremely enthusiastic team that appreciates collaboration
Show more Show less"
2792736763,Data Engineer,Capital One,2021-11-13,United States,"Plano, TX",Information Technology and Engineering,Full-time,"Banking, Financial Services, and Investment Banking","Locations: TX - Plano, United States of America, Plano, Texas

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You’ll Do

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies

Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems

Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake

Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community

Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment

Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications

Bachelor’s Degree

At least 2 years of experience in application development

At least 1 year of experience in big data technologies

Preferred Qualifications

3+ years of experience in application development including Python, SQL, Scala, or Java

1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)

2+ years experience with Distributed data or computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)

1+ years experience working on real-time data and streaming applications

1+ years of experience with NoSQL implementation (Mongo, Cassandra)

1+ years of data warehousing experience (Redshift or Snowflake)

2+ years of experience with UNIX Linux including basic commands and shell scripting

1+ years of experience with Agile engineering practices

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Job Category - Engineering, Technology
Show more Show less"
2802821506,Data Engineer,Flywheel Digital,2021-11-30,United States,United States,"Information Technology, Engineering, and Product Management",Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Management Consulting","Flywheel Digital

Data Engineer

Remote (or hybrid if local to Baltimore, MD or Seattle, WA)







We're looking for a Data Engineer to join our team as part of our Product Development function. The best candidates will hit the ground running and contribute to our data team as we develop and maintain necessary data automation, reports, ETL/ELT, and quality controls using leading-edge cloud technologies. You will have a deep knowledge and understanding of all stages in the software development life cycle. The ability to self-start, desire to learn new technology, manage multiple priorities, and strong communication are all in your wheelhouse!







Key Responsibilities

Be a driving force in assuring quality, timely, accurate data across several business areas
Build data pipelines that range from simple to complex, using technologies like Apache Airflow and AWS Lambda, Step Functions, and CloudWatch
Write code in Python, PostgreSQL and MySQL. You must have deep experience with SQL views and stored procedures, and you understand data modelling and the value of an ERD
Extract data from REST API endpoints
Be comfortable being called upon to engage directly with technical analysts to help build concise technical requirements
Have familiarity with version control concepts, have used GitHub in a team setting, and have experience collaborating with other engineers in a paired development environment
Be reliable, accountable, and can work without supervision, independently and as part of a team
Have high level of integrity, be action-oriented and an assertive communicator
Be flexible, and able to handle multiple priorities as needed
Strive to do things the right way, embrace change in dynamic, rapidly evolving environment
Love to learn and use cutting-edge technology







Your Experience

Bachelor’s Degree, preferably in IT/Data-related field of study
4 years of experience developing with Python
2 years of experience developing with MySQL and PostgreSQL (AWS Redshift would be ideal)
Experience working in an agile development environment
Experience with data modelling
Experience with data pipelines/batch automation concepts (Apache Airflow would be ideal)
Familiarity with Jira
Familiarity with GitHub
Experience with AWS S3
Experience with AWS Lambda and CloudWatch
Experience with other AWS technologies: EC2, Step Functions, Glue, Athena, Data Pipeline







What We Offer




Our benefits package incorporates what we’re passionate about – unlocking your future, overall well-being and sustainability – whilst giving you control over your benefits.

Unlimited PTO
401K – Saving Incentive plan
Very Generous Medical, Vision, and Dental Insurance plans
Flexible Spending Accounts
Great learning and development opportunities
Life Assurance and Disability insurance
Option to opt into the Ascential Shares Scheme







Inclusive Workforce




At Ascential, our goal is to create a culture where individuals of all backgrounds feel comfortable in bringing their authentic selves to work. We want all Ascential people to feel included and truly empowered to contribute fully to our vision and goals.




Everyone who applies will receive fair consideration for employment. We do not discriminate based upon race, colour, religion, sex, sexual orientation, age, marital status, gender identity, national origin, disability, or any other applicable legally protected characteristics in the location in which the candidate is applying.




If you have any accessibility requirements that would make you more comfortable during the application and interview process, please let us know so that we can support you.




For more information on our culture, visit Ascential.com.







About Flywheel




Flywheel Digital is a diverse collection of practitioners who have solved the most challenging problems for numerous Fortune 500 companies on Amazon. We love rolling up our sleeves to figure out the root cause of issues and implement structural fixes to get and keep our client's business on track. Our team of business managers, search managers, analysts, and software developers work together to provide industry-leading support to the best brands on Amazon. Flywheel are headquartered in Baltimore in the United States and have recently set up a European hub in London. In 2018 Flywheel was acquired by Ascential PLC.

Show more Show less"
2792739321,Data Engineer,Capital One,2021-11-13,United States,"Cambridge, MA",Information Technology and Engineering,Full-time,"Banking, Financial Services, and Investment Banking","314 Main Street (21020), United States of America, Cambridge, Massachusetts

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You’ll Do

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies

Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems

Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake

Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal and external technology communities, and mentoring other members of the engineering community

Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment

Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications

Bachelor’s Degree

At least 2 years of experience in application development

At least 1 year of experience in big data technologies

Preferred Qualifications

3+ years of experience in application development including Python, SQL, Scala, or Java

1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)

2+ years experience with Distributed data or computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)

1+ years experience working on real-time data and streaming applications

1+ years of experience with NoSQL implementation (Mongo, Cassandra)

1+ years of data warehousing experience (Redshift or Snowflake)

2+ years of experience with UNIX Linux including basic commands and shell scripting

1+ years of experience with Agile engineering practices

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Job Category - Engineering, Technology
Show more Show less"
2793778684,Junior Data Engineer,Massachusetts Institute of Technology,2021-11-10,United States,"Cambridge, MA",Information Technology,Full-time,"Non-profit Organizations, Internet Publishing, and Insurance","Working at MIT offers opportunities, an environment, a culture – and benefits – that just aren’t found together anywhere else. If you’re curious, motivated, want to be part of a unique community, and help shape the future – then take a look at this opportunity.

Information on MIT’s COVID-19 vaccination requirement can be found at the bottom of this posting.
Show more Show less"
2798299289,Data Engineer,"EDO, Inc.",2021-10-19,United States,"New York, NY",Information Technology,Full-time,"Marketing and Advertising, Online Media, and Computer Software","Role can be in any of EDO's office locations: New York, Los Angeles, San Francisco. Role is also open to full remote.

Who We Are

EDO was founded in 2015 to transform how data is used within the Media, Entertainment, and Advertising industry. Today, EDO is the leading data and analytics company for TV mid-funnel measurement and attribution. Customers include Disney, NBCU, Toyota,, and WarnerMedia. EDO's premier product offering Ad EnGage focuses on national linear TV; we are expanding our platform to cover the newest and fastest-growing segment of advertising with convergent TV (i.e. streaming) by developing new data sources and analytical techniques to measure the new ways ads are being bought, sold, and shown to consumers.

Before EDO, advertisers could only rely on their first party data and limited partnership opportunities. Advertisers would rely on survey based methodologies that would poll a small number of people on their attitude towards the brand. With EDO, advertisers are able to get full coverage of their campaigns and their competitive campaigns. All with no set up cost. Plus, EDO's outcome measurement is rooted in behavioral outcomes such as search which is much more correlated with economic outcomes than attitudes and the best KPI you can use to perform in-flight optimization. Marketers use this data to optimize their media plans and creatives.

About The Role

As a Data Engineer at EDO, you will join a team of talented Data Engineers working closely with Data Scientists to develop our next generation data pipeline. Our complex and challenging data pipeline combines multiple sources of advertising occurrence data and metadata with our own proprietary engagement data in real time to generate the mid-funnel engagement data which our clients rely on to make critical business decisions about their advertising strategy. You will have the opportunity to learn and work on cutting edge technologies related to big data and real time streaming.

About You

2+ years data engineering experience
Working knowledge pertaining to relational databases (MySQL, Postgres, etc), cloud data services (AWS), and data warehousing tools (Redshift, Snowflake, etc).
Production experience working with modern ETL data pipeline tools. You will work with the team to decide and utilize the appropriate tools for our data pipeline. (Spark, Kafka, Airflow, RabbitMQ, Kiba, Luigi, etc.).
Proficiency with a scripting language such as Ruby or Python and proficiency with another language such as Scala, Java.
Self-driven individuals who take ownership of their work
Ability to build products quickly and efficiently
Strong understanding of software engineering practices and principles
Previous industry experience working with TV or other advertising data is a huge plus


Benefits

Supportive, collaborative team and work that has immediate, clear impacts
Early-stage equity and competitive salary
Unlimited PTO along with trust and support to use it
Medical, dental, and vision insurance
Wellness Stipend - movie tickets, fitness discounts, commuter subsidies, meals and snacks
Show more Show less"
2792740254,Data Engineer,Capital One,2021-11-13,United States,"Plano, TX",Information Technology and Engineering,Full-time,"Banking, Financial Services, and Investment Banking","Locations: TX - Plano, United States of America, Plano, Texas

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You’ll Do

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications

Bachelor’s Degree
At least 2 years of experience in application development
At least 1 year of experience in big data technologies

Preferred Qualifications

3+ years of experience in application development including Python, SQL, Scala, or Java
1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
2+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
1+ years experience working on real-time data and streaming applications
1+ years of experience with NoSQL implementation (Mongo, Cassandra)
1+ years of data warehousing experience (Redshift or Snowflake)
2+ years of experience with UNIX/Linux including basic commands and shell scripting
1+ years of experience with Agile engineering practices

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Job Category - Engineering, Technology
Show more Show less"
2818346597,Data Engineer,"KR3 Information Systems, Inc.",2021-12-01,United States,"Seattle, WA",,Contract,,"Data Engineer

Location: Seattle, WA (Remote Till Covid Control)

Duration : Long Term

Client: Gspann

 

Key Skills:

·         NiFi, PySpark, Airflow (Incorta, Splunk, Azure)

·         4+ years of experience in developing

·         Supporting Big Data applications

·         Experience in large-scale Big Data & Analytics applications

·         Hands on experience in using technologies like Apache NiFi, PySpark, Airflow, Incorta and Splunk Exposure to Azure Cloud Platform

·         Working experience and communicating with business stakeholders and architects Industry

·         experience in developing relevant big data/ETL data warehouse

·         experience building cloud native data pipelines 

·         Experience in Python, Pyspark, Scala, Java and SQL Strong Object and Functional programming

·         experience in Python

·         Experience worked with REST and SOAP based APIs to extract data for data pipelines




Show more Show less"
2810639920,Data Engineer,Sutter Health,2021-11-02,United States,"Emeryville, CA",Information Technology,Full-time,"Non-profit Organizations, Wellness and Fitness Services, and Hospitals and Health Care","Position Overview

Data scientist provides support in making strategic data-related decisions by analyzing, manipulating, tracking, internally managing and reporting data from diverse internal and external sources. Collaborate with cross-functional teams to perform exploration and experimentation, building prototypes and best practices for our applications. This position will bring insight and change to how we approach customer, patients, business leaders and partners to solve the most complex problems with analytics. Provides a wide-range of analytical results and have the ability to communicate these informed conclusions and recommendations across an organization's leadership structure.

May work at the Emeryville Sutter Health office but most days, work may be done remotely (work from home option).

Qualifications

Education

Bachelor's Degree in Mathematics, Computer Science or relevant engineering or science area required.
Master's in Mathematics, Computer Science or relevant engineering or science area preferred.

Experience

3+ years of experience in large and medium projects in self-directed role
3+ years of proven experience in hypotheses development, identification of patterns within data, analyzing data and interpreting results.
3+ years in a directing or supporting Business Intelligence, Analytics and Data Modeling.
3+ years of experience and expertise in business intelligence tools (using Microstrategy, Business Objects, QlikView or Tableau).
3+ years of experience in big data technologies using (HANA, MongoDB or Hadoop).
6+ years of experience with a statistical analysis tool (using R, Python or Octave) preferred.
6+ years of experience scripting (using Javascript, Perl, Awk or Sed) preferred.
6+ years of experience in programming (using C, C++, or JAVA) preferred.
9+ years of software development life cycle experience preferred.

Department Specific Experience
Development experience using common Python Math and data analysis packages including pandas, NumPy, Scikit-Learn, as well as packages for database operation, web services and network analysis.
Experience with:
A pipeline orchestration framework (e.g. airflow, luigi, Prefect, etc.)
At least 2 years of Relational Databse like MySQL
Batch, stream, and offline processing to manage business state or perform ETL/ELT
Software development skills and tools: Git version control, issue tracking, and documentation
Experience with designing or leveraging APIs, especially for data access.
Familiar with Agile/Scrum

Organization:Sutter Health System Office

Employee Status: Regular

Benefits: Yes

Position Status: Exempt

Union: No

Job Shift: Day

Shift Hours:8 Hour Shift

Days of the Week Scheduled:Monday-Friday

Weekend Requirements: Other

Schedule: Full Time

Hrs Per 2wk Pay Period:80

Applications Accepted:All Applications Accepted
Show more Show less"
2728194218,Big Data Engineer,FinTech LLC,2021-09-24,United States,"Lake Oswego, OR",Engineering and Information Technology,Contract,"Appliances, Electrical, and Electronics Manufacturing, Manufacturing, and Retail","Role: Big Data Engineer
Location: Portland, OR
Type of Employment: Contract

Job Description:
Design & develop batch and complex event processing applications.
Design and develop Spark Streaming jobs to consume data from Messaging queues (like Kafka) and persist in HDFS/HBASE/Hive.
Design and develop text parsers (XML and JSON).
Design data models in HBase to store non-relational data such as XML JSON etc.
Design and develop access layer in Phoenix for HBase tables.
Performance tune Batch and Streaming applications to meet the required SLAs.
Design and develop ETL jobs to load data into Hive using Java/Python/HiveQL.
Design and develop ETL jobs to process data in Spark and load it into Hive/HBase.
Develop Sqoop jobs to load data from relational databases into HDFS/Hive.
Support Production activities
Show more Show less"
2788318551,"Senior Big Data Engineer, Experience Data Platform",TikTok,2021-11-11,United States,"Mountain View, CA",Engineering and Information Technology,Full-time,Internet Publishing,"TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.




Our team is responsible for optimizing app performance related experience for TikTok users, including client, video playback, shooting, uploading and network optimization. As a member of us, you will have opportunity to build test infrastructure and data platform to test and monitor performance metrics in a global environment.




Responsibilities:

- Design and develop big data systems under trillion level data environment;

- Collaborate with product managers to define and develop big data applications;

- Drive cross-team communication to align design and implementation.




Qualifications

- BS degree in Computer Science, Computer Engineering or other relevant majors;

- 3+ years of software engineering experience in a big data environment;

- Familiar with at least one of apache big data systems, Hadoop, Spark, Flink, Druid, Impala, etc;

- Strong communication skills;

- Excellent programming, debugging, and optimization skills in one or more general-purpose programming languages including but not limited to: Golang, Java, Python.

- Ability to think critically and to formulate solutions to problems in a clear and concise way.

- Open source committee will be a plus.







TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.




TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at USRC@tiktok.com

Show more Show less"
2820783752,Data Engineer,Greenhouse Software,2021-12-03,United States,United States,Information Technology,Full-time,Computer Software,"We believe in the power of hiring. Because the potential for people to do something outstanding has everything to do with being in the right role, on the right team, at the right time. That’s where Greenhouse comes in – from recruiting to on-boarding, we make software to help every company be great at hiring.

Greenhouse is hiring a Data Engineer to join our team!

As a member of our rapidly growing data engineering team, you will be given a high level of autonomy to guide the architecture of this new platform. Our data engineering team works with stakeholders in the product engineering teams as well as data analysts around the company to make sure their data is highly available and correct.

Learn more about our engineering culture here.

Who Will Love This Job


A standout colleague – you thrive off of developing and supporting your peers and junior teammates; no job is too small for you
A doer – you get things done, you move quickly, and you love working in a dynamic environment
A problem solver – you not only think about the bigger picture but can also connect the dots and dedicatedly resolve issues quickly and efficiently
An excellent communicator – you have a knack for explaining technical processes concisely (even to non-engineers), and work well with cross-functional internal teams


What You’ll Do



As a member of our rapidly growing data engineering team, you will work with stakeholders in the product engineering teams as well as data humans (analysts and scientists) around the company.
You will help design and build the data platform that supports both our product teams, as well as our internal data analysts.
You will build data pipelines and tools using Kubernetes and Argo, and help lay the foundation for our growing machine learning capabilities.
You will work across our data stack to help us take our data products to the next level - from data pipelines to analytical modeling to machine learning tools.


You should have


You’re an experienced software developer and feel comfortable writing in languages like Python, as well as working directly with SQL
You’re comfortable architecting data pipelines.
You’re comfortable developing and debugging ETLs that run across multiple systems and tools (Airflow, Argo, etc.)
You’re comfortable working with analysts and data scientists to design and build data transformations that improve analytics and clean data.
You’re comfortable with non-SQL analytics and ETL tools (Hadoop, Spark, dbt, etc.)
Your own unique talents! If you don’t meet 100% of the qualifications outlined above, tell us why you’d be a great fit for this role in your cover letter.


Applicants must be currently authorized to work in the United States on a full-time basis.

If you are based in California, we encourage you to read this important information for California residents linked here.

The ranges provided below are for Colorado-based hires only and will be commensurate with candidate experience. Pay ranges for candidates in other locations other than CO may differ based on the cost of labor in that location. Pay range: $128,000-$190,000.

Who We Are

At Greenhouse, we celebrate having a diverse group of hardworking employees – and it hasn’t gone unnoticed. In 2019, we were ranked #4 in Fortune’s Best Workplaces in New York and #5 in their Best Company Culture. We’ve also been recognized as a Best Company for Diversity by Comparably, and have been named to Inc. Magazine’s Best Workplaces list. We pride ourselves on fostering a collaborative culture throughout every step of a Greenhouse employee's journey. From day one of our interview process to executive ""Ask Me Anything"" sessions, we consistently cultivate an inclusive environment.

For all our employees, we offer a full slate of benefits from competitive salaries, stock options, medical, dental and vision coverage, disability coverage, employer paid life insurance, mental health resources, financial wellness benefits, and a fully paid parental leave program. For US-based employees, we offer flexible vacation, commuter benefits and a 401(k) plan, and for Dublin-based employees we offer 25 days' vacation and a pension plan.

Our success in making companies great at hiring depends on our ability to create a diverse, equitable and inclusive environment. To that end, we’re committed to attracting, developing, retaining and promoting a diverse workforce, and infusing DE&I throughout all of our internal practices. By ensuring that every Greenie is able to bring a diversity of talents to our work, we’re increasingly capable of living out our mission and providing real insight from our products to support our customers. We encourage people from underrepresented backgrounds and all walks of life to apply. Come grow with us at Greenhouse, where we’re building a team to face the world’s increasingly complex and diverse hiring needs.

Want to learn more about our interviewing process? Check out our interviewing at Greenhouse page.

**Due to COVID-19, all Greenhouse employees are working remotely until further notice.**


Show more Show less"
2826946723,Data Engineer,"Quest Analytics, LLC",2021-12-04,United States,"Overland Park, KS",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Quest Analytics is one of the fastest growing companies in the Healthcare software space in the US. Healthcare providers and insurance companies rely on our software. We do the important work of providing access to healthcare for all Americans!

Quest Analytics improves the patient experience by increasing the accuracy of medical provider networks. To fulfill this mission, we are searching for a Data Engineer to join our Data Operations team in our Overland Park, KS office. You will focus on building and optimizing core components of the data platform that powers our provider data management and network analytics products. Together, these products help the nation’s leading health plans, regulatory agencies, and benefits consultants provide consumers with convenient access to an adequate network of doctors and hospitals and an up-to-date, accurate directory of providers. We are currently focused on building for our next phase of growth. Come join us!

In This Role You Will

Build and maintain client data ingestion and export pipelines (Python and Scala centric)
Provide technical solution support across services and multiple levels of the stack
Refactor existing applications to improve scalability and maintenance of the data platform
Assist with the preparation and delivery of reportable data on a regular cadence
Maintain APIs that users and other systems use to interact with our data platform, including services for entity matching, aggregation, ingestion, and data access
Collaborate with site reliability engineers to deploy and tune infrastructure that ensures our systems remain performant, scalable, fault-tolerant, and secure
Support processes that match and master data across data sources
Support integration pipelines across internal tools and systems to include Salesforce, PowerBI, and Azure Data Lake
Perform peer reviews for other team members


We Are Looking For

Bachelor’s degree in Computer Science, or equivalent education/experience
2+ years of work experience with ETL, data integrations, or client data solutions
Experience with our main technologies: Python, Redshift, MongoDB and Postgres
Experience with the AWS ecosystem, especially EC2 and S3
Solid foundation in software engineering best practices
Self-motivated and able to work in a fast paced, deadline-oriented environment
Excellent troubleshooting, listening and problem-solving skills
Preferred Qualifications

Experience with Microsoft Azure ecosystem strongly preferred (ex. Azure Blob Storage)
Familiar with .NET and C# development
Bonus points for experience with the rest of our stack: Scala, Redis, Elasticsearch, Docker, Kubernetes, Databricks, Redshift, Airflow
Healthcare data experience a plus
We are not currently engaging with outside agencies on this role.

Ready to Evolve?

We want smart, driven individuals to help us create Quest Analytics future. If you invest yourself in your work, live with enthusiasm, and thrive on results, we want to know you. Bring your entrepreneurial spirit to a company that won’t limit you to a job description. At Quest Analytics, your ideas will be listened to and valued, your unique talents appreciated, and your contribution rewarded. You’ll enjoy a healthy work/life balance with Workplace Flexibility, a generous salary & benefits package, and plenty of room to grow personally and professionally. And you’ll have the opportunity to shape the future of an industry with systemic problems — working with more than 400 healthcare networks and nearly 500,000 providers to help improve access to healthcare in America.

What's In It For You

Great benefits package with:

Competitive salary and success sharing bonus
100% paid HDHP Health plan, Dental, Vision for Employee tier and cost-sharing for all other tiers
Company matching 401(k) and HSA
Generous PTO, Sick time, and 10 Holidays
Paid Life, Short & Long Term Disability
Paid maternity / paternity and much more
Wellness programs
Flexible work arrangements so you can balance work/life
The opportunity to get in on ground floor and grow and learn as the company grows
Work in a fun, flexible, casual environment with monthly Culture Club activities
Workplace Flexibility - choice of working in the office, hybrid, or remote
For those who chose to come into an office, we offer free gourmet coffee to fuel the brainpower necessary to conquer your goals, and free drinks and snacks.

Apply TODAY!

Visa sponsorship is not available at this time.

Quest Analytics provides equal employment opportunities to all people without regard to race, color, religion, sex, national origin, ancestry, marital status, veteran status, age, disability, sexual orientation or gender identity or expression or any other legally protected category.

Applicants must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
Show more Show less"
2816971196,Data Engineer,GlobalLogic,2021-11-30,United States,Dallas-Fort Worth Metroplex,,Full-time,,"Job Description
The Big Data Azure Lead Data Engineer will be responsible for architecting, designing, and implementing cost effective advanced stream data ingestion capabilities.

Qualifications:
BS, MS, in Computer Science, Software Engineering, or a related discipline
8+ years software development experience related to data engineering
Strong coding skills Java and Scala
Hands on experience in ingesting streamed data to azure environment. Should have good knowledge of Confluent Kafka, Kafka Streaming, Spark Streaming.
Experience in big data real-time streaming tools like Kafka Stream or Flink.
Experience working with big data file formats like Parquet, Avro and ORC at a petabyte scale
Experience building data platforms using Azure stack.
Experience building data ingestion pipelines using Azure Data Factory, Event Hub to ingest structured and unstructured data.
Experience in traditional and modern Big Data technologies (HDFS, Hadoop, Hive, Pig, Sqoop, Kafka, Apache Spark, hBase, Oozie, No SQL databases)
Comfortability designing and supporting high traffic, highly available systems with a focus on scalability, reliability, and fault tolerance
Strong knowledge on Azure Storage schematics such as Gen1 and Gen2
Experience in API based architecture.
Experience is leading and helping his team in achieving the goals.
Experience in of all phases of Software Development Lifecycle including design, development, testing, monitoring, and CI/CD
Should have experience in Docker, ZooKeeper, DataDog

Job Responsibilities
BS, MS, in Computer Science, Software Engineering, or a related discipline
8+ years software development experience related to data engineering
Strong coding skills Java and Scala
Hands on experience in ingesting streamed data to azure environment. Should have good knowledge of Confluent Kafka, Kafka Streaming, Spark Streaming.
Experience in big data real-time streaming tools like Kafka Stream or Flink.
Experience working with big data file formats like Parquet, Avro and ORC at a petabyte scale
Experience building data platforms using Azure stack.
Experience building data ingestion pipelines using Azure Data Factory, Event Hub to ingest structured and unstructured data.
Experience in traditional and modern Big Data technologies (HDFS, Hadoop, Hive, Pig, Sqoop, Kafka, Apache Spark, hBase, Oozie, No SQL databases)
Comfortability designing and supporting high traffic, highly available systems with a focus on scalability, reliability, and fault tolerance
Strong knowledge on Azure Storage schematics such as Gen1 and Gen2
Experience in API based architecture.
Experience is leading and helping his team in achieving the goals.
Experience in of all phases of Software Development Lifecycle including design, development, testing, monitoring, and CI/CD
Should have experience in Docker, ZooKeeper, DataDog
Show more Show less"
2791806785,Data Engineer,"Datto, Inc.",2021-12-04,United States,"Boston, MA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","As the world’s leading provider of cloud-based software and technology solutions delivered by managed service providers (MSPs), Datto believes there is no limit to what small and medium businesses can achieve with the right technology. Datto offers Unified Continuity, Networking, and Business Management solutions and has created a one-of-a-kind ecosystem of MSP partners. These partners provide Datto solutions to over one million businesses across the globe. Since its founding in 2007, Datto continues to win awards each year for its rapid growth, product excellence, superior technical support, and for fostering an outstanding workplace. With headquarters in Norwalk, Connecticut, Datto has global offices in the United Kingdom, Netherlands, Denmark, Germany, Canada, Australia, China, and Singapore. Learn more at datto.com.

A Look Inside The Job

Work on a fast paced, cutting edge datawarehouse stack using Snowflake database on AWS and airflow to bring disparate data sets from across the enterprise for rich analytics and machine learning
Design, implement and automate ETL procedures to integrate data from multiple internal and external sources
Identify data quality issues via data profiling, DQ checks and implement proper remediation methods
Collaborate with business and technology stakeholders to ensure successful data warehouse development and utilization
Create detailed technical design documents in accordance with business requirements
Perform quality assurance and regression testing to validate production readiness
Create detailed deployment plans for migration to production environment
Monitor/ensure acceptable levels of system performance, integrity and security

About You

Advanced degree in Engineering, Computer Science or related field
Understanding of Big Data technologies and solutions (Hadoop, Kafka, Hive, S3, Redshift, Snowflake etc.)
2+ years of industry experience in software development, data engineering, business intelligence, or related field with a track record of manipulating, processing, and extracting value from large datasets.
Demonstrated strength in data modeling, ETL development, and data warehousing
Advanced working SQL knowledge and experience working with relational databases, as well as working familiarity with a variety of databases.
Experience with Snowflake database preferred.
Experience with AWS cloud preferred
Must have working experience in one of the following: Spark, Airflow and Python
Some experience with designing and enhancing Tableau reports & data visualizations.
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to engineering teams and business audiences
Excellent oral and written communication skills

At Datto, we believe our employees are our greatest asset and offer all full-time employees a wide-ranging benefits package, including:

Comprehensive health-care benefits
Flexible paid time off policy
Generous paid paternal leave
“Datto University” virtual on-boarding program
Access to more than 5,000 courses via LinkedIn Learning
Education reimbursement
Employee Assistance Program
Headspace App
Charity match program
A dynamic and socially active work culture, including Employee Resource Groups
Networking and career development opportunities
And more!

By submitting an application, you acknowledge we will process your data in order to consider you for the position you apply for and for other open positions within our company for which you may be suited. We collect and store your data in accordance with our Recruiting Privacy Practices .

Datto is an equal opportunity employer.
Show more Show less"
2802895718,Data Engineer,wappier,2021-11-17,United States,"Boston, MA",Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Opportunity Description

Our client is looking for a Data Engineer to join our digital data team in the data

architecture operation and governance team to build and operationalize data

pipelines necessary for the enterprise data and analytics and insights initiatives,

following industry standard practices and tools. The bulk of the work would be in

building, managing, and optimizing data pipelines and then moving them effectively into production for key data and analytics consumers like business/data analysts, data scientists or any persona that needs curated data for data and analytics use cases across the enterprise. In addition, guarantee compliance with data governance and data security requirements while creating, improving, and

operationalizing these integrated and reusable data pipelines.

The data engineer will be the key interface in operationalizing data and analytics on behalf of the business unit(s) and organizational outcomes.

Tech Skills

Knowledge of AWS.
Knowledge of Azure or GCP is a plus
Orchestration: Airflow
Project management & support: JIRA projects & service desk, Confluence, Teams
Expert in ELT and ETL such as Informatica IICS, Databricks, Delta, Glue, ...
Expert in Relational database technologies and concepts:
Perform SQL queries
Create database models
Maintain and improve queries performance
Snowflake is a plus
Working knowledge of Python and familiar with other scripting languages
Good knowledge of cloud computing


Soft Skills

Pragmatic and capable of solving complex issues
Ability to understand business needs
Good communication
Push innovative solutions
Service-oriented, flexible & team player
Self-motivated, take initiative
Attention to detail & technical intuition


Experience

At least 5 years experiences in a data team as Data Engineer
Experience in a healthcare industry is a strong plus


Preferred Qualifications

BS or MS in Computer Science


Requirements

Responsibilities

Must work with business team to understand requirements, and translate them into technical needs
Gather and organize large and complex data assets, perform relevant analysis
Ensure the quality of the data in coordination with Data Analysts and Data Scientists (peer validation)
Propose and implement relevant data models for each business cases
Optimize data models and workflows
Communicate results and findings in a structured way
Partner with Product Owner and Data Analysts to prioritize the pipeline implementation plan
Partner with Data Analysts and Data scientists to design pipelines relevant for business requirements
Leverage existing or create new “standard pipelines” within to bring value through business use cases
Ensure best practices in data manipulation are enforced end-to-end
Actively contribute to Data governance community
Show more Show less"
2816037738,Data Engineer - Telecommute,Optum,2021-12-02,United States,"Eden Prairie, MN",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Combine two of the fastest-growing fields on the planet with a culture of performance, collaboration and opportunity and this is what you get. Leading edge technology in an industry that's improving the lives of millions. Here, innovation isn't about another gadget, it's about making health care data available wherever and whenever people need it, safely and reliably. Join us and start doing your life's best work.(sm)

As a Data Engineer, you will work on ingesting, enriching, and provisioning Optum’s Adobe clickstream data for business reporting, analytics, and data science. You will help develop, maintain, and optimize the data sets, data models, and large-scale data pipelines primarily in the Azure Databricks Spark cloud stack. You will partner with senior team members to drive best practices and set standards for data engineering patterns and optimization. You will be a key influencer in data engineering practices. If you have innovative ideas in data processing or would like to do research in latest new technologies in data engineering, this is role for you.

You’ll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges.

Primary Responsibilities

Build and deploy performance and scalable solutions by applying data engineering concepts and development best practices
Build scalable and end to end Spark pipelines for large-scale healthcare data
Ensure high quality solutions by design and build unit tests, integration test, performance test, and user acceptance tests
Optimize data pipelines to handle growing data volumes
Collaborate on designs for data pipelines and data tooling that meet performance and data quality standards
Build methods and tools to automate development activities
Ability to prioritize tasks and work concurrently on multiple tasks
Participate in business analysis and data discovery to gather data requirements
Ability to build complex but compact well performing SQL queries

You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Required Qualifications

Bachelor's Degree or equivalent work experience in a related field
3+ years of experience in distributed systems, data engineering, software engineering, or similar fields
2+ years of solid coding skills in a language such as Scala, Java, or Python
1+ years of experience with CI/CD development environment
1+ years of experience with Azure Cloud technologies

Preferred Qualifications

Background in the healthcare industry
Experience with DevOps, Continuous Integration, and Continuous Delivery
Experience developing Java RESTful Services using Spring Boot
Experience building and deploying applications to the Microsoft Azure cloud using Infrastructure as Code tools, such as Terraform
Experience working in an Agile environment
Expertise with modern programming languages, systems, and architectures
Develop analysis and design of transactional systems and/or programs

To protect the health and safety of our workforce, patients and communities we serve, UnitedHealth Group and its affiliate companies now require all employees to disclose COVID-19 vaccination status prior to beginning employment. In addition, some roles require full COVID-19 vaccination as an essential job function. UnitedHealth Group adheres to all federal, state and local COVID-19 vaccination regulations as well as all client COVID-19 vaccination requirements and will obtain the necessary information from candidates prior to employment to ensure compliance. Candidates must be able to perform all essential job functions with or without reasonable accommodation. Failure to meet the vaccination requirement may result in rescission of an employment offer or termination of employment.

Technology Careers with Optum. Information and technology have amazing power to transform the health care industry and improve people's lives. This is where it's happening. This is where you'll help solve the problems that have never been solved. We're freeing information so it can be used safely and securely wherever it's needed. We're creating the very best ideas that can most easily be put into action to help our clients improve the quality of care and lower costs for millions. This is where the best and the brightest work together to make positive change a reality. This is the place to do your life's best work.(sm)

All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy.

Colorado, Connecticut or Nevada Residents Only: The salary range for Colorado residents is $79,700 to $142,600. The salary range for Connecticut/Nevada residents is $87,900 to $156,900. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you’ll find a far-reaching choice of benefits and incentives.

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.

Job Keywords: Data Engineer, CI/CD, Scala, Java, Python, DevOps, Restful Services, Spring Boot, Data Engineering, Technology, Optum, Optum Technology, UHG, UnitedHealth Group, Telecommute, Telecommuter, Telecommuting, Work at Home, Work from Home, Remote
Show more Show less"
2576453170,Data Engineer,Photon,2021-08-16,United States,"Irving, TX",Information Technology,Full-time,IT Services and IT Consulting,"The ideal candidate will be responsible for developing high-quality applications. They will also be responsible for designing and implementing testable and scalable code. 

 

Responsibilities
Develop quality software and web applications
Analyze and maintain existing software applications
Design highly scalable, testable code
Discover and fix programming bugs




Qualifications

Bachelor's degree or equivalent experience in Computer Science or related field
Development experience with programming languages
SQL database or relational database skills

Show more Show less"
2766700093,Data Engineer,StockX,2021-09-30,United States,"Seattle, WA",Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","Help shape the next generation of ecommerce for the next generation of consumer.

Technology @ StockX

Our Technology Team is on a mission to build the next generation e-commerce platform for the next generation customer. We build world-class, innovative experiences and products that give our users access to the world’s most-coveted products and unlock economic opportunity by turning reselling into a business for anyone. Our team uses cutting edge technologies that handle substantial scale globally. We’re an internet-native, cloud-native company from day 1 - you won’t find legacy technology here. If you’re a curious leader who loves solving problems, wearing multiple hats, and learning new things, join us!

About The Role

As a Data Engineer, you will be empowered to use data to drive amazing customer experiences and business results. You will be responsible for the end to end development of data engineering solutions to support analytical needs of the business. The ideal candidate will be passionate about working with disparate datasets and be someone who loves to bring data together to answer business questions at speed. You should have deep expertise in the creation and management of datasets and a consistent record of translating data into meaningful insights through collaboration with analysts, data scientists and business partners.

What You'll Do

Design and build mission critical data pipelines with a highly scalable distributed systems architecture - including data ingestion (streaming, events and batch), data integration, data curation
Help continually improve ongoing reporting and analysis processes, simplifying self-service support for business partners
Automation of end to end data pipeline with metadata, data quality checks and audits
Optimize data pipelines to support BI and ML use cases
Support critical applications and near real time data needs from the data platform
Gather and publish metadata and new data to subscribed users
Work collaboratively with business analysts, product managers, data scientists as well as business partners, and actively participate in design thinking sessions
Participate in design and code reviews

About You

Minimum of 3 years of experience in data engineering, software development, business intelligence, data science, or a related field with a proven track record of manipulating, processing, and extracting value from large datasets
1+ years of experience in using programming languages (Python / Scala / Java / C#) to build data pipelines
1+ years of experience building with AWS or other cloud environments
Strong familiarity with batch processing and workflow tools such as AirFlow or NiFi
Strong business attitude with customer obsession; ability to collaborate with business partners to identify needs and opportunities for improved data management and delivery
Bachelor's degree in Computer Science, or a related technical field

Nice To Have

Masters in Computer Science or related quantitative field
Experience with data visualization tools such as Tableau, Looker, or PowerBI

About Us

Our global platform offers unprecedented access to current culture while our data-driven, bid-ask model provides buyers with the real-time visibility to know they’re getting a fair price. And, unlike other ecommerce sites, StockX hand-checks every purchase (20,000+ daily trades) at one of our regional authentication centers.

StockX’s special formula has rocketed the company to a multibillion dollar valuation, with 10M+ lifetime trades on the platform—more than half of those coming in the last year. And we’re just getting started.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. This job description is intended to convey information essential to understanding the scope of the job and the general nature and level of work performed by job holders within this job. However, this job description is not intended to be an exhaustive list of qualifications, skills, efforts, duties, responsibilities or working conditions associated with the position. StockX reserves the right to amend this job description at any time.
Show more Show less"
2806113255,Data Engineer,Harmer,2021-11-23,United States,"Chicago, IL ",,Full-time,,"Summary:

Our client is seeking a software engineer with a passion for data and the financial services business. The engineer will be part of the Data Systems Team which is responsible for the management, curation, and growth of the firm’s mission-critical data. This individual should bring best practice techniques and be interested in turning our data and data platform into a competitive advantage.

The Our client Data Team is currently working to move all data management to a cloud environment and is looking for a very talented and highly motivated individual to join our team. This individual will have the opportunity to learn data management in the cloud from the ground up and be a key enabler of our future.

The Data Systems Developer is responsible for the full life cycle of software development activities including working with the business, requirements gathering, design, software development, testing, documentation, and production support.

As a member of the Data Services Team, this individual will need to perform additional team related duties including actively participating in team discussions and meetings, mentoring of other team members, and performing occasional on-call rotation based production support.

Primary Responsibilities:

1. Responsible for all aspects of software development following the Agile methodology using the Scrum framework. Be part of self-managing and self-organizing team collaborating and producing shippable code and changes iteratively.

2. Deliver software products with minimal defects.

3. Deliver software projects that adhere to both team and firm software standards.

4. Partner with the business to deliver best-in-class data solutions.

5. Participate in the team on-call rotation to a. Ensure all critical overnight data delivery SLA(s) are met.

b. Perform daily review and actions for any non-critical overnight failures, data exceptions, or other business user inquiries.

6. Active participation in team meetings and discussions.

 

Minimum Qualifications:

1. Bachelor’s degree required in Computer Science or other related field.

2. At least 3 years of experience managing data and coding in Azure or AWS including data lake usage.

3. At least 3 years of full life cycle software development experience.

4. At least 3 years of experience in software development projects using .NET, Python, and/or MS SQL.

5. Experience implementing or using automated QA tools as part of the software development process.

6. Must have excellent technical and analytical skills.

7. Must have strong communication skills.

8. Must have a passion for new technologies and frameworks including Cloud and Agile Scrum.

9. Experience interfacing with business partners.

10. Track record of demonstrating leadership potential.

11. Knowledge of market data and financial data structures a plus. 

Show more Show less"
2817187602,"EST Data Engineer - SQL, Python, AWS, HIPPA",Motion Recruitment,2021-12-03,United States,"Los Angeles, CA",Information Technology,Full-time,Staffing and Recruiting,"Job Description

This multichannel partnership marketing company that provides partners with a strategic approach to building loyalty and acquiring new customers is looking for a Data Engineer. For over 25 years, they have connected thousands of partners with highly engaged consumers through a suite of continuity programs including their connections to over 250 publishers and 700+ titles, and owned and operated online programs ""4 Your Health"" and ""Stop, Breathe & Think"".

With their innovative marketing strategies, they are enhancing the operations of companies from a wide variety of industries including, retail, airline, and hospitality.

Required Skills & Experience

5+ years
SQL
Python
AWS data technologies (such as Redshift, Lambda, Step Functions, EMR, Athena, Glue, Airflow, Data Pipeline, etc.)
BI experience (Tableau, MicroStrategy)
BS in Computer Science
The Offer

Competitive Salary: Up to $130k/yr DOE

You Will Receive The Following Benefits

Medical Insurance & Health Savings Account (HSA)
Pre-tax Commuter Benefit
401k Matching

Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.

Posted By: Sophia Gutteridge
Show more Show less"
2785704947,Data Engineer,Equifax,2021-10-10,United States,"St Louis, MO",Analyst,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","



Job Summary 





 



Equifax is seeking a Data Engineer who can prepare data for analytical use by building data pipeline to gather data from multiple sources and systems, integrating, consolidating and cleansing data, and structuring



 





Who is Equifax? 





 



At Equifax, we believe knowledge drives progress. As a global data, analytics and technology company, we play an essential role in the global economy by helping employers, employees, financial institutions and government agencies make critical decisions with greater confidence. 

We work to help create seamless and positive experiences during life’s pivotal moments: applying for jobs or a mortgage, financing an education or buying a car. Our impact is real and to accomplish our goals we focus on nurturing our people for career advancement and their learning and development, supporting our next generation of leaders, maintaining an inclusive and diverse work environment, and regularly engaging and recognizing our employees. Regardless of location or role, the individual and collective work of our employees makes a difference and we are looking for talented team players to join us as we help people live their financial best.

 



The Perks of being an Equifax Employee?



We offer excellent compensation packages with market competitive pay, comprehensive healthcare packages, 401k matching, schedule flexibility, work from home opportunities, paid time off, and organizational growth potential.

Grow at your own pace through online courses at Learning @ Equifax.



 





What you’ll Do





 



Create and maintain data pipelines using the Google Cloud Platform using the following tools: Google Dataflow, PubSub, BigQuery and Cloud Storage (or their equivalent in other platforms such as AWS, Azure or Hadoop). 

Work with data scientists in building and optimizing our AI solutions for greater functionality in our data systems

Build analytics tools that utilize the data pipeline to provide actionable insights into operational efficienciesIdentify, design and implement process improvements: optimize data delivery and automate manual processes

Maintain data integrity and regionalization by defining boundaries through multiple GCP zones 





Qualifications: 



Bachelor’s Degree in Computer Science, Statistics, Mathematics or another quantitative field 

2+ years Experience with REST APIs, programming language with Java or Python or Scala or Go 

2 + years of experience with relational SQL and NoSQL databases 

2+ years of experience with big data tools: Google Dataflow or Google DataPrep or Hadoop



 





Extra Points for any of the following 





 



Hands on experience in Cloud technologies and Google Data Cloud tools, BigTable and BigQuery

Strong analytical skills and attention to detail and accuracy

Work experience in regulatory and data compliant environments and Credit Industry Domain knowledge is preferred



 





 



We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

If this sounds like somewhere you want to work, don’t delay, apply today - we’re looking for you!



 



 


Primary Location:


USA-St. Louis-2330 Ball


Function:


Function - Data and Analytics


Schedule:


Full time
Show more Show less"
2819535781,Data Engineer - Marketing,Stitch Fix,2021-12-04,United States,"San Francisco, CA","Research, Analyst, and Information Technology",Full-time,"Apparel and Fashion, Internet Publishing, and Retail","About The Team

The data engineering team is a small, nimble group of data engineers that drive the company toward clean and informative data. As a member of the data engineering team, you’ll contribute toward a clear, concise data model to help power data science, ETLs and tools to make us efficient, as well as self-service data and tools to facilitate scalable decision-making. As a team, we are driven by the thrill of helping our colleagues use data with less friction, which ultimately increases the velocity at which the business can progress!

About The Role

Individual contributor position on the data engineering team, within our Algorithms organization, working with a team that focuses on our Marketing data infrastructure
You will build and own large additions to our data engineering framework, contributing to a code framework that centralizes ETL logic and definitions
You will help to define, build and maintain a clear, concise data model, especially focused on scalable analytics infrastructure
You will build scalable data engineering solutions & frameworks to solve business and data problems
You will be involved in the day-to-day operations of the team, including maintaining and improving our current tools & scripts and supporting data that powers our business
You will have autonomy to help shape the future of data engineering at Stitch Fix by bringing your ideas on improving and automating what we do and how we do it

You’re Excited About This Opportunity Because You Will...

You will work with a variety of cross functional partners from marketing analysts and data scientists as well as our third party vendors to deliver up-to-date metrics on our Marketing organization
You will focus on our marketing data infrastructure, optimization, and scalability
Be part of a fast-growing team which has high visibility across the organization
Contribute ideas and direct the team’s investment to impactful directions
Contribute to a culture of technical collaboration and scalable development

We Get Excited About Candidates Who Have…

3+ years of independent and significant project experience
Experience in building out data models and data engineering capabilities
Experience coding and designing extensible and reusable Python and SQL
Experience in working autonomously and taking ownership of projects.
Ability to think globally, devising and building solutions to meet many needs rather than completing individual projects or tasks
Strong prioritization skills with business impact in mind
Familiarity with using Spark to access an S3 data warehouse
Strong cross functional communication skills that help simplify and move complex problems forward with business partners

YOU’LL LOVE WORKING AT STITCH FIX BECAUSE…

We are a group of bright, kind and goal oriented people. You can be your authentic self here, and are empowered to encourage others to do the same!
We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation
We are a technologically and data-driven business
We are committed to our clients and connected through our vision of “Transforming the way people find what they love”
We love solving problems, thinking creatively and trying new things
We believe in autonomy & taking initiative
We are challenged, developed and have meaningful impact
We take what we do seriously. We don’t take ourselves seriously
We have a smart, experienced leadership team that wants to do it right and is open to new ideas
We offer competitive compensation packages and comprehensive health benefits
You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day

About Stitch Fix

At Stitch Fix, we’re about personal styling for everybody, and we believe in both a service and a workplace where you can be your best, most authentic self. We’re the first fashion retailer to combine technology and data science with the human instinct of a Stylist to deliver a deeply personalized shopping experience. This novel juxtaposition attracts a highly diverse group of talented people who are both thinkers and doers. All of this results in a simple, powerful offering to our customers and a successful, growing business serving millions of men, women, and kids. We believe we are only scratching the surface on our opportunity, and we’re looking for incredible people like you to help us carry on that trend.
Show more Show less"
2818441466,Data Engineer,IBM,2021-12-01,United States,"Baton Rouge, LA",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

The position of the Data Engineer plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. The Data Engineer defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business. Develops Big Data and Cognitive technologies including API development. Expected to have experience with ETL tools & Data warehouses. Strong technical abilities to understand, design, write and debug complex code.

Required Technical and Professional Expertise


Minimum 4 years of hands-on coding experience in Java
Minimum 3 years of hands-on coding experience in SCALA
Minimum 3 years of hands-on experience working with Kafka
Minimum 3 years of experience in Big Data technologies (Hadoop, Spark, PySpark)
Minimum 3 years of hands-on experience with Spring Boot, Spring Cloud & Microservices
Minimum 3 years of experience using SQL and good RDBMS conceptual knowledge
Minimum 3 years of experience with ETL tools
Minimum 3 years of experience with Snowflake or Redshift or Other Datawarehouse
Experience with ADO or Jenkins for CI/CD


Preferred Technical And Professional Expertise


Experience in Kubernetes and Docker
Experience coding in Python
Big Data Certifications on Cloudera/Hortonworks/AWS/GCP/Azure
Certification on Snowflake Pro
Experience in Azure, AWS, GWP, IBM cloud etc
Experience with DBT


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Kyndryl offers a wide range of resources for eligible employees to thrive both inside and outside of work. In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to:


12 weeks of paid parental bonding leave.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money.
Discounts on retail products, services, and experiences. We consider qualified applicants with criminal histories, consistent with applicable law. Kyndryl will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.


Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2789631020,Data Engineer,Zoom,2021-12-03,United States,"Texas, United States",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2813961637,Cloud Data Engineer,Morgan Stanley,2021-11-15,United States,"Alpharetta, GA","Project Management, Analyst, and Engineering",Full-time,"Financial Services, Investment Banking, and Investment Management","Title: Cloud Data Engineer

About Us

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. We advise, originate, trade, manage and distribute capital for governments, institutions and individuals. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. The Technology division partners with our business units and leading technology companies to redefine how we do business in ever more global and dynamic financial markets.

Our sizeable investment in technology results in leading-edge tools, software, and systems. Our insights, applications, and infrastructure give a competitive edge to clients? businesses?and to our own.

Enterprise Technology & Services (ETS) delivers shared technology services for the Firm supporting all business applications and end users. ETS provides capabilities for all stages of the Firm?s software development lifecycle, enabling productive coding, functional and integration testing, application releases, and ongoing monitoring and support for over 3,000 production applications.

ETS also delivers all workplace technologies (desktop, mobile, voice, video, productivity, intranet/internet) in integrated configurations that boost the personal productivity of our employees. Application and end user services are delivered on a scalable, secure, and reliable infrastructure composed of seamlessly integrated datacenter, network, compute, cloud, storage, and database services.

Organizational Description

The Data Engineering & Analytics group in the Core Infrastructure at Morgan Stanley provides technologies and platform required to model, provision, transform, analyze, report, visualize, store and protect enterprise data on-prem and in public cloud. The team is responsible for the delivery and operation of these products

Job Description

We are seeking skilled, enthusiastic, and experienced engineers to join our team responsible for delivery and operation of big data, caching and messaging products like MongoDB, Kafka, Azure Databricks, Redis, Snowflake and others. This role also demands integrating internal systems with Public Cloud with heavy focus on automation and DevOps. Other responsibilities include troubleshooting and helping development team with best practices and on-boarding, monitoring, optimizing, and tuning. After a period of onboarding and training, new team members will take ownership of these products, working with global counterparts and customers to prioritize and execute on enhancements, extensions, and remediation of critical components of our infrastructure.

You have a strong understanding of Distributed Systems, Infrastructure and Automation. You have experience working to automate, deploy and manage applications with analytics and continuous deployment tools/process. You apply best coding practices and automation to build more efficient and ever-increasing quality products.

Experience- 8+ years

Required Skills

5+ years of experience in data engineering with an emphasis on automation, performance, query optimization and troubleshooting
Hands on 3+ years of experience using Java/Python/Scala & Linux is a must
2+ years of experience designing and building solutions utilizing various Cloud services, big data, and messaging products such as Azure, Azure SQL, Databricks/Spark, MongoDB, Kafka
Good knowledge of network and security protocols like TCP/IP, HTTP(s), TLS, DNS, OIDC/oAUTH, Proxies & Load balancers.
Experience working with Docker & Kubernetes
Strong fundamentals in distributed system design, development and deployment using agile/devops practices
Experience with Agile development methodology and CI/CD
Experience with tools such as GIT, Jira and Bitbucket
A self-starter with the ability to work effectively in teams
Good communication skills and excellent teamwork experience


Qualifications
Desired Skills

Deep knowledge of JVM internals
Knowledge of Ansible/Terraform
Experience with system performance
Contributor/Committer to open source projects

Posting Date

Nov 15, 2021

Primary Location

Americas-United States of America-Georgia-Alpharetta

Education Level

Bachelor's Degree

Job

Engineering

Employment Type

Full Time

Job Level

Associate
Show more Show less"
2418275827,Data Engineer,Stripe,2021-11-14,United States,"Seattle, WA",Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","Stripe is the best software platform for running an internet business. We handle billions of dollars every year for hundreds of thousands of businesses around the world. One third of Americans bought something on Stripe in the last year.

With all this data, the Data Science team is looking for talented engineers to help us manage business critical data leveraged across the entire organization. If you are data curious, excited about designing data pipelines, and motivated by having impact on the business, we want to hear from you.

Every record in our data warehouse is vitally important for the businesses that use Stripe, so we’re looking for people with a strong background in data engineering and analytics to help us scale while maintaining correct and complete data. You’ll be working with a variety of internal teams across Engineering and Business to help them solve their data needs. Your work will provide teams with visibility into how Stripe’s products are being used and how we can better serve our customers.

You Will

Identify data needs for business and product teams, understand their specific requirements for metrics and analysis, and build efficient and scalable data pipelines to enable data-driven decisions across Stripe
Design, develop, and own data pipelines and models that power internal analytics for product and business teams
Help the Data Science team apply and generalize statistical and econometric models on large datasets
Drive the collection of new data and the refinement of existing data sources, develop relationships with production engineering teams to manage our data structures as the Stripe product evolves
Develop strong subject matter expertise and manage the SLAs for those data pipelines

We’re Looking For Someone Who Has

3+ Years of experience in a Data Engineering or Data Science role, with a focus on building data pipelines or conducting data intensive analysis.
A strong engineering background and are interested in data
Prior experience with writing and debugging data pipelines using a distributed data framework (Hadoop/Spark/Pig etc…)
An inquisitive nature in diving into data inconsistencies to pinpoint issues
Knowledge of a scientific computing language (such as R or Python) and SQL
The ability to communicate cross-functionally, derive requirements and architect shared datasets

Some Things You Might Work On

Develop unified user data schemas and tables that provide a complete view of the business across our various products such as Stripe Connect, Atlas, or Sigma
Build data pipelines that track our marketing funnel from visits to onboarding to active usage of Stripe
Work on our centralized experimentation platform to pipeline experiment metrics and compute descriptive statistics
Improve our data visualization tooling and platform at Stripe to help the team create dynamic tools and reporting
Our stack spans tools in Scala, Python, R, Javascript, React, SQL

You Should Include These In Your Application

Resume
LinkedIn profile

Show more Show less"
2824868137,Data Engineer,CVS Health,2021-12-02,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Financial Services, and Hospitals and Health Care","Job Description

Looking for opportunities to use cutting edge technologies to construct data pipelines to analyze petabytes of data? Interested in working with data scientists to generate analytical insights that help members make the best decisions for the individual care needs?

As a Data Engineer you will work with our data scientists’ side by side to optimize our ability to engage with members to help them make better healthcare decisions via campaigns. A common campaign for us would include several predictive models that identify specific members to message at specific moments, a suite of creative tactics with varying behavioral economics principles to deliver content, and the use of a large number of channels and apps in a highly coordinated and journey-based fashion - all deployed by our own team through the experimentation platform that we’ve developed.

By joining our organization, you’ll learn about cutting edge machine learning techniques, develop the experiment platform to expand the ability to engage, and launch campaigns at large scale and high velocity.

Some of the responsibilities you will have as a Data Engineer include:

Participating in the design, build and management of large-scale data ETL (Extract / Transform / Load) workflows for real-time and offline analytic processing.
Integrating data from a variety of sources, assuring that they adhere to data quality and accessibility standards.
Collaborating with data scientists to integrate algorithms and models into automated processes.
Designing and implementing scalable, configurable and self-learning marketing campaign platforms.
Applying expertise, judgment and precedents to contribute to the resolution of moderately complex problems.
Leading portions of initiatives of limited scope, with guidance and direction


Required Qualifications


2+ years of relevant Data Engineering experience.
Applied experience with Python, Java, Scala, or C++.
Experience with Shell Scripts.
Applied experience with SQL and experience in one of the relational databases.
Good software engineering fundamental.
Strong problem-solving skills and critical thinking ability.
Strong collaboration and communication skills within and across teams.


COVID Requirements

COVID-19 Vaccination Requirement

CVS Health requires its Colleagues in certain positions to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, pregnancy, or religious belief that prevents them from being vaccinated.

If you are vaccinated, you are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status within the first 30 days of your employment. For the two COVID-19 shot regimen, you will be required to provide proof of your second COVID-19 shot within the first 60 days of your employment. Failure to provide timely proof of your COVID-19 vaccination status will result in the termination of your employment with CVS Health.
If you are unable to be fully vaccinated due to disability, medical condition, pregnancy, or religious belief, you will be required to apply for a reasonable accommodation within the first 30 days of your employment in order to remain employed with CVS Health. As a part of this process, you will be required to provide information or documentation about the reason you cannot be vaccinated. If your request for an accommodation is not approved, then your employment may be terminated.


Preferred Qualifications


Experience with Spark, Hadoop and or Hive.
Experience within the Healthcare Industry.
Development Experience within Cloud (GCP, AWS and or Azure).

Education

Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline

Master’s degree or PhD preferred

Business Overview

At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.
Show more Show less"
2686690030,Data Engineer,Copart,2021-11-15,United States,"Dallas, TX",Information Technology,Full-time,"IT Services and IT Consulting, Motor Vehicle Manufacturing, and Financial Services","The Data Engineer will be part of the Data Services Team. The Data Services team works very closely with all aspects of applications and data pipelines. We are looking for a Data Engineer to design, develop, and optimize the flow of data throughout the organization, enabling end-user to provide valuable insights of data across Copart. In this role, your work will broadly influence the company's data consumers, executives and analysts.




Key Responsibilities

Design and build the next generation data platform
Develop and automate data processing systems to deliver data insights at an enterprise scale.
Develop logging, metrics, and alerts that enable active monitoring of designed processes.
Collaborate with Product Managers and Application teams to develop data models and schemas that help provide easy access to complex data sets.
Assist in maintaining data integrity in production systems
Ability to balance and prioritize multiple conflicting requirements with high attention to detail.




Qualifications Requirements

Bachelor's degree or higher in computer science, engineering or similar
3+ years of experience designing, developing, testing, and implementing scalable, high-performing data warehouse and BI solutions
Good hands-on Experience on real-time data pipelines including Kinesis and Kafka, understanding of Database architecture including MPP and ad-hoc analysis using BI/Analytical tools like Tableau, Pentaho, OBIEE, or Power BI
Proven ability to analyze complex business problems using data and translate them into actionable insights stemming from data analysis
Experience with ETL and Data Blending and Transformation tools such as Pentaho Data Integrator, Talend Data Integration, Informatica
Experience with dbt , Airflow or Dagster, Snowflake highly desired.
Enterprise development knowledge and/or experience with databases such as SQL Server, Oracle, MySQL, and Columnar databases like Vertica, MemSQL, Netezza, Redshift
Good understanding of technology and industry and able to make decisions on the best technology for integrated solutions
Proven ability to communicate with business and technical audiences at all levels, including demonstrated success influencing senior leaders and decision-makers

Technical Skill Required: SQL, Python. BI/Analytical Tool Preferred: Tableau, Pentaho, PowerBI




For nearly four decades, Copart has led its industry in innovation and customer service, enabling it to grow profitably in markets across the globe. Our success is the direct result of the skills and efforts of our talented and diverse employees. Our mindset? It's never just a ""job"" when your coworkers are like family--it's like coming home.




Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled

Show more Show less"
2813964430,Cloud Data Engineer,Morgan Stanley,2021-11-11,United States,"Alpharetta, GA","Project Management, Analyst, and Engineering",Full-time,"Financial Services, Investment Banking, and Investment Management","Title: Cloud Data Engineer

About Us

Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. We advise, originate, trade, manage and distribute capital for governments, institutions and individuals. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow.

Technology/Role/Department at Morgan Stanley

Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. The Technology division partners with our business units and leading technology companies to redefine how we do business in ever more global and dynamic financial markets.

Our sizeable investment in technology results in leading-edge tools, software, and systems. Our insights, applications, and infrastructure give a competitive edge to clients businesses and to our own.

Enterprise Technology & Services (ETS) delivers shared technology services for the Firm supporting all business applications and end users. ETS provides capabilities for all stages of the Firm?s software development lifecycle, enabling productive coding, functional and integration testing, application releases, and ongoing monitoring and support for over 3,000 production applications.

ETS also delivers all workplace technologies (desktop, mobile, voice, video, productivity, intranet/internet) in integrated configurations that boost the personal productivity of our employees. Application and end user services are delivered on a scalable, secure, and reliable infrastructure composed of seamlessly integrated datacenter, network, compute, cloud, storage, and database services.

Organizational Description

The Data Engineering & Analytics group in the Core Infrastructure at Morgan Stanley provides technologies and platform required to model, provision, transform, analyze, report, visualize, store and protect enterprise data on-prem and in public cloud. The team is responsible for the delivery and operation of these products

Job Description

We are seeking skilled, enthusiastic, and experienced engineers to join our team responsible for delivery and operation of big data, caching and messaging products like MongoDB, Kafka, Azure Databricks, Redis, Snowflake and others. This role also demands integrating internal systems with Public Cloud with heavy focus on automation and DevOps. Other responsibilities include troubleshooting and helping development team with best practices and on-boarding, monitoring, optimizing, and tuning. After a period of onboarding and training, new team members will take ownership of these products, working with global counterparts and customers to prioritize and execute on enhancements, extensions, and remediation of critical components of our infrastructure.

You have a strong understanding of Distributed Systems, Infrastructure and Automation. You have experience working to automate, deploy and manage applications with analytics and continuous deployment tools/process. You apply best coding practices and automation to build more efficient and ever-increasing quality products.

Experience- 8+ years

Required Skills

5+ years of experience in data engineering with an emphasis on automation, performance, query optimization and troubleshooting
Hands on 3+ years of experience using Java/Python/Scala & Linux is a must
2+ years of experience designing and building solutions utilizing various Cloud services, big data, and messaging products such as Azure, Azure SQL, Databricks/Spark, MongoDB, Kafka
Good knowledge of network and security protocols like TCP/IP, HTTP(s), TLS, DNS, OIDC/oAUTH, Proxies & Load balancers.
Experience working with Docker & Kubernetes
Strong fundamentals in distributed system design, development and deployment using agile/devops practices
Experience with Agile development methodology and CI/CD
Experience with tools such as GIT, Jira and Bitbucket
A self-starter with the ability to work effectively in teams
Good communication skills and excellent teamwork experience


Qualifications
Desired Skills

Deep knowledge of JVM internals
Knowledge of Ansible/Terraform
Experience with system performance
Contributor/Committer to open source projects

Posting Date

Nov 11, 2021

Primary Location

Americas-United States of America-Georgia-Alpharetta

Education Level

Bachelor's Degree

Job

Engineering

Employment Type

Full Time

Job Level

Associate
Show more Show less"
2802793886,Data Engineer,Cedars-Sinai,2021-10-28,United States,"Los Angeles, CA",Information Technology,Full-time,"IT Services and IT Consulting, Research Services, and Hospitals and Health Care","Grow your career at Cedars-Sinai!

The Enterprise Information Services (EIS) team at Cedars-Sinai understands that true clinical transformation and the optimization of a clinical information systems implementation is fueled through the alignment of people, processes, and technologies.

Why work here?

Beyond an outstanding benefit package, we take pride in hiring the best, most committed employees. Our staff reflects the culturally and ethnically diverse community we serve. They are proof of our dedication to creating a multifaceted, inclusive environment that fuels innovation and the standard of patient care we strive for.

What Will You Be Doing In This Role

The Senior Data Engineer is responsible for application development supporting business objectives while guiding in all phases of the software development lifecycle: conception, design, testing, production, and maintenance. Analyses, designs, and builds applications using standard application design patterns and detailed approaches to application integration. Works on new and existing applications. Performs hands-on development, mentors junior developers, and assists in architecting solutions. Serves as liaison to internal customers, research groups and various business support areas.

Works with inter-departmental teams to analyze and understand business requirements. Provides technical expertise during the requirements gathering phase of a project. Accurately details new requirements, improvements to existing functionality, and implementation deficiencies that need to be addressed.
Develops functionality by following internal development standards. Technical solution to include detailed design documentation, code, configuration, and other supporting technical documents.
Facilitates design and technical meetings. Provides technical documentation to internal business and design teams.

#Jobs-Indeed
Show more Show less"
2792943682,Data Engineer,Meridian Technology Group,2021-11-14,United States,United States,"Information Technology, Engineering, and Education",Full-time,"IT Services and IT Consulting, Computer Software, and E-Learning Providers","Summary:




Leveraging ML, one of our new platforms is specifically designed to help elementary and middle school aged children learn at a rapid, iterative pace.




We seek a full-time Data Engineer to work remote from anywhere in the US to help us scale. This person will be helping us develop high-performance, high throughput services using modern technologies and techniques. Data Engineers, or Software Engineers who enjoy working with data are both encouraged to apply.




What you’ll be doing:




Design, develop, test, implement, document, and support Data & Analytics systems that adhere to software engineering best practices
Ensure testing and validation mechanisms are in place so that data transformations are verified, complete, documented, and meet SLAs




What we’re looking for / keys to success




3-15+ years of data engineering and/or software engineering
Experience designing and building scalable systems
Excellent SQL skills
Fluent in at least one general-purpose programming language, preferably Python




Preferred Qualifications:




Familiarity with DevOps, AWS, GCP or Azure
Experience with data mining, DBT, Snowflake or ML pipelines




We provide




90% - 100% of health and welfare benefit premiums
401(k) with employer match
26 paid days off year 1
Inclusive and supportive company culture
Opportunities for professional growth through professional learning and development programs
100% remote work environment

Show more Show less"
2819053022,Data Engineer,Austin Fraser,2021-11-29,United States,United States ,Information Technology,Full-time,Staffing and Recruiting,"Austin Fraser has partnered with an exciting established tech company. They run a global platform for investment analytics and startup analysis. They help maintain the API's for a front-end application that's been running for a few years now. They are in search of a strong Data Engineer to add to their existing team.







What you'll do:

Work on an existing data platform and infrastructure
Integrate with external systems and vendors
Data Ingestion, Cleansing & Mastering




What you'll need:

3-4+ Years of Data Engineering Experience
SQL
Python//Node
Kafka
AWS
Docker
API's




The fun stuff!:

Attractive Bonus & equity package
Unparalleled company culture







This role is remote with NO relocation required




No sponsorship available

Show more Show less"
2808114840,Data Engineer,Deckers Brands,2021-11-25,United States,"Colorado Springs, CO",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2824862878,Data Engineer,CVS Health,2021-12-02,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Financial Services, and Hospitals and Health Care","Job Description

Looking for opportunities to use cutting edge technologies to construct data pipelines to analyze petabytes of data? Interested in working with data scientists to generate analytical insights that help members make the best decisions for the individual care needs?

As a Data Engineer you will work with our data scientists’ side by side to optimize our ability to engage with members to help them make better healthcare decisions via campaigns. A common campaign for us would include several predictive models that identify specific members to message at specific moments, a suite of creative tactics with varying behavioral economics principles to deliver content, and the use of a large number of channels and apps in a highly coordinated and journey-based fashion - all deployed by our own team through the experimentation platform that we’ve developed.

By joining our organization, you’ll learn about cutting edge machine learning techniques, develop the experiment platform to expand the ability to engage, and launch campaigns at large scale and high velocity.

Some of the responsibilities you will have as a Data Engineer include:

Participating in the design, build and management of large-scale data ETL (Extract / Transform / Load) workflows for real-time and offline analytic processing.
Integrating data from a variety of sources, assuring that they adhere to data quality and accessibility standards.
Collaborating with data scientists to integrate algorithms and models into automated processes.
Designing and implementing scalable, configurable and self-learning marketing campaign platforms.
Applying expertise, judgment and precedents to contribute to the resolution of moderately complex problems.
Leading portions of initiatives of limited scope, with guidance and direction.


Required Qualifications


2+ years of relevant Data Engineering experience.
Applied experience with Python, Java, Scala, or C++.
Experience with Shell Scripts.
Applied experience with SQL and experience in one of the relational databases.
Good software engineering fundamental.
Strong problem-solving skills and critical thinking ability.
Strong collaboration and communication skills within and across teams.


COVID Requirements

COVID-19 Vaccination Requirement

CVS Health requires its Colleagues in certain positions to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, pregnancy, or religious belief that prevents them from being vaccinated.

If you are vaccinated, you are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status within the first 30 days of your employment. For the two COVID-19 shot regimen, you will be required to provide proof of your second COVID-19 shot within the first 60 days of your employment. Failure to provide timely proof of your COVID-19 vaccination status will result in the termination of your employment with CVS Health.
If you are unable to be fully vaccinated due to disability, medical condition, pregnancy, or religious belief, you will be required to apply for a reasonable accommodation within the first 30 days of your employment in order to remain employed with CVS Health. As a part of this process, you will be required to provide information or documentation about the reason you cannot be vaccinated. If your request for an accommodation is not approved, then your employment may be terminated.


Preferred Qualifications


Experience with Spark, Hadoop and or Hive.
Experience within the Healthcare Industry.
Development Experience within Cloud (GCP, AWS and or Azure).

Education

Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline.

Master’s degree or PhD preferred.

Business Overview

At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.
Show more Show less"
2825047213,Data Engineer (Remote),XSELL Technologies,2021-12-02,United States,United States,Information Technology,Full-time,Computer Software,"About XSELL

Ready to write the best chapter of your career? XSELL Technologies leverages artificial intelligence as a foundational capability to listen, learn and support agents in real-time with the exact information they need to exceed customers’ expectations and deliver top performer experiences.

Join us on our mission to empower agents, clients, and organizations to increase human performance and job satisfaction through making conversations more personal. We do this by pairing together the best elements of human touch and machine intelligence to drive results.

XSELL is currently seeking a Senior Data Engineer. As a member of our XSELL Data team, we look first and foremost for people who are passionate around solving data-related business problems through innovation and engineering practices. We’re currently seeking a Senior Data Engineer to be a key member of our team. We’re looking for someone with experience designing, implementing, and deploying a data science and analytics platform in a hybrid cloud environment. This role will work within the Agile framework of continuous delivery. A successful team member will not only possess the technical skills required to bring innovative solutions to complex problems, but they will also use their passion to work collaboratively and participate in nurturing the growth of fellow developers.

Ways You’ll Contribute

Design, build, and maintain the data collection and storage infrastructure that supports business analytics and data science.
Manage the flow of analytics data through our systems, ensuring that it is reliable and performant.
Evaluate alternatives and make recommendations for evolving cloud-based data architecture.
Develop infrastructure as code solutions (Terraform) for managing cloud resources.
Develop standardized tooling to support ELT development using Python, Snowflake, Kafka, and FiveTran.
Providing a self-service experience wherever possible for data consumers. Guiding customers where necessary, and coming up with improved solutions when new needs arise.

What You’ll Bring

5+ years of experience as an Engineer, with a combination of software engineering and data engineering
2- 3+ years of experience monitoring workflows including ETLs, responding to issues and improving performance and reliability.
Strong experience managing and processing data in relational databases, including using SQL to extract reports.
Bring cutting-edge industry practices into our organization; convince stakeholders and peers of the value; implement these practices and measure impact.
Advanced proficiency in Python (data structures, algorithms, object-oriented programming, using APIs)
Experience administering a cloud data warehouse, highly desired experience with Snowflake.
Advanced proficiency in Airflow -- building DAGs, developing custom operators, and leveraging plugins.
Experience with schema design and dimensional data modeling
Knowledge of software engineering best practices, coding standards, GitHub, automated testing and deployment
Experience with deploying and maintaining cloud infrastructure using Terraform or similar framework.
Experience supporting production systems and developing on-call/incident management playbooks.
Knowledge of and experience implementing data security and governance best practices.
The ability to work independently and set your own priorities with careful attention to detail and deadlines.
A service mindset to business stakeholders

XSELL is committed to a culture of teamwork; where everyone works together to plan, do, learn, and continuously improve. We accomplish that by staying true to our core values.

Best Chapter: Every XSELLer is plugged in and focused on writing their “best chapter yet”, both personally and professionally. We believe in working hard to achieve success, but that success only comes if we are doing it together. We do this with a high level of humility, integrity, and compassion towards our coworkers. We celebrate and recognize each other and have a lot of fun along the way.
Know Us By Our Results: We do what we say and say what we do. Our coworkers and clients will “know us by our results” – we welcome that and embrace transparency and measurement.
Do It The XSELL Way: Together we are building an inclusive culture full of top-performing, talented people that are striving towards common goals with resilience. People will admire not only the work we do but also that we “do it the XSELL way” – as one team. We do this through strong communication, collaboration, and accountability to each other.
Open for Business: We are always “open for business” – fiercely committed to improving ourselves, our team, and our company. We stay curious and approach every situation as an opportunity to learn and grow.
Conversations Happen In the Room: Feedback is imperative to our collective success. We approach the “conversation in the room” with respect, empathy, and candor. Our dialogue with each other is always open and honest.

XSELL Technologies is an Equal Employment Opportunity Employer and all employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

We are committed to the full inclusion of all qualified individuals. As part of this commitment, we will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, perform essential job functions, and/or receive other benefits and privileges of employment, please contact us.

#BI-Remote


Show more Show less"
2815148120,Data Engineer,1Password,2021-11-01,United States,United States,Information Technology,Full-time,Computer and Network Security,"Over 100,000 businesses and millions of people use 1Password to protect their most important information. We’re a kind, curious, and customer-focused team on a mission to build the world's most-loved password manager and give people more control over their data.

We’re looking for a Data Engineer to help take our data reporting and infrastructure to the next level. You’ll work with the Executive, Product, Marketing, Sales, Sales Engineering, Finance, and Customer Success teams every day – in short, your work will impact the whole company. You’ll be part of our first team dedicated to Data and have a critical role in shaping our data foundation.

As a Data Engineer, you’ll contribute to a variety of projects that range from designing robust and fully automated ETL processes to building tools for improving company-wide productivity with data.

You have a passion for designing, implementing, and operating stable, scalable, and efficient solutions to flow data from production systems into the data warehouse. You are curious about all the nuances in the source data systems & always make an effort to assert data quality checks and improve documentation.

New analytics technologies are emerging every day and we’re excited about the impact they’ll have – we hope you share our enthusiasm!

This is a remote opportunity within Canada.

What We're Looking For

Proficiency in Python and SQL
Proficiency with DBT or other data transformation tool
5+ years experience with at least one relational database – MySQL, PostgreSQL, Oracle, etc.
3+ years experience with Data Warehousing or Data Lake technologies.
3+ years experience with large-scale data pipelines and ETL tooling (Spark/Dask, aws-kinesis/kafka, Airflow/Prefect, etc.).
The ability to maintain confidentiality of sensitive customer data.
Experience developing data-pipelines to and from CRM and marketing tools (Salesforce, Marketo, Intercom, etc.).
Experience with BI tools (We use Looker)
A team player with a solution oriented attitude with both technical and soft skills to get things done.


Bonus Points For

Experience with AWS, Terraform & Kubernetes
Experience with Event Sourcing.
Experience working with data using Python (pandas, dask, numpy, etc).
Experience with Distributed Data Technologies.
You love to write & produce great documentation.


What You Can Expect

Interface with other engineers to extract, transform, and load (ETL) data from a wide variety of in-house and third-party data sources.
Ensure we have data consistency on both production and analytical databases. You’ll own the integrity of our data from end-to-end, and the company will make high impact decisions based on this data.
Architect and build a data warehouse to provide timely data to a variety of third-party applications (Salesforce, Marketo, etc).
Design and build tools that make our data pipelines and surfacing more reliable and easier to use.
Work closely with Application Engineers to roll out new tools and features.
Triage, identify, and fix scaling challenges.
Collaborate with internal data customers to gather requirements.
Help develop our data engineering function in areas of data architecture, business intuition, and insight.


What We Offer

Along with joining a connected, inclusive and passionate community you will be eligible for the following:

Remote-first environment with flexible working hours to accommodate work-life balance
Competitive salary, a comprehensive benefits package, and RRSP or 401K match program
Employee Stock Options Program
Flexible vacation and time off including additional personal and sick days
Wellness programs, Employee Assistance Program and an annual wellness allowance
Paid parental leave programs
Professional development and peer recognition opportunities
Company swag and a free family 1Password subscription (and a discount for friends!)


1Password is proud to be an equal opportunity employer and when we say bring your whole self to work, we mean it. You’ll join a diverse and inclusive community, built on trust, support and respect. Be yourself, find your people and share the things you love. As we continue to build our team, we welcome all individuals and do not discriminate on the basis of gender identity and expression, race, ethnicity, disability, sexual orientation, colour, religion, creed, gender, national origin, age, marital status, pregnancy, sex, citizenship, education, languages spoken and veteran’s status. Accommodation is available upon request at any point during the recruitment process, should you require any please do let us know.
Show more Show less"
2809527644,Data engineer with pyspark,Inceptra Solutions LLC,2021-11-22,United States,"New York, United States",,Full-time,,"Data engineer

Job Locations: NY. (Remote for now)
Required Experience: 9+ Years

Job Description

Migrating python based ETL jobs to Databricks
Roles & Responsibilities

1. Migrate underlying Looker views to Spark ETL jobs on databricks. Each of these views will have a corresponding table in our Datalake, that is updated by the ETL jobs on a regular basis.
2. Work with our team to QA these new tables and ensure data quality.
Eligibility

Mandatory Skills:- PySpark, AWS, SQL, DWH , DataBricks, Good Communication skill
Show more Show less"
2791935113,Data Engineer,Tevpro,2021-11-09,United States,"Houston, TX",,Full-time,,"Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and rapidly scaling environment? At Tevpro, you'll be part of a team of brilliant technologists who solve real problems and meet real customer needs.

We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Tevpro Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation.

Job Summary

This position will collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies.

The qualified candidate will join a team of Solution Architects, Data Scientists, and Cloud Operations to develop data-driven solutions to difficult business challenges and enhance business performance with data-based insights.

What You'll Do

Work with a team of Developers, Data Scientists, and Cloud Operations with deep experience in machine learning, distributed microservices, and full stack systems.
Develop Azure analytics components including Data Lake, Power BI, Data Factory, Azure Data Explorer, Azure Synapse, Data Warehouse, and Data Bricks.
Utilize programming languages like Java, Scala, Python, Apache Spark, PowerShell and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake.
Build ingestion pipelines and ETL jobs to consume data feeds from source systems (e.g. Azure feeds, O365, AD, Salesforce, SAP, APIs, etc).
Manage large scale data infrastructure and tools including collecting, storing, processing and analyzing a range of data and data systems.
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance.
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, and mentoring other members of the engineering community.


Qualifications And Requirements

At least 4 years of experience in application development.
At least 1 year of experience in big data technologies.
Experience in Data warehouse development using SAP data sources, MS SQL, and Azure Synapse tools.
Experience developing medium/large scale ETL systems and optimizing data pipelines.
Extensive Data Management experience e.g. data profiling, large volume data handling.
Solid knowledge on latest trends in Data Management, and Large-Scale Data Analytics.
Extensive knowledge of Python and/or PowerShell.
Experience in DevOps in Azure cloud environments.
Experience with designing, building, and operating analytics solutions using Azure cloud and serverless technologies.
Solid understanding of relational (SQL, MySQL) and nonrelational (Cosmos DB, MongoDB, Hadoop) databases.
Experience with Apache Spark a plus


Compensation And Benefits

Competitive salary
Internal and external training
PTO
Matching 401k
Health benefits – Medical, Dental & Vision


LOCATION

Houston, TX

TEVPRO ACCEPTS RESUMES ONLY DIRECTLY FROM A CANDIDATE AND ANY UNSOLICITED RESUMES SENT TO TEVPRO WILL BE CONSIDERED TO BE REFERRED TO US FREE OF ANY AGENCY CHARGES OR FEES.

We are unable to offer sponsorship. Candidates MUST be authorized to work for any employer in the U.S.

Powered by JazzHR

BZJJYhXdpe
Show more Show less"
2813259719,Data Engineer,Deloitte,2021-10-31,United States,"Chicago, IL","Management, Strategy/Planning, and Consulting",Full-time,"IT Services and IT Consulting, Management Consulting, and Accounting","Are you an experienced, passionate pioneer in technology - a solutions builder, a roll-up-your-sleeves technologist who wants a daily collaborative environment, think-tank feel and share new ideas with your colleagues - without the extensive demands of travel? If so, consider an opportunity with Deloitte under our Project Delivery Talent Model. Project Delivery Model (PDM) is a talent model that is tailored specifically for long-term, onsite client service delivery. PDM practitioners are local to project locations, minimizing extensive travel, and provides you with a full career path within the firm.

Work You'll Do/Responsibilities

Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis)
Design and implement reliable, scalable, robust and extensible big data systems that support core products and business
Establish solid design and best engineering practice for engineers as well as non-technical people

The Team

The US Cloud Engineering Offering focuses on enabling our client's end-to-end journey from On-Premise to Cloud, with opportunities in the areas of Cloud Strategy and Op Model Transformation, Cloud Development & Integration, Cloud Migration, and Cloud Infrastructure & Managed Services. Cloud Engineering supports our clients as they improve agility, resilience and identifies opportunities to reduce IT operations spend through automation by enabling Cloud. We accelerate our clients toward a technology-driven future, leveraging vendor solutions, Deloitte-developed software products, tools, and accelerators.

Required

Qualifications

Bachelor's degree or Master's degree in Computer Science or related technical field; or equivalent practical experience
Experience with the Big Data technologies (Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc)
Experience in performing data analysis, data ingestion and data integration
Experience with ETL(Extraction, Transformation & Loading) and architecting data systems
Experience with schema design, data modeling and SQL queries
Passionate and self-motivated about technologies in the Big Data area
Strong data & logical analysis skills
Limited Sponsorship may be available.
Travel up to 10% annually

Preferred

Presto/Dremio
HIVE
Data Analytics
Show more Show less"
2815433146,Data Engineer,Confidential,2021-12-01,United States,United States,,Contract,,"Role : Senior Software Engineer/Data Engineer with QA
Location – Remote
Job Type- C2C
Exp- 7+year
• Relevant experience in performing the role of data validation and QA automation.
• Experience in Python in the big data platforms. Knowledge and experience in QA automation tools and technologies
• Should have experience working in distributed computing and Cloud native architecture, AWS and Spark ecosystem, Python/PySpark.
• Experience in handling healthcare and financial/credit agencies/demographic data and familiarity with these domains

Must have:
PySpark, Spark, ETL, Healthcare Data
Please find final responsibilities for QA team.
-Understand requirements for user stories
-Write test plans and create tests cases for the user stories
-Participate in product planning , grooming and provide inputs
-Effectively document and evaluates test results based on test cases developed and findings
-Track defects and helps troubleshoot errors.
-Partners with engineers to drive QA efforts that leads to successful testing outcome
-Design, code and maintain automated scripts
-Troubleshoot environmental issues
-Mentor and collaborate with team members in test procedures, process and best practices
-Participate in automation and manual test plan reviews and code reviews



Show more Show less"
2822242495,Data Engineer,Crescens Inc.,2021-12-01,United States,"Clearwater, FL",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Job Responsibilities

Design and support the database and table schemas for new and evolving sources of data being brought into the data warehouse
Create and support the Analysis Services
Monitor and troubleshoot performance issues
Define and promote the team's design principles and best practices
Work with business teams to be able to define requirements for real time reporting

Required

Skills and Experience Required:

Very Strong in SQL (2012 or better): stored procedures, functions, views, joins, import/export data, and the ability to develop queries from SQL
Broad Knowledge of BIDS (Business Intelligence Development Studio) with heavy concentration in SSIS
Experience in Tableau and Power BI
Expertise in Excel and advance excel skills, must be able to: connect to various data sources, conditional formatting, pivot tables & pivot reporting, functions & formulas, and sorting & filtering
Have the ability to identify data anomalies in a timely manner.
Previous Healthcare experience
Previous Fintech experience (banking, banking integrations, treasury, payments)

Desired

Visual Studio .NET
Show more Show less"
2767015174,Data Engineer,Procter & Gamble,2021-10-25,United States,"St Bernard, OH",Information Technology,Full-time,Manufacturing,"We are looking for a Data Engineer to help develop data products that our Global Products Stewardship organization can leverage to quickly meet the constantly changing regulatory environment. The candidate will help develop appropriate systems (application) capable of extracting, transforming, and aggregating various data assets into a single repository. Create an algorithm capable of summarizing formula market share trends and actionable insights based.

Qualifications

We are looking for someone working towards a PhD degree in the fields of Computer Science, Management Information Systems.

Experience with ETL in SQL and NoSQL data stores
Experience in coding languages like R and Python
Familiarity with a range of data engineering approaches, covering theoretical best practices and the technical applications of these methods
Excellent communication skills with business intuition and ability to understand business systems, versatility and willingness to learn new technologies on the job
Bonus points:

Experience using automation best practices for CI/CD
Experience with best practices for development including query optimization
Familiarity with end-user visualization tools like Power BI and Tableau
Hands On experience with the Azure Stack, including computing services and data warehouses
Familiarity with GCP or AWS cloud providers
Whatweoffer:

Responsibilities as of Day 1 – you will feel the ownership of your project from the beginning, and you will be given specific projects and responsibilities.

Continuous mentorship – you will work with passionate people and receive both formal training as well as day-to-day mentoring from your manager.

Work and be part of a dynamic and encouraging environment - working over a diverse array of interesting problems.

Promote agility and work/life balance for employees, we value every individual and support initiatives.

Experience true support for work/life effectiveness and your long-term well-being.

Get a competitive salary and benefits' package.

About Us

We produce globally recognized brands, and we grow the best business leaders in the industry. With a portfolio of trusted brands as diverse as ours, it is paramount our leaders are able to lead with courage the vast array of brands, categories and functions. We serve consumers around the world with one of the strongest portfolios of trusted, quality, leadership brands, including Always®, Ariel®, Gillette®, Head & Shoulders®, Herbal Essences®, Oral-B®, Pampers®, Pantene®, Tampax® and more. Our community includes operations in approximately 70 countries worldwide.

Visit http://www.pg.com to know more.

Our consumers are diverse and our talents - internally - mirror this diversity to best serve it. That is why we’re committed to building a winning culture based on Inclusion and our ideal candidate is passionate about the same principle: you will join our daily effort of being “in touch” so we craft brands and products to improve the lives of the world’s consumers now and in the future. We want you to inspire us with your unrivaled ideas.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status, disability status, age, sexual orientation, gender identity and expression, marital status, citizenship, HIV/AIDS status or any other legally protected factor.

Immigration sponsorship is not available for this role. As a general matter, Procter & Gamble does not sponsor candidates for nonimmigrant visas or permanent residency. However, Procter & Gamble may make exceptions on a discretionary basis. Any exceptions would be based on the Company's specific business needs at the time and place of recruitment as well as the particular qualifications of the individual.

Procter & Gamble participates in e-verify as required by law.

Qualified individuals will not be disadvantaged based on being unemployed.
Show more Show less"
2805909506,"Software Engineer, Data Tools",Tesla,2021-10-30,United States,"Palo Alto, CA",Engineering and Information Technology,Full-time,"Renewable Energy Semiconductor Manufacturing, Motor Vehicle Manufacturing, and Utilities","The Role

This Is Accomplished Through Three Main Functions

This team builds design infrastructure and tooling that enables us to rapidly develop software with precision and agility. As a member of this team you will shape the landscape for how Tesla designs future systems. Our vehicles contain many systems, distributed across a large network architecture, working together to accomplish a multitude of vehicle functions. This team’s core technology is an infrastructure that describes, manages and analyzes how these systems communicate with each other.

Describe communication in an abstract machine-readable format.
Organize the data for utility, usability, and scalability.
Develop tools to utilize the data to augment engineering through analysis, visualization and code generation.

This is a software development role that requires someone who likes to think about the big picture. You will work with component owners to understand their use cases so you can develop new technologies to act as a force multiplier for their productivity. The software is heavily utilized throughout the entire engineering organization. You will excel on this team if you thrive on autonomy and enjoy the freedom (and responsibility) of driving your own projects from concept to completion.

Responsibilities

Interface with key leaders of components spanning all Tesla products including energy, autopilot, powertrain, and vehicle controls
Extract requirements and feature requests; identify pain points in the design process
Build a model of an engineering design and represent it in an abstract construct
Design, develop, and deploy tooling and services harnessing this information to augment the design process; Scale your solution
Look for opportunities to improve organizational efficiency and reduce cost

Requirements

1-3 years of experience developing in Haskell (or equivalent functional programming language) in a production environment
BS in Computer Science or related field
Experience designing a database schema
Excited to develop internal tools and infrastructure

Nice To Have

Python experience
C/C++ experience
HTML/Javascript experience
Build systems and continuous integration experience
Embedded systems experience
Show more Show less"
2817126620,Data Engineer,Nutrien,2021-12-02,United States,United States,"Information Technology, Engineering, and Analyst",Full-time,"Chemicals, Retail, and Warehousing and Storage","Data Engineer – Remote, US

At Nutrien, our Purpose is to grow our world from the ground up and we do so with safety and integrity as our core values. Nothing is more important than sending our people home safe, every day.

Nutrien Ag Solutions is the retail division of Nutrien™, the largest crop inputs company in the world. As part of our collective mission of Feeding the Future, Nutrien Ag Solutions provides full-acre solutions through our trusted crop consultants at more than 2,000 locations in North America, South America, Europe and Australia. For more than 150 years, we have been helping growers achieve the highest yields with a wide selection of products, including our proprietary brands: Loveland Products, Inc.; Proven®Seed and Dyna-Gro®Seed; as well as financial, custom application and precision ag services.

We harvest the best. Diverse views and experience make us strong. We look for people who have a safety-first mindset, who are collaborative team players, who deliver on their commitments, who are innovators in search of a better way, and who believe in inclusion.

Working at Nutrien Ag Solutions will provide you an opportunity to help us Feed the Future, and grow your career.

The Data Engineer is a key role within the Brand and Activation Insights and Analytics Team. The Data Engineer will be providing scalable data pipelines and automation to a wide range of projects and will work closely with Data Scientists, BI Specialists, and other teams within Marketing. This role is currently designed to grow into a Data Scientist position and in addition to standard Data Engineering responsibilities will support Data Scientists in ad-hoc analysis and more complex data science projects when needed. This role is perfect for someone with excellent technical skills, but is looking to grow their knowledge in modern statistical practices needed to become a Data Scientist.

The Data Engineer has several primary responsibilities including collecting, combining, and analyzing data to develop scalable production level pipelines to address the needs of the business. This role will report to a Senior Data Scientist within the Insights and Analytics team.




What you will do:

Integrate data sources, systems, and reports (e.g., pricing, CRM, sales data)
Improve data availability by acting as a liaison between Marketing, IT, and digital teams
Manage junior team members for project capacity, quality and methodology
Create production grade pipelines with longevity in mind
Analyze data through programming languages (SQL, Python) and support the development of reporting systems (e.g., Power BI) that will provide insights into real-time commercial performance and production
Collaborate with business and internal stakeholders to translate complex systems into technical requirements and validation criteria into user-friendly resources for the sales and marketing teams
Provide insight to data architecture needs and stop-gap support to enable meaningful work
Manage business processes with the field sales team to share insights and provide reports
Work with data scientists and support in ad-hoc work where applicable




What you will bring:

Bachelor’s Degree required, preferably in a computer science focused discipline; experience may be considered in lieu of education.
3+ years of related experience required, preferably in data engineering and preparation, including experience with very large datasets (requiring big-data techniques), and sparse or poor-quality datasets
3+ years of experience with Python or similar language with object-oriented development experience
3+ years with relational databases/warehouses (BigQuery, Snowflake, etc.)
1+ years of experience with document databases (DynamoDB, Mongo, etc.)
Experience using cloud-based platforms (GCP, AWS, Azure) preferred. Base knowledge required
Interest in marketing, data science, and modern statistics preferred
Experience with Databricks, Spark, CircleCi, and/or Kedro a plus
Agriculture industry experience a plus




Compensation & Benefits:

Salary Range: $88,000-$107,000. This range is estimated for the Data Engineer position in Loveland, Colorado.




We provide an attractive benefits package that includes comprehensive medical, dental, vision coverage, and life insurance and well as disability coverage for positions working more than 30 hours per week. In addition, we have a retirement program that encourages our employees to save for the longer term, with generous matching employer contributions. Our benefit package also demonstrates our culture of care with paid vacation, sick days and holidays as well as paid personal and maternity/parental leaves and an Employee and Family Assistance Program. Details of the benefits package will be shared in the application process.




In addition to base pay, this role is also eligible to participate in our annual incentive plan, consistent with the terms of our plan, which provide discretionary award opportunities reflecting components such as performance of the company and the employee. Details will be discussed through the application process.




This information is provided in compliance with the Colorado Equal Pay for Equal Work Act and is the company's good faith and reasonable estimate of the compensation range and benefits offered for this position. The compensation offered to the successful applicant may vary based on factors including experience, skills, education, location, and other job-related reasons. Nutrien also makes internal equity a consideration in all pay decisions.




Are you a good match? Apply today!

Nutrien Ag Solutions is an equal opportunity employer that is committed to creating an inclusive workplace. We evaluate qualified applicants without regard to race, color, religion, age, sex, sexual orientation, gender identity, genetic information, national origin, disability, veteran status, and other legally protected characteristics

This job will remain posted until filled. In accordance with Nutrien policies, you will be required to undergo a background check, and may be required to undergo a substance test. While we appreciate all applications we receive, only candidates under consideration will be contacted.

To stay connected to us and for the latest job postings and news, follow us on: LinkedIn, Facebook and Twitter

Show more Show less"
2826704320,Data Engineer,VeriCour,2021-12-03,United States,"Denver, CO",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","The Data Engineer will be responsible for building a functional and scalable data infrastructure to provide the organization with the ability to make informed data-driven decisions.

Responsibilities Create scalable data breakdown, ELT, and data warehousing solutions. Assess and define functional requirements for BI and DW solutions. Take the lead in establishing and maintaining standards and guidelines for the design, development, tuning, deployment, and maintenance of information and advanced data analytics. Enrich the data infrastructure framework by assessing new and existing technologies and techniques to create efficient processes around data extraction (including APIs), aggregation, and analytics. Support the data platform infrastructure and put into action solutions to ensure continuous improvement in platform stability.

Qualifications 7+ years' experience in Data Engineering. 3+ yearsrsquo experience in a cloud environment, Azure preferred. Skilled in building scalable data warehouses in a cloud data platform, Snowflake preferred. Practiced in gathering data through databases, and REST and SOAP APIs. Adept in transmitting data through API's, data throws, and data thrusts, ETL and ELT. Strong understanding of Azure technologies (SQL, DevOps, Data Factory, Databricks).

Agile Scrum Experience, Preferred.

VeriCour provides equal employment opportunities to all employees and applicants for employment without regard to age, ancestry, sex (including gender identity), sexual orientation, disability (physical or mental), race, color, national origin, creed, religion, veteran status, military service, genetic information, immigration status, marital status, or pregnancy-related conditions. Equal employment opportunity applies to all terms and conditions of employment, including hiring, placement, promotion, termination, layoff, recall, transfer, leave of absence, compensation, and training.
Show more Show less"
2814225560,Data Engineer,"Miracle Software Systems, Inc",2021-11-30,United States,"Novi, MI",,Full-time,,"Miracle Software Systems is looking for a Data Engineer to work for one of our clients in Dearborn, MI. Below is the detailed job description




Responsibilities:

We looking for a highly skilled Data Governance Analyst, focusing on Data Privacy and Use.
You will be part of a global team and work with subject matter experts who have professional and technical backgrounds including data management, information technology and security, risk management, automotive and consulting.
The Data Governance Analyst role will focus on privacy, customer data and risk management, ensuring data is efficiently utilized as an enterprise asset.
Strong collaboration, written and verbal communication, and customer service skills




Skills Required:

Knowledge of data management standards and data governance practices.
Understanding of Compliance, Regulatory and Privacy requirements (e.g. GDPR, HIPAA, CCPA, etc.)
Excellent verbal and written communication coupled with process improvement mentality.
Self-Starter who can work in ambiguous situations and drive to a solution.




Experience Required:

3-5 years of business requirement analysis, business process management, project management, consulting, data management or equivalent experience




Education Required:

Bachelor's degree in Information Technology/Computer Science, MIS, Economics, Finance, Mathematics, Statistics, Business Analytics or equivalent experience in a relevant field.




If interested please send your updated resume to sathili@miraclesoft.com or direct message to me or you can call me on (248)-412-1730







Show more Show less"
2810316019,Data Engineer,Ribbon Health,2021-11-15,United States,"New York, NY",Information Technology,Full-time,IT Services and IT Consulting,"Data is a core part of our product. Our data pipelines today consist of thousands of datasets from hundreds of unique sources and continues to grow every day. This pipeline powers our machine learning models and API, which powers production workflows that affect real patients.

We've experienced rapid growth in data scale over the past few years and are looking for an experienced developer to build scalable systems that can support the next phase of our growth. We are looking for someone who can architect efficient and scalable systems, set data engineering standards for the engineering organization, and enjoys rolling up their sleeves and coding.

What we look for at Ribbon

Passion and drive to simplify healthcare by building products that increase access to care and power every healthcare decision to be high-quality, cost-effective, and convenient
Commitment to Ribbon Health company values, working on an exceptional team, and building an exceptional company
Grit, hustle, desire, and a ""get-it-done"" attitude; strong comfort with a lean startup environment, where everyone is encouraged to participate in and contribute across all teams
Dedication to the creation of a diverse, equitable, and inclusive environment where teammates are celebrated for their unique perspectives and work together to simplify healthcare for all


What we're looking for in this role

You have a strong background in Computer Science or other equivalent field
You're an entrepreneur, a self starter, and want to help us build and scale applications and data pipelines.
You love solving ambiguous problems and want to understand how to help us aggregate healthcare data from across the web.
You have a passion for data and want to help us untangle and discover truth in an industry rife with fragmented data.
You have a track record of learning new technologies and languages on the job
You're very comfortable with SQL and relational databases; Basic Python experience required.


Your day-to-day

Develop and manage data scrapers: You will develop new data scrapers that consume data from 100's of sources across healthcare
Scale our data ingestion framework: You will help design and improve upon our current system of record for ingesting data from hundreds of different sources.
Build light-weight automation: You will develop systems and tools to configure, monitor, and orchestrate our data infrastructure
Streamline our internal data operations: You will build tools to empower internal stakeholders to manage data across our pipelines and allow our internal teams to quickly distribute data to our clients.


How We Live Out Our Values For Our Teammates

Our goal is to make this the best career decision any of us have ever made. We stand by our values to make it happen.

Run Toward Hard Problems | We are motivated by the toughest challenges. We seek out hard problems that have the most impact and solve them to help those who need it most. We encourage our teammates to take ownership of outcomes that motivate them. Everyone at Ribbon has a say in our objective and key result (OKR) planning process for their teams and across teams.

Put Your Team First | We are a family. We are all happier and healthier when we take care of each other and put each other's needs ahead of our own. We take care of you by offering fully covered insurance premiums on health, vision, and dental, a 401K plan match, and a flexible working policy that includes progressive family leave guidelines, flexible working schedules, and unlimited vacation.

Do What You Say | We are honest with each other. We are accountable to each other. When we commit to accomplishing our goals, we make it happen. Every team member has the opportunity to own high-impact work at Ribbon.

Stay Hungry, Keep Improving | We are humble. We will make mistakes, learn from those mistakes, and be better because of those mistakes. Here, feedback is a gift and mistakes are learning opportunities. We have a thoughtful culture that focuses on giving and receiving regular positive and constructive feedback to help us support each other and make each other better. Also, speaking of ""hungry"" we offer plenty of snacks, food, and coffee.

Practice Habits of Excellence | We measure our success by the process it took to get there. We will always do our very best and we are proud of the outcome because of it. At Ribbon, we focus on how we get things done by documenting and sharing our learnings, We are building the systems we need to scale our company and support our work for the long-term.

Build With Empathy | We are building the best healthcare experience for our users. When faced with a difficult decision, we do what's best for people's lives. This includes our team. Every Ribbon teammate shares working and lifestyle norms, and we hold each other accountable to respecting these norms so each person can balance work-life integration that works for them.

Ribbon Health is proud to be an Equal Employment Opportunity employer. We do not discriminate on any basis covered by appropriate law. All employment is decided on the basis of merit, qualifications, performance, and business need. If you need assistance or an accommodation due to a disability, you may contact us at recruiting@ribbonhealth.com.
Show more Show less"
2825089498,Data Engineer,Centene Corporation,2021-12-02,United States,"Rancho Cordova, CA",Information Technology,Full-time,Insurance and Hospitals and Health Care,"Position Purpose

Contribute to the development and maintenance of real-time processing applications
Contribute to the creation and maintenance of optimal data pipeline architectures
Conduct maintenance and support for core infrastructure health, system upgrades, monitoring, CI/CD and logging
Research streaming best practices and proper stream architecture
Collaborate with team members to better understand existing data requirements and validation rules
Analyze trends in data sets and contribute to the development of algorithms in order to improve upon the usefulness of raw dataThis position will provide the Health Plan Systems with a platform for real-time stream processing by performing application and production support to help ensure the availability of streaming services and the continuous flow of data.

Education/Experience

Bachelor's degree in Computer Science, Computer Engineering, Software Engineering, related field or equivalent experience. Master’s degree in Computer Science or Computer Engineering preferred. 2+ years of experience in Computer Engineering, Software Development, System Administration, Linux Administration, DevOps and Site Reliability Engineering. Experience with the following programs/platforms is preferred Streaming Frameworks - Apache Spark, Apache Storm, Kafka K-Streams, Apache Samza, Apache Flink, Apache Apex, Apache Nifi and Apache Pulsar; Storage Technologies - MongoDB, Oracle, Teradata, Hadoop, DocumentDB, SQL Server, Volt DB, Apache Ignite, CockroachDB, Amazon Aurora and Redis; Linux – RedHat; Continuous Integration and Deployment – CloudBees, Jenkins, Ansible Tower, Puppet and Chef.

Centene is an equal opportunity employer that is committed to diversity, and values the ways in which we are different. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other characteristic protected by applicable law.
Show more Show less"
2781233869,"Engineer, Data & Analytics",Comcast,2021-10-11,United States,"Philadelphia, PA",Information Technology,Full-time,"IT Services and IT Consulting, Internet Publishing, and Telecommunications","Comcast Business offers technology solutions ranging from Ethernet, internet, and WiFi connectivity to voice, television, and managed Enterprise solutions to power businesses of all sizes to perform better. From small businesses to mid-market and large Enterprise organizations, Comcast Business serves business customers across the country. Powered by an advanced, Gig-speed network and backed by 24/7 technical support, Comcast Business is one of the largest contributors to the growth of Comcast Cable. The organization is the nation’s largest cable provider to small and mid-size businesses and has emerged as a force in the Enterprise market, recognized by leading industry associations as one of the fastest growing provider of Ethernet services.""

Job Summary

Responsible for transforming large, complex data into consumable business databases and applications for self-service analytics and reporting. Create system architecture, design and specification using in-depth engineering skills and knowledge to solve difficult development problems and achieve engineering goals. Determine and source appropriate data for a given analysis. Work with data modelers/analysts to understand the business problems they are trying to solve then create or augment data assets to feed their analysis. Works with moderate guidance in own area of knowledge. This is a support position within the Business Data and Intelligence organization. The BDI group is responsible for Comcast Business data collection, and one of the major goals is to harmonize the data ingestion and consumption layers across Comcast Business. The Junior Database Administration Engineer, will be responsible for operational support of the BDI Data Mart (SQL Server Database) as well as being involved in strategic initiatives for automation and improved processes.

Job Description

Core Responsibilities

Perform engineering tasks such as database design, data manipulation, ETL, implementation, information storage and retrieval, data flow and analysis.
Preemptively recognize and resolve technical issues utilizing knowledge of policies and processes.
Identifies and reacts to system notification and log to ensure quality standards for databases and applications. Solve abstract problems beyond single development language or situation by reusing data file and flags already set.
Solves critical issues and shares knowledge such as trends, aggregate, quantity volume regarding specific data sources.
Participate in the implementation of solutions via data architecture, data engineering, or data manipulation within big data systems like Hadoop and SQL.
Acts as a liaison between business owners and technical associates to ensure the data collected and processed is both actionable and relevant to the end goals.
Determines appropriateness of data for storage and optimum storage organization. Determines how tables relate to each other and how fields interact within the tables to develop relational models.
Collaborates with technology and platform management partners to optimize data sourcing and processing rules to ensure appropriate data quality.
Consistent exercise of independent judgment and discretion in matters of significance.
Monitors all database environments (Development, QA, Production)
Interacts closely with cross team work streams, and suggests areas of improvement to development teams to improve operation efficiency.
Diagnoses and documents issues, risks and problems.
Responds to customer concerns in a timely and efficient manner.
Responsible for database access requests, data security and governance.
Monitors JIRA tickets and works in Agile and daily Scrums.
Communicates and understands impact of database changes to affected parties and makes recommendations, as appropriate. Maintains hardware platforms to perform at optimum response, capacity planning, and implementation of new databases due to conversions
Regular, consistent and punctual attendance. Must be able to work nights and weekends, variable schedule(s) and overtime as necessary.
Other duties and responsibilities as assigned.

Employees At All Levels Are Expected To

Understand our Operating Principles; make them the guidelines for how you do your job.
Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services.
Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences.
Win as a team - make big things happen by working together and being open to new ideas.
Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers.
Drive results and growth.
Respect and promote inclusion & diversity.
Do what's right for each other, our customers, investors and our communities.

Disclaimer

This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.

Comcast is an EOE/Veterans/Disabled/LGBT employer.

Education

Bachelor's Degree

Relevant Work Experience

2-5 Years

Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details.
Show more Show less"
2786157459,Data Engineer,PlayStation,2021-12-01,United States,"San Mateo, CA",Information Technology,Full-time,"Computer Software, Consumer Services, and Entertainment","PlayStation isn’t just the Best Place to Play —it’s also the Best Place to Work. We’ve thrilled gamers since 1994, when we launched the original PlayStation. Today, we’re recognized as a global leader in interactive and digital entertainment. The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation.

Data Engineer

San Mateo, CA

The Data Strategy & Operations (DSO) team has grown rapidly over recent years in response to a growing need for the business to use data to advise and shape key decisions, and to identify new opportunities. Currently there are approximately 120 staff within the DSO team, split between London and California, made up of high quality BI and data professionals covering BI architecture and platform support, data processing, insight reporting, predictive analytics, scrum masters and product management.

We are looking for a Data engineer to join the Data strategy & Operations team within the Sony PlayStation environment. You will be responsible for the design, development and maintenance of the data processing platform, taking initiative while working with a highly skilled team under limited supervision. Based out of our San Mateo offices, our team provides business intelligence services for various global business units associated with Sony PlayStation.

Responsibilities

Engineer data pipelines and provide automated solutions for DSO teams
Work proactively to address project requirements, and articulate issues challenges with enough lead time to address project delivery risk
System monitoring and alerting, dashboards, charts/reports and alerts delivery
Ensure code is fully scalable, maintainable, and performant
Verifies program logic by overseeing the preparation of test data, testing and debugging of programs
Work with Project Managers and Business Analysts to ensure the timely delivery of projects
Requires ability to work in a global and multi-cultural environment. Team members are in multiple geographies, resulting in time constraints due to time zones differences and a requirement for occasional travel
Participate in the agile development process
Develops new documentation, departmental technical procedures and user guides

Qualifications

BS Degree in Engineering or Masters, Computer Science or equivalent experience
3 to 5 years of experience in database development, programming, design, and analysis
3 plus years of experience in coding and scripting languages - Python, bash, Korn
3 to 5 years of experience in ETL programming (Ab Initio)
3 plus years of experience in SQL and a variety of database technologies – Snowflake, Teradata and Oracle
Good technical analysis & troubleshooting skills
Experience in designing and architecting medium to complex systems, well versed with design standards & framework
General knowledge in Linux, Unix Administration and Windows Administration
Knowledge of Dimensional Modelling
Experience with automation, configuration management, enterprise schedulers
Familiarity with AWS Cloud Services is a plus
Familiarity with Information Delivery tools (such as MicroStrategy/Tableau) is a plus

Preferred

Experience in developing large-scale data processing platforms
Extensive experience throughout the software development lifecycle
Interpersonal skills including presentation, negotiating, conflict resolution, etc.
Strong communication skills. It is vital that the successful candidate is able to explain complex technical issues in non-technical terms to business partners
Ability to multi-task and prioritize within parallel development cycles and aggressive timelines
Knowledge and experiences of SDLC methodologies e.g. Agile, Waterfall
Strong troubleshooting and problem solving ability
Skilled in business requirements analysis with ability to translate business information into technical specifications

Sony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to race, color, religion, gender, pregnancy, national origin, ancestry, citizenship, age, legally protected physical or mental disability, covered veteran status, status in the U.S. uniformed services, sexual orientation, marital status, genetic information or membership in any other legally protected category.

Reasonable Accommodation Notice Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.

We strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond.

We sincerely appreciate the time and effort you spent in contacting us and we thank you for your interest in PlayStation.

PRIVACY NOTICE TO SIE LLC’S JOB APPLICANTS

This Privacy Notice explains what personal information we at Sony Interactive Entertainment LLC collect from you, and why we collect it and use it. This Notice covers our practices regarding the personal information of all applicants to our job positions. Please review it carefully.

Categories of personal information we collect from you

Generally, We Obtain This Information Through Our Recruiting Team

We collect personal information about you throughout the recruiting process, in particular the following categories.

Identification and contact information
Direct identifiers such as your first and last name.
Indirect identifiers such as a government ID, your Social Security, work permit or passport #.
Contact information such as your email address, mailing address, telephone number.
Other information about you or that can be associated with you such as:
Sensitive/Protected Data. During the recruitment process, you may (voluntarily) provide us with your ethnicity, gender, military service information, or physical or mental health information, as well as your national origin and citizenship.
Professional or job position-related information , including your past professional experience, references; background verification; talent management and assessment; information regarding any conflicts of interests; and the terms and conditions of your job offer.
Non-public education information , including information about your education records, such as grades and transcripts.

Show more Show less"
2826784485,Data Engineer,TechFetch.com - On Demand Tech Workforce hiring platform,2021-12-04,United States,"New York, NY",Information Technology,Part-time,IT Services and IT Consulting,"""ALL our jobs are US based and candidates must be in the US with valid US Work Authorization. Please apply on our website directly."" Databricks expert : Job Descriptoin

6+ years of experience as data engineer.

Must have 2+ Years in implementing data engineering solutions with Databricks. Hands on experience in building data pipelines using Databricks. Hands-on technical experience with Apache Spark. Ability to understand current data engineering pipelines using Foundry tools and convert to modern pipelines using Databricks. Ability to experiment Lift and Shift of Foundry python code to Databricks. Databricks engineering - query tuning, performance tuning, troubleshooting, and debugging Spark. Deep understanding of ETL/ELT design methodologies, architecture, strategy, and tactics for complex ETL solution. Data processing/transformation using various technologies such as spark and cloud Services. Must have deep expertise in one of the programming languages for data processes (Python Experience with Python, PySpark or Spark to write data pipelines and data processing layers Must have worked with relational databases like Azure SQL. Good SQL experience for writing complex SQL transformation.

Other Skills

Performance Tuning of Spark SQL running on S3/Data Lake/Delta Lake/ storage and Strong Knowledge on Databricks and Cluster Configurations. Developing scalable and re-usable frameworks for ingesting large data in Databricks. Exposure to delta lake framework. Nice to have Databricks administration including security and infrastructure features of Databricks. Experience with Development Tools for CI/CD, Unit and Integration testing, Automation and Orchestration.
Show more Show less"
2803167700,Data Engineer (Remote),Huxley,2021-11-17,United States,"Boston, MA",Information Technology and Other,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Data Engineer | Boston, MA | $100K - $160K



I'm working with a fast-paced, blockchain-native tech company looking to bring on a Data Engineer. As a Data Engineer, you'll work to build a robust, scalable cloud data infrastructure in AWS.



What You'll Do:



Build out internal data collection framework to support rapidly growing analytics business
Work directly with the Director of Data Operations and Head of Data
Define and implement the data ingestion strategy
Build out data pipelines
Own ETL processes

What We're Seeking:



Strong OO Programming experience with Python
SQL experience
Proven knowledge of ETL and data integration
Experience analyzing data sets
Strong passion for modern tech and willingness to learn new skills
Experience writing and maintaining data pipelines
Excellent verbal and communication skills

Nice to have:



Experience with Cloud Technologies (AWS preferred)
Experience with data pipeline tools (Airflow, Luigi)
Exposure to big data technologies (Spark, Hive, Hadoop)










EOE Statement: Specialist Staffing Group is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.













To find out more about Huxley please visit www.huxley.com



Show more Show less"
2817962314,Data Engineer,Citi,2021-11-04,United States,"New York, NY",Information Technology,Full-time,"Banking, Financial Services, and Investment Banking","Job Id: 21313997

The Applications Development Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities.

Responsibilities

The candidate will have the responsibility in design and development of tools which will be primarily used by Fixed Income Trading desks and MQA.

Skills

2-3 plus years of experiences in languages like C#, python and Scala.

Proficient with SQL SERVER related technologies i.e. traditional database development,. SSIS and SSRS

Familiar with common testing framework such as Scalatest, JUnit, Mockito

Familiar with Apache Spark 2.x with good knowledge on common API like Spark RDD/DataFrame/DataSet API

Better to have experience on Spark query tuning and performance optimization

Better to have knowledge on Hive/Impala

Deep understanding of distributed systems

Education:

Bachelor’s degree/University degree or equivalent experience

This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.

-------------------------------------------------

Job Family Group:

Technology

-------------------------------------------------

Job Family:

Applications Development

------------------------------------------------------

Time Type:

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting

Effective November 1, 2021, Citi requires that all successful applicants for positions located in the United States or Puerto Rico be fully vaccinated against COVID-19 as a condition of employment and provide proof of such vaccination prior to commencement of employment.


Show more Show less"
2767102505,Data Engineer,Citi,2021-10-19,United States,"Irving, TX",Information Technology,Full-time,"Banking, Financial Services, and Investment Banking","Job Id: 21380677

The Applications Development Technology Lead Analyst is a senior level position responsible for establishing and implementing new or revised application systems and programs in coordination with the Technology team.

This is a position within the Ingestion team of the DRIFT data ecosystem. The focus is on ingesting data in a timely , complete, and comprehensive fashion while using the latest technology available to Citi. The ability to leverage new and creative methods for repeatable data ingestion from a variety of data sources while always questioning ""is this the best way to solve this problem"" and ""am I providing the highest quality data to my downstream partners"" are the questions we are trying to solve.

Responsibilities:

Partner with multiple management teams to ensure appropriate integration of functions to meet goals as well as identify and define necessary system enhancements to deploy new products and process improvements
Resolve variety of high impact problems/projects through in-depth evaluation of complex business processes, system processes, and industry standards
Provide expertise in area and advanced knowledge of applications programming and ensure application design adheres to the overall architecture blueprint
Utilize advanced knowledge of system flow and develop standards for coding, testing, debugging, and implementation
Develop comprehensive knowledge of how areas of business, such as architecture and infrastructure, integrate to accomplish business goals
Provide in-depth analysis with interpretive thinking to define issues and develop innovative solutions
Serve as advisor or coach to mid-level developers and analysts, allocating work as necessary
Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.

Qualifications:

6-10 years of relevant experience in Apps Development or systems analysis role
Extensive experience system analysis and in programming of software applications
Application Development using JAVA, Scala, Spark
Familiarity with event driven applications and streaming data
Experience with Confluent Kafka, HDFS, HIVE, structured and unstructured database systems (SQL and NoSQL)
Experience with various schema and data types -> JSON, AVRO, Parquet, etc.
Experience with various ELT methodologies and formats -> JDBC, ODBC, API, Web hook, SFTP, etc.
Experience working within the Agile and version control tool sets (JIRA, Bitbucket, Git, etc.)
Ability to adjust priorities quickly as circumstances dictate
Demonstrated leadership and project management skills
Consistently demonstrates clear and concise written and verbal communication

Education:

Bachelor’s degree/University degree or equivalent experience
Master’s degree preferred

This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.

-------------------------------------------------

Job Family Group:

Technology

-------------------------------------------------

Job Family:

Applications Development

------------------------------------------------------

Time Type:

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting

Effective November 1, 2021, Citi requires that all successful applicants for positions located in the United States or Puerto Rico be fully vaccinated against COVID-19 as a condition of employment and provide proof of such vaccination prior to commencement of employment.


Show more Show less"
2781250061,Data Engineer,Centene Corporation,2021-10-11,United States,"Charlotte, NC",Information Technology,Full-time,Insurance and Hospitals and Health Care,"You could be the one who changes everything for our 24 million members. Centene is transforming the health of our communities, one person at a time. As a diversified, multi-national Fortune 50 and rapidly growing organization, our mission is fueled by exceptional talent. To support our rapid growth, we are building our East Coast headquarters and innovation hub here in Charlotte.

About Us

We are revolutionizing the world of healthcare through digital transformation and building a world-class software engineering practice. Our high caliber team delivers leading edge technology and drives innovation to solve complex business challenges. Using collective innovation we are turning visions into action and challenging what is possible to support the healthcare of 1 in 15 individuals.

About You

You are a highly collaborative, strategic risk-taker driven to make a difference and change the face of healthcare. You thrive in a supportive, result-oriented community and are committed to the relentless pursuit of continuous growth. You are highly agile, excel in fast-paced environments and willing to push outside your comfort zone. You are ready to find your purpose at work

The Role

We are transforming technology and creating a digital evolution that will empower Centene to better serve our members. The Data Engineer will provide the Health Plan Systems with a platform for real-time stream processing by performing application and production support to help ensure the availability of streaming services and the continuous flow of data.

As Data Engineer you will

Contribute to the development and maintenance of real-time processing applications
Contribute to the creation and maintenance of optimal data pipeline architectures
Conduct maintenance and support for core infrastructure health, system upgrades, monitoring, CI/CD and logging
Research streaming best practices and proper stream architecture
Collaborate with team members to better understand existing data requirements and validation rules
Analyze trends in data sets and contribute to the development of algorithms in order to improve upon the usefulness of raw data

Our Comprehensive Benefits Package

Flexible work solutions including remote options, hybrid work schedules and dress flexibility
Competitive pay
Paid Time Off including paid holidays
Health insurance coverage for you and dependents
401(k) and stock purchase plans
Tuition reimbursement and best-in-class training and development

Additionally, You Will Bring
Education/Experience Computer Science, Computer Engineering, Software Engineering, related field or equivalent experience.
Master’s degree in Computer Science or Computer Engineering preferred.
2+ years of experience in Computer Engineering, Software Development, System Administration, Linux Administration.
Experience with the following programs/platforms is preferred
Oracle, ETL, Oracle Datawarehouse, Informatica, PowerCenter, Greenplum, Snowflake, Talend and AWS

Centene is an equal opportunity employer that is committed to diversity, and values the ways in which we are different. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other characteristic protected by applicable law.
Show more Show less"
2826784485,Data Engineer,TechFetch.com - On Demand Tech Workforce hiring platform,2021-12-04,United States,"New York, NY",Information Technology,Part-time,IT Services and IT Consulting,"""ALL our jobs are US based and candidates must be in the US with valid US Work Authorization. Please apply on our website directly."" Databricks expert : Job Descriptoin

6+ years of experience as data engineer.

Must have 2+ Years in implementing data engineering solutions with Databricks. Hands on experience in building data pipelines using Databricks. Hands-on technical experience with Apache Spark. Ability to understand current data engineering pipelines using Foundry tools and convert to modern pipelines using Databricks. Ability to experiment Lift and Shift of Foundry python code to Databricks. Databricks engineering - query tuning, performance tuning, troubleshooting, and debugging Spark. Deep understanding of ETL/ELT design methodologies, architecture, strategy, and tactics for complex ETL solution. Data processing/transformation using various technologies such as spark and cloud Services. Must have deep expertise in one of the programming languages for data processes (Python Experience with Python, PySpark or Spark to write data pipelines and data processing layers Must have worked with relational databases like Azure SQL. Good SQL experience for writing complex SQL transformation.

Other Skills

Performance Tuning of Spark SQL running on S3/Data Lake/Delta Lake/ storage and Strong Knowledge on Databricks and Cluster Configurations. Developing scalable and re-usable frameworks for ingesting large data in Databricks. Exposure to delta lake framework. Nice to have Databricks administration including security and infrastructure features of Databricks. Experience with Development Tools for CI/CD, Unit and Integration testing, Automation and Orchestration.
Show more Show less"
2803167700,Data Engineer (Remote),Huxley,2021-11-17,United States,"Boston, MA",Information Technology and Other,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Data Engineer | Boston, MA | $100K - $160K



I'm working with a fast-paced, blockchain-native tech company looking to bring on a Data Engineer. As a Data Engineer, you'll work to build a robust, scalable cloud data infrastructure in AWS.



What You'll Do:



Build out internal data collection framework to support rapidly growing analytics business
Work directly with the Director of Data Operations and Head of Data
Define and implement the data ingestion strategy
Build out data pipelines
Own ETL processes

What We're Seeking:



Strong OO Programming experience with Python
SQL experience
Proven knowledge of ETL and data integration
Experience analyzing data sets
Strong passion for modern tech and willingness to learn new skills
Experience writing and maintaining data pipelines
Excellent verbal and communication skills

Nice to have:



Experience with Cloud Technologies (AWS preferred)
Experience with data pipeline tools (Airflow, Luigi)
Exposure to big data technologies (Spark, Hive, Hadoop)










EOE Statement: Specialist Staffing Group is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.













To find out more about Huxley please visit www.huxley.com



Show more Show less"
2817962314,Data Engineer,Citi,2021-11-04,United States,"New York, NY",Information Technology,Full-time,"Banking, Financial Services, and Investment Banking","Job Id: 21313997

The Applications Development Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities.

Responsibilities

The candidate will have the responsibility in design and development of tools which will be primarily used by Fixed Income Trading desks and MQA.

Skills

2-3 plus years of experiences in languages like C#, python and Scala.

Proficient with SQL SERVER related technologies i.e. traditional database development,. SSIS and SSRS

Familiar with common testing framework such as Scalatest, JUnit, Mockito

Familiar with Apache Spark 2.x with good knowledge on common API like Spark RDD/DataFrame/DataSet API

Better to have experience on Spark query tuning and performance optimization

Better to have knowledge on Hive/Impala

Deep understanding of distributed systems

Education:

Bachelor’s degree/University degree or equivalent experience

This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.

-------------------------------------------------

Job Family Group:

Technology

-------------------------------------------------

Job Family:

Applications Development

------------------------------------------------------

Time Type:

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting

Effective November 1, 2021, Citi requires that all successful applicants for positions located in the United States or Puerto Rico be fully vaccinated against COVID-19 as a condition of employment and provide proof of such vaccination prior to commencement of employment.


Show more Show less"
2767102505,Data Engineer,Citi,2021-10-19,United States,"Irving, TX",Information Technology,Full-time,"Banking, Financial Services, and Investment Banking","Job Id: 21380677

The Applications Development Technology Lead Analyst is a senior level position responsible for establishing and implementing new or revised application systems and programs in coordination with the Technology team.

This is a position within the Ingestion team of the DRIFT data ecosystem. The focus is on ingesting data in a timely , complete, and comprehensive fashion while using the latest technology available to Citi. The ability to leverage new and creative methods for repeatable data ingestion from a variety of data sources while always questioning ""is this the best way to solve this problem"" and ""am I providing the highest quality data to my downstream partners"" are the questions we are trying to solve.

Responsibilities:

Partner with multiple management teams to ensure appropriate integration of functions to meet goals as well as identify and define necessary system enhancements to deploy new products and process improvements
Resolve variety of high impact problems/projects through in-depth evaluation of complex business processes, system processes, and industry standards
Provide expertise in area and advanced knowledge of applications programming and ensure application design adheres to the overall architecture blueprint
Utilize advanced knowledge of system flow and develop standards for coding, testing, debugging, and implementation
Develop comprehensive knowledge of how areas of business, such as architecture and infrastructure, integrate to accomplish business goals
Provide in-depth analysis with interpretive thinking to define issues and develop innovative solutions
Serve as advisor or coach to mid-level developers and analysts, allocating work as necessary
Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.

Qualifications:

6-10 years of relevant experience in Apps Development or systems analysis role
Extensive experience system analysis and in programming of software applications
Application Development using JAVA, Scala, Spark
Familiarity with event driven applications and streaming data
Experience with Confluent Kafka, HDFS, HIVE, structured and unstructured database systems (SQL and NoSQL)
Experience with various schema and data types -> JSON, AVRO, Parquet, etc.
Experience with various ELT methodologies and formats -> JDBC, ODBC, API, Web hook, SFTP, etc.
Experience working within the Agile and version control tool sets (JIRA, Bitbucket, Git, etc.)
Ability to adjust priorities quickly as circumstances dictate
Demonstrated leadership and project management skills
Consistently demonstrates clear and concise written and verbal communication

Education:

Bachelor’s degree/University degree or equivalent experience
Master’s degree preferred

This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.

-------------------------------------------------

Job Family Group:

Technology

-------------------------------------------------

Job Family:

Applications Development

------------------------------------------------------

Time Type:

------------------------------------------------------

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting

Effective November 1, 2021, Citi requires that all successful applicants for positions located in the United States or Puerto Rico be fully vaccinated against COVID-19 as a condition of employment and provide proof of such vaccination prior to commencement of employment.


Show more Show less"
2781250061,Data Engineer,Centene Corporation,2021-10-11,United States,"Charlotte, NC",Information Technology,Full-time,Insurance and Hospitals and Health Care,"You could be the one who changes everything for our 24 million members. Centene is transforming the health of our communities, one person at a time. As a diversified, multi-national Fortune 50 and rapidly growing organization, our mission is fueled by exceptional talent. To support our rapid growth, we are building our East Coast headquarters and innovation hub here in Charlotte.

About Us

We are revolutionizing the world of healthcare through digital transformation and building a world-class software engineering practice. Our high caliber team delivers leading edge technology and drives innovation to solve complex business challenges. Using collective innovation we are turning visions into action and challenging what is possible to support the healthcare of 1 in 15 individuals.

About You

You are a highly collaborative, strategic risk-taker driven to make a difference and change the face of healthcare. You thrive in a supportive, result-oriented community and are committed to the relentless pursuit of continuous growth. You are highly agile, excel in fast-paced environments and willing to push outside your comfort zone. You are ready to find your purpose at work

The Role

We are transforming technology and creating a digital evolution that will empower Centene to better serve our members. The Data Engineer will provide the Health Plan Systems with a platform for real-time stream processing by performing application and production support to help ensure the availability of streaming services and the continuous flow of data.

As Data Engineer you will

Contribute to the development and maintenance of real-time processing applications
Contribute to the creation and maintenance of optimal data pipeline architectures
Conduct maintenance and support for core infrastructure health, system upgrades, monitoring, CI/CD and logging
Research streaming best practices and proper stream architecture
Collaborate with team members to better understand existing data requirements and validation rules
Analyze trends in data sets and contribute to the development of algorithms in order to improve upon the usefulness of raw data

Our Comprehensive Benefits Package

Flexible work solutions including remote options, hybrid work schedules and dress flexibility
Competitive pay
Paid Time Off including paid holidays
Health insurance coverage for you and dependents
401(k) and stock purchase plans
Tuition reimbursement and best-in-class training and development

Additionally, You Will Bring
Education/Experience Computer Science, Computer Engineering, Software Engineering, related field or equivalent experience.
Master’s degree in Computer Science or Computer Engineering preferred.
2+ years of experience in Computer Engineering, Software Development, System Administration, Linux Administration.
Experience with the following programs/platforms is preferred
Oracle, ETL, Oracle Datawarehouse, Informatica, PowerCenter, Greenplum, Snowflake, Talend and AWS

Centene is an equal opportunity employer that is committed to diversity, and values the ways in which we are different. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other characteristic protected by applicable law.
Show more Show less"
2668548019,Big Data engineer,Mindtree,2021-09-14,United States,"Dallas, TX",Engineering and Information Technology,Full-time,IT Services and IT Consulting,"Mindtree is looking for Strong Python Data Engineer for its project in Dallas, TX Area, Who is expert in Python, Pyspark

As a Big Data Engineer, you will be




Minimum experience of 8- 12 years working as a Bigdata engineer in L2 L3 support type of projects Ability to develop data integration and transformation code pipelines in object oriented scripting language PySpark Python in Spark Han ds on experience in Azure Cloud components such as Azure Data Factory Azure Logic apps service Data Bricks AKS Azure devops or any Cloud technologies Strong skill in understanding database architecture data models and writing complex SQL queries code Hands on experience with integration of different data sources Files DBs APIs Ability to work with large volume of data sets in performing data ingestion loading transformation and aggregation Knowledge of various ETL techniques Experience with data pipeline and workflow management tools Azure DevOps Strong analytic skill to work with unstructured data Strong customer handling skills and communication skills Ability to coordinate with globally located teams Good understanding of L2 L3 support processes and tracking systems like ServiceNow JIRA.




Employment Type

Full-time




 Mindtree Equal Employment Opportunity Policy

Mindtree provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics.

Why Work with Us:

Recognized for our employee learning and talent development practices
Good work-life balance encouraged
Recognition is the cornerstone of our culture
Values-driven and engaged leadership




 About Mindtree             

Mindtree [NSE: MINDTREE] is a global technology consulting and services company, helping enterprises marry scale with agility to achieve competitive advantage. “Born digital,” in 1999 and now a Larsen & Toubro Group Company, Mindtree applies its deep domain knowledge to 300+ enterprise client engagements to break down silos, make sense of digital complexity and bring new initiatives to market faster. We enable IT to move at the speed of business, leveraging emerging technologies and the efficiencies of Continuous Delivery to spur business innovation. Operating in 18 countries and over 40 offices across the world, we’re consistently regarded as one of the best places to work, embodied every day by our winning culture made up of over 21,000 entrepreneurial, collaborative and dedicated “Mindtree Minds.” 

Welcome to possible!

Show more Show less"
2819002917,Data Developer (ETL) - Remote,Mutual of Omaha,2021-11-29,United States,"Omaha, NE",Information Technology,Full-time,IT Services and IT Consulting and Insurance,"The Data Developer participates in and assists with the development of application and business integration solutions. Uses a variety of programming language(s), platforms and technologies to provide business solutions to customers.



WHAT YOU'LL DO:



Assists with the development, maintenance and integration of applications and systems that support the business operations.
Responsible for having a working knowledge of one or more programming languages used to develop, maintain, and execute systems.
Responsible for understanding various approaches and assisting with designing of enhancements for business operations.
Responsible for assisting with development, testing, and debugging of application/systems.
Responsible for having an understanding of the supported business area(s) and possessing an awareness of related business objectives and challenges.
Responsible for complying with all Company Information Services policies and standards.
Responsible for ensuring appropriate security and privacy measures are implemented on technology solutions to protect Company data from intentional or accidental misuse.

ABOUT YOU:



2 plus years data / ETL experience.
Strong communication and problem solving skills.
Ability to multi-task and adapt to changes in assignments.
Ability to adapt quickly to new technology and business requirements.
Awareness of different technologies and technology domains (Mainframe, Client Server, Web. Portal, Cloud, etc.).
You
Promote a culture of diversity and inclusion within the department and the larger organization
Value different ideas and opinions
Listen courageously and remain curious in all that you do
You are able to work remotely and have access to high-speed internet.

VALUABLE EXPERIENCE:



Teradata or Snowflake, Informatica, Relational Databases, Multiple Scripting Languages (Unix / Window), API Integration
Data Warehouse Design, Data Modeling and Integration
Amazon Web Services (AWS)
BI Tools (ex. Tableau)
Data Streams (Confluent, Kafka, Stitch, Striim, etc.)
Scaled Agile Framework (SAFe)
Ability to maintain data quality through systematic approaches and methodologies (e.g. MDM) within supported data systems.

WHAT WE CAN OFFER YOU:



A diverse workplace where associates feel a sense of belonging.
An organization that feels like a small, close-knit community and has the strength of a Fortune 500 company.
Tuition reimbursement, training and career development.
Comprehensive benefits plan that includes medical, dental, vision, disability and life insurance.
Flexible spending accounts for healthcare and childcare needs.
401(k) plan with a 2% company contribution and 6% company match.
Competitive pay with an opportunity for incentives for all associates.
Flexible work schedules with a healthy amount of paid time off.
For more information regarding available benefits, please visit our Career Site.
Estimated Salary Range: $70,000 - $95,000
Pay commensurate with experience.

MUTUAL OF OMAHA:



Mutual of Omaha serves more than 4.8 million individual product customers and 39,000 employer groups. Our legacy of stability creates an environment where every associate is encouraged to experiment, innovate and grow in their own unique career path.



From day one, you’ll have the tools to be your best self at work. Here you’ll do meaningful work and your talents will have a positive impact on peoples’ lives as we help our customers protect what they care about and achieve their financial goals.



Each associate is a unique contributor to creating a diverse, dynamic, thriving and inclusive workplace. We want you to become engaged … feel a sense of belonging … and contribute to the company’s exceptional future.



Join forces with a company that can AMPLIFY YOUR STRENGTHS AND EMPOWER YOUR CAREER.



For inquiries about the position or application process, contact our HR Helpline at 1-800-365-1405.



If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at 1-800-780-0304. We are available Monday through Friday 7:00 am to 4:30 pm CST we will reply within 24 hours.



Mutual of Omaha and its affiliates are an Equal Opportunity /Affirmative Action Employer. Qualified applicants will receive consideration without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.



To All Recruitment Agencies: We do not accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes.



Circa



 



Show more Show less"
2816035853,Data Engineer - Telecommute,Optum,2021-12-02,United States,"Eden Prairie, MN",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Combine two of the fastest-growing fields on the planet with a culture of performance, collaboration and opportunity and this is what you get. Leading edge technology in an industry that's improving the lives of millions. Here, innovation isn't about another gadget, it's about making health care data available wherever and whenever people need it, safely and reliably. Join us and start doing your life's best work.(sm)

As a Data Engineer, you will work on ingesting, enriching, and provisioning Optum’s Adobe clickstream data for business reporting, analytics, and data science. You will help develop, maintain, and optimize the data sets, data models, and large-scale data pipelines primarily in the Azure Databricks Spark cloud stack. You will partner with senior team members to drive best practices and set standards for data engineering patterns and optimization. You will be a key influencer in data engineering practices. If you have innovative ideas in data processing or would like to do research in latest new technologies in data engineering, this is role for you.

You’ll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges.

Primary Responsibilities

Build and deploy performance and scalable solutions by applying data engineering concepts and development best practices
Build scalable and end to end Spark pipelines for large-scale healthcare data
Ensure high quality solutions by design and build unit tests, integration test, performance test, and user acceptance tests
Optimize data pipelines to handle growing data volumes
Collaborate on designs for data pipelines and data tooling that meet performance and data quality standards
Build methods and tools to automate development activities
Ability to prioritize tasks and work concurrently on multiple tasks
Participate in business analysis and data discovery to gather data requirements
Ability to build complex but compact well performing SQL queries

You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Required Qualifications

Bachelor's Degree or equivalent work experience in a related field
3+ years of experience in distributed systems, data engineering, software engineering, or similar fields
2+ years of solid coding skills in a language such as Scala, Java, or Python
1+ years of experience with CI/CD development environment
1+ years of experience with Azure Cloud technologies

Preferred Qualifications

Background in the healthcare industry
Experience with DevOps, Continuous Integration, and Continuous Delivery
Experience developing Java RESTful Services using Spring Boot
Experience building and deploying applications to the Microsoft Azure cloud using Infrastructure as Code tools, such as Terraform
Experience working in an Agile environment
Expertise with modern programming languages, systems, and architectures
Develop analysis and design of transactional systems and/or programs

To protect the health and safety of our workforce, patients and communities we serve, UnitedHealth Group and its affiliate companies now require all employees to disclose COVID-19 vaccination status prior to beginning employment. In addition, some roles require full COVID-19 vaccination as an essential job function. UnitedHealth Group adheres to all federal, state and local COVID-19 vaccination regulations as well as all client COVID-19 vaccination requirements and will obtain the necessary information from candidates prior to employment to ensure compliance. Candidates must be able to perform all essential job functions with or without reasonable accommodation. Failure to meet the vaccination requirement may result in rescission of an employment offer or termination of employment.

Technology Careers with Optum. Information and technology have amazing power to transform the health care industry and improve people's lives. This is where it's happening. This is where you'll help solve the problems that have never been solved. We're freeing information so it can be used safely and securely wherever it's needed. We're creating the very best ideas that can most easily be put into action to help our clients improve the quality of care and lower costs for millions. This is where the best and the brightest work together to make positive change a reality. This is the place to do your life's best work.(sm)

All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy.

Colorado, Connecticut or Nevada Residents Only: The salary range for Colorado residents is $64,800 to $116,000. The salary range for Connecticut/Nevada residents is $71,400 to $127,400. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you’ll find a far-reaching choice of benefits and incentives.

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.

Job Keywords: Data Engineer, CI/CD, Scala, Java, Python, DevOps, Restful Services, Spring Boot, Data Engineering, Technology, Optum, Optum Technology, UHG, UnitedHealth Group, Telecommute, Telecommuter, Telecommuting, Work at Home, Work from Home, Remote
Show more Show less"
2818729413,Data Engineer,NuSources,2021-12-02,United States,United States,"Information Technology, Finance, and Analyst",Full-time,"Market Research, Financial Services, and Investment Management","Title: Data Engineer, Markets

Location: Remote; Anywhere in the U.S.

Terms: Fulltime




Description

We are servicing financial firms with crypto currency trading technology, institutional-grade market data, as well as blockchain data and analytics. We are a technology company focused on building the future of finance by developing robust data infrastructure for blockchain networks and crypto markets.
We are looking for candidates excited to shape this future by contributing to the crypto and blockchain industries through an industry-leading firm. This full-time role offers a competitive base salary, comprehensive medical/dental/vision benefits, flexible time-off and a rewarding work environment.
Our data engineers build and maintain the technology underpinning our market data and index infrastructure. They are responsible for core software development, data ingestion, transformation and distribution, as well as measuring and improving the performance of our systems. The ideal candidate will have experience in crypto currencies, capital markets and/or FX. Deep Linux and AWS experience is important, as well as experience working with complex data-processing pipelines.




Responsibilities:

Manage multiple API integrations (REST, Web Socket and FIX)
Develop scalable and robust architecture for the existing state of our infrastructure as well as its future state while contributing to its maintenance and improvement.
Write reliable, reusable and efficient code and APIs to support our infrastructure and product requirements.
Analyze performance and identify bottlenecks.
Contribute to the status and health monitoring systems of our infrastructure.
Provide quick responses to production issues.
Contribute technical input and knowledge to the planning, design, and requirements process of new products.




Requirements:

Well versed in Python and JavaScript (node.js).
Experience with large data sets, preferably Redis, and PostgreSQL.
Knowledge of AWS infrastructure.
Knowledge of Linux.
Proficiency with communication APIs (HTTP short and long polling, HTTP streaming, REST, WebSockets).




Preferred:

Experience with C.
Experience with FIX.
5+ years experience with Linux.
3+ years experience with AWS.
3+ years experience with Redis.
Experience in crypto currencies, FX, or capital markets.




Technologies:

AWS, PostgreSQL, Linux, Redis, Python, Node.js, C/C++, HAProxy, JavaScript, Graphite/Grafana, Ansible, Nginx, Django, Git

Show more Show less"
2820373377,Data Engineer,"Greenium Tech, LLC",2021-12-03,United States,United States,,Contract,,"Job Title: Data Engineer

We're looking for an experienced Data Engineer to join our client's analytics team and work with the latest big data technologies.

 




Department: Insurance

 




Job Type and Location: 

Contract, Remote

 




Experience/Qualifications: 

•4-8+ years of professional experience in software/data engineering 

•GCP, SQL, Python, CI/CD are the must-haves

•Reasonable understanding of entity relationships 

•Working grasp of data modeling 

•Good working knowledge of SQL and at least one core programming language (Python, Scala, Java, C#, R, etc.) 

•General understanding of batch and streaming data patterns and technologies 

•Good grasp of TDD and data validation/QA 

•Knowledge of CI/CD practices

•Exposure to Big Data scenarios and distributed computing tools/frameworks, experience in our toolset a plus.

•Exposure to PaaS offerings in public cloud environments.

 




Behavioral Competencies: 

•Developing Technical Acumen 

•Developing Problem Solving Skills 

•Developing Adaptability/Flexibility 

•Developing Communication & Presentation Skills 

•Proficient Interpersonal Skills 

•Developing Creativity and Innovation 

•Developing Results Focus




Send resume to faiza@greeniumtech.com

Show more Show less"
2806965057,Data Engineer,Notion,2021-11-24,United States,"San Francisco, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","About The Role

Since the launch of Notion, the company has been on a mission to make toolmaking ubiquitous - from wikis to documents, notes, tasks, databases, etc. A strong product intuition and focus on users have helped the company achieve adoption across businesses of all sizes. Today, millions of users rely on Notion's building blocks to get their work done.

As Notion continues to grow quickly, there is a unique opportunity to build the foundations of data and help the product and company reach their full potential. This is where you come in — to design and build reliable, trusted and timely datasets that accelerate the decision-making process of key product and business functions. You will have a strong impact on the roadmap and the growth trajectory of the company.

What You'll Achieve

You'll define the processes and ETL infrastructure to transform and make data readily available across the company
You'll build core datasets to serve as unique sources of truth for product and business functions (product, marketing, sales, finance, customer experience, data science, business operations, IT, engineering)
You'll partner with data scientists and other internal stakeholders to understand their needs and then design, build and monitor pipelines that meet today's requirements but can gracefully scale with our growing data size
You'll implement automated workflows that lower manual/operational cost for stakeholders, define and uphold SLAs for timely delivery of data, move the company closer to democratizing data and a self-serve model (query exploration, dashboards, data catalog, data discovery)

Skills You'll Need To Bring

You are a self-starter and continuously gather and synthesize high-impact needs from business partners, design and implementing the appropriate technical solutions, and effectively communicating about deliverables, timelines and tradeoffs
You've spent 3+ years as a data engineer building core datasets and supporting business verticals as needed. You are passionate about analytics use cases, data models and solving complex data problems
You have hands-on experience shipping scalable data solutions in the cloud (e.g AWS, GCP, Azure), across multiple data stores (e.g Snowflake, Redshift, Hive, SQL/NoSQL, columnar storage formats) and methodologies (e.g dimensional modeling, data marts, star/snowflake schemas)
You are an SQL expert. You intimately understand aggregation functions, window functions, UDFs, self-joins, partitioning and clustering approaches to run correct and highly-performant queries
You are highly comfortable with object-oriented programming paradigms (e.g Python, Java, Scala)

Nice To Haves

You have worked at a fast-growing start-up, a SaaS company or are eager to contribute in such an environment (being a current Notion user would be great!)
You have hands-on experience in designing and building highly scalable and reliable data pipelines using BigData stack (e.g Airflow, DBT, Spark, Hive, Parquet/ORC, Protobuf/Thrift, etc)

Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Notion.

Notion is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Notion considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Notion is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation made due to a disability, please let your recruiter know.
Show more Show less"
2826628634,Analytics Engineer,Northwestern Mutual,2021-12-04,United States,"Milwaukee, WI",Information Technology,Full-time,Financial Services,"At Northwestern Mutual, we are strong, innovative and growing. We invest in our people. We care and make a positive difference.

Primary Duties & Responsibilities

Acquire, analyze, combine, synthesize, and structure data with clear definitions and sources for analytical consumption
Consult with data consumers to identify meaningful datasets for analytical consumption.
Develop data products using continuous deployment and integration practices
Apply engineering best practices in order to analyze, design, develop, deploy and support data analytics products.
Participate in agile story authoring, sizing, and demo sessions for product features
Participate in code reviews and provide feedback to the team

Qualifications

Bachelor's Degree
1-3 years of professional experience
At least 1 year of professional experience in data acquisition, cleansing, feature engineering, debugging and software documentation, using languages such as SQL, Scala, Python
At least 1 year experience with specific technical requirements/platforms like AWS
Experience using continuous integration and deployment concepts
Experience navigating various types of database models and DBMS’s to create data sets for analytics and model training and development.
Experience with Testing or data accuracy/quality designs
Proficient programming skills
Strong Python and cloud compute skills
Strong SQL skills and background in ETL
Familiar with distributed data systems and applications.
Familiar with data lake design and implementation considerations such as columnar storage formats (Parquet) and partitioning
Understanding of analytics and data science applications
Understanding of requirement driven data models such dimensional and relational.
Understanding of the business domain and the meaning of the data in it to accurately identify key and associated data which can be extracted, transformed and loaded for effective consumption downstream.
Understands data flow so that data can be shared across the company with one source of truth being the goal.
Build data validation to insure integrity for user consumption
Familiar and aware of regulations around the use of PII data.
Familiarity with data lake environments
Ability to explain their technical solutions to technical teams and non-technical teams
Excellent written and verbal communication skills
Exceptional analytical, conceptual, and problem-solving skills.
Self-motivated and seeking to learn
Experience with Agile methodologies and DevOps environment
Experience with user adhoc tools; power bi, business objects, Tableau

This job is not covered by the existing Collective Bargaining Agreement.

Required Certifications

Grow your career with a best-in-class company that puts our client’s interests at the center of all we do. Get started now!

We are an equal opportunity/affirmative action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender identity or expression, sexual orientation, national origin, disability, age or status as a protected veteran, or any other characteristic protected by law.

If you work or would be working in Colorado or outside of a Corporate location, please click here for information pertaining to compensation and benefits.
Show more Show less"
2784447972,SQL Data Engineer - Telecommute,UnitedHealthcare,2021-10-14,United States,"Minnetonka, MN",Information Technology,Full-time,"Insurance, Financial Services, and Hospitals and Health Care","UnitedHealthcare is a company that's on the rise. We're expanding in multiple directions, across borders and, most of all, in the way we think. Here, innovation isn't about another gadget, it's about transforming the health care industry. Ready to make a difference? Make yourself at home with us and start doing your life's best work.(sm)

You’ll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges.

Primary Responsibilities

Create, edit, and troubleshoot SQL stored procedures
Develop, implement and automate data management tools
Collaborate with business and technical teams to create business processes for accessing and storing data
Use problem solving skills to find the root cause of application issues.
Make process improvements as needed to streamline production efforts
Database optimization

You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Required Qualifications

Bachelor's Degree, computer science or related technical field, or relevant experience
5+ years of experience with SQL writing and reviewing stored procedures
2+ years of experience with reporting, data analysis, and file exchanges
2+ years of experience with creating ETL/SSIS packages
Experience handling and resolving complex database issues identified by the business team
Clear understanding of database indexing and stored procedures

Preferred Qualifications

Experience with Access

UnitedHealth Group requires all new hires and employees to report their COVID-19 vaccination status.

Careers with UnitedHealthcare. Let's talk about opportunity. Start with a Fortune 5 organization that's serving more than 85 million people already and building the industry's singular reputation for bold ideas and impeccable execution. Now, add your energy, your passion for excellence, your near-obsession with driving change for the better. Get the picture? UnitedHealthcare is serving employers and individuals, states and communities, military families and veterans where ever they're found across the globe. We bring them the resources of an industry leader and a commitment to improve their lives that's second to none. This is no small opportunity. It's where you can do your life's best work.(sm)

All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy.

Colorado, Connecticut or Nevada Residents Only: The salary range for Colorado residents is $64,800 to $116,000. The salary range for Connecticut/Nevada residents is $71,400 to $127,400. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you’ll find a far-reaching choice of benefits and incentives.

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.

Job Keywords: SQL Data Engineer, Telecommuter, Telecommuting, Work at Home, Work from Home, Remote
Show more Show less"
2418278316,Data Engineer,Stripe,2021-11-14,United States,United States,Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","Stripe is the best software platform for running an internet business. We handle billions of dollars every year for hundreds of thousands of businesses around the world. One third of Americans bought something on Stripe in the last year.

With all this data, the Data Science team is looking for talented engineers to help us manage business critical data leveraged across the entire organization. If you are data curious, excited about designing data pipelines, and motivated by having impact on the business, we want to hear from you.

Every record in our data warehouse is vitally important for the businesses that use Stripe, so we’re looking for people with a strong background in data engineering and analytics to help us scale while maintaining correct and complete data. You’ll be working with a variety of internal teams across Engineering and Business to help them solve their data needs. Your work will provide teams with visibility into how Stripe’s products are being used and how we can better serve our customers.

You Will

Identify data needs for business and product teams, understand their specific requirements for metrics and analysis, and build efficient and scalable data pipelines to enable data-driven decisions across Stripe
Design, develop, and own data pipelines and models that power internal analytics for product and business teams
Help the Data Science team apply and generalize statistical and econometric models on large datasets
Drive the collection of new data and the refinement of existing data sources, develop relationships with production engineering teams to manage our data structures as the Stripe product evolves
Develop strong subject matter expertise and manage the SLAs for those data pipelines

We’re Looking For Someone Who Has

3+ Years of experience in a Data Engineering or Data Science role, with a focus on building data pipelines or conducting data intensive analysis.
A strong engineering background and are interested in data
Prior experience with writing and debugging data pipelines using a distributed data framework (Hadoop/Spark/Pig etc…)
An inquisitive nature in diving into data inconsistencies to pinpoint issues
Knowledge of a scientific computing language (such as R or Python) and SQL
The ability to communicate cross-functionally, derive requirements and architect shared datasets

Some Things You Might Work On

Develop unified user data schemas and tables that provide a complete view of the business across our various products such as Stripe Connect, Atlas, or Sigma
Build data pipelines that track our marketing funnel from visits to onboarding to active usage of Stripe
Work on our centralized experimentation platform to pipeline experiment metrics and compute descriptive statistics
Improve our data visualization tooling and platform at Stripe to help the team create dynamic tools and reporting
Our stack spans tools in Scala, Python, R, Javascript, React, SQL

You Should Include These In Your Application

Resume
LinkedIn profile

Show more Show less"
2809733704,Big Data Engineer,"SpringML, Inc.",2021-10-29,United States,"Pleasanton, CA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Management Consulting","At SpringML, we are all about empowering the ‘doers’ in companies to make smarter decisions with their data. Our predictive analytics products and solutions apply machine learning to today’s most pressing business problems so customers get insights they can trust to drive business growth. We are a tight knit, friendly team of passionate and driven people who are dedicated to learning, get excited to solve tough problems and like seeing results, fast.

Your primary role will be to design and build data pipelines. You will be focused on designing and implementing solutions on Hadoop, Spark, Pig, Hive. In this role you will be exposed to Google Cloud Platform including Dataflow, BigQuery and Kubernetes so the ideal candidate will have a strong big data technology foundation and bring a passion to learn new technologies. If you believe you have these skills please email your resume to info@springml.com.

Required Skills:

4-7 years Python and Java programming
3-5 years knowledge of Java/J2EE
3-5 years Hadoop, Big Data ecosystem experience
3-5 years of Unix experience
Bachelors in Computer Science (or equivalent)


Duties and Responsibilities:

Design and develop applications utilizing the Spark and Hadoop Frameworks or GCP components.
Read, extract, transform, stage and load data to multiple targets, including Hadoop, Hive, BigQuery.
Migrate existing data processing from standalone or legacy technology scripts to Hadoop framework processing.
Should have experience working with gigabytes/terabytes of data and must understand the challenges of transforming and enriching such large datasets.


Additional Skills that are a plus:

C, Perl, Javascript or other programming skills and experience a plus
Production support/troubleshooting experience
Data cleaning/wrangling
Data visualization and reporting
Devops, Kubernetes, Docker containers


Powered by JazzHR

xeLSvfmYt5
Show more Show less"
2817840566,Data Engineer,Ocurate,2021-12-03,United States,"California, United States",,Full-time,,"Ocurate is searching for a senior data engineer to work on applying our deep machine learning framework in conjunction with our unique database on 260 million Americans in service of predicting customer lifetime value for our clients in theB2C/ecommerce space.

At Ocurate, you will have the opportunity to work with some of the most interesting and extensive datasets in the space, and apply and extend cutting edge machine learning technology.




Ocurate uses a class of deep machine learning, and unique data to predict customer lifetime value with best-in-class accuracy.

Ocurate is a fully remote company, with employees located mainly in New York and San Francisco/Bay Area. Our founder believes strongly in a healthy work/life balance, and a culture of working smarter not harder. Ocurate highly values diversity. We are supportive of families.




RESPONSIBILITIES AND CORE SKILLS INCLUDE |

3+ years experience in a developer role; ideally, you have delivered business critical software
Experience with and desire to mentor and foster the growth of junior software engineers.
Significant professional experience using cloud technology (such as AWS or Google Cloud)
Professional experience working with large (~ 1TB or greater) datasets, and using distributed computing to process such datasets
Fluency in Python
Fluency in SQL / relational algebra
Strong communicator in English with excellent written and verbal communication skills




Bonus Requirements (skills that are not required but which would be highly valued):

Professional experience in Devops and infrastructure-as-code (Terraform, AWS CDK, etc)
Fluency with GIS (Geographical Information Systems)
Familiarity with GPU based technologies (CUDA, OpenCL, etc)




WHAT WE OFFER |

Fully remote role in fully remote company
Competitive salaries, including base pay and equity-based compensation
Flexible PTO
401k with employer match
Monthly healthcare stipend




Show more Show less"
2808347734,Data Engineer,Honeywell,2021-11-01,United States,"Charlotte, NC",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Join a team recognized for leadership, innovation and diversity

The future is what you make it. When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers and doers who make the things that make the future. That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings smart and safe and even making it possible to breathe on Mars. Working at Honeywell isn’t just about developing cool things. That’s why all our employees enjoy access to dynamic career opportunities across different fields and industries.

Are you ready to help us make the future?

Join a company that is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data, analytics, Internet of Things, and design thinking. You will lead change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. You will work with customers to identify their high value business questions and work through their data to search for answers. You will be responsible for working within Honeywell to identify opportunities for new growth and efficiency based on data analysis.

Key Responsibilities

As a Data Engineer, you will be part of a team that delivers contemporary analytics solutions for the Data Management & Analytics function at Honeywell. You will build strong relationships with leadership to effectively deliver contemporary data analytics solutions and contribute directly to business success. You will develop solutions on various Database systems viz. Hive, Hadoop, SnowFlake, etc.

You will identify and implement process improvements – and if you don’t like to do the same thing twice, you will automate where possible. You are always keeping an eye on scalability, optimization, and process. You have worked with Big Data before, IoT data, SQL, Azure, AWS, SnowFlake

You will work on a team including scrum masters, product owners, data architects, data engineers/analyst, data scientists and DevOps. You and your team collaborate to build products from the idea phase through launch and beyond. The software you write makes it to production in sprints. Your team will be working on creating a new platform using your experience of APIs, microservices, and platform development.

YOU MUST HAVE

US Citizenship due to export control restrictions
Bachelor's degree in Computer Science, Engineering, Applied Mathematics, or other technical degree
4+ years of data warehouse experience including ETL and SQL

WE VALUE

Should have developed and deployed complex big data ingestion jobs in Talend/Informatica BDM bringing prototypes to production on Hadoop/NoSQL/MPP platforms.
Hands on experience with MapReduce, Pig/Hive, Spark, etc. and automation of data flow using NiFi and Airflow/Oozie.
Experience in developing and building applications to process very large amounts of data (structured and unstructured), including streaming real-time data (Spark, R/Python, Scala, Kafka, Spark streaming or other such tools).
Experience in working with at least one NoSQL system (HBase, Cassandra, MongoDB etc.). In-depth knowledge of schema design to effectively tackle the requirement.
Experience in writing complex SQL statements
Experience in working with cloud-based deployments. Understanding of containers & container orchestration (Swarm or Kubernetes).
Hands on experience in Cloudera, Hortonworks and/or Cloud (AWS EMR, Azure Data Lake Storage) based Hadoop distributions.
Good understanding of branching, build, deployment, CI/CD methodologies such as Octopus and Bamboo
Experience working with in Agile Methodologies and Scrum Knowledge of software best practices, like Test-Driven Development (TDD)
Effective communication skills and succinct articulation
Experience in building advanced analytics solutions with data from enterprise systems like ERPs, CRMs, Marketing tools etc.
Experience with dimensional modeling, data warehousing and data mining
Experience with machine learning solutions and data science methods promotion
Database performance management and API development
Technology upgrade oversight
Experience with visualization software, Tableau preferred.
Understanding of best-in-class model and data configuration and development processes
Experience working with remote and global teams and cross team collaboration
Consistently makes timely decisions even in the face of complexity, balancing systematic analysis with decisiveness

Additional Information

JOB ID: req259339
Category: Information Technology
Location: 855 S Mint St,Charlotte,North Carolina,28202,United States
Exempt
Must be a US Citizen due to contractual requirements.

Global (ALL)

Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, religion, or veteran status.
Show more Show less"
2808120282,Data Engineer,Deckers Brands,2021-11-25,United States,"Fort Worth, TX",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2814770491,Data Engineer,Alphataraxia Management LP,2021-12-01,United States,"Arlington, VA",,Full-time,,"We are hiring a Data Engineer to join our team! You will excel in this role if you have a penchant for problem solving, understanding data ecosystems, and building systems that can help expedite complex analysis and guide us to solve challenging problems in today's power markets.

This position is primarily responsible for building the data infrastructure necessary for investment transactions in both new and existing spaces. This role requires developing a deep understanding of new and existing data streams, as you make recommendations to the firm on longer term tool buildout and work closely with investment analysts to keep the data flowing needed to process short term investment decisions. Other responsibilities may include working with our underlying cloud infrastructure and building internal tools and workflows that allow better consumption of this data.

At Alphataraxia, we leverage our data ecosystem to transact on the best data available. As a Data Engineer, your work in building out critical data infrastructure and advancing our data capabilities will be central to our investment process. You will work alongside our investment teams to develop the systems and processes to extract, clean, and store the millions of rows of information that will ultimately advise our trading efforts.

Show more Show less"
2825185095,Backend/Data Engineer,Mediaocean,2021-12-03,United States,United States,Information Technology,Full-time,Computer Software,"Job Description

What You Will Do:

As a Backend Software Engineer on the Mediaocean team, you will be responsible for helping craft the future of our offerings - from the database layers to the APIs that surface our data and functionality to our users. A little about our team: we've built a large Python Flask application that is supported by an array of smaller services, and are in the process of adding further robustness to our systems by doubling down on service-based architecture. We integrate with a myriad of third-party APIs which require a rigorous attention to detail and creative solutions to ensure we handle all situations gracefully. We also design and build data engineering pipelines that enable large volumes of data to go through layers of ETL processing and analysis.

Responsibilities Will Include

Have autonomy to work on what matters and have an impact immediately
Build, test and ship well-engineered features and enhancements
Design, support, maintain and upgrade highly performant and tested APIs and internal services using tools like Python, Celery, Kubernetes, MySQL, Postgre, Mongo, Redis, AWS Redshift
Articulate a long-term vision for maintaining and scaling our systems
Work with other engineers, product managers, designers and company leadership to turn our vision into a concrete roadmap every quarter and to help develop an amazing experience for our agency & brand customers.

Who You Are

3+ years of experience in software engineering with strong sense of computer science fundamentals
You demonstrate strong critical thinking ability, such as you have a Computer Science degree, or prior work experience (in a technical role, or otherwise), went to a coding school, or you are self-taught, or some combination of the above
Proficiency in Python
Relational Databases - Postgre, MySql
NoSQL Databases - Mongo
Experience handling large amounts of data, building warehousing pipelines
Experience with large scale data warehousing tech like AWS Redshift is a plus

Why Mediaocean?

Full healthcare benefits (PPO & CDHP medical plans, dental, and vision) & 401k
New parents are offered six weeks paid leave
Open PTO; vacation/sick/religious observances/philanthropy opportunities
Professional development opportunities within our Learning & Development programs
Belong@Mediaocean affinity based groups of colleagues to create community
All of these benefits/perks are effective on the date of hire

We would hate to miss out on your application because you do not meet every requirement – transferrable skills and education will also be considered, so please do not hesitate to apply!

Mediaocean recognizes our true strength and value shine when all our team members feel there is space in the conversation for their voices, thoughts, ideas, perspectives, and concerns. Mediaocean is committed to being an equal opportunity employer, and we consider all applicants regardless of their age, race, color, gender, sexual orientation, ethnicity, religion, national origin, disability, or veteran status.
Show more Show less"
2555322636,Big Data Engineer,FinTech LLC,2021-05-21,United States,"Colorado, United States",Engineering and Information Technology,Full-time,"Appliances, Electrical, and Electronics Manufacturing, Manufacturing, and Retail","Role : Big Data Engineer
Location : Denver CO


Job Duties and Responsibilities

Evangelist for data engineering function leveraging big data processing framework.
Creation and optimization of data engineering pipelines for analytics projects.
Support data and cloud transformation initiatives
Support our software engineers and data scientists
Contribute to our cloud strategy based on prior experience
Understand the latest technologies in a rapidly innovative marketplace
Independently work with all stakeholders across the organization to deliver enhanced functionality

Skills - Experience and Requirements

A successful Data Engineer will have the following:
Must be from Data warehouse/Big data background.
Experience in advanced Apache Spark processing framework, spark programming languages such as Scala/Python/Advanced Java with sound knowledge in shell scripting.
Experience in working with Core Spark, Spark Streaming, Data Frame API, Data set API, RDD APIs & Spark SQL programming dealing with processing terabytes of data. Specifically, this experience must be in writing ""Big Data"" data engineering jobs for large scale data integration in AWS.
Advanced SQL experience using Hive/Impala framework including SQL performance tuning
Experience in writing spark streaming jobs integrating with streaming frameworks such as Apache Kafka or AWS Kinesis.
Create and maintain automated ETL processes with special focus on data flow, error recovery, and exception handling and reporting
Gather and understand data requirements, work in the team to achieve high quality data ingestion and build systems that can process the data, transform the data
Knowledge of using, setting up and tuning resource management framework such as standalone spark, Yarn or Mesos.
Experience in physical table design in Bigdata environment
Experience working with external job schedulers such as autosys, aws data pipeline, airflow etc.
Experience working in Key/Value data store such as Hbase
Experience in AWS services such as EMR, Glue (server less architecture), S3, Athena, IAM, Lambda and Cloud watch is required.
Show more Show less"
2814265080,Data Engineer,Infosys,2021-11-30,United States,United States,"Information Technology, Engineering, and Other",Full-time,"IT Services and IT Consulting, Information Services, and Computer Software","Location: Hartford, CT, Richardson, TX and Phoenix, AZ.




Data Engineer

2+ years of Data Engineering experience and

In-depth programming experience using Python and SQL.

Experience with data gathering, processing, transformation, data quality, system architecture, coding best practices
DataBricks Service (on any cloud)
Python and PySpark programming experience
Apache Airflow Experience
Snowflake
Strong SQL Experience

Show more Show less"
2809435473,Data Integration Engineer,Riskified,2021-11-01,United States,United States,Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","About Us

Riskified empowers merchants and shoppers to realize the full potential of eCommerce by making it safe, accessible, and frictionless. Our global team helps the world’s most-innovative eCommerce merchants eliminate risk and uncertainty from their business. Merchants integrate Riskified’s machine learning platform to create trusted customer relationships, driving higher sales while reducing costs. Riskified has reviewed hundreds of millions of transactions and approved billions of dollars of revenue for global brands and fast-growing businesses across industries, including Wayfair, Wish, Peloton, Gucci, and many more. As of July 29th, 2021, Riskified has begun trading on NYSE under the ticker RSKD.

About The Role

As a Data Integration Engineer at Riskified, you will be using technical skills, analytical insights and business perspective to ensure we have the most accurate and complete data set from each client. You will be responsible for helping new and existing customers to ensure they are receiving the best performance possible and leading the change on processing the data of the largest eCommerce merchants in the world. Riskified’s clients come in many different sizes and industries, use different technical platforms, and each one has their own unique data concerns and order flows that have to be uniquely assessed. Our team is the one to fully capture these aspects and recommend the best implementation as well as point out any possible issues.

What You'll Be Doing

Supporting the onboarding of new customers by completing the following:

Working with some of the largest companies in the world to perform comprehensive analysis of their data
Perform due diligence of business models and flows
Data modeling as part of the integration architecture
Combining the technical, business and analytical objectives to come up with tailored solutions for onboarding merchants
Data wrangling & sanitization
Prioritize, track, and communicate data issues internally and externally
Become the subject matter expert of riskified product and technology
Work closely with analysts, research and data science teams to accommodate changes in industry data
Perform comprehensive analysis of chargebacks data

Monitoring and resolving data irregularities of existing customers by completing the following:

Monitor key health indicators and automated alerts
Identify, research, and offer system-wide solutions for common issues
Work closely with Account Management to engage customers

Qualifications

3+ years of experience in a data-centric industry role (ETL, DBA, etc.)
2+ years with SQL or NoSQL databases
2+ years experience with data wrangling (R, Python for data processing)
2+ years with optimizing technical processes
Strong verbal and written communication skills
Eagerness to learn new technical concepts
Strong analytical skills and attention to detail

Life at Riskified

We are a fast-growing and dynamic tech company with 650+ team members globally. We value collaboration and innovative thinking. We’re looking for bright, driven, and passionate people to grow with us.

COVID-19 Update

Our NYC team is currently working remotely. If anyone prefers to work in our office, we’re happy to offer an option to do so safely.
When the situation improves, we’re looking forward to adapting a hybrid of remote and in-office work for all our team members.
We’re growing at a rapid rate and have transitioned all our interviews to Zoom.

Some Of Our NYC Benefits & Perks

Fully-covered medical, dental, and vision insurance from your first day
Equity for all employees, 401(k) + matching, commuter benefits
Catered lunch, fully-stocked kitchen, team events, happy hours, birthday celebrations
Yoga, pilates, soccer league, wellness classes
Wide-ranging opportunities to volunteer and make an impact in local communities
Commitment to your professional development with global onboarding, sales bootcamp, skills-based courses, full access to Udemy, lunch & learns
Awesome Riskified gifts and swag!

In The News

FoxBusiness: Fraud Protection Platform 'Riskified' Begins Trading on NYSE

Reuters: General Atlantic-Backed Riskified is Valued at 4.3 BLN in NYSE Debut

Fortune Magazine: 25 Best Workplaces in New York

Announcing Riskified's $165M Funding Round

Inc Magazine: Best Workplaces

Built In NYC: 100 Best Workplaces

TechCrunch: Riskified Prevents Fraud on Your Favorite eCommerce Site

Calcalist: Riskified is the Most Promising Startup

Riskified is deeply committed to the principle of equal opportunity for all individuals. We do not discriminate based on race, color, religion, sex, sexual orientation, national origin, age, disability, veteran status, or any other status protected by law.
Show more Show less"
2809435472,Data Integration Engineer,Riskified,2021-11-01,United States,United States,Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","About Us

Riskified empowers merchants and shoppers to realize the full potential of eCommerce by making it safe, accessible, and frictionless. Our global team helps the world’s most-innovative eCommerce merchants eliminate risk and uncertainty from their business. Merchants integrate Riskified’s machine learning platform to create trusted customer relationships, driving higher sales while reducing costs. Riskified has reviewed hundreds of millions of transactions and approved billions of dollars of revenue for global brands and fast-growing businesses across industries, including Wayfair, Wish, Peloton, Gucci, and many more. As of July 29th, 2021, Riskified has begun trading on NYSE under the ticker RSKD.

About The Role

As a Data Integration Engineer at Riskified, you will be using technical skills, analytical insights and business perspective to ensure we have the most accurate and complete data set from each client. You will be responsible for helping new and existing customers to ensure they are receiving the best performance possible and leading the change on processing the data of the largest eCommerce merchants in the world. Riskified’s clients come in many different sizes and industries, use different technical platforms, and each one has their own unique data concerns and order flows that have to be uniquely assessed. Our team is the one to fully capture these aspects and recommend the best implementation as well as point out any possible issues.

What You'll Be Doing

Supporting the onboarding of new customers by completing the following:

Working with some of the largest companies in the world to perform comprehensive analysis of their data
Perform due diligence of business models and flows
Data modeling as part of the integration architecture
Combining the technical, business and analytical objectives to come up with tailored solutions for onboarding merchants
Data wrangling & sanitization
Prioritize, track, and communicate data issues internally and externally
Become the subject matter expert of riskified product and technology
Work closely with analysts, research and data science teams to accommodate changes in industry data
Perform comprehensive analysis of chargebacks data

Monitoring and resolving data irregularities of existing customers by completing the following:

Monitor key health indicators and automated alerts
Identify, research, and offer system-wide solutions for common issues
Work closely with Account Management to engage customers

Qualifications

3+ years of experience in a data-centric industry role (ETL, DBA, etc.)
2+ years with SQL or NoSQL databases
2+ years experience with data wrangling (R, Python for data processing)
2+ years with optimizing technical processes
Strong verbal and written communication skills
Eagerness to learn new technical concepts
Strong analytical skills and attention to detail

Life at Riskified

We are a fast-growing and dynamic tech company with 650+ team members globally. We value collaboration and innovative thinking. We’re looking for bright, driven, and passionate people to grow with us.

COVID-19 Update

Our NYC team is currently working remotely. If anyone prefers to work in our office, we’re happy to offer an option to do so safely.
When the situation improves, we’re looking forward to adapting a hybrid of remote and in-office work for all our team members.
We’re growing at a rapid rate and have transitioned all our interviews to Zoom.

Some Of Our NYC Benefits & Perks

Fully-covered medical, dental, and vision insurance from your first day
Equity for all employees, 401(k) + matching, commuter benefits
Catered lunch, fully-stocked kitchen, team events, happy hours, birthday celebrations
Yoga, pilates, soccer league, wellness classes
Wide-ranging opportunities to volunteer and make an impact in local communities
Commitment to your professional development with global onboarding, sales bootcamp, skills-based courses, full access to Udemy, lunch & learns
Awesome Riskified gifts and swag!

In The News

FoxBusiness: Fraud Protection Platform 'Riskified' Begins Trading on NYSE

Reuters: General Atlantic-Backed Riskified is Valued at 4.3 BLN in NYSE Debut

Fortune Magazine: 25 Best Workplaces in New York

Announcing Riskified's $165M Funding Round

Inc Magazine: Best Workplaces

Built In NYC: 100 Best Workplaces

TechCrunch: Riskified Prevents Fraud on Your Favorite eCommerce Site

Calcalist: Riskified is the Most Promising Startup

Riskified is deeply committed to the principle of equal opportunity for all individuals. We do not discriminate based on race, color, religion, sex, sexual orientation, national origin, age, disability, veteran status, or any other status protected by law.
Show more Show less"
2801160730,"Data Engineer - Spark, Python",FlexIT Global,2021-11-19,United States,United States,Information Technology,Contract,IT Services and IT Consulting,"This job is not open to C2C or 3rd party candidates.




FlexIT client has an immediate need for Data Engineer - Spark, PySpark, Python 12 months Remote contract in Portland, Oregon.




Top Skills: Python, Spark, PySpark, AWS, Machine Learning/Data Science, CI/CD integration




Job Description:

We are looking for a motivated and experienced Software Data Engineer to join our clients Advanced Analytics & Machine Learning team.
This is a unique opportunity to enhance & upgrade our next generation Data Science Platform that supports a dynamic team of data scientists, data engineers, and data analysts, all working on Demand Sensing related projects.




Job Duties:

We are looking for strong experience in Python, AWS, Machine Learning/Data Science, CI/CD integration and the ability work with cross functional team.
The work will also involve building and incorporate automated unit & integration tests into the Data science platform




Necessary Skills:

Programming: Python
AWS: at least 2 years
Experience building Machine Learning/Data Science applications
Understanding of data structures, data modeling and software architecture on cloud-based infrastructure
Experience with technologies like Kubernetes, Docker, Jenkins, Terraform
Big Data / Hadoop: 2 years, experience with Spark
Agile/Kanban/Scrum experience
Demonstrated communication and interpersonal skills
Ability to work well and thrive in a fast-moving culture with complex technology applications
Educational qualifications BS in Computer Science or related field







At Flex IT believes that diverse teams improve our business. We are an equal opportunity employer and do not discriminate based on race, religion, color, nationality, gender, sexual orientation, age, marital status, veteran status, or disability status.

Flex IT is an IT Services Firm dedicated to advancing the careers of IT Professionals. We work with some of the most recognized companies in the country to place IT professionals that stand out amongst their peers. Talented individuals need challenging opportunities. To discover your next great opportunity and begin to build a career path, contact us today.

Show more Show less"
2785693302,Python Data Engineer,"Gardner Resources Consulting, LLC",2021-12-04,United States,United States,Information Technology,Contract,Staffing and Recruiting,"Our IT Client has immediate openings for multiple Python Developers for a Data-Centric Project.

These Developers will be able to support this project while working remote for the duration of the contract.




Must Haves:

8+ years of Data Focused Development Work
Hands-on Python Development Experience
Hands-on experience with Data Pipeline Development and scaling
Experience with Pipeline maintenance (Ideally ELK pipeline maintenance)
Understands how to Create Indexes
Experience creating batch jobs
Data Analytics Background with the ability to understand the logic behind the data
Development/programming ability to write services and move data
Experience writing queries and developing dashboards with specific KPI’s
Excellent communication skills and the interest to work as part of an innovation team.

Nice to Haves:

Experience with NodeRED
Experience with ELK Stack
Experience with Kafka
Experience with Nginx

Show more Show less"
2804851059,Software Engineer - Data Support (US Remote),Dell Technologies,2021-11-23,United States,"Round Rock, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Hardware Manufacturing, and Computer Software","Software Engineer - Data Support

Be a part of a team that’s ensuring Dell Technologies' product integrity and customer satisfaction. Our IT Software Engineer team turns business requirements into technology solutions by designing, coding and testing/debugging applications, as well as documenting procedures for use and constantly seeking quality improvements.

Join us as a Software Engineer - Data Support on our Information Technology team as a remote employee to do the best work of your career and make a profound social impact.

What You’ll Achieve

As an Software Engineer - Data Support Engineer, you will deliver products and improvements for a changing world. Working at the cutting edge, you will craft and develop software for platforms, peripherals, applications and diagnostics — all with the most sophisticated technologies, tools, software engineering methodologies and partnerships.

You Will

Become a SME in the Product data lifecycle
Own eco system data to meet the necessary needs to replicate business

validation prior to production

Plan and coordinate all transaction data dependencies within the

Testing phase

Track and manage all requests to product related data
Understand and troubleshoot how data moves from one system to the next via the eco system
Heavy collaboration with the business and IT to ensure Testing data needs are met.
Collaborate with the Product Team to ensure release testing needs are met.

Take the first step towards your dream career

Essential Requirements

Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role:

Broad knowledge of supporting business processes and test data needs
Ability to run SQL queries
Strong understanding of intersystem dependency around primary applications and multiple secondary applications
Excellent team player, yet capable of managing multiple solo projects at once
Ability to quickly adapt to new information and develop comprehensive knowledge of systems being tested

Desirable Requirements

Bachelor’s degree or equivalent
3 to 5 years of experience in IT Testing and/or business process

Here’s our story; now tell us yours

Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress.

What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life -- while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more.

We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today.

You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here.

Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Equal Employment Opportunity Policy here.

Job Id: R148593Job Function: Information Technology
Show more Show less"
2825097008,Data Engineer,Centene Corporation,2021-12-02,United States,"St Louis, MO",Information Technology,Full-time,Insurance and Hospitals and Health Care,"Position Purpose

Contribute to the development and maintenance of real-time processing applications
Contribute to the creation and maintenance of optimal data pipeline architectures
Conduct maintenance and support for core infrastructure health, system upgrades, monitoring, CI/CD and logging
Research streaming best practices and proper stream architecture
Collaborate with team members to better understand existing data requirements and validation rules
Analyze trends in data sets and contribute to the development of algorithms in order to improve upon the usefulness of raw dataThis position will provide the Health Plan Systems with a platform for real-time stream processing by performing application and production support to help ensure the availability of streaming services and the continuous flow of data.

Education/Experience

Bachelor's degree in Computer Science, Computer Engineering, Software Engineering, related field or equivalent experience. Master’s degree in Computer Science or Computer Engineering preferred. 2+ years of experience in Computer Engineering, Software Development, System Administration, Linux Administration, DevOps and Site Reliability Engineering. Experience with the following programs/platforms is preferred Streaming Frameworks - Apache Spark, Apache Storm, Kafka K-Streams, Apache Samza, Apache Flink, Apache Apex, Apache Nifi and Apache Pulsar; Storage Technologies - MongoDB, Oracle, Teradata, Hadoop, DocumentDB, SQL Server, Volt DB, Apache Ignite, CockroachDB, Amazon Aurora and Redis; Linux – RedHat; Continuous Integration and Deployment – CloudBees, Jenkins, Ansible Tower, Puppet and Chef.

Centene is an equal opportunity employer that is committed to diversity, and values the ways in which we are different. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other characteristic protected by applicable law.
Show more Show less"
2804088800,Data Engineer,StackPath,2021-11-18,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","About StackPath

StackPath is a platform of secure Internet services built at the cloud's edge. StackPath services enable developers to build protection and performance into any cloud-based solution—from apps, to games, web sites, and beyond—without needing cloud security and delivery expertise of their own. More than 800,000 customers already use StackPath services, ranging from early-stage enterprises to Fortune 100 organizations. Headquartered in Dallas, Texas, StackPath has offices across the U.S. and around the world. For more information, visit stackpath.com and follow StackPath at

About The Role

We are looking for a Software Data Engineer to join our team. You will develop systems that enable data to be transformed and made actionable across the enterprise. The Data Engineer will also create algorithms and conduct statistical analysis to assist with optimizing the business. Overall, you’ll strive for efficiency by aligning data systems with business goals across all product lines.

To succeed in this role, you should have strong analytical skills, the ability to combine data from different sources, knowledge of machine learning methods, and familiarity with several programming languages.

If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you.

This role will report to: Data Engineering Architect

Essential Duties And Responsibilities

Analyzing raw data.
Developing and maintaining datasets.
Improving data quality and efficiency.
Model queries and build templates for querying large data sets.
Model events, notification and alerts.
Build optimal data systems and pipelines.
Transform raw data to actional data from various sources.
Analyze and interpret trends and patterns related to the data.
Conduct complex data analysis and reporting on results.
Prepare data for prescriptive and predictive modeling.
Build algorithms and prototypes.
Explore ways to enhance data quality and reliability.
Identify opportunities for data acquisition.
Develop analytical tools and programs.
Collaborate with data scientists and architects on several projects.


Desired Skills And Experience

Previous experience with data as a software engineer
Experience with Kafka and/or distributed messaging platforms
Technical knowledge and/or experience of streaming frameworks (e.g. Spark, Flink, Beam)
Technical knowledge with data models, data mining, and segmentation techniques
Knowledge of programming languages (e.g. Go, Java, Python)
Knowledge of cloud platforms (e.g. GCP, AWS, Azure)
Knowledge of distributed systems and architectures
Knowledge or experience with SQL and NOSQL database design
Strong numerical and analytical skills
Degree in Computer Science, IT, or similar relevant experience in the field
Data engineering certifications is a plus


This Job Description Is Not Intended To Be All-inclusive.

StackPath is an Equal Opportunity Employer. EOE/AA M/F/D/V

If your experience and qualifications match our current needs, a member of our human resources team will contact you. We look forward to hearing from you.

StackPath collects and processes personal data submitted by job applicants in accordance with our

Powered by JazzHR

aKcT4mVZsa
Show more Show less"
2799798879,Data Engineer,RC CONSULTING LIMITED,2021-11-15,United States,United States,,Contract,,"Looking for an IICS developer to assist with the migration of all on-premise Powercenter workflows to IICS. Candidates will be using the Informatica migration tool and validating/testing the large repository of workflows in Powercenter in IICS. Workflows are extracting data from Oracle database and Snowflake. 12-month contract beginning January 2022, fully remote.

Show more Show less"
2826879667,Data Engineer,Lockheed Martin,2021-12-01,United States,"King of Prussia, PA",Information Technology,Full-time,Defense and Space Manufacturing,"The coolest jobs on this planet… or any other… are with Lockheed Martin Space.

At the dawn of a new space age, Lockheed Martin is a pioneer, partner, innovator and builder. Our amazing men and women are on a mission to make a difference in the world and every day we use our unique skills and experiences to create, design and build solutions to some of the worlds’ hardest engineering problems. Our culture inspires employees to dream big, perform with excellence and create incredible products. We provide the resources, inspiration and focus and if you have the passion and courage, we want to build a better tomorrow with you.

Are you ready to create world-class solutions that keeps our critical space assets safe? Do you want to work in a fast-paced agile environment that can get a little rowdy at times? Do you research emerging technologies and enjoy keeping your skills sharp?

Then you will love the Space Security division of LM Space in King of Prussia, PA.

We want someone who is passionate about their craft, adamant about product quality and focused on our customer’s mission. We constantly measure our employee’s success and reward our top performers through salary increases, bonuses and awards.

You will have the opportunity to support IRAD, unclassified and classified projects. Along with developing new capabilities to meet program achievements, you will create software engineering artifacts that lead to new business wins. You will also get the chance to demo for the United States Government (USG) and cross-corporation events.

You will be designing state-of-the-art concepts while delivering innovative and affordable capabilities in a new and emerging area of protecting USG space assets. Be part of the team working on a mission that you can be proud of, knowing that you are making a lasting difference in the world and in space.

You will need to be eligible to obtain access to classified USG information or already hold clearances.

To promote the sharing of ideas, Lockheed Martin fosters an inclusive work environment that encourages differences and big-picture thinking.

Here Are Some Of The Benefits You Can Enjoy

Our employees play an active role in strengthening the quality of life where we live and work by volunteering more than 850,000 hours annually.

Medical
Dental
401k
Paid time off
Work/life balance
Career development
Mentorship opportunities
Rewards & recognition

Learn more about Lockheed Martin’s competitive and comprehensive benefits package.
Show more Show less"
2809436440,Data Integration Engineer,Riskified,2021-11-01,United States,"New York, NY",Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","About Us

Riskified empowers merchants and shoppers to realize the full potential of eCommerce by making it safe, accessible, and frictionless. Our global team helps the world’s most-innovative eCommerce merchants eliminate risk and uncertainty from their business. Merchants integrate Riskified’s machine learning platform to create trusted customer relationships, driving higher sales while reducing costs. Riskified has reviewed hundreds of millions of transactions and approved billions of dollars of revenue for global brands and fast-growing businesses across industries, including Wayfair, Wish, Peloton, Gucci, and many more. As of July 29th, 2021, Riskified has begun trading on NYSE under the ticker RSKD.

About The Role

As a Data Integration Engineer at Riskified, you will be using technical skills, analytical insights and business perspective to ensure we have the most accurate and complete data set from each client. You will be responsible for helping new and existing customers to ensure they are receiving the best performance possible and leading the change on processing the data of the largest eCommerce merchants in the world. Riskified’s clients come in many different sizes and industries, use different technical platforms, and each one has their own unique data concerns and order flows that have to be uniquely assessed. Our team is the one to fully capture these aspects and recommend the best implementation as well as point out any possible issues.

What You'll Be Doing

Supporting the onboarding of new customers by completing the following:

Working with some of the largest companies in the world to perform comprehensive analysis of their data
Perform due diligence of business models and flows
Data modeling as part of the integration architecture
Combining the technical, business and analytical objectives to come up with tailored solutions for onboarding merchants
Data wrangling & sanitization
Prioritize, track, and communicate data issues internally and externally
Become the subject matter expert of riskified product and technology
Work closely with analysts, research and data science teams to accommodate changes in industry data
Perform comprehensive analysis of chargebacks data

Monitoring and resolving data irregularities of existing customers by completing the following:

Monitor key health indicators and automated alerts
Identify, research, and offer system-wide solutions for common issues
Work closely with Account Management to engage customers

Qualifications

3+ years of experience in a data-centric industry role (ETL, DBA, etc.)
2+ years with SQL or NoSQL databases
2+ years experience with data wrangling (R, Python for data processing)
2+ years with optimizing technical processes
Strong verbal and written communication skills
Eagerness to learn new technical concepts
Strong analytical skills and attention to detail

Life at Riskified

We are a fast-growing and dynamic tech company with 650+ team members globally. We value collaboration and innovative thinking. We’re looking for bright, driven, and passionate people to grow with us.

COVID-19 Update

Our NYC team is currently working remotely. If anyone prefers to work in our office, we’re happy to offer an option to do so safely.
When the situation improves, we’re looking forward to adapting a hybrid of remote and in-office work for all our team members.
We’re growing at a rapid rate and have transitioned all our interviews to Zoom.

Some Of Our NYC Benefits & Perks

Fully-covered medical, dental, and vision insurance from your first day
Equity for all employees, 401(k) + matching, commuter benefits
Catered lunch, fully-stocked kitchen, team events, happy hours, birthday celebrations
Yoga, pilates, soccer league, wellness classes
Wide-ranging opportunities to volunteer and make an impact in local communities
Commitment to your professional development with global onboarding, sales bootcamp, skills-based courses, full access to Udemy, lunch & learns
Awesome Riskified gifts and swag!

In The News

FoxBusiness: Fraud Protection Platform 'Riskified' Begins Trading on NYSE

Reuters: General Atlantic-Backed Riskified is Valued at 4.3 BLN in NYSE Debut

Fortune Magazine: 25 Best Workplaces in New York

Announcing Riskified's $165M Funding Round

Inc Magazine: Best Workplaces

Built In NYC: 100 Best Workplaces

TechCrunch: Riskified Prevents Fraud on Your Favorite eCommerce Site

Calcalist: Riskified is the Most Promising Startup

Riskified is deeply committed to the principle of equal opportunity for all individuals. We do not discriminate based on race, color, religion, sex, sexual orientation, national origin, age, disability, veteran status, or any other status protected by law.
Show more Show less"
2814243530,Remote Data Engineer,Toughbyte,2021-11-30,United States,United States,,Full-time,,"Our partner provides a smart enterprise platform that builds a deep language intelligence operating system for technical domains, including Insurance, Financial Services, and Life Sciences. Their platform, built by the former leadership of the MIT Media Lab, harnesses AI and Natural Language Understanding to deliver new capabilities to augment human performance. Their NLU platform is a pre-built “no-code” drag and drop solution to reduce the deployment time of applications from months to days.




Now they are looking for a Data Engineer experienced with orchestration of data and ML pipeline workflows and writing batch and stream data processing pipelines for: ingestion, ETL, and analytics.




Tasks:

Collaborate with the VP Eng. on the overall data strategy for the B2B SaaS applications and API functionality delivery, breaking down tasks into manageable and achievable deliverables
Work cross-functionally with AI scientists, Backend Engineers, DevOps and Product Managers to design and implement new data models for the product line
Expand the current data-processing framework to include all active projects across multiple environments
Process unstructured data into a form suitable for analysis
Mentor other data engineers on best practices
Understand the products from a customer perspective and the software from an engineering perspective
Own assignments from proof-of-concept to design, architecture, code delivery, and deployment




Must-have: 

Strong programming skills in Python 
Experience working with Google Cloud Composer (Airflow) 
Experience with Google Cloud DataFlow or Apache Beam and its runners (knowing how things work under the hood is a plus)
Experience with Elasticsearch and PostGres and an interest in learning Graph databases (Neo4j and DGraph)
Experience with DataLakes, Google Cloud Storage




Nice-to-have: 

Knowledge of other programming languages
Knowledge of other workflow orchestration tools
Knowledge of S3, Delta lake
Familiarity with dashboard technologies (Looker, Ploty, Tableau, Grafana, ELK, etc.)
Familiarity with scaling (Redis, SQL, Elasticsearch, PostGres, Graph Dbs, Kafka, etc.)
Knowledge of data warehousing and ETL concepts
Familiarity with AWS equivalent tech stack: Glue, EMR, Data Pipelines
Data security, sub-second latency, Machine Learning and NLP experience




Benefits:

Fully-remote position
Additional vacation week between Christmas and New Year




Interview process:

Intro call with Toughbyte
1-2 hour Technical interview with VP of Engineering 
1h call with the team
Show more Show less"
2784455614,Data Engineer,Discover Claims,2021-11-08,United States,"Charlotte, NC",,Full-time,,"Job Overview 

We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will partner with our Data Team on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. For more information, please visit www.discover-claims.com. Candidate must reside in Charlotte, NC.  




Responsibilities for Data Engineer 

Create and maintain optimal data pipeline architecture 
Assemble large, complex data sets that meet functional / non-functional business requirements. 
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. 
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. 
Manage analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. 
Work with Data Team to assist with data-related technical issues and support their data infrastructure needs. 
Work with data and analytics experts to strive for greater functionality in our data systems. 
Ability to communicate across both technical and non-technical teams and translate technical language into non-technical terminology. 
Given a set of needs and conditions, develop technical solutions with actionable steps and present them to a non-technical audience. 




Qualifications:

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. 
Experience building and maintaining stored procedures, using API integration. 
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. 
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. 
Build processes supporting data transformation, data structures, metadata, dependency and workload management. 
A successful history of manipulating, processing and extracting value from large, disconnected datasets. 
Working knowledge of message queuing, batch processing, and highly scalable ‘big data’ data stores. 
Strong project management and organizational skills. 
Experience supporting and working with cross-functional teams in a dynamic environment. 
We are looking for a candidate with 2+ years of experience in a Data Engineer role, who has attained a bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field and an advanced degree or certification in Data Engineer. 




Preferred Competencies: 

Experience with data pipeline and workflow management tools 
Experience with stream processing 
Experience with big data tools: Hadoop, Spark, etc 
Experience with AWS cloud services: EC2, EMR, RDS, Redshift 
Experience with object-oriented/object function scripting languages: Python, .NET 




Salary and Incentives: 

Compensation: Comparable to market rate for a data engineer with 2 years of experience 
FTE, PTO, health benefits and IRA matching, some remote work available 

 

 

Show more Show less"
2808120328,Data Engineer,Deckers Brands,2021-11-25,United States,"Brooklyn, NY",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2822811009,Data Engineer,Lockheed Martin,2021-11-07,United States,"King of Prussia, PA",Information Technology,Full-time,Defense and Space Manufacturing,"The coolest jobs on this planet… or any other… are with Lockheed Martin Space.

At the dawn of a new space age, Lockheed Martin is a pioneer, partner, innovator and builder. Our amazing people are on a mission to make a difference in the world and every single day we use our skills and experiences to create, design and build solutions to some of the worlds’ hardest engineering problems. Our culture encourages employees to dream big, perform with excellence and create incredible products. We provide the resources, inspiration and focus and if you have the passion and courage to dream big, we want to build a better tomorrow with you.

The 21st Century Warfare Program is looking for a motivated Data Engineer to join our Joint All Domain Operations Center (JADOC) team. This application is for the next generation of all domain capabilities; built in preparation for live real world exercises. The ideal candidate has a passion and enthusiasm towards handling such complex efforts.

In This Role You Will

Respond with agility and purpose when interacting with stakeholders from multiple business areas, not exclusively Space.
Be focused on aiding a team to develop new data oriented software that tracks and maintains knowledge of entities across the globe.
Help design the database that will be the core of this application.
Aid the team in data management and querying.
Construct displays to show the stored data and analytics on it.
Clearly communicate ideas and collaborate with their team and others.

Typically has 9 - 15 years of professional experience.

To promote the sharing of ideas, Lockheed Martin fosters an inclusive work environment that encourages differences and big-picture thinking.

Here Are Some Of The Benefits You Can Enjoy

Our employees play an active role in strengthening the quality of life where we live and work by volunteering more than 850,000 hours annually.

Medical
Dental
401k
Paid time off
Work/life balance
Career development
Mentorship opportunities
Rewards & recognition

Learn more about Lockheed Martin’s competitive and comprehensive benefits package.
Show more Show less"
2797854844,Backend Data Engineer (SWE),Haystacks.AI,2021-11-16,United States,"New York, NY ",,Full-time,,"Backend Data Engineer (Senior-Lead Level)

Haystacks.ai | New York City




About us: 

Haystacks.ai is turning antiquated ""back of the napkin"" style residential real estate investing into actual science based on human behavioral data.  We are building an engine that collects over a billion individual data points on a weekly basis and uses machine learning techniques to produce a shortlist of buy and sell signals for real estate investment strategies. 




Haystacks recently concluded its seed financing with participation from leading venture capital firms in the US. The founding team includes 2 serial entrepreneurs with a track record of multiple exits and several billion dollars in capital raised to date.




About the role:

What excites us about Haystacks is the application of a wide spectrum of human behavioral data points, previously never applied in the world of real estate-, and using them to produce a buy/sell decision on properties. This presents an opportunity for researching, organizing, and unifying these data points into a data lake in order to develop best-in-class machine learning algorithms on it.  




Haystacks.ai is looking to hire a senior backend data engineer to join the core data team.  You’ll work closely with the founding team to architect and build the Haystacks engine.  




Responsibilities:

Architect and contribute to the core infrastructure of the Haystacks platform
Develop data pipelines that enable investment professionals and portfolio managers to efficiently extract insights from alternative data
Master data model management
Develop and maintain CI/CD pipelines
REST API Development

Qualifications:

Research mentality: Eager to learn the domain, study new and existing data sources, analyze them, provide recommendations, and document and present findings elegantly
At least highly proficient in Python,SQL and Terraform
Proven experience designing, developing, and optimizing scalable, reliable, and maintainable ETL data pipelines 
Experience transforming and manipulating large volumes of data leveraging a serverless architecture
Proven success working with relational and unstructured databases/data lakes/data warehouses
Knowledge of either message queuing, stream processing, or highly scalable ‘big data’ data stores
Exposure to ML Ops







Nice to Haves:

At least 5+ years of data engineering/data science experience or 3+ years with a graduate degree in a relevant technical/STEM field 
Real Estate or Finance experience




Benefits:

Haystacks.ai offers a comprehensive benefits package that includes a competitive total compensation of salary and equity and generous PTO
While we are currently temporarily working remotely due to COVID-19, this position will be based in our New York office.  
Opportunity to join a promising early-stage startup with exponential upside potential
Pet-friendly office!




Haystacks is proud to be an equal employment opportunity and affirmative action employer. We do not discriminate based upon race, religion, color, national origin, gender, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.







Show more Show less"
2816176407,Technology Engineer (Data Engineer),PNC,2021-11-16,United States,"Raleigh, NC",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Banking, and Financial Services","Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. We work together each day to foster an inclusive workplace culture where all of our employees feel respected, valued and have an opportunity to contribute to the company’s success.

As a Technology Engineer (Data Engineer) for PNC's Security Analytics Hub, you will have the opportunity to work fully remote. Our team focuses on producing data driven insights into multiple areas of risk facing the bank, including cybersecurity and physical security.

Day To Day Responsibilities

Acquire/map datasets that align with our business partner needs
Develop algorithms that shape data into useful and actionable information
Build, test, and maintain database pipeline architectures
Collaborate with management to understand and meet company objectives
Form new data validation methodologies and data analysis tools
Ensure continued compliance with data security policies and governance

Technical Qualifications

Education: BS/BA in technical discipline
5+ years of Python development
5+ years of experience with development/decomposition of complex SQL (RDMS Platforms)
3+ years of experience with test-driven development. Continuous Integration/ Development (e.g. GIT, Jenkins, Maven)
3+ years with CRON/Shell Scripting
Experience with utilization of REST API and/or EDPI
Hands on experience with project management tools such as JIRA, Confluence
Ability to work with end users (BI analysts, data scientists, etc.) to solve technical issues
Experience working in an Agile Team construct
Extensive knowledge of databases, data warehouses, systems integrations, and data flows is mandatory for this role.
Additionally, candidates should be well-versed in data architecture, data development, with a proven history of providing effective data solutions.

Required Skills To Be Considered For This Role

Coding: Proficiency in coding languages is essential to this role. Common programming languages used by the team include SQL, Python.
Relational and non-relational databases: You should be familiar with both relational and non-relational databases, and how they work (Teradata, Oracle, etc).
ETL (extract, transform, and load) systems: Moving data from databases and other sources into a single repository, like a data warehouse.
Data storage knowledge: As solutions are designed, when to use a data lake versus a data warehouse, for example.
Automation and scripting. Candidate should be able to write scripts to automate repetitive tasks (e.g. Cron jobs, Linux, shell scripting).
Big data tools: Understanding of Hadoop, MongoDB, and Kafka helpful, but not required.
Data security: Securely managing and storing data to protect it from loss or theft per PNC guidelines.

Job Description

Leverages technical knowledge and industry experience to design, build and maintain technology solutions. Assists with selecting appropriate platforms, integrates and configures solutions.
Develops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.
May provide consultation on common issues and best practices for junior staff.
Provides a systematic analysis on client requirements within the traceability framework and resolves any functional problems encountered.
Ensures quality of project deliverables while maintaining compliance with relevant standards and processes.

PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:

Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.

Competencies

Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.

Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.

Effectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.

Emerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.

Industry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.

IT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).

IT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.

Planning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.

Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Work Experience

Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

Education

Bachelors

Additional Job Description

COMPENSATION

Base Salary

$55,000 to $142,600

Role

Placement within the compensation range is based on the specific role and the following factors

Where a person is paid in the compensation range is aligned to their experience and skills.

– Lower in range –Building skills and experience in the job

– Within the range–Experience and skills align with proficiency in the role

– Higher in range –Experience and skills add value above typical requirements of the role

– Compensation Range may vary based on Geographic Location

INCENTIVE

Role is incentive eligible with the payment based upon company, business and individual performance.

Benefits

PNC offers employees a comprehensive range of benefits to help meet your needs now and in the future. Depending on your eligibility, options for full-time employees include medical/prescription drug coverage (with a Health Savings Account feature); dental and vision options; employee and spouse/child life insurance; short- and long-term disability protection; maternity and parental leave; paid holidays, vacation days and occasional absence time; 401(k), pension and stock purchase plans; dependent care reimbursement account; back-up child/elder care; adoption assistance; educational assistance and a robust wellness program with financial incentives. To learn more about these and other programs, including benefits for part-time employees, visit pncbenefits.com > New to PNC.

Disability Accommodations Statement

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.

The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO)

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.

California Residents

Refer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.
Show more Show less"
2820806575,Cloud Data Engineer,Accenture Federal Services,2021-11-30,United States,United States ,Information Technology,Full-time,IT Services and IT Consulting,"We are:

Accenture Federal Services, helping our federal clients tackle their toughest challenges while unleashing their fullest potential…and then some. What makes our approach so unique? Operating from the nation’s capital, we bring together commercial innovation and leading-edge technologies to deliver an integrated and interactive experience that far exceeds expectations. How? Our passion meets purpose! Through our diverse culture and inclusive thinking, we embrace our employees' ideas taking them from concept to practical solutions. Not to mention, we sleep well at night knowing our work directly impacts and improves the way the world works. We keep our tech smarts sharp by providing abundant training and certification opportunities. Through our diverse culture, workforce, and inclusive thinking, we embrace our employees' ideas, taking them from concept to practical solutions. Are you ready to learn and grow in a career, while making a difference?




You are:

The ideal candidate will understand the state-of-the-art algorithms in the area of computer vision and how to build efficient and scalable deep learning models and has facility to turn the latest research literature into functional prototypes.




The work:

You will solve unique client problems using computer vision and will be responsible for supporting the research, design, analysis, and development of high-performance deep learning algorithms. You will be developing novel approaches and applying advanced computer vision capabilities to challenging use cases, from biometrics to geospatial applications or 3D vision.

The ideal candidate will understand the state-of-the-art algorithms in the area of computer vision and how to build efficient and scalable deep learning models. Finally, the ideal candidate has facility and experience turning the latest research literature into functional prototypes.




Here’s what you need:

Skills with Python, Tensorflow, Keras, and/or PyTorch
Experience developing Computer Vision specific systems (multiple projects)
Domain expertise in specific areas of computer vision: object detection, image classification, semantic segmentation, etc.
Required coursework (one or more): Image processing, computer vision, deep learning, machine learning.
M.S. degree in computer science or electrical engineering.




Bonus Points:

Ph.D. degree in computer science or electrical engineering.
Unix/Linux experience (Debian/RHEL) and comfort with basic shell operations.
Excellent documentation habits to include code documentation, technical papers, readme files, etc.
Experience working with structured and unstructured data (point clouds, raster/vector geospatial data, images, and videos, etc.).

Show more Show less"
2820846434,Data Engineer,FilmRise,2021-11-30,United States,"Brooklyn, NY",Engineering,Full-time,Motion Pictures and Film,"FilmRise is looking to hire a Data Engineer to build and maintain a fast-expanding library of ETL/ELT and analytics engineering orchestrations in support of key KPI and data quality controls across our cloud data stack. The person in this role will report to the Senior Manager, Analytics, and will work cross-functionally with a variety of technical and non-technical stakeholders to design and implement scalable solutions that help realize transformative data science and reporting products in a dynamic streaming entertainment environment.







Responsibilities:

Work with variety of teams to onboard data and support an expanding suite of reporting, advanced analytic and operational directives
Scope and design optimal schema in accordance with modeling best practices for appropriate analytic and operational use-cases
Maintain and expand core ETL orchestrations with an emphasis on augmenting data observability and controls across different layers of the stack
Contribute new features with requisite unit/integration testing, QA and UAT
Conduct ad hoc data analysis as needed towards data quality and coverage inquiries
Collaborate closely with data science stakeholders to identify and build out optimal inputs for predictive modeling and machine learning methodologies




Basic Qualifications:




Technical:

2+ years of relevant work experience
1+ year as an individual contributor / maintainer of batch, streaming pipelines + orchestrations in a data warehousing or data science context
Proficiency in general purpose programming languages, preferably python and bash (node.js a plus)
Strong foundations in data modeling, (dimensional, object, app access patterns) and transformations (pandas, regex, fuzzy matching)
SQL foundations writing/tuning complex, efficient analytic queries, experience building workflows / programs with ORM functionality (SQLAlchemy)
Development lifecycle fundamentals: automated testing (pytest, selenium), source control workflows (git, GitHub Actions), code refactoring
Familiarity with Tableau data interfaces, architecture, optimizations, visuals




Written/Collaborative:

Ability to translate strategic directives and tactics into implementations
Ability to translate designs, implementations into documentation (ERDs, UML, docstring)
Adept at gathering feedback and requirements from technical and non-technical stakeholders




Preferred Qualifications:

Experience with Cloud Data tooling (AWS, GCP)
Experience with Airflow, Luigi or other related orchestration tool
Experience within big data ecosystem (HDFS, SparkSQL, Presto, columnar file formats [parquet, ORC])




Bonus:

serverless tooling (AWS Lambda/step functions, serverless framework, AWS chalice)
Web Frameworks (Django, Flask, React)
containerization (Docker, AWS ECS, Kubernetes)
DBT




If you are a qualified candidate, please send an updated resume and cover letter to HR@filmrise.com.

FilmRise is an equal opportunity employer.

Show more Show less"
2792477224,Big Data Engineer,Alignment Healthcare,2021-10-20,United States,"Orange, CA",Engineering and Information Technology,Full-time,"Insurance, Wellness and Fitness Services, and Hospitals and Health Care","Job Number: 3064

Position Title: Data Engineer

External Description

Alignment Healthcare was founded with a mission to revolutionize health care with a serving heart culture. Through its unique integrated care delivery models, deep physician partnerships and use of proprietary technologies, Alignment is committed to transforming health care one person at a time.

By becoming a part of the Alignment Healthcare team, you will provide members with the quality of care they truly need and deserve. We believe that great work comes from people who are inspired to be their best. We have built a team of talented and experienced people who are passionate about transforming the lives of the seniors we serve. In this fast-growing company, you will find ample room for growth and innovation alongside the Alignment community.

Position Summary

The Data Engineer will develop a new data engineering platform that leverage a new cloud architecture and will extend or migrate our existing data pipelines to this architecture as needed. You will also be assisting with integrating the SQL data warehouse platform as our primary processing platform to create the curated enterprise data model for the company to leverage. You will be part of a team building the next generation data platform and to drive the adoption of new technologies and new practices in existing implementations. You will be responsible for designing and implementing the complex ETL pipelines in cloud data platform and other solutions to support the rapidly growing and dynamic business demand for data and use it to deliver the data as service which will have an immediate influence on day-to-day decision making.

General Duties/Responsibilities (may Include But Are Not Limited To)

Interfacing with business customers, gathering requirements and developing new datasets in data platform
Building and migrating the complex ETL/EDI pipelines from on premise system to cloud and Hadoop/Spark to make the system grow elastically
Identifying the data quality issues to address them immediately to provide great user experience
Extracting and combining data from various heterogeneous data sources
Designing, implementing, and supporting a platform that can provide ad-hoc access to large datasets
Modelling data and metadata to support machine learning and AI

Supervisory Responsibilities

N/A

Minimum Requirements

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Minimum Experience

3+ years relevant experience in cloud based data engineering.
Requires Spark and Scala
Demonstrated ability in data modeling, ETL development, EDI Development and data warehousing.
Data Warehousing Experience with SQL Server, Oracle, Redshift, Teradata, etc.
Experience with Big Data Technologies (NoSQL databases, Hadoop, Hive, Hbase, Pig, Spark, Elasticsearch etc.)
Experience in using Scala, .net, Java, Python and/or other data engineering languages
Knowledge and experience of SQL Server and SSIS.
Experience with X12(837,834,278) and HL7 transactions

Education/Licensure

Bachelors or Masters in Computer Science, Engineering, Mathematics, Statistics, or related field

Other

Excellent communication, analytical and collaborative problem-solving skills
Building and migrating the complex ETL/EDI pipelines from on premise system to cloud and Hadoop/Spark to make the system grow elastically
Preferred
A Healthcare domain and data experience
Healthcare EDI experience is a plus
API development experience is a plus
Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
Experience building data products incrementally and integrating and managing datasets from multiple sources
Experience leading large-scale data warehousing and analytics projects, including using Azure or AWS technologies – SQL Server, Redshift, S3, EC2, Data-pipeline, Data Lake, Data Factory and other big data technologies
Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space
Linux/UNIX including to process large data sets.
Experience with Azure, AWS or GCP is a plus
Microsoft Azure Certification is a plus
Demonstrable track record dealing well with ambiguity, prioritizing needs, and delivering results in an agile, dynamic startup environment
Problem solving skills and Ability to meet deadlines are a must
Microsoft Azure Certification is a plus
Python and Java are a plus
Experience with X12(837,834,278) and HL7 transactions preferred

Work Environment

The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Essential Physical Functions

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

While performing the duties of this job, the employee is regularly required to talk or hear. The employee regularly is required to stand, walk, sit, use hand to finger, handle or feel objects, tools, or controls; and reach with hands and arms.
The employee frequently lifts and/or moves up to 10 pounds. Specific vision abilities required by this job include close vision and the ability to adjust focus.
Alignment Healthcare, LLC is proud to practice Equal Employment Opportunity and Affirmative Action. We are looking for diversity in qualified candidates for employment: Minority/Female/Disable/Protected Veteran.
If you require any reasonable accommodation under the Americans with Disabilities Act (ADA) in completing the online application, interviewing, completing any pre-employment testing or otherwise participating in the employee selection process, please contact careers@ahcusa.com.

City: Orange

State: California

Location City: Orange

Location State: California

Community / Marketing Title: Big Data Engineer

Company Profile

Alignment Healthcare was founded with a mission to revolutionize health care with a serving heart culture. Through its unique integrated care delivery models, deep physician partnerships and use of proprietary technologies, Alignment is committed to transforming health care one person at a time.

By becoming a part of the Alignment Healthcare team, you will provide members with the quality of care they truly need and deserve. We believe that great work comes from people who are inspired to be their best. We have built a team of talented and experienced people who are passionate about transforming the lives of the seniors we serve. In this fast-growing company, you will find ample room for growth and innovation alongside the Alignment community.

EEO Employer Verbiage

On August 17, 2021, Alignment implemented a policy requiring all new hires to receive the COVID-19 vaccine. Proof of vaccination will be required as a condition of employment subject to applicable laws concerning exemptions/accommodations. This policy is part of Alignment’s ongoing efforts to ensure the safety and well-being of our staff and community, and to support public health efforts.

Alignment Healthcare, LLC is proud to practice Equal Employment Opportunity and Affirmative Action. We are looking for diversity in qualified candidates for employment: Minority/Female/Disable/Protected Veteran.

If you require any reasonable accommodation under the Americans with Disabilities Act (ADA) in completing the online application, interviewing, completing any pre-employment testing or otherwise participating in the employee selection process, please contact careers@ahcusa.com.
Show more Show less"
2721106585,Senior Big Data Software Engineer,Zillow,2021-11-22,United States,United States,Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Financial Services","About The Team

Zillow is disrupting real estate by empowering people to unlock life's next chapter! The Zillow Data Engineering team supports multiple lines of business and is responsible for implementing, operating and improving data pipelines and creating data sets to empower Zillow Group brands and customers. We achieve this goal by building and deploying highly scalable data pipelines, adhering to software/data engineering best practices and ensuring the quality of our data to the delight of our consumers.

About The Role

In this role, you will evangelize and build Data Products for customer, property and business-specific data to simplify critical ML and Analytics products, like the Zestimate and pricing of Zillow-owned homes, to enrich the customer experience, and simplify marketing operations. You will partner with other data engineering teams and platform teams within AI to lead the architecture, implementation, and operations of big data pipelines and tools for building high-quality data marts.

As a Member Of This Team, You Will

Architect, design, build, implement and support data pipelines/products to serve ML and Analytical use cases
Collaborate with product managers, engineers, data scientists, and analysts on mission-critical property data needs to build world-class datasets
Identify opportunities to evangelize and support existing data processes
Contribute back to common tooling/infrastructure to enable self-service tooling to expedite customer onboarding

This role has been categorized as a Remote position. “Remote” employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.

In Colorado, the standard pay range for this role is $154,000.00 - $246,000.00 Annually. This range is specific to Colorado and may not be applicable to other locations.

Who you are

5+ years software development experience with very high proficiency in Python or Scala or Java.
Led the design/implementation of config driven, scalable, reliable services and workflows/pipelines using EMR, Kafka, Spark, Hive, Airflow or equivalents.
Experienced in establishing and promoting high standards in pipeline monitoring, data validation, testing, etc.
You have deep experience in applying automation to data engineering (DataOps).
Passionate about data engineering / analytics and distributed systems.
Excellent interpersonal skills and passionate about collaborating across organizational boundaries.
Comfortable distilling informal customer requirements into problem definitions, resolving ambiguity and balancing challenging objectives.
Passionate about mentorship, and coaching/onboarding/leading teammates.
A degree in Computer Science or a related technical field; or equivalent work experience
Here at Zillow - we value the experience and perspective of candidates with non-traditional backgrounds. We encourage you to apply if you have transferable skills or related experiences.

In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location.

Get to know us

Zillow is reimagining real estate to make it easier to unlock life’s next chapter.

As the most-visited real estate website in the United States, Zillow® and its affiliates offer customers an on-demand experience for selling, buying, renting or financing with transparency and nearly seamless end-to-end service. Millions of people visit Zillow and its affiliate sites every month to start their home search, and now they can rely on Zillow to help them finish it — and no matter what job you're in, you will play a critical role in making this vision a reality.

At Zillow, we're powered by our innovative and inclusive work culture, where everyone has the flexibility, support and resources to do the best work of their careers. Our efforts to streamline the real estate transaction is supported by our passion to redefine the employee experience, a deep-rooted culture of innovation, a fundamental commitment to Equity and Belonging, and world-class benefits. But don't just take our word for it. Read our reviews on Glassdoor and recent recognition from multiple organizations, including: Fortune’s 100 Best Companies to Work For® List 2021 Bloomberg Gender-Equality Index 2021, Human Rights Campaign (HRC) Corporate Equity Index and HRC’s Best Place to Work for LGBTQ Equality 2021, Fortune Best Workplaces for Technology 2020, Fortune Best Workplaces for Millennials 2020, Fortune Best Workplaces for Parents 2020, and the Deloitte Technology Fast 500.

Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com.

Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.
Show more Show less"
2817112686,Analytics Engineer,Palmetto,2021-12-02,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Renewable Energy Semiconductor Manufacturing, and Computer Software","Company Introduction

Palmetto is a VC-backed high-growth company with a promote-from-within culture for talent development. We offer excellent traditional benefits such as unlimited vacation, medical, dental, and vision coverage, and retirement plans. Our #1 Value is Customer Experience and we pride ourselves on over-delivering. To learn more about our services visit Palmetto.com.

Palmetto is a clean technology company with a soul. Fundamental to our mission is “Leading the world to a clean energy future.”

About the Data & Analytics Team

The Data & Analytics team is on a mission to empower the fast-iterating machine that is Palmetto. For us, Mission Accomplished is an unprecedented leveraging of data across the organization, enabling everyone at Palmetto to move smarter and faster. Our team’s North Star is the safekeeping of a single source of truth for all of the business, and we accomplish this through careful data modeling and rigorous data quality testing.




Summary of Role

The Analytics Engineers are the lifeblood of our data team. In your day-to-day, you will help build and be accountable for the analytics layer of our team’s data environment, making data standardized and easily accessible. You will drive optimization, documentation, testing, and tooling to improve data quality and give more autonomy to data analysts, scientists, and business users.




Primary Job Duties

Contribute to building and refining a data warehouse with dbt
Translate production data from multiple sources into facts and dims
Ship data products iteratively




Qualifications

You know, love, and have 1-2 years of hands-on experience using dbt (data build tool)
You write tests, document your models, and iteratively develop within dbt
You have experience with Postgresql-like SQL dialects (we use Snowflake)
Experience with Great Expectations is a definite plus







Equal Employment Opportunity

Palmetto embraces diversity and is an Equal Employment Opportunity employer. Employment is decided on the basis of qualifications, merit, and business need. We do not discriminate based upon race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or any other status protected under federal, state, or local law.




Palmetto is leading our world toward a clean energy future with revolutionary technology, full turnkey sales services, industry-leading logistics, thousands of solar panel installations, and an endless passion for all things sustainable. We’ve structured, financed, and developed clean energy projects across 4 continents and 22 countries, and we’re not stopping anytime soon. We are a high growth company with a promote-from-within culture. We offer excellent traditional benefits such as unlimited vacation, medical, dental, and vision coverage.




For more about our Privacy Policy, visit: https://palmetto.com/privacy-policy

Show more Show less"
2798099961,Data Engineer,"KGS Technology Group, Inc",2021-11-19,United States,United States,,Full-time,,"· 3 years of experience developing Data Pipelines for Data Ingestion or Transformation using Java or Scala or Python
· 2 years experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc..) At least 3 years of developing applications with Monitoring, Build Tools, Version Control, Unit Test, TDD, Change Management to support DevOps
· 3 years of experience with SQL and Shell Scripting experience
· 2 years of experience with software design and must have an understanding of cross systems usage and impact
· Must have expertise in Spark, Kafka, AWS, SQL
· Must score 70% or higher on Glider

Desired Experience:

· 2+ years of experience working with Dimensional Data Model and pipelines in relation with the same
· 2+ years experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service
· 2+ years of experience working with Streaming using Spark or Flink or Kafka or NoSQL Intermediate level experience/knowledge in at least one scripting language (Python, Perl, JavaScript)
· Hands on design experience with data pipelines, joining data between structured and unstructured data
Show more Show less"
2788368541,Data Engineer III,Bank of America,2021-10-17,United States,"Addison, TX",Information Technology,Full-time,"IT Services and IT Consulting, Banking, and Financial Services","Job Description:

Position Summary

The Data Engineer III collects, analyzes, tests and researches data to support the LADMT data management strategy. This position interacts with both technical and non-technical resources to develop and maintain data inventories, reporting, and data classification. Will provide technical direction and system architecture advice for individual initiatives which will include structured and unstructured data sources. Serves as a fully seasoned/proficient technical resource. May collaborate with external programmers to coordinate delivery of software and process solutions. Routine accountability is for technical knowledge and capabilities. Works under minimal supervision. This position is for a self-starter with leadership qualities, responsible for formulating and managing medium to small-sized projects, as well as assisting in strategy development and roadmaps to deliver high value enterprise data management solutions.

Required Skills

Bachelor's Degree in Computer Science/related field or Equivalent working experience.
Minimum 5 -7+ years of applicable experience.
Knowledge of Information Architecture concepts (Metadata, Classification, Data Mapping. Etc.)
Knowledge of Big Data concepts and tools (Hadoop)
Proficient in Data Management and Analysis.
Trustworthy teammate and strong collaborator.
Strong Office Product skills (Microsoft, Excel, PowerPoint, Visio)
Ability to manage multiple and mixed priorities.
Technical knowledge and experience.
Advanced SQL skills.
Knowledge of ETL and Data Analytics concepts and tools (i.e. python, R, SSIS, etc.)
Strong Communication skills – verbal and written.
Attention to detail and ability to work with minimal instruction.
Process mapping and design.
Lead and adapt to change and transformation.

Desired Skills

Knowledge of Reporting tools (MicroStrategy, Tableau, eSMART)
Knowledge of Data Quality practices and Use Case testing scenarios.
Knowledge of Agile project management concepts.
Knowledge of Information Architecture concepts (Metadata, Classification, Data Mapping. Etc.)
Experience working with structured and unstructured data.

Show more Show less"
2822834603,Data Developer,Ramsey Solutions,2021-12-02,United States,"Franklin, TN",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Description

Are you an experienced data developer who isn't ready to apply but is interested in hearing more? Click here to request an informal virtual coffee meeting with one of our developers!

Eight out of 10 Americans live paycheck to paycheck, and more than 50% of Americans have less than $10,000 saved for retirement. That’s not okay! We’ve been told the lies that debt is normal, credit cards are a way of life, and you can’t buy a car without payments. Enough is enough. It’s time for the Ramsey Boot. Our goal is to cause so much disruption to the toxic money culture of this country that we’ll force the financial industry to shift its strategies and how it operates. We exist to provide biblically based, common-sense education and empowerment that give HOPE to everyone in every walk of life. For the past 30 years, we’ve helped millions claw their way out of debt and change their family tree. If you’re passionate about joining this rebellious crusade, apply today!

About The Role

To learn about our Data Engineering team, check out this blogpost on our internal tech blog, Ramsey In-House. This Data Engineer will be responsible for all aspects of data integrity for products that impact millions of families across the country. In this role, you’ll be utilizing our data platform to consolidate and design data structures for our critical business metrics and reporting systems. Your efforts will directly affect how we measure our key performance indicators and track user engagement with our products. You’ll be working with our business leaders and technology teams to deliver solutions that support our data analysts and software engineers, while driving improvements in our data platform system.

What Winning In This Role Looks Like

Designing analytical models that advance business stakeholders’ ability to assess the impact their products are having on those we serve
Enabling systematic and ad hoc analyses by writing code that integrates, aggregates, and conditions data from myriad sources
Using a wide variety of technologies and custom tools to optimize queries, enrich raw data, and improve access to it
Continuously learning and perfecting your craft as a programmer and modeler
Partnering with members of the data analytics team to translate business metrics into models and automated workflows that positively shape business outcomes
Collaborating with developers and data analysts to determine the organization’s needs and best uses for data

Required

The skills you need to win:

2-5+ years of experience with SQL, DML, DDL.
2-5+ years of experience writing code that aggregates and transforms data from multiple data sources
2-3+ years of experience designing, building, and optimizing star schemas and denormalized analytics models in support of downstream BI platforms
Experience with relational/big data repositories/RDBMS’s
Experience with designing and implementing ELT, ETL processes
Understanding of data quality, data cleansing, data lifecycle, and metadata management

Preferred

2-5+ years of experience with Python, Scala, Java, or another object-oriented programing language
Experience with one or more of the following: AWS Redshift, PostgreSQL, Aurora, MySQL
Experience with Business Intelligence tools such as Tableau, QuickSight
Experience using various tools such as Spark, AWS Glue, Hive, Flink, and Beam

Relevant Tools

Hadoop ecosystem (things like Hive, Pig, Impala, Ambari, Oozie, Sqoop, Zookeeper, Mahout)

About Ramsey Solutions

We’re a debt-free company that was founded in 1992 by Dave Ramsey.
We have 1000+ team members who are 100% dedicated to our mission.
We believe collaboration, innovation and a shared sense of mission come from being present with each other. That’s why all of our team members work together under one roof at our headquarters in Franklin, Tennessee.

Benefits

Here are some of the perks and benefits at Ramsey Solutions

And by the way, we're not stuffy or corporate around here.

A 401(k) match of 4% after one year as a team member (you can still contribute in the first year)
Health insurance on day one with a $500 HSA match every year
One fully paid workweek of ministry time after one year to volunteer for your favorite charity or nonprofit
Generous PTO and paid sick time off
We prioritize work-life balance and rarely exceed a 40-hour work week
Weekly devotionals with world-renowned speakers, pastors and authors
$300/year to put toward achieving your fitness goals
Casual dress and work environment

It’s a calling, and we’re on a mission to change lives. Join the crusade! Apply now.

EOE, including disability/vets
Show more Show less"
2819071082,Data Engineer,Progrexion,2021-11-05,United States,"Phoenix, AZ",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Progrexion and its affiliated companies, Lexington Law and CreditRepair.com, comprise the nation’s largest consumer advocacy network and employ over 1,500 people at locations throughout the Wasatch Front and in Idaho. Progrexion offers a full range of services with an emphasis in on-line and direct response marketing. Our creativity and drive stem from our relaxed office vibe and our amazing team of over-achieving, wicked-talented experts (Facebook.com/Progrexion). If you have the creativity and drive to work in a fast paced, dynamic environment, have excellent attention to detail and problem solving skills, and want to work in a strong team environment; it may be time to think about Progrexion.

We are passionate about improving, monitoring and protecting our clients' credit reports. We level the financial playing field for our clients through credit report repair so they can realize their financial dreams. As reported in USA Today, an independent research group found that 79% of all credit files in America contain some errors. The credit bureaus track approximately 250 million credit files and process over 4.5 billion updates annually. If 79% of those reports with errors means that over 185 million Americans are in need of our service! That's opportunity!

The Marketing team is looking for an outstanding Data Engineer to join its growing Data team. This individual will play a central role in one of our organization’s most highly visible divisions, helping to build, and maintain the data warehouse to guide strategic decisions of c-level executives and shape the way that we serve our customers. The Data Engineer will report to the Marketing Data Systems Director.

The Data Engineer will work closely with their Director as well as the analytics team to clean, create, and evaluate data related to key business questions. To this end, most of your time will be spent working within SQL Server and MySQL databases. You will be involved in supporting the wide range of analyses carried out by our group.

Responsibilities

Design and build data warehouses to support the production reporting and analytics needs of the marketing team.
Ensure data quality and availability for ongoing analytics projects.
Develop and maintain a query library to support recurring data requests.
Carry out ad-hoc data extracts and analyses as needed.
Help implement and deliver long-term data warehouse and production reporting projects.

Qualifications

Experience in SQL and ETL development.
Knowledge of Python a plus.
Attention to detail and overarching curiosity are both essential.
Willingness to learn new techniques and programming languages.
Responsible and reliable; able to set and meet deadlines.

IND123
Show more Show less"
2809732712,Big Data Engineer,"SpringML, Inc.",2021-10-29,United States,"Indianapolis, IN",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Management Consulting","At SpringML, we are all about empowering the ‘doers’ in companies to make smarter decisions with their data. Our predictive analytics products and solutions apply machine learning to today’s most pressing business problems so customers get insights they can trust to drive business growth. We are a tight knit, friendly team of passionate and driven people who are dedicated to learning, get excited to solve tough problems and like seeing results, fast.

Your primary role will be to design and build data pipelines. You will be focused on designing and implementing solutions on Hadoop, Spark, Pig, Hive. In this role you will be exposed to Google Cloud Platform including Dataflow, BigQuery and Kubernetes so the ideal candidate will have a strong big data technology foundation and bring a passion to learn new technologies. If you believe you have these skills please email your resume to info@springml.com.

Required Skills:

4-7 years Python and Java programming
3-5 years knowledge of Java/J2EE
3-5 years Hadoop, Big Data ecosystem experience
3-5 years of Unix experience
Bachelors in Computer Science (or equivalent)


Duties and Responsibilities:

Design and develop applications utilizing the Spark and Hadoop Frameworks or GCP components.
Read, extract, transform, stage and load data to multiple targets, including Hadoop, Hive, BigQuery.
Migrate existing data processing from standalone or legacy technology scripts to Hadoop framework processing.
Should have experience working with gigabytes/terabytes of data and must understand the challenges of transforming and enriching such large datasets.


Additional Skills that are a plus:

C, Perl, Javascript or other programming skills and experience a plus
Production support/troubleshooting experience
Data cleaning/wrangling
Data visualization and reporting
Devops, Kubernetes, Docker containers


Powered by JazzHR

R4cP69r2mT
Show more Show less"
2644267103,"Engineer, Data",Chainalysis Inc.,2021-11-20,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Chainalysis has become known as the leader in blockchain investigation and compliance software. Our products have built trust in blockchains by taking down terrorist financing campaigns, disrupting major ransomware operations, identifying the Twitter hackers, and more.

Now, we are building the blockchain data platform for cryptocurrency. Data engineers will be critical to that mission by building and scaling the ETL pipelines, data stores, and services our customers rely on every day to stop crime, understand risk, and strategize about their business. Working alongside infrastructure and security-focused engineers, they obsess over making our services highly available and safe for our customers to use for their most sensitive and real-time blockchain workflows. They deeply understand what is possible with cloud-native technologies and use those insights to enable our customers to push the boundaries of the cryptocurrency landscape.

In one year you’ll know you were successful if…

You have created efficient data pipelines, leveraging the most relevant services from AWS, and have made data consumable for downstream systems and services.
You’ve improved data quality and have made new datasets available to our product suite that detect activities for market manipulation, fraud, behavioral patterning, and more.
You have built cloud-native data ingestion and aggregation processes that intake gigabytes of data per day.
You have helped modernize our stack to a streaming architecture.
Your team’s services are easy to set up locally and their health in production is simple to understand.
You have debugged production issues and participated in a blameless post-mortem process to make our systems stronger.

A Background Like This Helps

Designed and implemented microservices-based systems in a major cloud provider like AWS or GCP.
Experience with object-oriented programming languages. We mostly use Java but appreciate a variety of languages!
Working SQL knowledge
Experience with Python
Experience in using event-streaming platforms such as Kafka
Knowledge of workflow orchestration tools such as Airflow
A bias to ship and iterate alongside product management and design partners
You have regularly participated in code and architecture reviews with your team
Exposure to or interest in the cryptocurrency technology ecosystem
Experience with Terraform and Kubernetes is a plus!
1-4 years of experience

At Chainalysis, we help government agencies, cryptocurrency businesses, and financial institutions track and investigate illicit activity on the blockchain, allowing them to engage confidently with cryptocurrency. We take care of our people with great benefits, professional development opportunities, and fun.

You belong here.

At Chainalysis, we believe that diversity of experience and thought makes us stronger. With both customers and employees around the world, we are committed to ensuring our team reflects the unique communities around us. Some of the ways we’re ensuring we keep learning are an internal Diversity Committee, Days of Reflection throughout the year including International Women’s Day, Juneteenth, Harvey Milk Day, and International Migrant’s Day, and a commitment to continue revisiting and reevaluating our diversity culture.

We encourage applicants across any race, ethnicity, gender/gender expression, age, spirituality, ability, experience and more. Additionally, if you need any accommodations to make our interview process more accessible to you due to a disability, don't hesitate to let us know. You can learn more here. We can’t wait to meet you.

Applying from the EU? Please review our Candidate GDPR Notice.

By submitting this application, I consent to and authorize Chainalysis to contact my former employers, and any and all other persons and organizations for information bearing upon my qualifications for employment. I further authorize the listed employers, schools and personal references to give Chainalysis (without further notice to me) any and all information about my previous employment and education, along with other pertinent information they may have, and hereby waive any actions which I may have against either party(ies) for providing a reference. I understand any future employment will be contingent on the Company receiving satisfactory employment references.

Chainalysis COVID-19 Policy - USA

All employees are required to have or obtain a COVID-19 vaccination as a condition of employment at Chainalysis, unless an exemption has been approved. All employees shall be required to report their vaccine status. All new employees shall be required to provide proof of their vaccination status prior to the start of their employment.

Chainalysis COVID-19 Policy - EMEA

As an employer, Chainalysis is obliged to ensure a healthy and safe working environment. This means that we must try to prevent the coronavirus from spreading inside the workplace and all employees are obliged to follow the local regulations issued by the relevant health authorities.
To help support a safe work environment, we encourage all employees in EMEA to get fully vaccinated against COVID-19.
Employees will not be required to attend an event or in-person customer meeting.
Employees in the EU and the UK are allowed to travel internationally for internal meetings to any country deemed “green or amber” by the EU and the UK authorities. All attendees for Chainalysis in-person events or meetings will be required to adhere to the following guidelines:
International travel will only be permitted if you receive approval from both your manager and Executive Leader
You must familiarize yourself and comply with any screening/safety protocols imposed by the entity/individual hosting the in-person meeting or event
You must comply with any and all safety guidelines and travel restrictions established by applicable law
If you are in close or proximate contact with others at the event/customer site and test positive for COVID-19, you must immediately notify the People Team and avoid contact with others for 10 days

Chainalysis COVID-19 Policy - APAC

With circumstances changing on a regular basis and parts of our APAC team going in and out of mandatory lockdown, APAC will continue to follow country legislation and guidelines.


Show more Show less"
2796917210,Data Engineer,Kintec Global Recruitment,2021-11-15,United States,United States,Engineering and Research,Full-time,"IT Services and IT Consulting, Renewable Energy Semiconductor Manufacturing, and Utilities","Ideal candidates will possess strong python and SQL experience, have familiarity with AWS cloud computing tools, and academic and/or applied knowledge of data science. Knowledge and/or experience working in electric power or gas markets is an advantage.




The Data Engineer will assist the Data Science Lead with a wide variety of tasks to further the role of data science in producing actionable insights for researchers and help maintain existing data science platforms.




Additional responsibilities may include:




Evaluating, testing, repairing, and improving existing machine learning models
QA and maintenance of all associated datasets and pipelines on diverse platforms
Quickly diagnose and respond to client questions about the product
Scoping client feature requests and the product roadmap
Building tools to dynamically evaluate model quality, model drift, data quality
Build new big data modeling tools to support internal research, consulting activity, and new or existing products
Both optimization models and statistical or machine learning models
Expand existing products and analytics with new data streams, analytical layers, and interfaces
Build novel or functional data interfaces and views for research teams to promote insights for clients
Conduct exploratory data analysis (distributions, cleanliness, statistical tests) on all large datasets
Assist research team with transition and modernization of data infrastructure around existing internal analytical models
Work with researchers to understand data volume and structuring challenges to bring more data into the AWS cloud platform
Contribute to the expansion of data capabilities




Education and experience in the following areas:




Applied or academic knowledge of statistical modeling, stochastic, machine learning, and neural network models
2-4+ years of experience working directly in applied data science
Portfolio of projects or work in this field demonstrating strong aptitude in the technical skillsets below in either case
Some applied or academic knowledge of optimization modeling and simulation
Advanced knowledge of Python 3
Git bash and embedded git interfaces
Pyspark, numpy, pandas, ODBC, matplotlib or similar
API interactions using html and json libraries
Optimization libraries
Advanced knowledge of SQL
Functional experience with statistical models written in R
Experience working in an AWS cloud environment
Strong time series data skills including demonstrated experience collecting, cleaning, and transforming large volumes of data efficiently using dataframes and lazy evaluation engines
Experience working with Snowflake
Experience using Azure Dev Ops or working with agile software development tools
Experience visualizing data with R-shiny, d3.js, or other python-based tools
Show more Show less"
2808120317,Data Engineer,Deckers Brands,2021-11-25,United States,Greater Phoenix Area,Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
1768190025,"Big Data Engineer (Kafka, Spark)",Photon,2020-06-23,United States,"Wilmington, DE",Information Technology,Full-time,IT Services and IT Consulting,"Greetings everyone,




We hope you are staying safe. We are looking for an experienced Big Data Engineer to join our new Data Analytics Initiatives. The candidate should be strong in Big Data solution implementation with the below mentioned skills. The ideal candidate should have experience in implementing realtime and batch streaming using Scala with high degree of Kafka integration. The Java Microservices experience will be added value atleast they should be conceptually sound high with strong skill in Bigdata implementation.




Who are we?

For the past 20 years, we have powered many Digital Experiences for the Fortune 500. Since 1999, we have grown from a few people to more than 4000 team members across the globe that are engaged in various Digital Modernization. For a brief 1 minute video about us, you can check https://youtu.be/uJWBWQZEA6o.




What will you do?

Apply your expertise in machine learning/data mining techniques and build forecasting, prediction, segmentation, recommendation and fraud detection systems in banking domain
Build data pipeline frameworks to automate high-volume and real-time data delivery for our Spark and streaming data hub
Transform complex analytical models in scalable, production-ready solutions
Build data APIs and data delivery services to support critical operational and analytical applications
Implement Machine Learning algorithms to drive personalized customer experience and provide key insights to the business
Extend/augment company data with third party data, enhance data collection procedures to include information required to build analytic systems
Assist with designing and building infrastructure to facilitate analytics and experimentation
Present results and make recommendations in a clear manner to leadership
Provide thought leadership and mentor data science community across the organization




What are we looking for?

The candidate should have Bachelor and Graduate degree in Engineering or related fields
At least 4 years of experience on designing and developing Data Pipelines with Spark using Python, Scala or Java
Experience with using Hive Query and optimizing its performance for common analytics operation
Experience with Data Streaming using Kafka and its optimization
Understanding of how internally Hadoop works and how to optimize its performance for a large scale analytics productions
Demonstration of a large scale production analytics in the past work experience
Show more Show less"
2822048460,Data Engineer,The Hartford,2021-11-06,United States,"Charlotte, NC",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

Join a fast-paced and talented Agile Kanban team to unlock Data Capabilities for The Hartford’s Commercial business in Maintenance organization. You will have an opportunity to maintain Legacy data assets using Oracle and Informatica, while growing your knowledge with emerging technologies as we move aggressively with cloud based assets. We use both Legacy and latest DATA technologies, software engineering practices, Agile delivery framework, and are passionate about technology and building well architected and innovative solutions that drive optimal business value generation.

Position will design, develop, and maintain large scale data assets across data warehouses, data marts, and data processes, leveraging next generation data and analytic technology stack across AWS Cloud, Talend, Snowflake, and Big Data; focus on addressing challenges across legacy tech stack, data freshness issues, speed of delivery and quality; drive a technology step change by enabling business while simplifying the data environment and improving speed of delivery; provide technical leadership, mentoring, and coaching to technical team; implement design patterns across the portfolio delivery teams; deliver high quality work of high technical complexity; research and evaluate alternative solutions and recommend the most efficient and cost-effective solution for the systems design.

Role Expectations

Design and develop high quality, scalable software modules for next generation analytics solution suite
Prototype high impact innovations, catering to changing business needs, by learning and leveraging new technologies (AWS Cloud, Big Data, Snowflake).
Integrate with Data Quality Services to ensure Quality data is Published to consumers.
Possesses functional knowledge and skills reflective of a competent practitioner with the ability to deliver on work of varying technical complexity
Consults with functional management in the analysis of short and long-range business requirements and recommends innovations which anticipate the future impact of changing business needs
Works closely with client management to identify and specify the complex business requirements and processes for diverse development platforms, computing environments (e.g., Cloud, host based, distributed systems, client server), software, hardware, technologies and tools
Coordinate activities with cross-functional IT unit stakeholders (e.g., database, operations, telecommunications, technical support, etc.)
Researches and evaluates alternative solutions and recommends the most efficient and cost effective solution for the systems design
Work within a self-organized scrum development team regarding all design and implementation

Qualifications

Bachelor’s degree with at least 3 years of applicable work experience.
Desired educational experience includes, but are not limited to: Computer Science, Engineering, IT, Management Information Systems, Data Analytics, Applied Mathematics, and Business.
Desire candidates with prior Data Engineer/ETL competencies and prior experience with successful enablement of Data Delivery initiatives.
Understanding of current and emerging IT products, services, processes and methodologies.
Analytical approach with a strong ability to uncover and resolve problems by delivering innovative approaches and solutions.
Strong ability to estimate project tasks and to deliver upon committed dates. Ability to develop and maintain systems according to a defined set of standards.
Ability to work as part of and with high performing teams.

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$90,480 - $135,720

Benefits

Our company’s success is due to our employees’ dedication and passion for their work. They are our greatest asset. That’s why we are committed to offering employees and their families a comprehensive benefits package and award-winning well-being programs. By helping our employees achieve their full potential, we unlock our own. Visit https://www.thehartford.com/careers/benefits for details.

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

Data Engineer - GE08AE
Show more Show less"
2798065899,Sr. Big Data Engineer (Analytics),App Annie,2021-12-03,United States,"California, United States",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","*YOU CAN WORK REMOTELY FROM ANY LOCATION AS LONG AS YOU ARE LOCATED IN PST/PDT OR MST TIME ZONE




Something about us

App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. More than 1,300 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business. We are a global company, headquartered in San Francisco but as a “remote” first company, we care about your results and not your location.

Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.




What can you tell your friends when they ask you what you do?




I am an experienced Big Data engineer who can create innovative new products in the analytics and data space. I participate in the development that creates the world's #1 app stores analytics service. Together with my team I build out new product features and applications using agile methodologies and open source technologies. I work directly with Product Managers, Software Architects, and I am on the front lines of coding new and exciting analytics and data mining products. I love what I do and excited to join an entrepreneurial company with a start-­up culture!




You will be responsible for and take pride in….

As a Big Data Engineer, you will be in charge of our data analysis projects and to build clean, robust and maintainable data processing program that can support these projects on huge amount of data, this includes:

Able to design and implement complex product components based on requirements with possible technical solutions.
Write data analysis and statistics programs using Pyspark with a commitment to maintaining high quality work while being confident in dealing with data mining challenges.
Discover any feasible new technologies lying in the Big Data ecosystem, share them to team with your professional perspectives.
Get up to speed in the machine learning domain, implementing analysis components in a distributed computing environment with instruction from Data Scientists.
Be comfortable conducting detailed discussions with Data Scientists regarding specific questions related to specific data models.
You should be a strong problem solver with proven experience in big data.

You should recognize yourself in the following…

Master's degree in Math or Computer Science and at least 2+ years of experience in Big Data Engineering.
Hands-on experience and deep knowledge of Hadoop ecosystem.
Knowledge and experience with PySpark, Mapreduce, HDFS, Linux, Storm, Kafka.
Proficient with programming in Python, experience in Pandas, Sklearn or Other data science and data analysis toolset is a big plus.
Having a background of data mining and machine learning domain, familiar with common algorithms and libs is a plus.
Passion for cloud computing (AWS in particular) and distributed systems.
You must be a great problem solver with the ability to dive deeply into complex problems and emerge with clear and pragmatic solutions.
Good communication, and cooperation globally.




This is what we offer…

We provide a $1,000 (country equivalent) WFH allowance to set you up for remote work success.
Remote working from anywhere in PST time zone! We are not office centric anymore and never will be.
90-days global passport. Work from anywhere in the world for 90 days a year!
Internet allowance for stable internet connection, so your video does not freeze on Zoom.
Flexible working days. We love to meet, but if you need to get your kids behind school-zoom, need to leave early to get to your band repetition or gym classes, do your thing.
Paid leave, so long as you promise to come back!
Health and dental benefits.
An international team of talented and engaged people from different cultural backgrounds and locations.
Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!
Unlimited access to online learning platform Udemy to help you develop your skills.
Virtual initiatives and events to keep you connected with your colleagues.
Generous Employee Referral Program. Up to $10,000 for specific roles.




Yes, I want this job!

Show more Show less"
2755098478,Data Engineer,Wyre,2021-10-13,United States,"San Francisco, CA",Engineering,Full-time,"Computer Software, Internet Publishing, and Financial Services","In order to port over the next billion people into a secure and open financial system, you’re going to need a network of applications that connect to the fiat world… Wyre’s APIs make that happen.

Our mission is to empower fintech projects to execute their vision by offering them secure access to the largest financial network in the world (the Wyre Network).

To accomplish this mission, we’ve built a simple set of tools that allows fintech projects to materialize their visions. (1) Our instant Fiat-to-Crypto Checkout gateway is now being used by hundreds of applications (ie. MetaMask, Opera, BRD) to offer the best way to convert card payments into crypto, and (2) our flexible APIs (Transfers API, Custody API, Users API), allow projects to build e-wallets, merchant processing services, and money transfer platforms from the ground up.

We focus on compliance, licensing, regulatory, liquidity, and payment processing aspects so our partners can do what they do best, creating amazing tools on the blockchain.

We’re looking for an exceptional Data Engineer to join our BI & Analytics team. This role will focus on making data accessible to the entire company for enhanced data-driven decision-making. We’re looking for a team-centered self-starter who is excited about Cloud and fintech technologies and wants to work in a fast-paced environment.

Come join the Wyre family.

Responsibilities

Perform analysis, conceptualize, design, implement and develop solutions for critical BI components from the ground up
Strong verbal and written communication skills, including the ability to effectively lead and influence interactions with both business and technical teams
Perform data-flow, system, and data analysis to develop meaningful presentations of data in BI applications
Plan and implement standards, define/code
Collaborate closely with internal and external teams to understand and apply changes/modifications impacting data warehouse
Monitor ETL processes, system audits, and performance. Proactively resolve issues as found
Support the performance of BI systems
Provide timely and accurate estimates for new functionality requirements


Requirements

Bachelor's degree in Computer Science or a related technical field from an accredited institution
Mastery in Business Intelligence and Data warehousing concepts and methodologies
5+ years of developing end-to-end Business Intelligence solutions: Data Warehouse, data modeling, ETL, and reporting
Experience with Cloud-based data-warehouse system: Snowflake, Redshift, Azure SQL Data warehouse is a huge plus
Experience with ETL tools like Xplenty/AWS Glue/Talend/Nifi
Demonstratable advanced SQL writing and experience in data mining (SQL, ETL, data warehouse, etc.)
Skills in Shell Programming and any Object Oriented Programming language
Should be able to write custom ETL programming from complex data processing and transformations using any programming language, such as PL/Sql, Python, Java, etc
Fast-learner and ability to pivot priorities quickly
Close attention to detail and strong organizational skills
Exceptional ability to communicate across teams and departments
Creative problem solver


Benefits

Enjoy a highly fulfilling, mission-driven culture
You are an owner! We offer stock options to each of our employee
An opportunity to build the future and freedom to work wherever you want
Fair pay, no matter where you live along with a competitive benefits package
Health, dental, and vision benefits for you and your family
Life insurance and disability benefits
Equity options for all full-time employees
401(k) plan with corporate matching
Computer setup of your choice
Unlimited paid time off to relax and recharge
Flexible work hours
Opportunity to work in a growing startup
Show more Show less"
2803173667,Data Engineer,Practifi,2021-11-17,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Practifi is the single, unified workspace for every role in an advisory firm. We're the operating system for teams who support complex clients at scale. We are a global SaaS WealthTech scale-up with offices in Chicago, USA and Sydney, Australia, powering growing financial advice firms around the world.

We are looking for a Data Engineer to join our Chicago team to support our massive client growth. This role is primarily focused on analysing, transforming and migrating CRM-based data from a diverse range of source systems into the Salesforce.com platform underpinning Practifi. This is a client facing role within an internal consulting group so if you’re wanting to extend your reach from pure technical to include client engagement, this is the perfect opportunity.

As a Data Engineer at Practifi, your primary responsibilities will include data strategy, data profiling & mapping, data migration, and continuous client communication.

What You'll Do

Reporting to the Onboarding Manager and working closely with the Sales, Professional Services and Client Success teams to understand client and data requirements needed to support successful and smooth solution implementations.
Leverage your existing system and process analysis skills to produce data strategies that create a seamless and uninterrupted experience for our clients.
Collaborating with clients to successfully map source data to the Practifi data model.
Leverage the Salesforce ecosystem and industry leading tools to extract, transform and load data.
Perform data profiling tasks to collect statistics, trends, impacts, and summaries that lead to a structured and successful implementation.
Provide key insights based on data analytics to aid the client in drawing conclusions as to the business value and impact of their data and best approaches for migrating and transforming data to support new system architectures.
Work with the Onboarding Manager to provide regular status updates to internal and external stakeholders.


About You

2+ years previous experience working in a similar data- focused role.
2+ years experience transforming data in scripting languages (such as Python) or database systems or SQL.
Adept in the use of ETL products & technologies.
Some experience working on the Salesforce platform is ideal.
Experience working with APEX Data Loader a plus.
Previous experience in the Financial Advice/ RIA industry a plus.
Desire to work in a consulting environment with active client engagement.


Benefits

20 days paid vacation per year
Remote first culture
3 'Practifi' days per year
401k matchHealth benefits
Casual dress code
Yearly Learning & Development budget
Opportunity to collaborate with the team in Sydney, Australia
Practifi is a fun, and hugely dynamic environment with an awesome culture and a fast pace. If you’re ready to push hard into the next big phase of your career on the Salesforce platform, talk to us!

This is a permanent, full-time position. The successful candidate will be working remotely, however, Practifi would be expecting for you to travel to our Chicago office once every three months.

Our success depends on a strong commitment to diversity, equity and inclusion. We encourage applicants from all backgrounds. Practifi is an equal opportunity employer, and does not discriminate against any applicant for employment due to age, color, sex, disability, national origin, race, religion, veteran status, or any other protected class.
Show more Show less"
2777950264,Data Engineer,Farmers Insurance,2021-11-03,United States,"Los Angeles, CA",Information Technology,Full-time,"Insurance, Financial Services, and Consumer Services","We are Farmers!

Join a team of diverse professionals at Farmers to acquire skills on the job and apply your learned knowledge to future roles at Farmers. Farmers Insurance also offers extensive training opportunities through the award winning University of Farmers named by Training magazine amongst top 10 corporate training units in the world.

Job Summary

Provides expertise in the design and functionality of business applications; Understands business processes and products and how best they can be supported by the application systems; Creates and validates the detailed technical designs to ensure alignment with business requirements; Develops and performs quality checks on project deliverables; Creates and validates estimates for new application functionality; Performs impact analysis of application changes across various components, holding an end-to-end view of the system; Specifies / recommends integration and testing criteria; Supports the implementation activities as well as troubleshoots application/system/environmental issues, as required.

Essential Job Functions

Use MS SQL SSIS to build ETL process to create new business functionalities as well to solve business problems: Respond to new requests for reports/data understanding business objectives and processes; review and refine technical requirements/User Stories; and communicate estimated hours and timeline to complete; Extract data directly from relational databases (e.g. DB2, SQL Server), data warehouses, or other data stores using SQL; Ability to create manual as well as automated data exports/reports; and Support application unit testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. Work productively on assigned tasks; Collaborate effectively with other team members; Demonstrate accountability to management and business for hours spent on assigned tasks; and diligently strive to deliver value.

Physical Actions

Essentially sedentary work consisting of occasional walking, standing, and lifting/carrying 10 lbs. maximum

Functional ability of seeing, hearing and speaking
Ability to type proficiently

Physical Environment

Work in a climate-controlled office, with occasional travel by car or airplane.

Education Requirements

High school diploma or equivalent required. Bachelor’s degree preferred, in Information Systems or related field.

Preferred Skills And Abilities

Work within structure of SAFe Agile team on the successful delivery of Business Intelligence projects, enhancements, and defects. Independently lead and deliver new projects and enhancements. Collaborate with Agile team members to understand functional and technical requirements. Prepare estimates based on high-level requirements and assumptions. Translate functional requirements into technical specifications for ETL development; develop source-to-target mappings and actively manage Development, Unit Testing and Implementation efforts. Troubleshoot production defects, perform root cause analysis and provide guidance to team on the fixes.

Experience in developing ETL and reporting applications using Microsoft SQL Server (strongly preferred), or Informatica or similar ETL technologies.
Experience in a BI/Data Warehouse environment with involvement in design, development, implementation, troubleshooting and support of ETL process on MS SQL Server or DB2 or similar DB platform.
Experience with Python and unstructured data manipulation is a plus.
Experience working in an Agile Environment is a plus.
Good knowledge of business intelligence best practices, processes, and methodologies.
Good programming experience in writing Stored Procedures, Queries, Views, User Defined Functions, and Common Table Expressions using SQL or T-SQL.
Highly committed, motivated, enthusiastic and a natural team player.
Good interpersonal and communication skills (both verbal and written) and ability to interact with and effectively address concerns.
Good prioritization, time management, analytical, and organization skills.
Experienced in facilitating in-person and remote meetings with business & IT.
Experienced in effective management of multiple competing and frequently changing assignments and priorities.

Experience Requirements

2+ years experience with data extraction, manipulation and presentation in usable format.

Special Skill Requirement

Experience with Python and unstructured data manipulation is a plus.

Benefits

Farmers offers a competitive salary commensurate with experience, qualifications and location
CO Only: The pay range for this job being performed in CO would be $72,000 - 96,000
Bonus Opportunity (based on Company and Individual Performance)
401(k)
Medical
Dental
Vision
Health Savings and Flexible Spending Accounts
Life Insurance
Paid Time Off
Paid Parental Leave
Tuition Assistance
For more information, review “What we offer” on https://www.farmers.com/careers/

Job Location(s): US - CA - WdlndHills-6301, US - RW - Remote Work - Farmers, US - TX - Remote, US - OK - OklaCty-Memrl, US - CA - WdlndHills-6303, US - KS - Kansas City, US - MI - Caledonia KM2, US - OH - Indpdc-4500

Salary Grade: Grade 35

Hiring Manager: Matthew S Woods

Want to learn more about our culture & opportunities? Check out farmers.com/careers and be sure to follow us on Instagram and LinkedIn!
Show more Show less"
2720271611,Data Engineer - Insights Platform,Spotify,2021-11-21,United States,"New York, NY",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","We are looking for data engineers to join our team of hardworking engineers that share a common interest in big data, distributed backend systems, ML, their scalability and continued development. By joining the Data and Insights organization, you’ll be a key contributor in making the systems that power our large scale data processing, insights, and machine learning efforts more reliable. Above all, your work will change the way the world experiences music.

The Insights Platform teams within Data and Insights enable the consumption of Insights by helping anyone at Spotify answer their questions using data. Inside Insights Platform, the data discovery and Analytics platform team helps insight creators and consumers discover, contextualize, and analyze Spotify's data. Learn more about how we do data discovery here !

Join us and help to amplify productivity, quality and innovation across Spotify

What You'll Do

Design, build and maintain data pipelines that power Spotify’s analytics and data discovery platform
Be a valued member of an autonomous, multi-functional agile team
Maintain system architecture documentation and runbooks
Build, automate, maintain, scale, and monitor user-facing systems using standard methodologies, with reliability and scalability in mind
Collaborate with other specialists, product managers, and designers to identify and solve exciting problems, crafting an awesome engineering experience within Spotify
You’ll initiate, influence and drive technical projects across teams within Spotify
Hack on what you want during regular hack days and bi-annual hack weeks

Who You Are

You have experience with large scale data systems
You know how to write distributed, well designed services
You have experience with Java, Scala and their tooling ecosystem
You are experienced with deploying and operating services on Linux
You have a deep understanding of system design, data structures, and algorithms
You care about quality and you know what it means to ship high quality code
As a great influencer with great communication skills, you love sharing your knowledge with others and helping them grow

Where You'll Be

We are a distributed workforce enabling our band members to find a work mode that is best for them!
Where in the world? For this role, it can be within the Americas region in which we have a work location and is within working hours.
Working hours? We operate within the Eastern Standard time zone for collaboration and ask that all be located in that time zone.
Prefer an office to work from home instead? Not a problem! We have plenty of options for your working preferences. Find more information about our Work From Anywhere options here .

Spotify is an equal opportunity employer. You are welcome at Spotify for who you are, no matter where you come from, what you look like, or what’s playing in your headphones. Our platform is for everyone, and so is our workplace. The more voices we have represented and amplified in our business, the more we will all thrive, contribute, and be forward-thinking! So bring us your personal experience, your perspectives, and your background. It’s in our differences that we will find the power to keep revolutionizing the way the world listens.

Spotify transformed music listening forever when we launched in 2008. Our mission is to unlock the potential of human creativity by giving a million creative artists the opportunity to live off their art and billions of fans the chance to enjoy and be passionate about these creators. Everything we do is driven by our love for music and podcasting. Today, we are the world’s most popular audio streaming subscription service with a community of more than 381 million users.

This position is not eligible to be performed in Colorado.
Show more Show less"
2819002917,Data Developer (ETL) - Remote,Mutual of Omaha,2021-11-29,United States,"Omaha, NE",Information Technology,Full-time,IT Services and IT Consulting and Insurance,"The Data Developer participates in and assists with the development of application and business integration solutions. Uses a variety of programming language(s), platforms and technologies to provide business solutions to customers.



WHAT YOU'LL DO:



Assists with the development, maintenance and integration of applications and systems that support the business operations.
Responsible for having a working knowledge of one or more programming languages used to develop, maintain, and execute systems.
Responsible for understanding various approaches and assisting with designing of enhancements for business operations.
Responsible for assisting with development, testing, and debugging of application/systems.
Responsible for having an understanding of the supported business area(s) and possessing an awareness of related business objectives and challenges.
Responsible for complying with all Company Information Services policies and standards.
Responsible for ensuring appropriate security and privacy measures are implemented on technology solutions to protect Company data from intentional or accidental misuse.

ABOUT YOU:



2 plus years data / ETL experience.
Strong communication and problem solving skills.
Ability to multi-task and adapt to changes in assignments.
Ability to adapt quickly to new technology and business requirements.
Awareness of different technologies and technology domains (Mainframe, Client Server, Web. Portal, Cloud, etc.).
You
Promote a culture of diversity and inclusion within the department and the larger organization
Value different ideas and opinions
Listen courageously and remain curious in all that you do
You are able to work remotely and have access to high-speed internet.

VALUABLE EXPERIENCE:



Teradata or Snowflake, Informatica, Relational Databases, Multiple Scripting Languages (Unix / Window), API Integration
Data Warehouse Design, Data Modeling and Integration
Amazon Web Services (AWS)
BI Tools (ex. Tableau)
Data Streams (Confluent, Kafka, Stitch, Striim, etc.)
Scaled Agile Framework (SAFe)
Ability to maintain data quality through systematic approaches and methodologies (e.g. MDM) within supported data systems.

WHAT WE CAN OFFER YOU:



A diverse workplace where associates feel a sense of belonging.
An organization that feels like a small, close-knit community and has the strength of a Fortune 500 company.
Tuition reimbursement, training and career development.
Comprehensive benefits plan that includes medical, dental, vision, disability and life insurance.
Flexible spending accounts for healthcare and childcare needs.
401(k) plan with a 2% company contribution and 6% company match.
Competitive pay with an opportunity for incentives for all associates.
Flexible work schedules with a healthy amount of paid time off.
For more information regarding available benefits, please visit our Career Site.
Estimated Salary Range: $70,000 - $95,000
Pay commensurate with experience.

MUTUAL OF OMAHA:



Mutual of Omaha serves more than 4.8 million individual product customers and 39,000 employer groups. Our legacy of stability creates an environment where every associate is encouraged to experiment, innovate and grow in their own unique career path.



From day one, you’ll have the tools to be your best self at work. Here you’ll do meaningful work and your talents will have a positive impact on peoples’ lives as we help our customers protect what they care about and achieve their financial goals.



Each associate is a unique contributor to creating a diverse, dynamic, thriving and inclusive workplace. We want you to become engaged … feel a sense of belonging … and contribute to the company’s exceptional future.



Join forces with a company that can AMPLIFY YOUR STRENGTHS AND EMPOWER YOUR CAREER.



For inquiries about the position or application process, contact our HR Helpline at 1-800-365-1405.



If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at 1-800-780-0304. We are available Monday through Friday 7:00 am to 4:30 pm CST we will reply within 24 hours.



Mutual of Omaha and its affiliates are an Equal Opportunity /Affirmative Action Employer. Qualified applicants will receive consideration without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.



To All Recruitment Agencies: We do not accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes.



Circa



 



Show more Show less"
2790834965,Data Analytics Engineer,"DailyPay, Inc.",2021-12-04,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","About Us:

DailyPay is the leader in the on-demand pay industry with an unrivaled technology platform, an unmatched list of blue-chip clients and an extensive list of industry awards. We are rewriting the invisible rules of finance by creating a new financial system. A financial system that is more equitable and inclusive, and benefits everyone. A financial system that enables workers to access their earned pay when they need it. We believe that money should move faster and smoother between employer and employee, between merchant and shopper, between financial institution and customer.

We are a mission-driven company hyper-focused on designing technology that can build a better financial system and future. It’s no wonder that we are growing at an extraordinary pace. Now we are looking for people who are as passionate as we are about reimagining how money moves. If you’re willing to define new rules, change systems and lives, come join us at DailyPay.

The Role:

DailyPay is looking for a Data Analytics Engineer to join our Analytics Engineering group inside the DailyPay Data Team. The Analytics Engineering group is responsible for building the data infrastructure that underpins our data analytics and data products that are used cross-functionally inside the company (sales, marketing, operations, engineering, etc.) as well as by DailyPay partner companies. The team also ETLs internal and external data to help the Data Team provide insights about the payroll industry in general, as well as about personal finance and financial wellbeing.

The mission of the Data Team is critical for continuous development and success of our product, understanding the needs of our customers and partners, and maintaining DailyPay’s leading role in the early wage access industry -- and our Data Analytics Engineers are instrumental in helping to realize this vision for DailyPay.

If this opportunity excites you, we encourage you to apply even if you do not meet all of the qualifications.

How You Will Make an Impact:

Build and maintain company’s ETL and data pipelines
Produce, support and maintain data reports, analytics, metrics and dashboards for internal and external use
Design and implement data testing and scaling capabilities
Maintain and optimize monitoring and alerting for company’s ETL and data pipelines, data warehouse, and analytics infrastructure
Optimize database performance while reducing warehouse costs and development times
Participate in code approvals and PR review process for company-wide analytics engineering efforts


What You Bring to The Team:

3+ years SQL experience; expert SQL capability
Familiarity with BI tools such as Tableau, Looker, or similar
Excellent presentation and communication skills
1+ years of dbt experience preferred
Experience with Snowflake, Redshift, and ETL tools like Fivetran or Stitch is a plus
Python experience is a plus


What We Offer:

Competitive compensation
Opportunity for equity ownership
Exceptional health, vision, and dental care
Employee Resource Groups
Fun company outings and events
Unlimited books from Amazon
Unlimited PTO
401K with company match


No sponsorship is available for this position.

DailyPay does not accept and will not review unsolicited resumes from search firms.

DailyPay requires all colleagues in in-office positions be vaccinated against the Covid-19 virus unless there is a documented and approved medical or religious accommodation. As a condition of employment, prior to your start date, you will be required to complete an attestation of vaccination.

DailyPay is committed to fostering an inclusive, equitable culture of belonging, grounded in empathy and respect, which values openness to opinions, awareness of lived experiences, fair treatment and access for all. We strive to build and develop diverse teams to create an organization where innovation thrives, where the full potential of each person is engaged, and their views, beliefs and values are integrated into our ways of working.

We welcome people of all backgrounds to join us on our mission*. If you require reasonable accommodation for any aspect of the recruitment process, please send a request to peopleops@dailypay.com. All requests for accommodation will be addressed as confidentially as practicable.

_______________________________________________________________________________________

DailyPay is an equal opportunity employer. All qualified applicants will receive consideration without regard to race, color, religion or creed, alienage or citizenship status, political affiliation, marital or partnership status, age, national origin, ancestry, physical or mental disability, medical condition, veteran status, gender, gender identity, pregnancy, childbirth (or related medical conditions), sex, sexual orientation, sexual and other reproductive health decisions, genetic disorder, genetic predisposition, carrier status, military status, familial status, or domestic violence victim status and any other basis protected under federal, state, or local laws.
Show more Show less"
2814497096,IT Data Engineer,Qualcomm,2021-12-01,United States,San Diego Metropolitan Area,Information Technology,Full-time,"Computer Software, Wireless Services, and Semiconductor Manufacturing","Company:Qualcomm Incorporated

Job Area:Information Technology Group, Information Technology Group > IT Data Engineer

General Summary

General Summary

Implements large scale data processing (structural, statistical etc.,) pipelines, creates production inference pipelines, associated APIs and analytics that support/provide insights for data driven decision making. Designs and develops data models, APIs, and pipelines to handle analytical workloads, data sharing, and movement across multiple systems at various grains in a large-scale data processing environment. Designs and maintains data systems and data structures for optimal read/write performance. Implements machine learning or statistical/heuristic learning in data pipelines based on input from Data Scientists.

The Responsibilities Of This Role Include

Working independently with some supervision.
Responsible for own work. Decision-making is limited. Errors made typically only impact timeline (i.e., require additional time to correct).
Requires verbal and written communication skills to convey basic, routine factual information about day-to-day activities to others who are fully knowledgeable in the subject area.
Some tasks require multiple steps which must be performed in a specific order; directions or manuals can accurately document the steps necessary to perform the task.
Some creativity may be required to troubleshoot technical problems or deal with novel circumstances.
Limited problem solving required, generally in the nature of troubleshooting simple processes or technology.


The Responsibilities Of This Role Do Not Include

Does not provide supervision to others.
Has no influence over key organizational decisions.
Does not have a role in strategic planning.
Does not have financial accountability.


Principal Duties And Responsibilities

Completes assigned tasks for programming routine data pipelines and system integrations under some supervision.
Completes assigned technical tasks to improve data quality under some supervision; assists in implementing data enrichment and data cleansing.
Maintains summarized datasets and data APIs under some supervision.
Assists with basic statistical analysis; maintains machine learning pipelines in production under direct supervision.
Learns how to use data to discover tasks that can be automated and implements automation under some supervision.
Seeks knowledge of advances in IT Data Engineering; consults with more experienced colleagues to understand advanced concepts.
Works with team members to complete moderate technical tasks and gain insight from project challenges.
Escalates complex technical issues to an appropriate party (e.g., project lead, colleagues).
Contributes to technical conversations with tech leads/managers.
Writes technical documentation for straightforward projects under the direction of a supervisor.


Job Description

Roles and Responsibilities:

Work in data streaming, movement, data modeling and data pipeline development
Develop pipelines and data model changes in support of rapidly emerging business and project requirements
Develop code and maintain systems to support analytics Infrastructure & Data Lake
Partner/Contribute to data analysis and machine learning pipelines
Design data recovery processes, alternate pipelines to check data quality.
Create and maintain continuous data quality evaluation processes
Optimize performance of the analytics platform and develop self-healing workflows
Be a part of a global team and collaborate and co-develop solutions


Minimum Qualification

Bachelor’s degree in computer science, information technology, or engineering
3+ Years of prior experience in Data Engineering and Databases
Experience with code based ETL framework like Airflow/Prefect
Experience with Google BigQuery, Google PubSub, Google Dataflow
Experience building data pipelines on AWS or GCP
Experience developing data APIs and pipelines using Python
Experience with databases like MySQL/Postgres
Experience with intermediate Python programming
Experience with advanced SQL (analytical queries)


Preferred Qualifications

Experience with Visualization tools like Tableau/QlikView/Looker
Experience with building Machine Learning pipelines


Physical Requirements

Frequently transports between offices, buildings, and campuses up to ½ mile.
Frequently transports and installs equipment up to 5 lbs.
Performs required tasks at various heights (e.g., standing or sitting).
Monitors and utilizes computers and test equipment for more than 6 hours a day.
Continuous communication which includes the comprehension of information with colleagues, customers, and vendors both in person and remotely.


Education

Minimum Qualifications

Bachelors - technical field (e.g., Computer Engineering, Computer Science, Information Systems), See the required degree associated with years of work experience

Work Experiences

1+ years of any combination of academic or work experience with Data Structures and algorithms.1+ years of any combination of academic or work experience with SQL or NoSQL Databases.1+ years of any combination of academic or work experience with programming (e.g., Java, Python).3+ years IT-relevant experience. with a high School diploma or equivalent1+ years IT-relevant experience with Bachelor’s degree in a non-technical field (e.g. Business, Humanities, Marketing)

Skills

Certifications:

Education

Preferred Qualifications

Bachelors - Computer Science, Bachelors - Engineering, Bachelors - Information Systems

Work Experiences

1+ years experience working in a large matrixed organization. ,2+ years of any combination of academic or work experience with programming (e.g., Java, Python). ,2+ years IT-relevant experience. with Bachelor’s degree in a technical field.

Skills

Applicants: If you are an individual with a disability and need an accommodation during the application/hiring process, please call Qualcomm’s toll-free number found here for assistance. Qualcomm will provide reasonable accommodations, upon request, to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. Qualcomm is an equal opportunity employer and supports workforce diversity.

To all Staffing and Recruiting Agencies:Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications.

EEO Employer: Qualcomm is an equal opportunity employer; all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or any other protected classification.

If you would like more information about this role, please contact Qualcomm Careers .
Show more Show less"
2794687813,Data Engineer,"Marqeta, Inc",2021-11-16,United States,"Oakland, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Named one of Fast Company’s Most Innovative Companies in the World in 2021, Marqeta powers innovative payment solutions for many of the apps and services you enjoy daily. Our open API modern card issuing platform provides unprecedented flexibility and control for industry-leading companies such as Square, Coinbase, J.P.Morgan, and Uber, to issue cards, authorize transactions and manage payment operations in real-time.

We are a team of industry experts and technology innovators who take a dynamic approach to solving challenging problems. Marqeta is certified as a 2021-2022 Fortune Great Place to Work, highlighting our company culture and open and collaborative work environment. We power possibilities for our customers and each other by bringing the brightest talent together to do the best work of our lives.

Marqeta strives to build a global team as diverse as the markets we serve, staying true to our values: Connect the Customer, Everyone Belongs, Marqeta Cares, Lead Innovation, Deliver Results, Quality First and Build One Marqeta. We are not expecting any single candidate to meet all job requirements listed below, so please apply. It's an exciting time to join Marqeta. As we grow, your career and opportunities will grow as well. Learn more about Marqeta on our Website, Twitter and LinkedIn

Marqetans may choose to work remotely, or split their time between the office and home. Marqeta values flexibility in work arrangements and embodies an inclusive and collaborative culture.

Data Engineer Summary

We are seeking an experienced data engineer interested in building enterprise level data products and solutions. You’ll help solve the company’s toughest problems, create and prototype data products, and scale our existing data platform to meet our expanding innovative customer base. You’ll be a part of the Data & Insights team where we identify and drive new capabilities to unleash value through data models, data feeds, reports, and advanced analytics. The Senior Data Engineer is expected to be a problem solver for Marqeta’s growing data needs, be able to deliver on projects in a timely manner while juggling multiple priorities, and proactively ideate with the broader data team. The ability to interact and communicate with technology and business team members.

What You'll Do

Help develop and enhance a data environment consistent with industry best practices and cutting edge approaches that also meets governance, compliance, and regulatory requirements.
Develop, document, maintain, support, and enhance our Snowflake data warehouse.
Work with business partners to clarify requirements when necessary to create both high-level and low-level design docs.
Operate in a time-sensitive environment with competing deadlines, by appropriately prioritizing the short and long term paths based on an Agile development process.

What We're Looking For

5+ years of relevant experience as a backend engineer with a Bachelor’s degree; or 2 years of experience with an advanced degree. In lieu of a degree, 8+ years of relevant experience may suffice
Mastery of Python and SQL
Experience with AWS (Redshift, etc.)
Previous work with NoSQL databases (DynamoDB, Cassandra, MongoDB, HBase, etc.)
The ability to optimize queries for high volume environments
Experience in designing and developing data modeling and mining, ETL, data warehouse, deployment and performance tuning (custom or structured ETL, preferably working directly with large data environments).
Experience designing, building and launching extremely efficient and reliable data pipelines to move data (both large and small amounts) throughout data warehouses
Experience with git, and the pull request workflow
Experience with CI/CD
A positive outlook towards work, strong work ethic, and ability to work in a team environment
The ability to listen to the needs of others and comprehend complex matters, articulate issues in a clear and concise manner, and present effectively in both oral and written presentations to all levels in the organization
The ability to demonstrate humility, empathy, and to take constructive feedback positively
A desire to grow in your career, learn, share ideas and help others grow and learn
Demonstrated experience working productively on cross-functional teams and taking a collaborative, team oriented approach

Nice to haves

Experience with Snowflake
Experience with Kubernetes
Experience with Docker
Experience with Debezium
Experience in developing distributed applications using Kafka, Airflow, etc.
Experience with big data frameworks
Experience with payments or the FinTech space

Benefits And Perks

Rich suite of benefit plans; employee premiums paid 100%
Flexible Time Off
Paid Medical, Pregnancy, Parental and Family Leaves
Retirement savings program with Company contribution
Competitive pay
Meaningful equity
Employee Stock Purchase Plan
Free perks programs that include, financial coaching, and ID theft protection
Bi-annual “Hack Week” to support and reward innovation
Open, transparent culture that includes Town Hall meetings, Lunch-and-Learns and more!
Access to corporate gym membership rates, other discounts and employee perks
And for select regions; a monthly stipend to support our hybrid work model, and pet insurance

As part of our dedication to the diversity of our workforce, Marqeta is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant, candidate, or employee on the basis of race, color, religion, creed, national origin or ancestry, sex, gender, gender identity, gender expression, sexual orientation, age, physical or mental disability, medical condition, marital/domestic partner status, military or veteran status, genetic information or any other legally-recognized protected basis under federal, state or local laws, regulations or ordinances.

The Applicant and Candidate Privacy Notice applies to the personal data that you directly provide to us or that we collect during the application and candidate recruitment process.


Show more Show less"
2810769726,Junior Data Engineer,Gravity IT Resources,2021-11-23,United States,United States,Information Technology and Engineering,Full-time,IT Services and IT Consulting and Hospitals and Health Care,"Job Title: Junior Data Engineer

Location: Remote

Work Authorization: USC/GC Holder

Job Type: FTE







Position Overview: Our client delivers truly disruptive and transformative products and services that will impact the healthcare industry. The work we do makes a difference. Our client is looking for an exceptional Data Engineer with a passion for technology to help revolutionize the world of Healthcare IT. Data engineers are at the core of a data-driven business; they build and maintain the infrastructure that empowers analysts and data scientists to drive insights. We’ve built a team of passionate, creative, and innovative engineers and data scientists that are changing the world and having fun doing it!







You may be a great fit for Data Engineering opportunity, IF…

You are a gifted Data Engineer, passionate about technology in healthcare IT.
You are a collaborator. You thrive in environments that freely exchange ideas and viewpoints.
You are an innovator that believes in making a difference and having fun doing it.







Your Role:

Create, maintain, and support ETL pipelines.
Work with application development teams to understand data representation.
Maintain documentation for the Data Warehouse and other data products.
Support data usage needs of downstream analytics teams.







Skills & Requirements:

BS in Computer Science or equivalent work experience.
SQL and relational databases.
Object-oriented programming.
Strong problem-solving skills, adaptable, proactive and willing to take ownership.
Strong commitment to quality, architecture, and documentation.
Experience using AWS or other cloud services, a plus.
Experience with big data tools (Hadoop, Spark, Kafka, Airflow), a plus.
Experience with Python, Scala and R, a plus.







Benefit Highlights:

Health Insurance, 401(k), Vacation, Employee Assistance Program, Flexible Spending Accounts
Employee Resource Groups
Professional development opportunities including tuition reimbursement programs and unlimited access to LinkedIn Learning
Weekly catered breakfast and lunch, treadmill workstations, quarterly onsite massages, onsite dry cleaning, onsite car wash and many more!

Show more Show less"
2813512388,"Data Engineer, Pipeline (511)",Techstars,2021-11-30,United States,United States,Information Technology,Full-time,Venture Capital and Private Equity Principals,"This is a fully remote role and can be located anywhere in the continental US.

As a Data Engineer, you will be an important part of a team building innovative solutions that empower our internal financial and investment teams as well as our network of investors. The solutions this team develops will literally change the industry. As part of Techstars’ data engineering organization you and your team will build a modern real-time data analytics platform that implements ML/AI to inform Techstars investments and empowers investors with insights.

As an organization, we value innovation and collaboration. We make heavy use of Open Source technologies and cloud infrastructure. We believe in sustainable software development using Agile Development methodologies and mature devops practices to quickly and consistently provide value. We believe in creating robust, performant, maintainable, observable solutions.

What You Will Do

As part of a team of engineers working in an agile environment you will build and deploy quality data ingest, cleansing, analytics and ML solutions
Ensure that all data and software solutions are secure, performant, reliable, observable and testable
Work with team members in a collaborative manner
Continuously improve the quality of the products and solutions delivered


What You Bring

A passion for building data solutions
A deep appreciation for dev/ops
Experience working with distributed systems and cloud infrastructure
Data engineering experience with ETL, streaming, data pipelines, cleansing and mastery
Diverse experience with languages (ie. SQL, Python, Node, Scala)
Experience working with a variety of relational and non-relational database systems (ie Postgres, MongoDB, Redis)
Experience with cloud based data visualization technologies (ie. Looker, Domo, Airtable)
Experience working in an agile development environment
Excellent communication and collaboration skills, a desire to learn and teach


Nice to have

Experience in financial/investment data
Experience developing with containerization technologies (Docker, Kubernetes etc.)


Compensation range: $85,000 - $110,000 + 10% Bonus

US Benefits

About Techstars

Techstars is the worldwide network that helps entrepreneurs succeed. Founded in 2006, Techstars began with three simple ideas - entrepreneurs create a better future for everyone, collaboration drives innovation and great ideas can come from anywhere. Now we are on a mission to enable every person on the planet to contribute to, and benefit from, the success of entrepreneurs. In addition to operating accelerator programs and venture capital funds, we do this by connecting startups, investors, corporations and cities to help build thriving startup communities. Techstars has invested in more than 2,300 companies with a combined market cap of more than $29B.

Techstars’ mission is to help entrepreneurs succeed wherever they are in the world and whatever their background is. Regional accelerator programs all around the world are the cornerstone of the strategy. The investment approach is fundamentally driven by the worldwide network of managing directors, who interact with startup founders daily, guiding, mentoring and cultivating them along the journey. The scale of this reach results in a diversified strategy that provides investors with a uniquely qualified deal flow.

We help Techstars founders connect with other entrepreneurs, experts, mentors, alumni, investors, community leaders, and corporations to grow their companies.

www.techstars.com

Techstars is an affirmative action, equal opportunity employer and does not discriminate on the basis of race, sex, age, national origin, religion, physical or mental handicaps or disabilities, marital status, Veteran status, sexual orientation, gender identity nor any other basis prohibited by law.
Show more Show less"
2789621977,Data Engineer,Zoom,2021-12-03,United States,"Seattle, WA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2789630060,Data Engineer,Zoom,2021-12-03,United States,"Washington, United States",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2644262426,"Engineer, Data",Chainalysis Inc.,2021-11-21,United States,"Washington, DC",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Chainalysis has become known as the leader in blockchain investigation and compliance software. Our products have built trust in blockchains by taking down terrorist financing campaigns, disrupting major ransomware operations, identifying the Twitter hackers, and more.

Now, we are building the blockchain data platform for cryptocurrency. Data engineers will be critical to that mission by building and scaling the ETL pipelines, data stores, and services our customers rely on every day to stop crime, understand risk, and strategize about their business. Working alongside infrastructure and security-focused engineers, they obsess over making our services highly available and safe for our customers to use for their most sensitive and real-time blockchain workflows. They deeply understand what is possible with cloud-native technologies and use those insights to enable our customers to push the boundaries of the cryptocurrency landscape.

In one year you’ll know you were successful if…

You have created efficient data pipelines, leveraging the most relevant services from AWS, and have made data consumable for downstream systems and services.
You’ve improved data quality and have made new datasets available to our product suite that detect activities for market manipulation, fraud, behavioral patterning, and more.
You have built cloud-native data ingestion and aggregation processes that intake gigabytes of data per day.
You have helped modernize our stack to a streaming architecture.
Your team’s services are easy to set up locally and their health in production is simple to understand.
You have debugged production issues and participated in a blameless post-mortem process to make our systems stronger.

A Background Like This Helps

Designed and implemented microservices-based systems in a major cloud provider like AWS or GCP.
Experience with object-oriented programming languages. We mostly use Java but appreciate a variety of languages!
Working SQL knowledge
Experience with Python
Experience in using event-streaming platforms such as Kafka
Knowledge of workflow orchestration tools such as Airflow
A bias to ship and iterate alongside product management and design partners
You have regularly participated in code and architecture reviews with your team
Exposure to or interest in the cryptocurrency technology ecosystem
Experience with Terraform and Kubernetes is a plus!
1-4 years of experience

At Chainalysis, we help government agencies, cryptocurrency businesses, and financial institutions track and investigate illicit activity on the blockchain, allowing them to engage confidently with cryptocurrency. We take care of our people with great benefits, professional development opportunities, and fun.

You belong here.

At Chainalysis, we believe that diversity of experience and thought makes us stronger. With both customers and employees around the world, we are committed to ensuring our team reflects the unique communities around us. Some of the ways we’re ensuring we keep learning are an internal Diversity Committee, Days of Reflection throughout the year including International Women’s Day, Juneteenth, Harvey Milk Day, and International Migrant’s Day, and a commitment to continue revisiting and reevaluating our diversity culture.

We encourage applicants across any race, ethnicity, gender/gender expression, age, spirituality, ability, experience and more. Additionally, if you need any accommodations to make our interview process more accessible to you due to a disability, don't hesitate to let us know. You can learn more here. We can’t wait to meet you.

Applying from the EU? Please review our Candidate GDPR Notice.

By submitting this application, I consent to and authorize Chainalysis to contact my former employers, and any and all other persons and organizations for information bearing upon my qualifications for employment. I further authorize the listed employers, schools and personal references to give Chainalysis (without further notice to me) any and all information about my previous employment and education, along with other pertinent information they may have, and hereby waive any actions which I may have against either party(ies) for providing a reference. I understand any future employment will be contingent on the Company receiving satisfactory employment references.

Chainalysis COVID-19 Policy - USA

All employees are required to have or obtain a COVID-19 vaccination as a condition of employment at Chainalysis, unless an exemption has been approved. All employees shall be required to report their vaccine status. All new employees shall be required to provide proof of their vaccination status prior to the start of their employment.

Chainalysis COVID-19 Policy - EMEA

As an employer, Chainalysis is obliged to ensure a healthy and safe working environment. This means that we must try to prevent the coronavirus from spreading inside the workplace and all employees are obliged to follow the local regulations issued by the relevant health authorities.
To help support a safe work environment, we encourage all employees in EMEA to get fully vaccinated against COVID-19.
Employees will not be required to attend an event or in-person customer meeting.
Employees in the EU and the UK are allowed to travel internationally for internal meetings to any country deemed “green or amber” by the EU and the UK authorities. All attendees for Chainalysis in-person events or meetings will be required to adhere to the following guidelines:
International travel will only be permitted if you receive approval from both your manager and Executive Leader
You must familiarize yourself and comply with any screening/safety protocols imposed by the entity/individual hosting the in-person meeting or event
You must comply with any and all safety guidelines and travel restrictions established by applicable law
If you are in close or proximate contact with others at the event/customer site and test positive for COVID-19, you must immediately notify the People Team and avoid contact with others for 10 days

Chainalysis COVID-19 Policy - APAC

With circumstances changing on a regular basis and parts of our APAC team going in and out of mandatory lockdown, APAC will continue to follow country legislation and guidelines.


Show more Show less"
2687464931,Data Engineer,Groupon,2021-11-14,United States,"Chicago, IL",Information Technology,Full-time,Internet Publishing,"Groupon is an experiences marketplace that brings people more ways to get the most out of their city or wherever they may be. By enabling real-time mobile commerce across local businesses, live events and travel destinations, Groupon helps people find and discover experiences––big and small, new and familiar––that make for a full, fun and rewarding life. Groupon helps local businesses grow and strengthen customer relationships––resulting in strong, vibrant communities. Even with thousands of employees spread across multiple continents, we still maintain a culture that inspires innovation, rewards risk-taking and celebrates success.

Search and Ranking Data Science teams at Groupon are at the heart of our decision making system that provides value to the millions of merchants and customers that use our platforms on a daily basis. We use cutting edge data technologies, data science methods, and machine learned models to build solutions that tune an inventory of merchant-provided goods and services to our customers' needs.

Your role as a Data Engineer will be to design, develop and maintain monitoring and alerting systems for data quality in offline ETL, machine learning model performance, and offline and online ranking and search components.

We're a ""best of both worlds"" kind of company. We're big enough to have resources and scale, but small enough that a single person has a surprising amount of autonomy and can make a meaningful impact. We're curious, fun, a little intense, and kind of obsessed with helping local businesses thrive. Does that sound like a compelling place to work?

You’ll Spend Time On The Following

Design, develop, deploy and maintain algorithms, data pipelines, automated processes, and services to monitor search and ranking infrastructure.
Create and maintain dashboards, alerting mechanisms and constantly finetune them for better accuracy and efficiency.
Work with product and engineering leaders in Search and Ranking teams to identify questions and issues in data quality and systems’ robustness.
Determining when technical debt can be acquired or must be reduced to maintain efficient team velocity.
Directly contribute to “North Star” architecture planning for relevance technological road-maps.
Mentor team members in the areas of technical expertise and career building.

We’re Excited About You If You Have

A BS or MS degree in Computer Science, Mathematics, or similar quantitative field
5+ years of work experience as a Data Engineer or Systems Engineer
Expert level at structured data systems like RDBMS, Data Warehouses
Expert level at Big Data technologies like Hadoop, Spark
Expert level at a general purpose programming language like Python, Java, Scala, or similar
High level of expertise in DevOps tools and methodologies, e.g., Jenkins, Teradata, Git, Artifactory, etc.
High level of expertise in Unix Shell Scripting
Familiarity with AWS is a plus
Familiarity with test automation techniques is a plus
Ability to ideate and bring projects to completion independently
Ability to navigate variety of technologies and projects, learn new technologies quickly, prototype rapidly
Self-driven problem solving skills and can identify problems unilaterally, but still bring back to the team

We Value Engineers Who Are

Customer-focused: We believe that doing what’s right for the customer is ultimately what will drive our business forward.
Obsessed with quality: Your production code just works & scales linearly
Team players. You believe that more can be achieved together. You listen to feedback and also provide supportive feedback to help others grow/improve.
Fast learners: We are willing to disrupt our existing business to trial new products and solutions. You love learning how to use new technologies and then rapidly apply them to new problems.
Pragmatic: We do things quickly to learn what our customers desire. You know when it’s appropriate to take shortcuts that don’t sacrifice quality or maintainability.
Owners: Engineers at Groupon know how to positively impact the business.

Groupon's purpose is to build strong communities through thriving small businesses. To learn more about the world's largest local ecommerce marketplace, click here for the latest Groupon news. Plus, be sure to check out the values that shape our culture, guide our strategy and make our company a great place to work. And just don't take our word for it. Hear from real Groupon team members and learn more about our inclusive employee groups. If all of this sounds like something that's a great fit for you, then click apply and let's see where this takes us.

Groupon is an Equal Opportunity Employer

Qualifications for employment, promotion, and other terms and conditions of employment are based upon the ability to perform the job. Equal-employment opportunities are provided to all applicants and employees without regard to race, creed, religion, color, age, national origin, sex, disability, medical condition, sexual orientation, gender identity or expression, genetic information, ancestry, marital status, military discharge status (excluding dishonorable discharge), veteran status, citizenship status, or other legally protected status. We are all responsible for maintaining this policy. Groupon is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may email us at hraccommodations at groupon.com. If you have concerns related to Groupon’s equal employment opportunities, you may contact Groupon's Ethics Reporting Service Ethicspoint.
Show more Show less"
2797288457,Data Engineer,Amazon,2021-11-18,United States,"Arlington, VA","Information Technology, Consulting, and Engineering",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

We are looking for an outstanding Data Engineer who is data-driven, uncompromisingly detail oriented, smart, efficient, and driven to help our business succeed. You have passion for technology. You are keen to leverage existing skills while trying new approaches. You are not tool-centric; you determine what technology works best for the problem at hand and apply it accordingly. You can explain complex concepts to your non-technical customers in simple terms.

We are moving from traditional database technologies to near real time data processing and advanced reporting services built around natural language processing and machine learning.

You will help us analyze large amounts of data, discover and solve real world problems and build metrics and business cases to help business teams to make decisions. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment.


Basic Qualifications

3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, scripting, data warehousing, and building ETL pipelines
Experience in SQL

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Preferred Qualifications

Experience in big-data using Hadoop, Hive, and other open-source tools/technologies
Familiar with AWS tools
Ability to work independently with minimum supervision
Experience in designing and building large data warehouse systems
Strong organizational and multitasking skills with ability to balance competing priorities
Good work experience in BI Reporting tools and databases in a business environment.


Company - Amazon.com Services LLC

Job ID: A1735236
Show more Show less"
2797288457,Data Engineer,Amazon,2021-11-18,United States,"Arlington, VA","Information Technology, Consulting, and Engineering",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

We are looking for an outstanding Data Engineer who is data-driven, uncompromisingly detail oriented, smart, efficient, and driven to help our business succeed. You have passion for technology. You are keen to leverage existing skills while trying new approaches. You are not tool-centric; you determine what technology works best for the problem at hand and apply it accordingly. You can explain complex concepts to your non-technical customers in simple terms.

We are moving from traditional database technologies to near real time data processing and advanced reporting services built around natural language processing and machine learning.

You will help us analyze large amounts of data, discover and solve real world problems and build metrics and business cases to help business teams to make decisions. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment.


Basic Qualifications

3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, scripting, data warehousing, and building ETL pipelines
Experience in SQL

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Preferred Qualifications

Experience in big-data using Hadoop, Hive, and other open-source tools/technologies
Familiar with AWS tools
Ability to work independently with minimum supervision
Experience in designing and building large data warehouse systems
Strong organizational and multitasking skills with ability to balance competing priorities
Good work experience in BI Reporting tools and databases in a business environment.


Company - Amazon.com Services LLC

Job ID: A1735236
Show more Show less"
2827120101,Data Engineer - Remote,The Hartford,2021-11-09,United States,"Charlotte, NC",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

Join a fast-paced and talented Agile team in The Hartford’s Enterprise Data Organization to unlock Data Capabilities for our Group Benefits business. You will have an opportunity to participate in the entire software development lifecycle process in support of continuous data delivery, while growing your knowledge with emerging technologies. We use the latest data technologies, software engineering practices, Agile delivery framework, and are passionate about technology and building well architected and innovative solutions that drive optimal business value generation.

This cutting edge and forward focused team presents the opportunity for collaboration, self-organization within the Scrum Team and visibility as we focus on continuous Business data delivery.

What’s in it for you?

Experience deeper understanding of Data analytics, Emerging technologies and Development practices
Collaboration with a high-performing, forward-focused team, Product Owner(s) and Business stakeholders engagement
Opportunity to expand your communication, analytical, interpersonal, and organization capabilities
Experience working in a fast paced environment – driving business outcomes in Agile ways of working
Enable and influence the timely and successful delivery of business data capabilities and/or technology objectives
Enhance your entrepreneurial mindset – network opportunity and influencing outcomes
Hone your development skills using various tools such as Talend, Snowflake, Informatica, B2B, PL/SQL, Hadoop, etc. to build data assets that enable business value generation
Appreciation and opportunity to learn and support rapid software construction and deployment using DevOps and Cloud based future technologies
Supporting environment that fosters can-do attitude and opportunity for growth and advancement based on consistent demonstrative performance
Optimize business value by leveraging your DATA experience and depth
Be part of a Scrum Team – driving work independently or collaboratively towards achieving business outcomes
Act as a resource for colleagues with less experience

Qualifications

Must be authorized to work in the U.S. without company sponsorship .
Bachelor’s degree (or foreign equivalent) in Computer Science, Computer Engineering or a related field.
At least 2 years' experience in data engineering, big data, analytics and operations concepts: SQL, ETL, performance tuning, production engineering, job scheduling, continuous deployment and operations support
Experience with ETL tools like Talend or Informatica
Minimal knowledge on programming languages such as Python, Java, Spark; version control tools like GitHub.
Preferred experience with Cloud technologies such as AWS, Snowflake, Dremio
Preferred experience in PL/SQL and use of databases such as Oracle and SQL Server;
Experience in Agile development methodologies with a preference of Scrum and/or SAFe a strong preference.
Experience with end-to-end Data Warehousing architecture and concepts and ETL best practices
Delivery experience including full lifecycle from conception to successful implementation.
Experience with Insurance domain

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

Benefits

Our company’s success is due to our employees’ dedication and passion for their work. They are our greatest asset. That’s why we are committed to offering employees and their families a comprehensive benefits package and award-winning well-being programs. By helping our employees achieve their full potential, we unlock our own. Visit https://www.thehartford.com/careers/benefits for details.

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

Data Engineer - GE08AE
Show more Show less"
2807083983,Big Data Engineer,Amazon Web Services (AWS),2021-11-20,United States,"Dallas, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

DESCRIPTION

Amazon Web Services (AWS) is the leading platform for designing and developing applications for the cloud and is growing rapidly with hundreds of thousands of companies in over 190 countries on the platform. The Worldwide Revenue Operations (WWRO) team will be the authoritative source of customer metadata and the solutions team for applications that action AWS’ strategies to better serve our customers. We invest resources in information and solutions enabling AWS sales and business teams that yield increased customer adoption and an optimal customer experience.

Are you an experienced Big Data Engineer passionate about building scalable, enterprise-level systems? We are looking for a Big Data Engineer to play a key role in building next generation tools and solutions. In addition to technical expertise, you will invest time to understand the needs of the business, the data behind it, and how to transform information into technical solutions that allow the business to take action.

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build ETL to ingest the data into the data lake. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

Location: This role open to these locations: Seattle & Dallas. Relocation offered from within the US to any of these locations.

About Us

Inclusive Team Culture

Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have twelve employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance

Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.


Basic Qualifications

This position requires a Bachelor's Degree in Computer Science or a related technical field, and 7+ years of relevant work experience.
5+ years of work experience with ETL, Data Modeling, and Data Architecture.
Expert-level skills in writing and optimizing SQL.
Experience with Big Data technologies such as Hadoop, Hive/Spark.
Proficiency in one of the scripting languages - python, ruby, linux or similar.
Experience operating very large data warehouses or data lakes.

Preferred Qualifications

Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
Experience with building data pipelines and applications to stream and process datasets at low latencies.
Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
Knowledge of Engineering and Operational Excellence using standard methodologies.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon Web Services, Inc.

Job ID: A1823029
Show more Show less"
2801441924,Big Data Engineer,Cognizant,2021-11-16,United States,"Mt. Laurel, NJ",Engineering and Information Technology,Full-time,IT Services and IT Consulting and Management Consulting,"***Please note, this position is not offering visa sponsorship now or in the future***

Job description
Perform ETL/ELT design, development and unit testing, including data acquisition, cleansing, standardization, validation, transformations, database persistence, and job execution processes
Assist with evaluating various tests for different environments and tasks
Investigate and analyze reported data issues
Passion for analyzing data to solve problems and improve systems
Passion for solving tough technical challenges and delivering quality products that meets end user requirements
Strong communicator - verbal and written
Service Line

CDB AIM [0000000018-AIA-TSG Pool]

Technical skills

Primary Skill Set:- Spark Scala, Teradata

Secondary Skill Set:- Big Data, Hive, Sqoop, Python, Shell scripting

Preferred/Nice To Have

Expertise in AWS platform

Experience in working in an Agile environment

Experience in communication industry

Employee Status : Full Time Employee

Shift : Day Job

Travel : No

Job Posting : Nov 16 2021

About Cognizant

Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.

Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.

Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.
Show more Show less"
2778647996,Data Engineer - 2015,"KIOXIA America, Inc.",2021-11-04,United States,"Round Rock, TX",Information Technology,Full-time,"IT Services and IT Consulting, Appliances, Electrical, and Electronics Manufacturing, and Computer Software","Company Description

KIOXIA America, Inc. (formerly Toshiba Memory America, Inc.) is the US-based subsidiary of KIOXIA Corporation, a leading worldwide supplier of flash memory and solid state drives (SSDs). From the invention of flash memory to today’s breakthrough BiCS FLASH™ 3D technology, KIOXIA continues to pioneer cutting-edge memory solutions and services that enrich people's lives and expand society's horizons. The company's innovative 3D flash memory technology, BiCS FLASH™, is shaping the future of storage in high-density applications, including advanced smartphones, PCs, SSDs, automotive and data centers

Job Description

If you are a creative thinker, obsessive about pushing the envelope, always ready for the next challenge, joining KIOXIA’s Business Generation Team is the logical next step in your career. Data is essential to our team - we bridge the gap between business and data. KIOXIA is seeking a savvy pipeline-centric Data Engineer who is gifted at telling insightful data stories by gathering insights, creating engaging analytic models, and designing intelligent automation to showcase persuasive business solutions which will enable us to drive towards a data-driven digital organization.

Beyond technical prowess, you’ll need the social aptitude to communicate highly complex data trends to internal customers and leadership in a way that’s easy to understand. Our ideal candidate will be as versatile as the project requires you to be, you’ll never be bored! Come in wearing your propeller hat and be the blueprint for bringing data to life.

Responsibilities

Gather insight, help define strategies through data transformation, create tangible design expressions and transform the essence of these ideas into compelling business solutions are the factors for success.
Develop ETL data pipelines using SSIS, Talend, or similar solutions to produce intelligent and fast-performing solutions that support business processes.
Scope, define and manage the development of transfer of data from any source to any target as for business requirements.
Develop the data infrastructure to allow the business to adopt and develop a web-based application to expedite, modernize, and digitize business processes.
Consult, adopt, and lead the business as it transforms into a digital framework – web applications, real-time analytics, anomaly detection, digital workflows, DB and applications security, and uniform user management.
Collect requirements directly from business users and manage vendors to deliver a project within timeline and budget.
Formulate and collaborate over the creation of technological roadmaps that deliver comprehensive digital transformation
Deploy best in class approaches to data/reports cataloging to support a self-service utilization of those resources
Manage vendors, through the selection process, contract negotiation, budget and timeline control, to final deliverable release

Qualifications

Minimum of 3-5 years of crafting and presenting cohesive and persuasive business approaches and strategies through data transformation.
Bachelor’s degree in computer science, information technology, engineering, or equivalent. Or a Master’s degree in statistics, applied math, or related discipline is a plus.
Minimum of 3 years of experience with SQL, 3NF, and dimensional modeling and data visualization/exploration tools
Experience building or maintaining ETL processes
Data Pipeline design using tools such as SSIS or Talend
Familiarity with BI, visualization, and reporting tools
Knowledge of data sets optimization methodologies and Data Warehousing Modernization
Experience automating business processes (preferred)
MSFT Data Engineer or DevOps certification (preferred)

Additional Information

Req# 2015;

All your information will be kept confidential according to EEO guidelines.


Show more Show less"
2817812170,Data Engineer,Travelers,2021-12-03,United States,"Hartford, CT",Information Technology,Full-time,Insurance,"Company Summary



Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.



Target Openings



1

Job Description Summary



This position is a Data Engineer - Agile Team Lead for Analytics Incident Management Team. Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer on the Incident Management team, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to utilize data to understand, troubleshoot and provide root cause analysis on incidents related to the environment and jobs that support Artificial Intelligence, Machine Learning and business intelligence/insights.

This position may be based 100% remotely or in one of our offices.

Primary Job Duties & Responsibilities



Responsible for the health of the environment through production support processes including production environment and scheduled jobs monitoring and incident and problem management.



Manage the onboarding of recently deployed production assets to the Production support team for high level maintenance and support.



Provide production metrics, insights, and improvement actions (tactical and strategic) of the Analytic environment utilizing Key Performance Indicators (KPIs).



Stewardship of Disaster Recovery and Resilience plans in Enterprise One and ensuring that DR plans are up to date.



Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.



Define, prioritize and ensure a ready backlog of work for a cross-functional product team, accept final product output, focusing on achievement of defined outcomes versus defining how the work is completed.



Translate production support technology strategies and needs into execution ready work for an Agile product team; define team goals and strategy, ensuring alignment with Agile engineer, architect and business leads vision.



Articulate team goals and strategy effectively to key stakeholders, Agile engineer, architect and business Leads, and team members.



Optimize the flow of value by setting objectives and key performance indicators (KPIs) for solutions.



Provide feedback on work-in-progress, clarify requirements and contribute to removing roadblocks or impediments; Look for opportunities for continuous team and process improvement.



Share best practices across teams to ensure alignment and consistency in ways of working within a value stream.



Foster an innovative, inclusive and diverse team environment, promoting positive team culture, encouraging collaboration and self-organization.



Execute on our business vision through partnership and high collaboration with the Agile engineer, architect and business leads.



Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.



Incorporate core data management competencies including data governance, data security and data quality.



Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.



Minimum Qualifications



Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.



Four years of data engineering or equivalent experience.



Education, Work Experience, & Knowledge



Bachelor’s Degree in STEM related field or equivalent preferred



Six years of related experience



Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.



Job Specific Technical Skills & Competencies



Experience with one or more ETL / Data Integration tools (e.g.: Ab Initio, Talend, Informatica) would be preferred



Experience with AWS, Snowflake would be a plus



5 years of software engineering experience within the Data and Analytics field preferred



Experience with one or more Data platforms (e.g.: Snowflake, Teradata, SQL Server) preferred



Must demonstrate a proactive nature with willingness to contribute, collaborate and work in an agile team environment



Exposure with DevOps pipeline and implementation practices



Enjoy learning new technologies with strong learning ability



The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.



Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.



Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.



Strong verbal and written communication skills with the ability to interact with team members and business partners.



Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.



Employment Practices



Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.




If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.




Travelers reserves the right to fill this position at a level above or below the level included in this posting.



To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.




Show more Show less"
2817834987,Data Engineer- Public,IBM,2021-12-02,United States,"Austin, TX",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $75,000 to $145,000 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment
Prior experience working with clients in the public space
Experience with data integration and data management


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2799822011,Data Engineer (Engineering),Morgan Stanley,2021-11-17,United States,"Alpharetta, GA","Project Management, Analyst, and Engineering",Full-time,"Financial Services, Investment Banking, and Investment Management","As a Data Engineer, you will work on high-quality data solutions, partnering with various engineering and business teams within the enterprise to design and develop data driven insights that inform business and product decisions. Additionally, you will be responsible for identifying, researching, and resolving complex technical problems that enhance the combined business decision making capabilities.

Your technical skills, business acumen, and creativity will be essential as you build tools to automate reporting and generate timely business insights.

Responsibilities

Define best practices, develop frameworks and architectural solutions for data movement and analytics at scale.
Train and mentor members within the data engineering team on technology platforms and tools used to develop data solutions.
Prepare documentation - runbooks, training documents and user guides - for frameworks and ETL jobs.
Partner with engineering teams to operationalize/scale the deployment of solutions to achieve optimum performance and efficiency.
Partner with business teams across the enterprise to help understand their data and analytic needs, identify the best data sources and design robust and maintainable solutions.

Required Skills

BA/BS degree in a technical or quantitative/business-oriented field or equivalent practical experience.
5+ years of relevant experience.\Excellent communication, documentation, and planning skills.
Expert-level analytical skills - specifically using SQL.
Independent-working, fast-learning and problem-solving.
Experience working with any big data platform developing ETL and analytic solutions using the tools provided.
Leverage SQL, and other analytic platforms to gather, clean, and prepare data; create dashboards/reports; develop KPIs; analyze trends; provide insights.

Preferred Skills

Experience working on Hadoop with hands-on knowledge of services within the ecosystem.
Experience with data integration and ETL tools and platforms like IBM DataStage, Streamsets.
Experience working with atleast one interpreted programming language such as Perl or Python.
Exposure to business intelligence tools and creation of reports & analytics.
Understanding of cloud-based technologies.
Understanding of distributed data processing frameworks like Spark.
Familiar with automation, workflow and data flow concepts.
Experience working in the Financial industry.

#etrade

Posting Date

Nov 17, 2021

Primary Location

Americas-United States of America-Georgia-Alpharetta

Education Level

Bachelor's Degree

Job

Engineering

Employment Type

Full Time

Job Level

Vice President
Show more Show less"
2789623679,Data Engineer,Zoom,2021-12-03,United States,"Berkeley, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2812775023,"Software Engineer, Data Infrastructure",DoorDash,2021-11-29,United States,"Chicago, IL",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Come help us build the world's most reliable on-demand, logistics engine for delivery! We're bringing on experienced engineers to help us further our 24x7, global infrastructure system that powers DoorDash’s three-sided marketplace of consumers, merchants, and dashers.

The Data Infrastructure team manages DoorDash's massive database and makes data accessible for teams driving decision making, machine learning, and experimentation. The team is relatively small, so there's an opportunity for impact where you can help grow the team and shape the roadmap for data infrastructure at DoorDash.

What You’ll Do

Work on our data pipeline, ETL systems, and real-time data
Come up with solutions for scaling data infrastructure
Help all departments of the company have access to our data
Collaborate in a dynamic startup environment
Improve logistics by taking on cutting-edge, technical problems

What We're Looking For

B.S., M.S., or PhD. in Computer Science or equivalent
5+ years of experience with CS fundamental concepts and OOP languages like Java and Python
Experience working with databases (e.g. SQL) and data infrastructure
Experience in big data technology like Presto, Snowflake, Hadoop, Airflow, Kafka
A passion for analyzing data to inform decisions
Experience improving efficiency, scalability, and stability of system resources

Why You’ll Love Working at DoorDash

We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies.
We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day.
We are learners - We’re not afraid to dig in and uncover the truth, even if it’s scary or inconvenient. Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute.
We are customer-obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility.
We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.
We offer great compensation packages and comprehensive health benefits.

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly and always learn and reiterate to support merchants, Dashers and the communities we serve. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods. Read more on the DoorDash website, the DoorDash blog, the DoorDash Engineering blog, and the DoorDash Careers page.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. Our leaders seek the truth and welcome big, hairy, audacious questions. We are grounded in our company values, and we make intentional decisions that are both logical and display empathy for our range of users—from Dashers to Merchants to Customers.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

Pursuant to the Colorado Fair Pay Act, the base salary range in Colorado for this position is $136,000 - $182,750, plus opportunities for equity and commission. Compensation in other geographies may vary. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

If you need any accommodations, please inform your recruiting contact upon initial connection.


Show more Show less"
2813502108,Data Engineer,iSpot.tv,2021-11-30,United States,United States,,Full-time,,"


We are looking for an experienced Data Engineer to join our growing team of analytics experts. This position will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.




Contribute to building and maintaining data pipelines as well as the implementation of the data lake and data warehouse
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Collaborate with data science and engineering team members to create data tools that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Follow software engineering best practices with readable code that is in source control, testable, deployable, and appropriately documented 
Show more Show less"
2810615279,Analytics Engineer,Navy Federal Credit Union,2021-11-26,United States,"Northern, VA",,Full-time,,"[Principals Only]
Develop data ingestion strategies, designs, and implementations for Navy Federal's Cloud Data Lake. Design and build data transformations to target models in various data lake zones in support of predictive, adaptive analytics and machine learning models. Work with product owners and multiple teams to build automated data pipelines, lead functional teams and solve highly complex problems.
Show more Show less"
2768490193,Data Engineer,Purple,2021-10-27,United States,"Lehi, UT",Information Technology,Full-time,"Marketing and Advertising, Manufacturing, and Retail","Purple is a digitally-native vertical brand with a mission to help people feel and live better through innovative comfort solutions. To us, comfort means more than great products, it means empowering every employee to feel comfortable being themselves. We believe your career at Purple will be a one-of-a-kind “Career in Comfort” because our workforce is one-of-a-kind. We are committed to a culture of collaboration where every voice is heard and understood. As an innovation company at our core, we believe a diversity workforce brings better insights, solutions and products and serves as the backbone to bettering our company. Join with us as we add to our team of exceptional individuals who will help us take over the world — one mattress at a time.

Job SummaryAs part of the Data Analytics team at Purple, Data Engineering provides a critical service to the company by developing and maintaining data pipelines from various data sources into Purple’s data warehouse. The ideal candidate for this position will have 3+ years of prior experience building and maintaining data pipelines. As a seasoned data engineer, the candidate will be able to demonstrate advanced SQL skills, and skills in Python scripting adequate to get data via API requests. The candidate will possess strong analytical and problem-solving skills, combined with client-facing consultative communication abilities. They will have a natural tendency toward detail-oriented work that provides accurate data in an efficient manner and will be able to demonstrate good data mining and troubleshooting skills. This candidate will be expected to work in tandem with other members of the data engineering team, including mentoring more junior members of the team, and should be comfortable working in a team environment.Job Description

Responsibilities

Design, build, and maintain data pipelines using SQL, Matillion, Python 3.X and Amazon Web Services
Identify and fix performance issues in existing pipelines
Identify and safely solve problems in existing datasets, including the design of renumeration processes that do not interrupt or otherwise damage existing reporting
Be an example of good data engineering practices and design patterns, such as idempotence
Proactively identify and correct data quality issues
Develop data profiling processes to facilitate better data quality checks
Build datasets using SQL for reporting purposes
Provide support for ad-hoc data requests and file processing, using various file formats such as XML, CSV and JSON
Provide mentoring for more junior members of the data engineering team

Qualifications & Experience

3+ years of experience in data engineering in some capacity (required)
Moderate level of expertise in SQL (required)
Moderate level of expertise in Python (required)
Experience in AWS environment (preferred, but not required)
Experience with Snowflake (preferred, but not required)
Some experience in Linux (preferred, but not required)
College degree, preferably in a data-related field (Stats, Economics, Math) or Computer Science, Information Science

Benefits And Perks

Medical, Dental, Vision
401(k) Match
Generous PTO
Market Money
Earn a Mattress
Purple Swag
Amazing Purple Products
WHY WORK AT PURPLE?

Make your mark: We value innovative thinking. At Purple, you will be empowered to bring your ideas to life as we work together to improve people’s lives through comfort.
Gain unique experience: Be a part of one of the fastest growing companies in Utah! The contributions you make will matter at Purple as the company continues to grow with you.
Awesome culture: Join the tight-knit team at Purple and you can enjoy working alongside industry experts, making close friends, and annual employee appreciation events.

Purple provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

This policy applies to all terms and conditions of employment.
Show more Show less"
2595444125,Big Data Engineer,Softrams,2021-12-03,United States,"Woodlawn, MD",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Management Consulting","Softrams is one of the fastest growing Digital Services firm in the Washington Metropolitan regions crafting human centered, empowering digital services with focus on HX, AI, Cloud, DevOps and Cyber Security. Offices in Leesburg VA, Baltimore MD and Plano TX and teams across USA.

Recognized as one of the Top Workplaces in Technology (2021)
INC 5000, Fastest growing companies in America (2nd year in a row)
Washington Business Journal Top 75 Fastest Growing Companies in Greater Washington area
2020 NXT UP - Top Federal Emerging Technology and consulting firms
2020 Inaugural DC Metro’s Most Successful Companies
2020 Washington Technology Fast 50

NVTC Tech 100 (2019, 2020)

Job Description

The Government Health IT Solutions of Softrams is seeking a Big Data Engineer for a fulltime/ direct hire position in the Baltimore metro area.

The selected candidate will wrangle large, complex datasets and set up data pipelines to provide select data for quality analysis and network with appropriate internal sources to gather and/or exchange data on specialized matters.

Other Key Responsibilities Include But Not Limited To

Identify data quality issues and properly source data that is most relevant to the quality analysis for a given model;
Advise on the methods and data needed and/or available to evaluate the (intelligence or data?) problem;
Collaborate with data collectors and analysts to identify and close gaps on complex monitoring problems;
Set up streamlined and highly efficient data pipelines to enable all stakeholders to have access to the most complete datasets as quickly as possible
Analyze, evaluate, and assess quantitative data (using statistical software, computer models, geospatial models, software languages, and mathematical models) to contribute to or develop software tools, analytic models, or reports.

Required Skills

Master’s in Data Science, Mathematics, Statistics, Analytics, or related field and 4+ years of related experience
In depth knowledge of and DOCUMENTED experience in some or all of the following:
Relational Databases and Relational Database Management Systems
Non-Relational Database concepts
Programming and scripting in Python, R, and/or SAS
Data Mining
Cloud computing (AWS, Azure, or GCP)
Apache Kafka and Spark (Scala experience a plus)
Data engineering using Python and SQL Queries to extract and transform large volumes of data into a format suitable for analysis

Zeppelin, Jupyter, or Anaconda

Machine Learning, text analytics, and/or predictive modeling
Linux and Windows
Working in a team-based agile work environment

Desired Skills

An in-depth knowledge of CMS (Center for Medicare and Medicaid Services) protocols.
Experience using and in-depth knowledge of CMS’s Integrated Data Repository (IDR) and Teradata technology and solutions.
Experience using administrative claims data or health insurance claims data and topic areas such as Medicare, Medicaid, and other public health insurance programs.
Experience working in an analytical research environment
Hadoop ecosystem (map reduce, parallel processing and distributed computing concepts)
Proven experience in developing functional applications and systems of medium to high technical complexity
Knowledge must include architectural design, web part development, management and troubleshooting with a focus on planning, deploying and supporting implementations at an Enterprise scale.
Ability to manage multiple projects efficiently and able to meet deadlines.
Experience with Section 508 accessibility standards.

Public Trust Clearance

This role requires the hired candidate to go through public clearance. A minimum of 3 years of stay in the U.S. within the last 5 years is a must to be eligible to qualify for public trust clearance sponsorship.

Benefits

Health, Dental, Vision and STD, LTD, Life Insurance & Voluntary Life insurance.
Retirement 401(k) Plan with employer matching. Immediate vesting.
Vacation & Sick leaves
Discretionary bonus

Work Location

Softrams is a 100% remote at the moment, and we expect our employees to be onsite 2-3 times a week post-covid. Must be able to work on-site in Woodlawn, MD when onsite work resumes.

About Softrams

Softrams is a Maryland & Virginia-based small business information technology, consulting, and solutions provider specializing in emerging technologies for UX/UI, Mobile Apps, DevOps, Big Data Analytics, Data Science, and Cyber Security. We offer innovative technology implementations and build customer-centric services that are simple, intuitive, scalable, efficient and most importantly usable.

Softrams is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, nation origin, sexual orientation, gender identity, disability or protected veteran status.

As a HUBZone certified business, we strongly encourage candidates who reside in a HUBZone area to apply. Click on the link here to check if you are in the HubZone area ( http://map.sba.gov/hubzone/maps/ ).
Show more Show less"
2816007058,Analytics Engineer,Trust In SODA,2021-12-02,United States,United States,Information Technology and Engineering,Full-time,Computer Software,"We're looking for a Remote (United States) Senior Analytics Engineer to join the fastest growing software management platform in the Bay Area, which ships code better and faster.

What you'll be doing:

Provide data-driven solutions to solve complex business problems
Refine our best practices pertaining to data modeling, data quality testing, etc.
Train users across the organization to self-serve requests using explorable data sets
Collaborate with other departments to learn the importance & requirements of their requests

What we're looking for:

Excitement to work in a collaborative, rapidly growing company
Expertise in Python
Proficiency in Airflow
Familiarity with Looker
Experience using Snowflake
Bachelor’s in computer science/math or equivalent experience

What we offer:

Ability to work fully remote
Competitive salary & benefits
Unlimited PTO with a 2-week minimum
Show more Show less"
2819067004,Data Engineer,BenchPrep,2021-11-29,United States,"Chicago, IL",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","As a Data Engineer at BenchPrep, you will help develop our products to allow for informative and timely delivery of data insights, ultimately helping millions of students and professionals achieve success. On a day-to-day basis, the focus is understanding and translating business needs into effective data architecture, in-depth SQL queries, and ETL processes to connect multiple data sources for our cloud-based SaaS products. Our product roadmap includes a significant focus on data analytics providing you the opportunity to meaningfully impact on our business and customers.

In the role, you will:

Design and develop the data pipeline architecture including extract, transform, and load (ETL) processes
Develop and tune queries for accurate and performant reporting. Optimize data extract processes used by reporting tools (Domo). Monitor and report on ETL job performance and status.
Design and build data sets (for warehousing or as data extracts) to efficiently serve large, complex analytic requirements
Build processes to support data transformation, metadata, dependency, and workload management.


Your proactive approach will be highly helpful as not only will you design and build BenchPrep's most technically complex data storage and access methods, you will also advise and coach software engineers and data analysts on how to achieve optimal functionality, performance, and scalability in our data and reporting systems. In a similar vein, while performing ad-hoc reporting and data extraction for internal users and external client requests, you'll constantly look for ways to develop tools and/or automation to streamline similar ad hoc reporting requests into standard reports.

Skills and experiences we value:
Demonstrated success developing and tuning data pipelines and ETL processes
Strong SQL and relational database knowledge, ideally PostgreSQL
Analytical and problem-solving mindset
Ability to translate business questions and analytic requirements to specific data sets and query results that satisfy them
Familiarity with non-relational data storage technologies (NoSQL)
Note: We know that excellent candidates can have all sorts of backgrounds and experiences, so please don't hesitate to apply even if you don't meet 100% of the listed requirements! And check out our latest blog post to learn more about inclusion at BenchPrep in the Engineering team.""


Nice to have and/or you'll learn:

Experience developing and maintaining data warehouses in big data solutions e.g. Snowflake
Conceptual knowledge of data and analytics, such as dimensional modeling, ELT, reporting tools, data governance, data warehousing, structured and unstructured data.
BI Tools (Sisense)


About BenchPrep:

We deliver the most advanced and flexible learning experience for certification, credentialing, test prep, continuing education, and training. Our cloud-based learning platform helps training organizations, associations and the extended enterprise deliver a highly engaging and effective learning experience for individuals who are trying to advance their careers. We incorporate the latest in learner-centered technology, including personalization, gamification, data science, usability and omni-channel delivery.

We're sitting in a pivotal time in the BenchPrep history. The number of learners on our cloud-based learning platform has almost reached 7 million in 2021.

We're committed to helping students learn better, and that starts with our own people.

COVID-19:

Speaking of our people, in March 2020, we put safety first and quickly moved our people to working remotely. We've learned that our employees are really productive working at home and still (mostly) work remotely. Our first core value is ""People First"" and the pandemic has reinforced how true this value reigns to us. What is the future of BenchPrep's plans for working in-office or remote? We haven't finalized that, but what we do know is that collaboration and connection are our top priorities. Remote, in-office (Chicago), or hybrid... employees know how they work best. Let us know what your preferences or requirements are for being remote only, hybrid or in-office.

Life at BenchPrep:

We work at BenchPrep because we're dedicated to the mission and each day we have an opportunity to be challenged and learn. We work hard and have lots of fun. Culture is our lifeline at BenchPrep. We celebrate our people, both professionally and personally. We care about learning so much that we offer employees $1,200 annually to develop their skills so they can continue to operate everyday with new skills. It's no wonder we were selected in Inc's Best Workplaces of 2020 and Crain's 2020 Best Places to Work in Chicago lists.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We are looking for high performing and motivated professionals who are excited about the chance to leverage technology to impact the lives of millions of learners. Join us.
Show more Show less"
2806410118,Data Engineer,Blockchain.com,2021-10-30,United States,"San Francisco, CA","Research, Information Technology, and Engineering",Full-time,"IT Services and IT Consulting, Internet Publishing, and Financial Services","Blockchain is the world's leading software platform for digital assets. Founded in 2011, we provide the largest production blockchain platform in the world, powering more than 50 million non-custodial wallets. We share the passion to code, create, and ultimately build an open, accessible and fair financial future, one piece of software at a time.

We are looking for a talented data engineer to join our Consumer Data Science team. The group is part of a larger DS team and focuses on customer analytics and modelling, informing all product decisions and creating models to improve efficiency, growth, and security. In order to do this, we use data from various sources, and of varying quality. Our ETL processes serve both the wider company (in the form of clean, simplified tables of aggregated statistics and dashboards) as well as the Data Science team itself (cleaning and processing data for analysis and modelling purposes, ensuring reproducibility).

We are looking for someone with experience in designing, building, and maintaining data pipelines and our data lake. As a data engineer, you will be involved in all aspects of data collection, cleaning and processing, ensuring quality and availability of data. You will collaborate closely with data scientists, platform, and front-end engineers, defining requirements and designing new data processes, as well as maintaining and improving existing ones. We are looking for someone who is passionate about high quality data and understands the impact they have in solving real-life problems. Being proactive in identifying issues, digging deep into their source, and developing solutions, are at the heart of this role.

What You Will Do


Maintain and evolve the current data lake infrastructure and look to evolve it for new requirements
Maintain and extend our core data infrastructure and existing data pipelines and ETLs
Provide best-practices and frameworks for data testing and validation and ensure reliability and accuracy of data
Complement our data scientists by providing a reliable, secure and maintainable modelling framework that can be used to easily deploy models to production
Design, develop and implement data visualization and analytics tools and data products


What You Will Need


Bachelor’s degree in Computer Science, Applied Mathematics, Engineering or any other technology related field
Previous experience working in a data engineering role
Fluency in Python
Previous experience with ETL pipelines
Experience working with Google Cloud Platform
In-depth knowledge of SQL and no-SQL databases
Experience with Git


Nice to have


Experience with Airflow or Google Composer
Experience with other programming languages, like Java, Kotlin or Scala
Experience with Spark or other Big Data frameworks
Experience with distributed and real time technologies (Kafka, etc..)


Compensation And Perks


Unlimited vacation policy; work hard and take time when you need it.
Apple equipment.
Full-time salary based on experience and meaningful equity in an industry-leading company
Benefits: dependant on employee location
Flexible hours and smart working options


Application


CV/Resume or Linkedin profile
Link to github, stackoverflow, personal website and/or blog (if applicable).


When you apply to a job on this site, the personal data contained in your application will be collected by one or more of the following subsidiaries of Blockchain Luxembourg S.A (each, a “Controller”):


Blockchain Access UK Ltd.
Blockchain (GB) Limited
Blockchain (US), Inc.
Blockchain (LT), UAB


You may contact our Data Protection Officer by email at dpo@blockchain.com. Your personal data will be processed for the purposes of managing Controller’s recruitment related activities, which include setting up and conducting interviews and tests for applicants, evaluating and assessing the results thereto, and as is otherwise needed in the recruitment and hiring processes. Such processing is legally permissible under Art. 6(1)(f) of Regulation (EU) 2016/679 (General Data Protection Regulation) as necessary for the purposes of the legitimate interests pursued by the Controller, which are the solicitation, evaluation, and selection of applicants for employment.

Your personal data will be shared with Greenhouse Software, Inc., a cloud services provider located in the United States of America and engaged by Controller to help manage its recruitment and hiring process on Controller’s behalf. Accordingly, if you are located outside of the United States, your personal data will be transferred to the United States once you submit it through this site. Because the European Union Commission has determined that United States data privacy laws do not ensure an adequate level of protection for personal data collected from EU data subjects, the transfer will be subject to appropriate additional safeguards under the standard contractual clauses.

Your personal data will be retained by Controller as long as Controller determines it is necessary to evaluate your application for employment. Under the GDPR, you have the right to request access to your personal data, to request that your personal data be rectified or erased, and to request that processing of your personal data be restricted. You also have to right to data portability. In addition, you may lodge a complaint with an EU supervisory authority.
Show more Show less"
2775207951,Big data Support Engineer (Spark),Mindtree,2021-11-30,United States,"Bellevue, WA",Project Management and Information Technology,Full-time,IT Services and IT Consulting,"Job Description:

3 + years of technical experience in working with Bigdata technologies like Spark, (or) .NET (C#) with SQL Server.
Having Azure domain experience is a big asset.

 

Soft Skills

Leadership - handle technically challenging and politically sensitive customer situations
Strong communications skills – Excellent spoken and written English communication skills
Effective, polished interaction with customer to gather information quickly; explain customer responsibilities in resolving issue; communicate next steps and status; and inspire confidence
The successful Support Engineer has the drive and intellectual horsepower to resolve difficult customer issues; directly supports customers through telephone, email, and chat services as applicable
Demonstrable troubleshooting skills
Cross-team collaboration

 

Bigdata Skills

Expertise in Spark ecosystems, Data frame API, Data set API, RDD APIs & Spark SQL.
Expertise in workspace and cluster configuration, performance tuning and log monitoring.
Good understanding on security of spark clusters, network connectivity and IO throughput.
Experience with spark streaming jobs integrating with streaming frameworks.
Hands on experience with Python, Scala and SQL.
Integrating Databricks with various ETL tools and perform required operations.

 Time of operation: This track will be in 24X7 shift model. Therefore, candidates should be flexible to cover during holidays and weekends to accommodate MS roster

 

ABOUT MINDTREE

Mindtree delivers digital transformation and technology services from ideation to execution, enabling Global 2000 clients to outperform the competition. “Born digital,” Mindtree takes an agile, collaborative approach to creating customized solutions across the digital value chain. We are co-headquartered in Bangalore, India and New Jersey.

Founded in 1999, we are now 16,000+ Mindtree Minds across the globe. Our annual revenue crossed $780+ million in 2016-17. Mindtree provides services in e-commerce, mobile applications, cloud computing, digital transformation, data analytics, EAI and ERP, with more than 290 clients and offices in 14 countries.




Visit http://careers.mindtree.com for more details

 

Mode of Hiring

Full time

Show more Show less"
2827318169,Big Data Engineer,Tech Holding,2021-11-09,United States,"Los Angeles, CA",Engineering and Information Technology,Full-time,Computer Software,"We are looking to bring on a Big Data Engineer to join our team. You will be responsible for expanding and optimizing our data and pipeline architecture. The Big Data Engineer will support our software developers, data analysts, and data scientists on data initiatives. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company's data architecture to support our next generation of products and data initiatives. If you're looking to work in a collaborative work environment with some of the industry's brightest minds, this would be a great opportunity. We are looking for someone with experience in leading multiple projects and teams.

Required Skills & Experience

Experience with leading multiple projects and teams.

Experience with big data tools: Hadoop, Spark, Kafka, Airflow, etc.

Experience with relational SQL and NoSQL databases.

Experience with Python, Java.

Experience using AWS (EC2, ECS, Lambda, EKS, EMR, Glue)

Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.
Show more Show less"
2791807638,Data Engineer,"Datto, Inc.",2021-12-04,United States,"Dallas, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","As the world’s leading provider of cloud-based software and technology solutions delivered by managed service providers (MSPs), Datto believes there is no limit to what small and medium businesses can achieve with the right technology. Datto offers Unified Continuity, Networking, and Business Management solutions and has created a one-of-a-kind ecosystem of MSP partners. These partners provide Datto solutions to over one million businesses across the globe. Since its founding in 2007, Datto continues to win awards each year for its rapid growth, product excellence, superior technical support, and for fostering an outstanding workplace. With headquarters in Norwalk, Connecticut, Datto has global offices in the United Kingdom, Netherlands, Denmark, Germany, Canada, Australia, China, and Singapore. Learn more at datto.com.

A Look Inside The Job

Work on a fast paced, cutting edge datawarehouse stack using Snowflake database on AWS and airflow to bring disparate data sets from across the enterprise for rich analytics and machine learning
Design, implement and automate ETL procedures to integrate data from multiple internal and external sources
Identify data quality issues via data profiling, DQ checks and implement proper remediation methods
Collaborate with business and technology stakeholders to ensure successful data warehouse development and utilization
Create detailed technical design documents in accordance with business requirements
Perform quality assurance and regression testing to validate production readiness
Create detailed deployment plans for migration to production environment
Monitor/ensure acceptable levels of system performance, integrity and security

About You

Advanced degree in Engineering, Computer Science or related field
Understanding of Big Data technologies and solutions (Hadoop, Kafka, Hive, S3, Redshift, Snowflake etc.)
2+ years of industry experience in software development, data engineering, business intelligence, or related field with a track record of manipulating, processing, and extracting value from large datasets.
Demonstrated strength in data modeling, ETL development, and data warehousing
Advanced working SQL knowledge and experience working with relational databases, as well as working familiarity with a variety of databases.
Experience with Snowflake database preferred.
Experience with AWS cloud preferred
Must have working experience in one of the following: Spark, Airflow and Python
Some experience with designing and enhancing Tableau reports & data visualizations.
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to engineering teams and business audiences
Excellent oral and written communication skills

At Datto, we believe our employees are our greatest asset and offer all full-time employees a wide-ranging benefits package, including:

Comprehensive health-care benefits
Flexible paid time off policy
Generous paid paternal leave
“Datto University” virtual on-boarding program
Access to more than 5,000 courses via LinkedIn Learning
Education reimbursement
Employee Assistance Program
Headspace App
Charity match program
A dynamic and socially active work culture, including Employee Resource Groups
Networking and career development opportunities
And more!

By submitting an application, you acknowledge we will process your data in order to consider you for the position you apply for and for other open positions within our company for which you may be suited. We collect and store your data in accordance with our Recruiting Privacy Practices .

Datto is an equal opportunity employer.
Show more Show less"
2809303649,Data Engineer (Remote),Virtually Human,2021-11-22,United States,"San Francisco, CA",Engineering,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Want To Work For a Cutting Edge Tech Start-Up Within Blockchain and NFT’s?
Are you a motivated, results-oriented team player?
Do You Appreciate the Flexibility of Working From Home?


Join Us

Virtually Human Studios (VHS) in exploring the fringes of entertainment delivery for the next generation. Founded in 2019, Virtually Human is a gaming and entertainment blockchain startup and proud creators of the viral NFT gaming platform of its time, ZED RUN. VHS has partnered with some of the most innovative and leading gaming and sports giants around the world, including Unikrn and Atari just to name a few.

The Opportunity

We are looking for a certified Data Engineer to join and contribute to the delivery of our Blockchain entertainment product, working within a medium size team and supported by the CTO.

About You

You have at least 3 years of experience working in a similar position, ideally within blockchain. You are a team player who can get up to speed quickly, and can influence and motivate them for alignment with key business objectives.

You have the flexibility required to work with a globally distributed development team across multiple time zones along with a good internet connection at all times to allow for easy facilitation of group video calls. You can write and speak fluent English.

Selection Criteria

Proven ability to take raw data and transform it in ways to best capture its value and insights;
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets;
Strong experience writing SQL queries for analyzing data and transforming it according to business requirements;
Experience with big data tools: Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and MongoDB;
Experience with cloud services such as Redshift and BigQuery;
Experience with building and managing data warehouses and data lakes;
Experience with data pipeline and workflow management tools: dbt, Luigi, Airflow, etc;
Experience with both batch and real time data processing;
Demonstrated experience using Python, GIT, SQL, Visualisation Tools, Data Notebooks (e.g. jupyter) and Linux;
Google cloud experience is desirable but not essential.


Why Work For VHS?

Attractive and competitive salary;
Flexible work from home arrangement;
A supportive friendly environment of dedicated and passionate co-workers;
Exposure to the new aged world of Blockchain and NFT’s;
Make the role your own!


To Apply

To be considered for this position please provide a copy of your resume and cover letter and/or digital video resume outlining and addressing the selection criteria.
Show more Show less"
2750597478,Data Engineer,Zuora,2021-09-20,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","We are only accepting applications from candidates based in the USA and authorized to work in the USA. The person hired for this position will be expected to perform work within the United States.

OUR VISION: THE WORLD. SUBSCRIBED.

Customers have changed. They’re looking for new ways to engage with businesses. Consumers today have a new set of expectations. They want outcomes, not ownership. Customization, not generalization. Constant improvement, not planned obsolescence.

In the old world (let’s call it the Product Economy) it was all about things. Acquiring new customers, shipping commodities, billing for one-time transactions. But in today’s new era, it’s all about relationships. More and more customers are becoming subscribers because subscription experiences built around services meet consumers’ needs better than the static offerings or a single product.

Our vision is “The World Subscribed” where one day every company will be a part of the Subscription Economy® (a phrase coined by our CEO, Tien Tzuo and author of the best selling book Subscribed).

THE ROLE

At Zuora, data is a key strategic pillar for operating our business. All our teams rely on accurate, timely data to measure and improve outcomes, including building better products, improving the customer experience, optimizing the sales process, and ultimately increasing the overall value we deliver to our customers.

As An Engineer On The Zuora Corporate Data Team, You'll Have The Opportunity To Design And Build Robust End-to-end Solutions To Support Data-driven Decision Making Across The Entire Company, Including

Pipelines and tools for delivering a reliable flow of metrics from all our products to help understand customer usage
Orchestration for extracting and transforming data from all our business applications and systems
A centralized data warehouse that assembles key data and insights about customers, users and products into one central location
Integrations with BI tools and other applications to provide business and technical users with secure, flexible trustworthy access to the data they need, through interfaces that meet their specific needs

Specific technical skills that you'll have a chance to learn and refine include:

Building and monitoring data pipelines using open source tools and frameworks
Designing, implementing and operating robust API services
Provisioning and maintaining complete architectures on public cloud infrastructure (AWS)
Working with a variety of data stores and technologies
Data modeling and solving complex analytic transformations using SQL

Skills

Joining the Corporate Data Team will also give you the opportunity to develop the whole range of skills you need to scale your effectiveness as an organizational leader

As an engineer, advancing your career depends on much more than your ability to solve isolated technical problems.

Working directly with end users in a variety of different roles to understand business requirements and identify appropriate technical solutions
Working cross-functionally to support an effective corporate data governance program
Writing design and implementation documentation
Running a transparent, predictable software delivery lifecycle, including planning, testing and release management
Operating high-availability, mission-critical services

Successful candidates for this position should be able to demonstrate a solid foundation as software engineers, experience building and operating complex data pipelines, excellent communication skills, and a strong desire to learn.

Specific Desired Experience And Knowledge Includes

python for data integration and application development
complex SQL for data transformation, validation, and analytics
data pipeline orchestration (we currently use Airflow)
provisioning and monitoring public cloud infrastructure (AWS)
interactive data exploration and visualization

About Zuora & Our “zeo” Culture

Zuora (NYSE: ZUO) Zuora provides the leading cloud-based subscription management platform that functions as a system of record for subscription businesses across all industries. Powering the Subscription Economy®, the Zuora platform was architected specifically for dynamic, recurring subscription business models and acts as an intelligent subscription management hub that automates and orchestrates the entire subscription order-to-revenue process seamlessly across billing and revenue recognition. Zuora serves more than 1,000 companies around the world, including Box, Ford, Penske Media Corporation, Schneider Electric, Siemens, Xplornet, and Zoom.

At Zuora, we have one CEO but every employee is empowered and supported to be the ‘ZEO’ of their own career experience. By embedding inclusion and belonging into our processes, policies and culture, we are building a workplace where our 1,200+ ZEOs across North America, Europe, and APAC can bring all the elements of who they are into their work. In addition to an industry-leading six-month, 100% paid parental leave for all our ZEOs, we also offer programs to support your mental health and give back to our communities along with “career cash” and plenty of learning and development opportunities.

To learn more visit www.zuora.com

Zuora is proud to be an Equal Employment Opportunity employer.

Think, be and do you! At Zuora, different perspectives, experiences and contributions matter. Everyone counts. Zuora is proud to be an Equal Opportunity Employer committed to creating an inclusive environment for all.

Zuora does not discriminate on the basis of, and considers individuals seeking employment with Zuora without regards to, race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics.

We encourage candidates from all backgrounds to apply. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us by sending an email to assistance(at)zuora.com.
Show more Show less"
2797549712,Data Engineer - ETL - Migration,Fidelity Investments,2021-12-04,United States,"Durham, NC","Quality Assurance, Information Technology, and Engineering",Full-time,"IT Services and IT Consulting, Information Services, and Financial Services","Job Description

The Role

If you are an experienced engineer and want to be a part of an exciting journey to work within one of Fidelity’s most dynamic Software Engineering Domains, looking for a collaborative team environment where you will have a wealth of opportunities to innovate and have intellectual curiosity to learn, Enterprise Cybersecurity may be right for you!

The Expertise and Skills You Bring

Bachelor’s or master’s degree in a technology related field (e.g., Engineering, Computer Science, etc.) required.
2 to 3+ years of ETL/data migration experience (SSIS, Informatica)
2+ years of experience in SQL
Experience with Python or PowerShell is a plus
Experience with Postman/API development is a plus
Experience in agile methodologies (Kanban and SCRUM)
Experience supporting mission critical applications quickly
Excellent communication skills, both through written and verbal channels
Excellent collaboration skills to work with multiple teams in the organization
Ability to understand and adapt to changing business priorities and technology advancements
You are a strategic thinker and enjoy using your critical problem-solving skills.


The Value You Deliver

Designing, building, and supporting critical solutions for applications to provide the best customer experience
Exploring new technology trends and leveraging them to simplify and modernize our ecosystem
Driving Innovation and influencing the team to implement solutions with forward thinking
Collaborating with internal and external teams to deliver technology solutions for the business needs
You enjoy finding ways to improve development agility and productivity
Resolving technical roadblocks to the team and mitigating potential risks
Delivering system automation by setting up continuous integration/continuous delivery pipelines
Motivated to explore the latest data technologies and promote continuous learning.


The Team

Fidelity’s Enterprise Cybersecurity group is seeking a Data Engineer to build and maintain the eco system that manages associates’ digital identity and access entitlements from onboarding through to separation. Our vision is to empower Fidelity associates to succeed by making access and insider threat services seamless, secure, and appropriate. In this role you will be responsible for leveraging your scripting and ETL expertise to establish and manage platform integrations. You will join a team of engineers, product owners, architects, business partners and stakeholders in US and across our global sites.

Certifications

Company Overview

At Fidelity Investments, our customers are at the heart of everything we do. As a privately held company with a rich 75-year history, our mission has remained the same since our founding: to strengthen the financial well-being of our clients. We help people invest and plan for their future. We assist companies and non-profit organizations in delivering benefits to their employees. And we provide institutions and independent advisors with investment and technology solutions to help invest their own clients’ money.

Join Us

At Fidelity, you’ll find endless opportunities to build a meaningful career that positively impacts peoples’ lives, including yours. You can take advantage of flexible benefits that support you through every stage of your career, empowering you to thrive at work and at home. And you don’t need a finance background to succeed at Fidelity—we offer a range of opportunities for learning and growth so you can build the career you’ve always imagined. We welcome associates from different backgrounds and with different perspectives to help us innovate and make a difference for our customers and our communities.

We invite you to Find Your Fidelity at fidelitycareers.com.

Fidelity Investments is an equal opportunity employer. We believe that the most effective way to attract, develop and retain a diverse workforce is to build an enduring culture of inclusion and belonging.

Fidelity will reasonably accommodate applicants with disabilities who need adjustments to participate in the application or interview process. To initiate a request for an accommodation, contact the HR Leave of Absence/Accommodation Team by sending an email to accommodations @fmr.com, or by calling 800-835-5099, prompt 2, option 2.


Show more Show less"
2816588770,Data Engineer,"Miracle Software Systems, Inc",2021-12-02,United States,"Atlanta, GA",,Contract,,"About the job

We Miracle Software Systems is looking for Data Engineer @ Atlanta GA , 3+ months




Position: Data Engineer




Location: Atlanta GA




Duration: 3+ Months







Primary Skills: GCP,SQL,Cloud




Good understanding of GCP platform and data services like BigQuery, Dataflow, Cloud Pubsub, Cloud functions, Cloud SQL, and including engines like 
  GAE, GCE, and GKE  
SQL skills including advanced skills like performance-tuning, clustering, Indexing, modeling, database optimizing, etc.
Ability to handle huge datasets and performing quick data analysis to extract insights from raw data for sharing with clients with storytelling  
Should be able to code (Python preferred) to write new applications (cloud functions, dataflow, etc.) and also a lot of existing running workloads needs frequent updates,
  patches  
Good client interaction and communication skills
Must know CICD concepts as almost all pipelines are automated via the CICD approach by using Concourse technology under the hood  
Must know PowerShell scripting  
Domain-specific knowledge infrastructure, VMWare space (VMs, Datastore, and Hosting servers) 
Ability to work under high pressure and customer demanding environment with tight deadlines




Please reach me at hkilaparthi@miraclesoft.com or (248)-412-0316




Show more Show less"
2791067910,Data Engineer,Anvyl,2021-11-08,United States,"New York, United States",Engineering,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","At Anvyl we are on a mission to make bringing products to life easier. We believe everyone should be able to make the physical products they want to see in the world and no one should be left out because finding suppliers, scaling up production, or paying for goods is too hard. So we’re building software where brands manage suppliers, oversee production, and track in-depth product data from procurement to delivery of inbound goods. It saves hours a day of manual work, reduces supply chain costs, and provides actionable data on supplier activity throughout sourcing, production, and the product lifecycle. These tools fuel and empower the most important relationships you have - the ones with your suppliers. We are looking for an experienced and self-motivated Data Engineer to join the Insights team at Anvyl. You will collaborate with skilled designers, data scientists, and data engineers to deliver data products for modern supply chains managed on Anvyl. You should demonstrate a deep understanding of data engineering principles and core CS fundamentals, curiosity, data fluency, and a collaborative work ethic.

Requirements

What You'll Do

Build products that unlock supply chain insights using data
Develop ETL/ELT jobs and pipelines to ingest, clean, and model data
Work with cutting edge technologies, like Prefect, Kafka, Dask, Kubernetes, and BigQuery
Scrape, gather, and integrate data from external sources
Design, architect, and implement data infrastructure for easier automation and greater scalability
Develop processes to improve code and data quality


What We’d Love to See:

Strong coding skills in Python and SQL
4+ years experience with object-oriented programming languages
4+ years experience in custom ETL/ELT design, implementation and maintenance.
You know how to work with large data sets, and distributed systems
You have used one or more high-level JVM-based processing frameworks such as Kafka, Beam, Dataflow, Spark, or something we didn’t list- but not just Pig/Hive/BigQuery/other SQL-like abstractions.
You have proven understanding about data modeling, data access, and data storage, caching, replication, and optimization techniques.
You have worked in a cloud-native (GCP preferred) development and production environment where all CI/CD take place
You care about agile software processes, data development, reliability, and responsible experimentation.
You are comfortable with asynchronous communication, being able to work independently while always sharing context with your team members.
You have data wrangling skills and can easily handle complex datasets using SQL, including complex joins.
You are comfortable owning your project timelines, prioritizing tasks with user and business impact in mind, assessing speed/precision tradeoffs, and proactively communicating project statuses to stakeholders and teammates
You work well collaboratively, both in a technical and cross-functional context.
You are curious and excited to learn new methods, approaches and perspectives, and are eager to investigate interesting trends in the data


Example projects you could work on at Anvyl:

Develop MLOPS pipelines to streamline development and deployment of ML models
Develop data infrastructure to support data testing, automation, and ELT/ETL
Discover and integrate data from external sources to form the foundation of a new Data Product
Create data models to support rapid feature development and reduce code repetition
Streamline deployment and testing processes


What we value:

Desire to learn and grow
Bias towards action
Team-oriented attitude, you derive joy from seeing others succeed
Enthusiasm for, and interest in, how technology impacts the physical world we live in
Great restaurant recommendations!


Benefits

We are a team that believes in cooperation, learning, quality, and putting our people and customers up front. We are a small company offering large company benefits - health, dental, and vision offerings, 401k availability, and many more perks. We are a remote company and want to make sure our employees have the flexibility to do their work where they feel best, and know that they can step away to recharge with our unlimited paid time away.

We are a diverse team spanning all professions, cultures, races, gender, and orientations. Our teammates are located across the country as well as in China, giving us a truly global footprint. We enjoy spending time together in person when - especially if there is Korean BBQ - or having a group brain-storming session on the next product innovation.


Show more Show less"
2812350444,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"Los Angeles, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2805272868,Data Engineer,Courier Network,2021-12-01,United States,United States,,Full-time,,"Your Role:

Our quickly growing small business specializes in expedited air courier services, from anywhere to everywhere in the world. We are looking for a BI specialist who is passionate about data, analytics, and true reporting. 

 

Our data analytics BI warehouse and pipeline/engines are built on Sisense, TMS (Transportation Management System), and Priority ERP Accounting. You will help us see more of our business, teach others in the company about analytics, and improve the use and reporting of our data. 

 

You will become an integral part of providing data-driven insights that inform significant company decisions, and that can also be safely and reliably shared with customers.

 

Your Responsibilities:

Monitor and corrections of all data platforms.
 Build Elasticubes and Dashboards using Sisense.
Improve and develop new TMS and Priority ERP Accounting data models.
Generate efficient end-to-end reporting solutions (from data ingestion to customers).
Work with key business managers to define key metrics and reporting requirements.
Maintain and improve our data ecosystem (ETL, DB technology, data optimizations).
Drive the adoption and effective use of our software tool within every team.

 

You are a good fit if you:

Have a solid understanding of data warehouse, ETL, Pipeline tools, and BI tools.
Have deep experience with Sisense or other advanced BI tools.
Know query optimization, indexing, SQL query optimization, and analysis.
Familiar with Priority Accounting or a similar ERP.
Familiar with an advanced global TMS platform (Transportation Management System).
Are very proficient in JavaScript, Python, API, Frameworks & EDI.
Are familiar with the AWS ecosystem, have solid scripting skills and write clean code.
Can communicate clearly and directly.

 

Your Education and Experience:

BA/BS in a quantitative field.
3-5+ years of work experience as a data engineer, or in a highly analytical role.
Experience writing SQL queries and using Sisense and a TMS.
Experience with programmatic scripting using JavaScript and Python.
Strong grasp of statistics and experience conducting rigorous data analyses.
Experience developing models and visualizations, including Excel.

 

Useful for you to have:

The capacity to juggle multiple priorities effectively within a fast-paced environment (critical).
Be a highly motivated self-starter with the ability to execute plans independently (important).
Be able to learn new data-related tools and technologies to maintain and improve the overall data management and BI strategy.
Be passionate about spreading the value of data throughout the company.
Communicate insights to a broad audience with varying levels of technical expertise.

 

Why work at CNW Global?

We are a fast-moving, fun-loving, passionate group of people who really care about solving expedited air logistics emergencies for our customers. We work for them! We empower our employees to drive our business and to suggest changes when we don't get it right. These are our values:

Exceed Customer Expectations: we provide an exceptional experience on each and every challenge.
Take Ownership: we are trusted to make decisions that are in the best interests of our customers. We think and act like owners. We care and are agile, and that makes all the difference in the world.
Be Curious: We are curious, ask questions, seek to understand and try new things.
Do the Right Thing: We earn trust by being transparent, respectful, and honest with each person with whom we interact.
Get Results: Results fuel our excitement, and we know how our personal accomplishments tie to the success of the company.

 

Our benefits:

CNW offers its employees a generous Employee Benefits Package including:

Competitive Wages.
Fully paid medical insurance for you and your family.
We provide a 401k Plan with a generous contribution.
Discretionary bonuses.
And, much more!

.

All benefits offered are subject to eligibility requirements, terms, and provisions set forth in the respective policies and plan documents, which you may request from Human Resources.

CNW is committed to providing equal employment opportunities to all employees and applicants. CNW does not tolerate discrimination against job applicants or employees because of race, color, creed, sex, religion, age, national origin, disability, marital status, genetic predisposition or carrier status, sexual orientation, and military status or any other protected class recognized under federal, state, or local law. This commitment extends to all aspects of the company's employment practices including, but not limited to, recruiting, hiring, promoting, transferring, compensation, benefits, training, leaves of absence, termination, and other terms and conditions of employment.

Show more Show less"
2812726169,"Software Engineer, Data Infrastructure",DoorDash,2021-11-29,United States,"Mountain View, CA",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Come help us build the world's most reliable on-demand, logistics engine for delivery! We're bringing on experienced engineers to help us further our 24x7, global infrastructure system that powers DoorDash’s three-sided marketplace of consumers, merchants, and dashers.

The Data Infrastructure team manages DoorDash's massive database and makes data accessible for teams driving decision making, machine learning, and experimentation. The team is relatively small, so there's an opportunity for impact where you can help grow the team and shape the roadmap for data infrastructure at DoorDash.

What You’ll Do

Work on our data pipeline, ETL systems, and real-time data
Come up with solutions for scaling data infrastructure
Help all departments of the company have access to our data
Collaborate in a dynamic startup environment
Improve logistics by taking on cutting-edge, technical problems

What We're Looking For

B.S., M.S., or PhD. in Computer Science or equivalent
5+ years of experience with CS fundamental concepts and OOP languages like Java and Python
Experience working with databases (e.g. SQL) and data infrastructure
Experience in big data technology like Presto, Snowflake, Hadoop, Airflow, Kafka
A passion for analyzing data to inform decisions
Experience improving efficiency, scalability, and stability of system resources

Why You’ll Love Working at DoorDash

We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies.
We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day.
We are learners - We’re not afraid to dig in and uncover the truth, even if it’s scary or inconvenient. Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute.
We are customer-obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility.
We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.
We offer great compensation packages and comprehensive health benefits.

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly and always learn and reiterate to support merchants, Dashers and the communities we serve. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods. Read more on the DoorDash website, the DoorDash blog, the DoorDash Engineering blog, and the DoorDash Careers page.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. Our leaders seek the truth and welcome big, hairy, audacious questions. We are grounded in our company values, and we make intentional decisions that are both logical and display empathy for our range of users—from Dashers to Merchants to Customers.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

Pursuant to the Colorado Fair Pay Act, the base salary range in Colorado for this position is $136,000 - $182,750, plus opportunities for equity and commission. Compensation in other geographies may vary. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

If you need any accommodations, please inform your recruiting contact upon initial connection.


Show more Show less"
2812229860,Data Engineer (Remote),The Hartford,2021-10-30,United States,"Hartford, CT",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

This role will be part of the Actuarial Technology and Innovation Team, a dedicated hybrid actuarial/data science team utilizing statistical modeling, machine learning, and advanced data engineering techniques to enhance or overhaul core Actuarial processes. Our team is a cross-functional team of data scientists, data engineers, and actuaries working in a highly collaborative development environment which involves heavy interaction with and training of partner-customers in Actuarial. We are seeking candidates with a strong foundation in data management, software engineering and process automation who have a drive for finding efficient solutions to maximize business value.

fast-paced environment.

Responsibilities

Consult with business partners across the enterprise to enhance and deploy production-grade analytical applications and data processes
Build automated data pipelines with MLflow that serve advanced statistical models and track key metrics
Use Spark, data.table or pandas to interact with massive 100 Million+ row datatsets in Hadoop, Amazon S3, Hive or Oracle
Prototype high impact innovations that advance the Data Engineering capabilities of the Actuarial department, by leveraging new technologies (AWS, Containers and Big Data)
Leverage a full Rstudio Enterprise stack to build and deploy R/Python applications and APIs
Develop novel solutions to replace or optimize legacy (Excel/SAS) data processes
Guide less experienced developers on solution implementation and best practices through documentation and hands on instruction
Use Enterprise GitHub for version control, documentation, code collaboration, and technical project management
Support Actuarial Technology Training and Data Engineering community enhancements as needed / desired
Proactively accesses technical issues and risks that could impact speed, functionality, flexibility, or clarity
Manage data and project work in a Linux-based filesystem

Minimum Requirements

Must be authorized to work in the US, now and in the future.
2+ years programming experience with R or Python in a business setting.
Demonstrated history of manipulating and extracting value from various data structures and databases.
2+ years using SQL in a business environment.
Ability to articulate and train technical concepts regarding data management to analytical and non-technical partners.

Nice To Have

Experience using GitHub for version control strongly preferred.
Experience with the Hadoop ecosystem (HDFS, Spark, and/or HIVE) preferred, especially with Amazon EMR.
Experience with containers (Docker or Kubernetes) is a plu s.
Any AWS Cloud certification is a plus
R Shiny and R Markdown development experience desired.
Experience with Linux-based file management desired.

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$90,480 - $135,720

Benefits

Our company’s success is due to our employees’ dedication and passion for their work. They are our greatest asset. That’s why we are committed to offering employees and their families a comprehensive benefits package and award-winning well-being programs. By helping our employees achieve their full potential, we unlock our own. Visit https://www.thehartford.com/careers/benefits for details.

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

Data Engineer - GE08AE
Show more Show less"
2801394747,Data Engineer,Rackner,2021-11-19,United States,Washington DC-Baltimore Area,"Information Technology, Engineering, and Consulting",Full-time,IT Services and IT Consulting,"Title: Sr. AWS Data Engineer

Location: Remote




Who We Are:

Rackner is a software consultancy that builds cloud-native solutions for startups, enterprises, and the public sector. We are an energetic, growing consultancy with a passion for solving big problems for both startups and enterprises. We are always learning and incorporating new things. We stay on the bleeding edge, appraising new technologies and incorporating them if they provide additional value to our customers. Our customers hail from a diverse, ever growing list of industries. We work with small startups, hypergrowth companies, and some of the largest enterprises.







Essential Functions:

Experience developing cloud-based software services and solutions.
Experience creating and driving large scale ETL pipelines in AWS based environment.
Experience with integration of data from multiple data sources.
Experience creating and driving large scale big data analytics pipelines.
Strong software development and programming skills with focus on data using Java, Python or other object-oriented languages.
Must Have Python.
Strong software development and programming skills using Python(PySpark)
Experience with AWS big data technologies : S3, Glue, EMR, Kinesis, RDS, Redshift, Athena
Experience with Hadoop and Apache Spark cluster and management
Strong SQL and database development skills, using RDBMS such as MySQL, PostgreSQL, AWS RDS
Experience with NoSQL databases such as AWS DynamoDB
AWS Services:EC2, S3, RDS, RedShift, KMS, Athena, Glue, Elastic Search, Lambda and EMR
Must Have: Python, AWS
Terraform Experience required




Core Competencies:

Customer Service
Building Relationships
Business Knowledge / Organizational Acumen
Self-Motivation/Self Starter
Leading Self and Others




Benefits:

401K with employer matching 100 percent up to 6 percent of employee 401K contribution
15 Days PTO (Paid Time Off) prorated based on your start date
10 Days Holidays
Health insurance (medical, dental and vision)
Basic Life Insurance, Short-Term and Long-Term Disability
Weekly Pay schedule (Fridays)




Rackner provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

Show more Show less"
2792437243,Data Engineer,Anheuser-Busch,2021-10-20,United States,"St Louis, MO",Information Technology,Full-time,Food and Beverage Services and Manufacturing,"Company

Job Description

Budweiser. Bud Light. Stella Artois. Michelob ULTRA. That’s right, over 100 of America’s most loved brands, to be exact. But there’s so much more to us than our top-notch portfolio of beers, seltzers, and more. We believe our people are our greatest asset, and we’re looking for people like you to join our shared dream. We dream big to create a future with more cheers. Are you up for the Challenge?

Role Summary

The US BEES product team is a part of the Anheuser-Busch Digital Sales function and works closely with our Sales and Global partners to provide an exceptional ordering experience for our wholesalers and retailers.

In this role, you will work at the intersection of understanding business problems so that you can build data assets to support products that empower teams to make data driven decisions. This will entail developing a deep understanding of existing processes, data that supports the processes, and high frequency iterations to ship aesthetically compelling data and reporting products. You will also have the opportunity to influence data architecture and technology to promote the quality and innovation necessary for industry changing data driven decisions at all levels of the company.

Job Responsibilities

Meaningfully relate data for our suite of BEES products
Routine interactions with Commercial, Product and Engineering teams to iterate quickly and continuously change / update / add data assets
Build data models using the latest cloud technologies that support fast, low maintenance and scalable problem solving.
Create sustainable data pipelines and support Product and the Front-End teams on all data needs.
Job Qualifications

Bachelor's degree in Computer Science or related S.T.E.M. field
Relevant real-world experience developing scalable Data Assets
Experience in building data models and designing user experiences on cloud technology
SQL and Python proficiency (Extra Credit: Databricks, Azure Data Lake / Synapse / Data Factory)

Job Function SOLUTIONS

Primary Location United States-Missouri-St. Louis-A-B Headquarters Complex

Schedule Full-time

Job Type Permanent

Salary $88,400 - $99,450

Posting Date Sep 14, 2021

WHY ANHEUSER-BUSCH

Anheuser-Busch is here for the times that matter. The moments where we celebrate, defy challenges, dream of the brighter future we are building today– and all the moments in between. We are a company that brings people together for richer conversations, stronger communities and a future with more cheers!

Challenge Accepted! Apply Today!

Benefits

Health benefits including Medical, Dental, Vision, Wellness and Tax-Advantaged Savings and Spending Accounts
Life Insurance and Disability Income Protection
Generous Parental Leave and FMLA policies
401(k) Retirement Savings options with a company matching contribution
Chance to work in a fast-paced environment among a company of owners
Free Beer!

As the leading global brewer, Anheuser-Busch InBev is committed to finding innovative ways to continually improve. It's this kind of thinking that creates a unique work environment by rewarding talent, celebrating diversity, and encouraging forward thinking. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other characteristic protected by applicable law.
Show more Show less"
2825066084,Data Engineer,ETalentNetwork,2021-12-02,United States,United States,,Contract,,"ONLY W2 ROLE.----
W2 ROLE
NO C2C ---------
Experience with GitLab or Jenkins
• Experience with Neo4j Graph databases
• Experience building data models
• Experience in building ETL workflows to cleanse, transform, and store data
• Experience building Tableau dashboard visualizations
• Experience with HANA, Oracle, MySQL
• Strong understanding of data virtualization
• Strong problem solving, conceptualization, and communication skills
• Demonstrates willingness to learn, self-starter, and dependable
Show more Show less"
2802623193,Big Data Engineer,Amazon Web Services (AWS),2021-11-17,United States,"Dallas, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

DESCRIPTION

Amazon Web Services (AWS) is the leading platform for designing and developing applications for the cloud and is growing rapidly with hundreds of thousands of companies in over 190 countries on the platform. The Worldwide Revenue Operations (WWRO) team will be the authoritative source of customer metadata and the solutions team for applications that action AWS’ strategies to better serve our customers. We invest resources in information and solutions enabling AWS sales and business teams that yield increased customer adoption and an optimal customer experience.

Are you an experienced Big Data Engineer passionate about building scalable, enterprise-level systems? We are looking for a Big Data Engineer to play a key role in building next generation tools and solutions. In addition to technical expertise, you will invest time to understand the needs of the business, the data behind it, and how to transform information into technical solutions that allow the business to take action.

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build ETL to ingest the data into the data lake. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

Location: This role open to these locations: Seattle & Dallas. Relocation offered from within the US to any of these locations.

About Us

Inclusive Team Culture

Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have twelve employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance

Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.


Basic Qualifications

This position requires a Bachelor's Degree in Computer Science or a related technical field, and 7+ years of relevant work experience.
5+ years of work experience with ETL, Data Modeling, and Data Architecture.
Expert-level skills in writing and optimizing SQL.
Experience with Big Data technologies such as Hadoop, Hive/Spark.
Proficiency in one of the scripting languages - python, ruby, linux or similar.
Experience operating very large data warehouses or data lakes.

Preferred Qualifications

Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
Experience with building data pipelines and applications to stream and process datasets at low latencies.
Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
Knowledge of Engineering and Operational Excellence using standard methodologies.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon Web Services, Inc.

Job ID: A1815115
Show more Show less"
2810563129,Data Engineer,Wish,2021-11-23,United States,"San Francisco, CA",Analyst,Full-time,"Computer Software, Internet Publishing, and Manufacturing","Company Description

Wish is a mobile e-commerce platform that flips traditional shopping on its head. We connect hundreds of millions of people with the widest selection of delightful, surprising, and—most importantly—affordable products delivered directly to their doors. Each day on Wish, millions of customers in more than 160 countries around the world discover new products. For our over 1 million merchant partners, anyone with a good idea and a mobile phone can instantly tap into a global market.

We're fueled by creating unique products and experiences that give people access to a new type of commerce, where all are welcome. If you’ve been searching for a supportive environment to chase your curiosity and use data to investigate the questions that matter most to you, this is the place.

Job Description

At Wish, our Data Science & Engineering team is composed of Data Scientists, Data Analysts & Data Engineers who focus on centralizing corporate data in order to gain insights, knowledge and scalability, that empower a proactive and rigorous analysis of key business indicators. Our mission is to derive wisdom from data via the application of Data Science.

As a Data Engineer joining the Buyer Risk DSE team, you will help to develop systems and services to secure our platform and our users (eg. detecting and preventing account takeovers, establishing product features to proactively protect users, building out data pipelines to detect and prevent bad traffic from polluting data, promo abuse, fraudulent payments, etc). Ideally the person we are looking for is someone who was involved in these types of operations at scale and has hands-on knowledge.

What you'll be doing:

Conceptualize, build and operationalize scalable infrastructure to support real time streaming of our models and rules for account security, transaction security, network analysis, anomaly detection, etc.
Own feature engineering with data scientists, to build scalable, reliable ML pipelines for low latency, high throughput, high accuracy models and rules
Own end to end model development and deployment, or support the tech lead for the development and deployment
Audit the features being generated for reliability, scalability and backfill availability
Ensuring data integrity of product analytics and ML models and rules from automated traffic
Working with internal stakeholders and external vendors to identify any loopholes or vulnerabilities in current product features

Qualifications

Master’s degree in Computer Science, or related fields. PhD preferred.
1+ years building successful consumer facing software products
1+ years building successful machine learning infrastructure
1+ years years with big data systems, such as Spark, Hadoop
Computer Science fundamentals in object-oriented design, data structures, algorithm design, problem solving, and complexity analysis
Machine learning fundamentals in statistical learning, accuracy metrics, loss functions, hyper-parameter tuning, feature engineering and ML system design
Proficiency in at least one modern object-oriented programming language such as Python, Java or C++
Full stack or backend engineering experience preferred, with strong system fundamentals
Strong analytical ability to heavily utilize data insights in decision making.
You enjoy taking end-to-end responsibilities, and ownership over a project.
You enjoy communicating with stakeholders and people with different backgrounds.
You always start from business problems, not technical details. Even better, you start from the press release of the final product, and the FAQ you might anticipate from customers, management and stakeholders.

Additional Information

Wish values diversity and is committed to creating an inclusive work environment. We provide equal employment opportunity for all applicants and employees. We do not discriminate based on any legally-protected class or characteristic. Employment decisions are made based on qualifications, merit, and business needs. If you need assistance or accommodation due to a disability, please let your recruiter know. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.

Individuals applying for positions at Wish, including California residents, can see our privacy policy here.
Show more Show less"
2818774509,Data Engineer,AgreeYa Solutions,2021-12-02,United States,"Plano, TX",,Contract,,"Looking for candidate with solid experience in Azure Databricks and Spark
Show more Show less"
2811358564,Big Data Platform Engineer,Kraken Digital Asset Exchange,2021-11-24,United States,"Texas, United States",Information Technology and Engineering,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","About Kraken

Our mission is to accelerate the adoption of cryptocurrency so that you and the rest of the world can achieve financial freedom and inclusion. In our first decade, Kraken has risen to become one of the largest, most successful and respected crypto exchanges on the planet.

We are changing the way the world thinks about finance and our range of successful products are playing a critical role in the mainstream adoption of crypto assets. We continue to trail-blaze into new territory with the introduction of Kraken Bank, providing a more seamless integration between crypto and the traditional financial system. This makes us the first crypto company (ever) to be awarded a U.S. state banking charter.

Our diverse group of 2,000+ Krakenites are distributed all over the world as part of our 'remote first' culture, united by a shared passion for delighting customers, upholding crypto values and achieving our meaningful mission. We attract people who push themselves to improve, are radically transparent and think differently in order to unlock their potential.

Crypto is a rapidly evolving industry and we’re just getting started. We’re growing fast and you're invited to join the revolution!

Site Reliability Engineer - Big Data

As a Site Reliability Engineer in Big Data you will work within a team of world-class engineers to establish and maintain infrastructure which is critical in enabling Kraken to make data-driven decisions.You 'll be responsible for helping keep our data platform online and operating at full efficiency. The data platform processes hundreds of thousands of records per second and must provide stable and rapid access for all of our internal users and systems.You 'll also have the opportunity to leverage your expertise and help implement best practices with regards to operating data infrastructure in Kubernetes and AWS.

Responsibilities


Monitor and support data infrastructure in UAT and production environments
Manage infrastructure releases using Kubernetes
Collaborate with data engineers and data software engineers to improve infrastructure stability, monitoring, and alerting.
Participate in support rotations to help respond to infrastructure issuesRequirements:
3+ years in a DevOps role (SRE, Data Ops, DevOps, etc...)
Solid understanding of Infrastructure as Code, Linux, Docker and Kubernetes
Experience with monitoring tools such as Prometheus and Grafana
Experience using Git as a version control system
Previous experience operating one or more of the following tools: Debezium, Mirrormaker, Kafka, Druid, Superset, or Airflow.
Strong understanding of security best practices
Ability to work autonomously with little supervision


Nice To Have


Understanding of Terraform
Experience with Helm and Helm chart customization
Experience with Go or Python programming languages
Experience managing EMR or maintaining hosted Jupyter/Zeppelin environments
Knowledge of AWS best practices
Understanding of best practices with regards to alerting and monitoring using Prometheus and Grafana
Experience with Slack, JIRA, or Gitlab APIs
Passion for crypto


Role Summary

This role will help the Big Data team stabilize it's infrastructure to scale with the growing demand on our existing tools such as Superset and Airflow. It will also help stabilize our data pipelines to ensure tools like Superset and Zeppelin can provide accurate data in a timely manner.

Location Tagging: #US #EU

We’re powered by people from around the world with their own unique and diverse experiences. We value all Krakenites and their talents, contributions, and perspectives, regardless of their background.

As an equal opportunity employer we don’t tolerate discrimination or harassment of any kind. Whether that’s based on race, ethnicity, age, gender identity, citizenship, religion, sexual orientation, disability, pregnancy, veteran status or any other protected characteristic as outlined by federal, state or local laws.

Check out all our open roles at https://www.kraken.com/careers .

Stay in the know

Follow us on Twitter

Catch up on our blog

Follow us on LinkedIn
Show more Show less"
2804103619,Big Data Engineer,"Yoh, A Day & Zimmermann Company",2021-10-24,United States,"Ridgefield Park, NJ",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Staffing and Recruiting, and Financial Services","looking for local candidates only! Plano, TX,

Citizens,GC,EAD'S are encouraged to apply

w2 only

Big Data Engineer

The main function of the Data Engineer is to develop, evaluate, test and maintain architectures and data solutions within our organization. The typical Data Engineer executes plans, policies, and practices that control, protect, deliver, and enhance the value of the organization’s data assets.

Responsibilities:Design, construct, install, test and maintain highly scalable data management systems.

Ensure systems meet business requirements and industry practices.

Design, implement, automate and maintain large scale enterprise data ETL processes.

Build high-performance algorithms, prototypes, predictive models and proof of concepts.

***Must haves***

Analytical and problem solving skills, applied to Big Data domain
Proven understanding and hands on experience with Hadoop, Hive, Pig, Impala, and Spark
5-8 years of SQL, Hive, Hadoop and Python, Shell (4-5 years)
Java/J2EE development knowledge
3+ years of demonstrated technical proficiency with Hadoop and big data projects Day to Day duties:.
Must be able to optimize performance tuning/monitoring and development at the same time.

We are looking for an expert in SQL/Hive and moderate skills in python/shell and Hadoop. (A lot of times candidates screened have been really good in SQL but not in python/shell/Hadoop or vice versa.)

All backend is in Hadoop/AWS.

Mostly in house clusters, we do have the AWS Cloud platform though, so having that skill will really help.

About 70% of the work we do is using SQL in high query language/ Hive. The other 30% is Python, shell script, oozie, spark, etc.

Hive/SQL
Hadoop
Python/Shell Scripting (exchanging data between UNIX and other sources into Hadoop. All Hive tables we create will be pointed to the files in Hadoop) 4. AWS - not super required but some of our data comes from AWS S3

Please note that our intent is to bring on a contractor for long-term (will be extended based on competency).
Show more Show less"
2805775334,Professional Big Data Software Engineer,AT&T,2021-11-19,United States,"Alpharetta, GA","Engineering, Analyst, and Design",Full-time,IT Services and IT Consulting and Telecommunications,"Join AT&T and reimagine the communications and technologies that connect the world. We’re committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won’t just imagine the future – you’ll create it.




As a Professional Data Scientist, you will:

Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the Big Data Environment.
Support the standardization, customization and ad-hoc data analysis, and will develop the mechanisms to ingest, analyze, validate, normalize and clean data.
Apply rigorous iterative data analytics, supports Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value.
Work with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data.
Develop and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods and techniques.




Qualifications

Bachelors of Science in Computer Science, Math or Scientific Computing preferred.
Typically requires 5-8 years experience.Feature engineering, using SQL, Python, Spark, Scala and Pyspark to access data and enhance existing analytic scripts and models.
Experience with at least 2 of the following: Azure, AWS, Snowflake, DeltaLake, Databricks
Developing automation scripts and creating End to End data pipelines.
Exploring new technologies in Azure.




A career with us, a global leader in communications and technology, comes with big rewards. As part of our team, you’ll lead transformation surrounded by trailblazing industry leaders like you. You’ll be empowered to go above and beyond – making a difference through company-sponsored initiatives or connecting and networking through one of our many employee groups. And regardless of where you’re at in your career trajectory, you’ll be rewarded by the impact that comes with making a difference in the lives of millions. With AT&T, you’ll be a part of something greater, do incredible things and be rewarded with a chance to change the world,

#ChiefDataOffice

Show more Show less"
2812351365,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"Austin, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2814020819,Data Engineer,My Data Outlet,2021-11-30,United States,United States,,Full-time,,"Description:

My Data Outlet (“MDO”) is an innovator in delivering data integration tools for Research and Financial modeling. The MDO Software Development Kit simplifies Investment Data, giving users a single access point through R and Python for extracting data, factor research, and deploying models into production. MDO is based in Chicago, Illinois. For more information, please visit mydataoutlet.com.  




The Investment Data Engineer is responsible for integrating new content integrations into the MDO platform. Day to Day includes analyzing the content sets and understand the underlying data nuances, then transforming this via SQL code so that it can be accessed by our end-users simply through our open source connectors.




Job Overview:

This is a full time salaried position
Work with clients to define requirements for data integrations of financial data vendors
Develop stored procedures for SQL and Snowflake, use to call the data from APIs
Ability to perform performance tuning and building reusable code that can be leveraged for other integrations
Maintain internal cloud deployments
Integrate code into Azure DevOps

 

BS degree in Finance or computer science field
SQL Server, Snowflake
R and Python knowledge
Expertise of QA Direct, Xpressfeed or FactSet data is required.
Comfortable Communicating with clients: e-mail and phone
Genuine enthusiasm for problem solving, working with financial data, and developing quality code
Show more Show less"
2812722856,Data Reliability Engineer,DoorDash,2021-11-29,United States,"New York, NY",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Data is at the foundation of DoorDash success. The Data Engineering team builds database solutions for various use cases including reporting, product analytics, marketing optimization and financial reporting. By implementing dashboards, data structures, and data warehouse architecture; this team serves as the foundation for decision-making at DoorDash.

DoorDash is looking for a Data Reliability Engineer to be a technical powerhouse to help us measure and improve our accuracy, validity, reliability, timeliness, relevance, and completeness to improve our data quality and scale our data management practices.

What You Will Do

Improve data reliability through technological means. Develop and implement new technology solutions as needed to ensure ongoing improvement of data reliability and observability
Track defect rate with continuous improvement goals to increase trust and reliability of Data
Improve deployment efficiency by contributing to Integration and Smoke Test suites.
Participate in new software development engineering. Help define business rules that determines the quality of data, assists the product owner in writing test scripts that validates business rules, and performs detailed and rigorous testing to ensure data quality
Develop a solid understanding of the technical details of data domains, and clearly understand what business problems are being solved
Engage with application, data platform and data engineering teams to help reengineer ingestion pipelines to be more stable, reliability, and instrumented with monitoring
Design and develop real-time processing solutions for data quality
Create and enhance data solutions that enable seamless integration and flow of data across the data ecosystem
Manage Incidents, drive blameless post mortems with cross functional teams
Design software solutions for operational metadata management, data quality, sensitive data management, and data steward activities

Qualifications

Hiring at various job and qualification levels.

10+ years of professional experience
7+ years experience working in data engineering, business intelligence, or a similar role with a focus on reliability and scalability
3+ years experience with Incident Management, Jira, Monitoring/Alerting, Anomaly Detection tools such as PagerDuty, DataDog or similar systems
Proficiency in programming languages such as Python/Java
3+ years of experience in ETL orchestration and workflow management tools like Airflow, flink, Oozie and Azkaban using AWS/GCP
Expert in Database fundamentals, SQL and distributed computing
3+ years of experience with the Distributed data/similar ecosystem (Spark, Hive, Druid, Presto) and streaming technologies such as kafka/Flink.
Experience working with Snowflake, Redshift, PostgreSQL and/or other DBMS platforms
Excellent communication skills and experience working with technical and non-technical teams
Knowledge of reporting tools such as Tableau, superset and Looker
Comfortable working in fast paced environment, self starter and self organizing
Ability to think strategically, analyze and interpret incidents

Why You’ll Love Working at DoorDash

We are leaders – Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies.

We are operators – We believe the only way to predict the future is to build it. Creating solutions to lead our company and our industry is what we do on every project, every day.

We are learners – Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute. We are committed to learning and implementing what is best for our customers, merchants, and dashers.

We are one team – The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly and always learn and reiterate to support merchants, Dashers and the communities we serve. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods. Read more on the DoorDash website, the DoorDash blog, the DoorDash Engineering blog, and the DoorDash Careers page.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. Our leaders seek the truth and welcome big, hairy, audacious questions. We are grounded in our company values, and we make intentional decisions that are both logical and display empathy for our range of users—from Dashers to Merchants to Customers.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

We're committed to supporting employees’ happiness, healthiness, and overall wellbeing by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

If you need any accommodations, please inform your recruiting contact upon initial connection.
Show more Show less"
2812348746,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"Nashville, TN",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2789626323,Data Engineer,Zoom,2021-12-03,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2821610805,Big Data Engineer,TEKsystems,2021-11-30,United States,"Charlotte, NC",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","W2 ONLY

Wells Fargo

Big data engineer (Hadoop, spark, kafka)

24 month contract

100% REMOTE

Interview and hire off 1 step this week!!

Description

Use of this job is restricted to Wells Fargo Technology. Regarded across the enterprise as an expert in multiple identified areas of expertise with responsibility for developing standards and enterprise-wide best practices and for engineering complex, largescale technology solutions to address highly complex and cross-organizational issues. Designs, codes, tests, debugs and documents programs using Agile development practices. Maintains broad knowledge of other technology engineering disciplines and collaborating with other key experts to ensure we are making the right technology choices for Wells Fargo. Translates advanced technology experience, an in-depth knowledge of the organizations tactical and strategic business objectives, the enterprise technological environment, the organization structure, and strategic technological opportunities and requirements into technical engineering solutions. Responsible for being an expert resource for architects in the development of target architectures to ensure that they can be properly designed and implemented through sound engineering practices. Maintains knowledge of industry best practices and new technologies and recommends innovations that enhance operations and/or provide a competitive advantage to the organization. Provides expert counsel to technology leadership and advises and mentors others with the goal of knowledge transfer. Represents Wells Fargo to external industry groups, influencing industry standards. Responsible for being an expert resource for architects in the development of target architectures to ensure that they can be properly designed and implemented through sound engineering practices. Provides expert counsel to technology leadership and advises and mentors others with the goal of knowledge transfer. Represents Wells Fargo to external industry groups, influencing industry standards. Required Qualifications: 7+ years of software engineering experience Desired Qualifications; An industry-standard technology certification Strong verbal, written, and interpersonal communication skills

Skills

python, sql, spark, hadoop

Top Skills Details

python,sql,spark

About TEKsystems

We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.

The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.
Show more Show less"
2814466608,Data Engineer,Zoom,2021-12-01,United States,"Florida, United States",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Zoomies help the world connect — and deliver happiness while doing it. We set out to build the best video conferencing product for the enterprise, and today help people communicate better with products like Zoom Phone, Zoom Rooms,

Zoom Video Webinars, Zoom Apps, and OnZoom.

We’re problem-solvers and self-starters, working at a fast pace to design solutions with our customers and users in mind. Here, you’ll work across teams to dig deep into impactful projects that are changing the way people communicate, and enjoy opportunities to advance your career in a diverse, inclusive environment.

The Data Science team lies at the foundation of Zoom’s success - you'll be working cross-functionally with teams of engineers, scientists, marketers, and product professionals on some of the most critical projects in the company - whether it's exploratory research to predict user behavior, or running experiments to optimize untapped areas of growth, or developing machine learning models that deliver “happiness” to our users more consistently and at scale.

If you are passionate about data engineering and looking to join a fun and fast-moving team, we’d love to meet you! Our team is taking Zoom's data culture to the next level by integrating predictive models into our infrastructure, and we are looking for someone like you to help us get there! This role is based in most places in the US.

Responsibilities

Partner with architecture and other senior leads to address the data needs of our rapidly-growing business
Join a group of passionate people committed to delivering “happiness” to our users and to each other
Partner with data scientists, sales, marketing, operation, and product teams to build and deploy machine learning models that unlock growth
Build custom integrations between cloud-based systems using APIs
Write complex and efficient code to transform raw data sources into easily accessible models by coding across several languages such as Java, Python, Scala and or SQL
Design, build, and launch new data models that provide intuitive analytics to the team
Build data expertise and own data quality for the pipelines you create

Requirements

Bachelor's/Masters degree in Computer Science, Management of Information Systems, or equivalent
Three or more years of relevant software engineering experience (Python, Scala and Java) in a data-focused role
Passion for creating data infrastructure technologies from scratch using the right tools for the job
Experience in solving complex data processing and storage challenges through scalable, fault-tolerant architecture
Experience in designing and building highly scalable and reliable data pipelines using BigData (Airflow, Python, Redshift/Snowflake).
Software development experience with proficiency in Python, Java, Scala or another language.
Passionate about data engineering, analytics, distributed systems and solving complex data problems.
Prior experience shipping scalable data solutions in the cloud (AWS, Azure, GCP) and database technologies such as Snowflake, Redshift, SQL/NoSQL and or columnar databases

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2818080212,Data Engineer,Ignyte Group,2021-11-04,United States,"Washington, DC",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Management Consulting","Who We Are

Business has changed - so should consulting. We are strategists, technologists, engineers, and designers who bridge the gap between consulting, design, and marketing to create powerful digital experiences for our customer's brands and users.

Recently named as one of Washington Business Journal’s Best Places to Work in Washington, DC, Ignyte is looking for a Data Engineer to join our progressive start-up culture and help us build a new type of consulting company.

What You'll Do

At Ignyte, our Data Engineers are passionate about creating innovative data-driven solutions across various industries that address critical business problems. You'll be challenged daily as you wear multiple hats to drive multiple project types to completion in both a development and business-facing role.

As a Data Engineer, we give you the opportunity to create your own career path based on your interests, the skills you already possess as well as the skills you'd like to have. Your everyday tasks in supporting our analytics solution development efforts can range anywhere working with our clients to understand their reporting needs to working with our developers to create machine learning solutions.

You’ll work with our firm's leadership from day one to formulate your own job description and career goals. Not sure where’d you fit in? We’ll work with you to figure it out as part of the application process.

What We're Looking For:

BS or MS degree in Computer Science, Mathematics, Statistics, Finance, or related technical field
2-3+ years experience with SQL, NoSQL, relational database design, and methods for efficiently retrieving data
2-3+ years of experience in a variety of programming languages such as R, Python, Java, and Scala
""Big 4"" consulting experience and/or a data role at a leading tech company is a plus
Strong experience developing and launching efficient and reliable ETL pipelines to move and transform data
Experience in designing, architecting and implementing data warehouses
Ability to architect highly scalable distributed systems using open source tools and big data technologies such as Hadoop, HBase, Spark, Storm, Etc
Knowledge of reporting technologies (e.g., PowerBI, Tableau, MicroStrategy etc.); Hands on experience preferred
Experience handling structured and unstructured data from internal and third party sources
Experience with cloud computing platforms such as Amazon Web Services or Microsoft Azure is a plus
Ability to assist in proposal writing for business development opportunities as requested
Hard working, self-motivated individuals who are okay with a healthy dose of ambiguity and complexity
Experience working in small- to medium-sized teams to achieve project goals and complete major deliverables
Ability to set, manage and meet expectations and deadlines


What You'll Gain

Experience working with a team of smart and driven professionals at a passionate DC consulting startup
Exposure to complex technical business issues and challenges
Opportunities to leverage your technical knowledge and analytical skills to solve complex business problems
The ability to mold your own career path based on the skills you have and want to have


Powered by JazzHR

NTa4xJBTCs
Show more Show less"
2789628272,Data Engineer,Zoom,2021-12-03,United States,San Francisco Bay Area,Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2808119370,Data Engineer,Deckers Brands,2021-11-25,United States,"Vancouver, WA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2817119054,Data Engineer,Quadrant Resource,2021-12-02,United States,United States,,Contract,,"REQUIRED SKILLS:
• 3+ years of PySpark programming experience around building data pipelines is mandatory
• Strong skills in Python Programming with focus around data pipeline activities
• DataBricks or DataProc knowledge/expereince will be a plus
• Strong SQL Experience
• Apache Airflow Experience is good to have
• Snowflake is a plus
• CI/CD Experience with Jenkins Pipelines, Code Coverage, Scans etc. preferred
• Less dependent and self-learner of new technologies as we may adapt in future (like Kuberenetes, Docker etc.,)

Show more Show less"
2816930125,Data Engineer,Walker & Dunlop,2021-11-30,United States,United States,Information Technology,Full-time,"Banking, Financial Services, and Leasing Real Estate","Department

Information Technology

Ready to bring your whole self to work every day? At Walker & Dunlop, we didn’t get to where we are by hiring ordinary individuals. We got here by hiring the exceptional! WD is looking for individuals who are caring, collaborative, driven, insightful, and tenacious to join our team!

Walker & Dunlop ’ s mission is to deliver the best borrower experience of any commercial real estate lender in the world, and we are achieving this goal by leading the industry in data science and technological innovation.

The technology team at W&D has a creative and entrepreneurial culture – everyone on the team interacts directly with customers, and we all contribute to product development and planning. A commitment to innovation and a passion for disrupting the old-fashioned real estate industry are our highest priorities!

What You Will Be Doing

Design, develop and own data pipelines in Google Cloud that power internal analytical tools that are transforming how W&D does business
Drive the collection and refinement of new data sources and continually improve upon existing data integrations
Develop a solid understanding of the features and data sources needed to successfully analyze and execute real estate finance transactions
Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals to design, develop, test, and support new features
Maintain coding, compliance, and security standards
Proactively learn existing software frameworks and code bases
Participate in pair programming, code review, and design decisions
Present possible technical solutions to various stakeholders, clearly explaining your decisions and how they address real user needs, and incorporating user feedback in subsequent iterations

What We ’ Re Looking For

Bachelor’s or master’s degree in computer science
3-5 years of experience in full stack Python development (Vue.js/React/Angular, Flask/Django/Falcon, PostgreSQL/MySQL/SQL Server)
You have proficient software development knowledge, with experience building, growing, maintaining a variety of products, and a love for creating elegant applications
You have an entrepreneurial mindset and are product-oriented
You are curious and willing to continue learning in data engineering, but also in data science, frontend, and backend technologies

Technologies We Use

Python 3 (critical)
Python packages for data processing or ML, such as scikit-learn, numpy, beautifulsoup, matplotlib, nltk, pandas (critical)
PostgreSQL / BigQuery (or similar, critical)
Modern Devops i.e. Docker, GitHub Actions, Google Cloud, CI/CD (preferred)
Vue.js (or similar frontend framework, helpful)

What to expect your first 6 months?

At 30 days – You’ll have familiarized yourself with how the existing data integrations work, how this data is used across our suite of products and developed code to ingest and clean a new data source.
At 90 days – You’ll have a working knowledge of the domain and a deeper understanding about the problem-space. You’ll have a good idea of the value provided by your tasks and have implemented / refined a couple of them.
At 180 days – You’ll be able to use a scientific approach to identify and propose new features or improvements that would benefit the project and collaborated with the team to implement them. You’ll be able to code an automated data pipeline that ingests, cleans, and stores new data sources within the Google Cloud environment. You will have enough real estate domain expertise to be able to read through a new dataset and understand if there are any issues. You will take full ownership of the correctness of this data and understand its importance within the organization.

Still reading? Then we think you should apply!

EEO Statement

Walker & Dunlop is an equal employment opportunity employer and does not discriminate based on race, color, national origin, religion, gender identity, sexual orientation, sex, age, disability, veteran or military status, genetic information, or any other characteristic protected by applicable law.

SPAM

Please be wary of recruitment scams. An indication of a scam might be a request for sensitive or bank information at the time of application or emails coming from a non walkerdunlop.com email address. Please call us at 301.215.5500, if you have any concerns about information requested during or after the application process.
Show more Show less"
2826261203,"Data Engineer (Python, Spark, AWS)",Wavicle Data Solutions,2021-11-09,United States,"Chicago, IL",Information Technology,Full-time,IT Services and IT Consulting,"Description

Wavicle Data Solutions designs and delivers data and analytics solutions to reduce time, cost, and risk of companies’ data projects, improving the quality of their analytics and decisions now and into the future. As a privately-held consulting service organization with popular, name brand clients across multiple industries, Wavicle offers exciting opportunities for data scientists, solutions architects, developers, and consultants to jump right in and contribute to meaningful, innovative solutions.

Our 250+ local, nearshore and offshore consultants, data architects, cloud engineers, and developers build cost-effective, right-fit solutions leveraging our team’s deep business acumen and knowledge of cutting-edge data and analytics technology and frameworks.

Wavicle Has Been Recognized By Industry Leaders As Follows

At Wavicle, you’ll find a challenging and rewarding work environment where we enjoy working as a team to exceed client expectations. Employees appreciate being part of something meaningful at Wavicle.

Chicago Tribune’s Top Workplaces
Inc 500 Fastest Growing Private Companies in the US
Crain’s Fast 50 fastest growing companies in the Chicago area
Talend Expert Partner recognition
Microsoft Gold Data Platform competency


About The Role

We are looking for a Data Engineer with strong real-life experience in building data pipelines using emerging technologies

Responsibilities

Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of sources like Hadoop, Spark, AWS Lambda, etc.
Experience with AWS Cloud on Data Integration with Apache Spark, EMR, Glue, Kafka, Kinesis and Lambda in S3, Redshift, RDS, and MongoDB/DynamoDB ecosystems.
Strong real-life experience in Python development, especially in PySpark in AWS Cloud environment.
Design, develop, test, deploy, maintain and improve data integration pipeline.
Develop pipeline objects using Apache Spark / Pyspark / Python or Scala.
Design and develop data pipeline architectures using Hadoop, Spark and related AWS Services.
Load and performance test data pipelines built using the above-mentioned technologies.


Requirements

At least 5 years of hands-on professional work experience with AWS and Python programming, experience with Python frameworks (e.g., Django, Flask, Bottle) is required
Expert level knowledge of using SQL to write complex, highly-optimized queries across large volumes of data.
Working experience on ETL pipeline implementation using AWS services such as Glue, Lambda, EMR, Athena, S3, SNS, Kinesis, Data-Pipelines, Pyspark, etc.is required.
Hands-on experience using programming language Scala, Python, R, or Java.is required.
Hands-on professional work experience using emerging technologies (Snowflake, Matillion, Talend, Thoughtspot and/or Databricks) is highly desireable.
Expert level knowledge of using SQL to write complex, highly-optimized queries across large volumes of data is required.
Knowledge or experience in architectural best practices in building data lakes.
Strong problem solving and troubleshooting skills with the ability to exercise mature judgement.
Bachelor or Master's degree in Computer Science, or related field is required.
At this time, we are looking for individuals interested in full-time, salaried employment (no contractors please).
Must be open to up to 25% travel to client location.


Equal Opportunity Employer

Wavicle is an Equal Opportunity Employer and committed to creating an inclusive environment for all employees. We welcome and encourage diversity in the workplace regardless of race, color, religion, national origin, gender, pregnancy, sexual orientation, gender identity, age, physical or mental disability, genetic information or veteran status.

Benefits

Health Care Plan (Medical, Dental & Vision)
Retirement Plan (401k, IRA)
Life Insurance (Basic, Voluntary & AD&D)
Unlimited Paid Time Off (Vacation, Sick & Public Holidays)
Short Term & Long Term Disability
Training & Development
Work From Home
College Tuition Benefit
Bonus Program


Show more Show less"
2808120312,Data Engineer,Deckers Brands,2021-11-25,United States,"Scottsdale, AZ",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2807637022,Data Engineer - Reinventing Venture Capital,NFX,2021-10-27,United States,"San Francisco, CA",Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","NFX is a pre-seed and seed venture firm for Founders, by Founders based in San Francisco with $875M in capital to fund Founders. We were founded in 2017 by former CEOs who have collectively started 10 technology companies, so we deeply believe in the power of transformative ideas. Now we're building the VC firm we wish existed when we were Founders. A VC firm that runs like a software company.

Venture capital is a ""people business"", but we're certain that software will radically change how innovation is funded and supported in the next 10 years. The Product team builds NFX's internal deal review software. As the 2nd Data Engineer on the Product team, you will be on the front lines of the deal review and evaluation process, reinventing how VCs make decisions with software, and helping Founders successfully fundraise.

As a member of the Product team, you'll get full access to NFX content, events, conferences just like our Founders. You'll meet some of the most successful people in the startup world and get exposed to the best startup ideas and tactics. And of course, if you ever want to start your own company, you will learn a lot about that from working at NFX.

This is a unique opportunity to innovate how investment decisions are made and to gain unparalleled exposure to how venture capital works from the inside.

Who are you?

You love data but also know when it's not helpful in decision making. Hours go by when you're coding and working with data but you also maintain the healthy perspective that data does not provide the answer for many questions.

You move with speed. You move incredibly fast, making decisions and overcoming obstacles with speed.

You have incredible attention to detail. You have an eye for the smallest discrepancies and take note of all of the facts when arriving at a conclusion.

You have an innate curiosity for people and their origin stories. VC will always be a people's business. Data helps to make it more efficient.

Learning makes you happy. You approach life with a beginner's mind and with deep curiosity. You are constantly interested in improving your skills, learning from your team, and community. Inside and outside of work, you ask for feedback continuously, listen intently, and are constantly iterating.

The nitty-gritty stuff that you probably have on your LinkedIn but don't define who you are:

2+ years professional experience working on a data team or backend engineering team.
Degree most likely in engineering, math, statistics, economics, business, or data science.
Based in the Bay Area or looking to be in the Bay Area -- remote is ok for the right person.


We will not be a good *fit* for you if:

You don't like wearing many hats. We're a small, nimble team and everyone pitches in to make our team successful.
You're an engineer who hasn't designed databases and worked with large datasets or you're a data person with no backend engineering experience.
You are looking for an investment track role.


This role WILL be a good fit for you if:

Strong proficiency with SQL and data analysis, munging, and cleaning
2+ years of backend software development designing databases
Rails experience is a plus
You approach data engineering as a team sport.
You are applying to work or are currently working at a software startup.
Have an interest in the startup and VC ecosystems, though VC experience is not a prerequisite to be successful in this role.


If this sounds like you, here's what you'll do in a typical week:

Identify datasets that assist in reviewing teams and companies and build the data pipelines that integrates with our review pipelines
Analyze trends, patterns, and anomalies from our proprietary data set
Work with engineers, product managers, and designers of the Product team to build tools that drive efficiencies in the deal review process through categorization, filtering, and ML systems.


Send us:

Your LinkedIn link or resume
A note on what interests you about being on the team, and why you should be the next NFX member on the Product team.


NFX is a collaborative and close-knit team and we're taken care of. You should expect:

Competitive comp
Medical, Dental, and Vision Insurance
401(k) with employer contribution
Flexible Time Off
Generous maternity/paternity leave policies
Cell phone reimbursement
Paid commuter benefits
Educational credit
Life and supplemental life insurance
Short-term and long term disability
A team of high-caliber, principled, and fun people
An atypical venture culture led by tech founders not financiers
A vibrant and modern office right in the heart of the Financial District (5m walk to Montgomery BART and across the street from Salesforce Transit Center when we do return)
Show more Show less"
2788306902,Data Engineer,DivcoWest,2021-11-10,United States,"Austin, Texas Metropolitan Area",Information Technology and Engineering,Full-time,Leasing Non-residential Real Estate,"COMPANY BACKGROUND

Founded in 1993, DivcoWest is a dynamic and growing multi-disciplinary real estate investment firm headquartered in San Francisco, with offices in Los Angeles, Menlo Park, Boston, Washington DC and New York City. Known for our long-standing relationships and track record of success in markets where innovation thrives, DivcoWest combines a vibrant entrepreneurial spirit with an institutional approach and a forward-thinking state-of-the-art technology infrastructure.




JOB SUMMARY

DivcoWest is searching for a Data Engineer to join our growing team of analytics experts. Our technology team is focused on delivering solutions that streamlines real estate operations, enhances the value of the real estate portfolio, and improves the experience of space and people’s everyday lives. Our dynamic technology team builds innovative products, implements state of the art technologies, provides service to facilitate technology operations at our corporate and property sites, and invests in real estate focused technology companies. 




The Data Engineer will be responsible for supporting the technology team’s focus by expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder who enjoys optimizing data systems and building them from the ground up. The hire must be self-directed, driven and comfortable supporting the data needs of multiple teams, systems and products. This role may be located out of our San Francisco, Los Angeles or properties.




ESSENTIAL DUTIES & RESPONSIBILITIES

Create and maintain optimal data pipeline architecture
Identify, design and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability
Design, develop, and deploy a high-volume ETL pipelining system to manage complex real-time, data collection
Work with stakeholders including the Executive, Data and Infrastructure teams to assist with data-related technical issues and support their data infrastructure needs
Cross-train with the rest of the data team members, to support business functions during team members absence
Stay current with developments in new market trends and innovations in technology, especially those related to commercial real estate




SKILLS AND ABILITIES

Advanced working SQL knowledge and experience working with relational databases
A successful history of manipulating, processing and extracting value from large disconnected data sets
Excellent oral and written communication skills, including the ability to explain technology solutions in business terms and translate business requirements into technical specifications
Proven analytical and problem-solving abilities with keen attention to details
Knowledge of commercial real estate operations an asset




TECHNICAL SKILLS

Microsoft SQL Server 2012 or Higher
Data warehouse design, development and maintenance, optimization for reporting and analysis
SQL Server Integration Services (SSIS) - ETL design, development and maintenance
SQL Server Analysis Services (SSAS) – OLAP cube design, development and maintenance
SQL Server Reporting Services (SSRS) – web enabled report design, development and maintenance
Strong Microsoft Excel skills including Visual Basic for Applications competency
Proficient designing, implementing custom REST-ful APIs for usage in integrations with cloud/web-based 3rd party applications
Adept at consuming 3rd party web-based APIs and integration end points (REST-ful, SOAP, SFTP file transfer, etc.)
Proficiency with Microsoft C#, .Net Framework preferred.
Familiarity with MRI real estate enterprise resource planning (ERP) system a plus




QUALIFICATIONS

Bachelor’s degree in Information Technology, Software Engineering, Computer Science or related field or higher
At least 4-5 years of experience in IT, preferably within 1 or more commercial real estate organizations
Experienced with systems integrations, business intelligence systems, and database management




DivcoWest aims to create environments that inspire ingenuity, promote growth, and enhance the health, happiness, and well being of all people. A disciplined code of ethics is at the core of all that we do. DivcoWest values our partners and our people and believe that the collective energy of a diverse team is what drives our creative ideas and solutions. In recognition of the dedication and hard work of DivcoWest's employees, the Company offers a comprehensive benefits package as well as an employee assistance program.




DivcoWest is an Equal Opportunity Employer. We are committed to building a team that represents a variety of backgrounds, perspectives and skills. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state or local law.




Please review our company Priviacy Policy in regards to the use of any personal information you provide us at: https://divcowest.com/privacy-policy.php

Show more Show less"
2744604358,Data Engineer,"Vizient, Inc",2021-09-16,United States,"Irving, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Hospitals and Health Care","When you’re the best, we’re the best. We instill an environment where employees feel engaged, satisfied and able to contribute their unique skills and talents. We provide extensive opportunities for personal and professional development, building both employee competence and organizational capability to fuel exceptional performance now and in the future.

Summary

In this role, you will develop software products for larger, more complex stories spanning multiple technology domains. You will analyze and query large transactional data to measure performance against key indicators.

Responsibilities: .

Design, develop, enhance, code, test, deliver and debug Data Engineering software collaboratively in a team environment.
Collaborate with others to solve Data Engineering challenges and deliver working software solutions.
Take an active interest in technical trends and emerging technology.

Qualifications

Relevant degree preferred.
5 years of relevant experience required
Experience with Apache Spark (Spark Scala, Java, or PySpark) required
Proficient with SQL and other relational databases required.
Experience with large datasets required.
Skills with AWS Cloud, AWS S3, RDS preferred.
Equally productive in an in-office or office / virtual / remote hybrid environment.

Estimated Hiring Range

$86,300.00 - $128,400.00

This position is also incentive eligible.

Vizient has a comprehensive benefits plan! Please view our benefits here:

http://www.vizientinc.com/about-us/careers

Equal Opportunity Employer: Females/Minorities/Veterans/Individuals with Disabilities

The Company is committed to equal employment opportunity to all employees and applicants without regard to race, religion, color, gender identity, ethnicity, age, national origin, sexual orientation, disability status, veteran status or any other category protected by applicable law.


Show more Show less"
2811777388,Data Engineer/Analyst,Canopy One Solutions Inc,2021-11-30,United States,"Denver, CO",,Contract,,"Position: Data Engineer/Analyst

Location: Denver, CO (need onsite from day 1)

Duration: Long Term

 

Description:

Client is looking for a Data Engineer (or) Analyst with hands on experience working on various data sources which include Sybase, Splunk and SQL.
Candidate must have experience with ETL
Proficient in a scripting language such as Python, Perl or shell
Develop procedures and functions (Automate) of ETL from various data sources using Python.
Contribute to architecture and automation discussions across Network Operations.
Support and maintain current build-out of Operational Intelligence system, including three environments and over 350 virtual machines
Experience in AI/ML is a huge plus




Show more Show less"
2802620869,Big Data Engineer,Amazon Web Services (AWS),2021-11-17,United States,"Dallas, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

DESCRIPTION

Amazon Web Services (AWS) is the leading platform for designing and developing applications for the cloud and is growing rapidly with hundreds of thousands of companies in over 190 countries on the platform. The Worldwide Revenue Operations (WWRO) team will be the authoritative source of customer metadata and the solutions team for applications that action AWS’ strategies to better serve our customers. We invest resources in information and solutions enabling AWS sales and business teams that yield increased customer adoption and an optimal customer experience.

Are you an experienced Big Data Engineer passionate about building scalable, enterprise-level systems? We are looking for a Big Data Engineer to play a key role in building next generation tools and solutions. In addition to technical expertise, you will invest time to understand the needs of the business, the data behind it, and how to transform information into technical solutions that allow the business to take action.

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build ETL to ingest the data into the data lake. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

Location: This role open to these locations: Seattle & Dallas. Relocation offered from within the US to any of these locations.

About Us

Inclusive Team Culture

Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have twelve employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance

Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.


Basic Qualifications

This position requires a Bachelor's Degree in Computer Science or a related technical field, and 7+ years of relevant work experience.
5+ years of work experience with ETL, Data Modeling, and Data Architecture.
Expert-level skills in writing and optimizing SQL.
Experience with Big Data technologies such as Hadoop, Hive/Spark.
Proficiency in one of the scripting languages - python, ruby, linux or similar.
Experience operating very large data warehouses or data lakes.

Preferred Qualifications

Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
Experience with building data pipelines and applications to stream and process datasets at low latencies.
Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
Knowledge of Engineering and Operational Excellence using standard methodologies.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon Web Services, Inc.

Job ID: A1817825
Show more Show less"
2819138738,Data Engineer,Penske,2021-12-03,United States,"Tampa, FL",Information Technology,Full-time,IT Services and IT Consulting,"(**Job Number:** 2120572 ) **About Penske:** Most people know us for our big yellow trucks. But we're so much more than that. At Penske we have a 50-plus year history of leading the transportation and supply-chain industry, delivering world-class and award-winning technology solutions and the key to our success is our people. We are experiencing rapid business growth and have added headcounts to IT teams across the organization to keep up with this expansion. Going into Winter 2021/2022, we are hiring immediately for full-time, long-term roles. At Penske you will ensure our technology solutions keep our company and our customers moving forward. **What You Will Be Doing:** As a Penske Associate Data Engineer I you will develop your technical skills and business acumen by participating in the effort to develop, enhance, and support existing and new data systems. You will take direction from our database architects, as well as collaborate with our data analysts and data scientists to ensure optimal data delivery consistent throughout ongoing projects. Learning from our diverse team of data engineering experts, you will have the opportunity to influence our data and analytics roadmap by constant interactions with various business and technology teams. This position can sit out of our corporate headquarters in Reading, PA or our IT Center in Tampa, FL. **Penske Responsibilities:** + Formulate and define system scope and objectives as well as preparing detailed specifications + Prepare software test plans + Provide production/technical support to end users + Conduct discussions and/or meetings with end users + Perform project leadership role to complete high-level and technical systems design for new and enhanced systems + Proficient in Data Modeling, analytics and data governance + Build and Support Analytical, Data Engineering, Data Modeling and Data warehouse projects **Penske Qualifications:** + Bachelor's Degree in Computer Science/Computer Engineering or equivalent years of software development experience required + 1 years exposure to Data Engineering, Data Modeling, and Data Warehousing required + Basic knowledge of SQL variants required, such as PostgreSQL, MySQL, Oracle, SQL Server, or DB2 + Basic knowledge of the full lifecycle development cycle in a large complex environment required Basic knowledge of data visualization tools like PowerBI, Qlikview, Tableau or other Reporting Tools is preferred + Basic knowledge of AWS, Pivotal Cloud Foundry, Spring Cloud Data Flow, Gemfire, GreenPlum is preferred - Experience working in an AGILE environment preferred + Ability to work in a team environment and seek guidance on tasks from senior developers and leads. + Regular, predictable, full attendance is an essential function of the job + Willingness to travel as necessary, work the required schedule, work at the specific location required, complete Penske employment application, submit to a background investigation (to include past employment, education, and criminal history) and drug screening are required. **Physical Requirements:** -The physical and mental demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. -The associate will be required to: read; communicate verbally and/or in written form; remember and analyze certain information; and remember and understand certain instructions or guidelines. -While performing the duties of this job, the associate may be required to stand, walk, and sit. The associate is frequently required to use hands to touch, handle, and feel, and to reach with hands and arms. The associate must be able to occasionally lift and/or move up to 25lbs/12kg. -Specific vision abilities required by this job include close vision, distance vision, peripheral vision, depth perception and the ability to adjust focus. Penske is an Equal Opportunity Employer. **About Penske Truck Leasing** Penske Truck Leasing Co., L.P., headquartered in Reading, Pennsylvania, is a partnership of Penske Corporation, Penske Automotive Group and Mitsui & Co., Ltd. A leading global transportation services provider, Penske operates a premier fleet of vehicles and serves its customers from locations in North America, South America, Europe, Australia, and Asia. Penske's product lines include full-service truck leasing, contract maintenance, commercial and consumer truck rentals, used truck sales, transportation and warehousing management and supply chain management solutions. Visit www.GoPenske.com to learn more. #DICE **Work Locations** : 5401 West Kennedy Blvd Suite 700 5401 West Kennedy Blvd Suite 700 Tampa, FL 33609 **Primary Location** : United States-Florida-Tampa **Job** : Information Technology : **Req ID:** 2120572
Show more Show less"
2822321624,Data Engineer,Tomorrow.io,2021-12-01,United States,"Boulder, CO",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","tomorrow.io's R&D Team is a mixture of scientists and engineers committed to generating the best and most novel data and models across all times: historical, real-time and forecast. The story just begins when the data hits our ingest and post-processing services. Every product that the user sees is the result of a pipeline of algorithms that needs to be run quickly and continuously. We are the team that builds the architecture behind the data and the models, to prepare the weather analyses, for the Product and Engineering team to serve to the masses.

We're looking for an Data Engineer that will help us accelerate data science models to business value and make sure we are delivering the best weather forecast in the world.

As a Data Engineer at Tomorrow.io, you'll work closely with our atmospheric data scientists and weather applications engineers to enable rapid experimentation of modeling and to help operationalize the ML pipelines.

And...you will get to work with the best people you've ever worked with. We promise!

What you'll bring:

3+ years of experience as a software or data engineer, preference towards MLOps - building and deploying ML models in production environments
Experience with a cloud environment, e.g. GCP, AWS, Azure
Experience with ML libraries and technologies in Python (TFX, PyTorch)
Strong experience with data pipelining technologies (Airflow, Apache Beam/Dataflow, Kubeflow)
Experience with containerized Python development using Docker
Proficient SQL with hands on experience with databases (Postgres) and data warehouses (BigQuery, RedShift, Snowflake)
Prior experience in a data engineering role is preferred


So if big data is your middle name and you love translating innovative ML models into robustly-engineered ML solutions, then this team is for you.

If you have reached this point and you are super excited but not sure you check all the boxes - we still want to speak with you! Your passion is priceless. Other things can be learned.

Proof of eligibility to work in the United States lawfully must be provided.

Location: Remote

___________________________________________________________________________________________

About Tomorrow.io:

Tomorrow.io is the world's leading Weather Intelligence Platform™. Fully customizable to any industry impacted by the weather, customers around the world including Uber, Delta, Ford, National Grid and more use Tomorrow.io to dramatically improve operational efficiency.

Tomorrow.io was built from the ground up to help teams predict the business impact of weather, streamline team communication and action plans, improve productivity, and optimize profit margins.

Space: In case you have not heard, we are also going to space with our Operation Tomorrow Space initiative. We are building the first-of-its-kind proprietary satellites equipped with radar, and launching them into space to improve weather forecasting technology for everyone on Earth.

How we roll: We work in an ""one office"" environment. We believe that magic happens when people work together. Together also includes Zoom meetings, flexible hours and unlimited vacation days. Your success is achieved by your impact and deliveries and not by the hours you put in. We believe in transparency and directness, putting work before ego and empathy. We grow fast and move faster but we always see people first. Each person has their own career growth path for we believe that the only way for the company to grow is if you grow.
Show more Show less"
2814462651,Data Engineer,Zoom,2021-12-01,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Zoomies help the world connect — and deliver happiness while doing it. We set out to build the best video conferencing product for the enterprise, and today help people communicate better with products like Zoom Phone, Zoom Rooms,

Zoom Video Webinars, Zoom Apps, and OnZoom.

We’re problem-solvers and self-starters, working at a fast pace to design solutions with our customers and users in mind. Here, you’ll work across teams to dig deep into impactful projects that are changing the way people communicate, and enjoy opportunities to advance your career in a diverse, inclusive environment.

The Data Science team lies at the foundation of Zoom’s success - you'll be working cross-functionally with teams of engineers, scientists, marketers, and product professionals on some of the most critical projects in the company - whether it's exploratory research to predict user behavior, or running experiments to optimize untapped areas of growth, or developing machine learning models that deliver “happiness” to our users more consistently and at scale.

If you are passionate about data engineering and looking to join a fun and fast-moving team, we’d love to meet you! Our team is taking Zoom's data culture to the next level by integrating predictive models into our infrastructure, and we are looking for someone like you to help us get there! This role is based in most places in the US.

Responsibilities

Partner with architecture and other senior leads to address the data needs of our rapidly-growing business
Join a group of passionate people committed to delivering “happiness” to our users and to each other
Partner with data scientists, sales, marketing, operation, and product teams to build and deploy machine learning models that unlock growth
Build custom integrations between cloud-based systems using APIs
Write complex and efficient code to transform raw data sources into easily accessible models by coding across several languages such as Java, Python, Scala and or SQL
Design, build, and launch new data models that provide intuitive analytics to the team
Build data expertise and own data quality for the pipelines you create

Requirements

Bachelor's/Masters degree in Computer Science, Management of Information Systems, or equivalent
Three or more years of relevant software engineering experience (Python, Scala and Java) in a data-focused role
Passion for creating data infrastructure technologies from scratch using the right tools for the job
Experience in solving complex data processing and storage challenges through scalable, fault-tolerant architecture
Experience in designing and building highly scalable and reliable data pipelines using BigData (Airflow, Python, Redshift/Snowflake).
Software development experience with proficiency in Python, Java, Scala or another language.
Passionate about data engineering, analytics, distributed systems and solving complex data problems.
Prior experience shipping scalable data solutions in the cloud (AWS, Azure, GCP) and database technologies such as Snowflake, Redshift, SQL/NoSQL and or columnar databases

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2812349661,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"Washington, DC",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2819539685,Data Engineer,Apple,2021-12-04,United States,"Austin, TX",Information Technology,Full-time,Computers and Electronics,"
Summary

Apple ignited the personal computer revolution in the 1970s with the Apple II and reinvented the personal computer in the 1980s with the Macintosh. Today, Apple continues to lead the industry in innovation with its award-winning computers, operating systems, smart phones and tablet computers, this is made possible because we value the “Think Different” philosophy.


Make a difference.

The Operations team at Apple is looking for a dynamic and motivated candidate for the role of a Data Engineer. The role is an opportunity for a self-driven individual to utilize their business acumen, acquire process knowledge and apply analytical skills to deliver creative, value-added solutions to the Operations team at Apple.


The engineer needs to be adept in the use of data forensics, statistical tools and techniques to be able to identify process gaps, root cause issues and recommend optimal solutions. Knowledge and hands on experience of quantitative analysis in the supply chain domain is expected. Ability to use statistical tools and techniques to identify process gaps, root cause issues and drive data driven decision making is desirable.


Ability to think strategically and execute on operational strategies to make definitive and measurable improvements for the operations teams along with providing leadership in a cross functional environment across geographies is a must have. Ability to crisply articulate findings to senior leadership and a passion for driving excellence is desired. Must be able to work in a fast paced environment, perform effectively under dynamic conditions such as directional changes, tight deadlines and limited resources. Organizational skills and the ability to multi task are essential. Commitment to keeping up to date with industry leading technologies, techniques, tools and best practices and experience with SQL, Teradata, Python and Tableau experience is an absolute must. Must be able to work in a fast-paced environment, perform effectively under dynamic conditions such as directional changes, tight deadlines and limited resources.


An understanding of data sources & relationships, reporting tools and systems knowledge is required. Experience with measuring and managing data quality is desirable. Ability to translate technical content for non-technical audiences and vice-versa would be beneficial. A positive attitude and the ability to communicate and negotiate are necessary to be successful in this role.


Ability to think out of the box and influence peers and management with data driven models using advanced analytics is a must have. Ability to leverage quantitative skills, select appropriate tools and techniques, create frameworks to drive policy changes and implementing corrective actions to improve the customer experience will be a measure of success for this role. Excellent verbal and written communication & presentation skills using data visualization applications is desired.


Key Qualifications

Minimum 5 years experience within Operations and Supply Chain desired

Proven data driven decision making skills

Computational analysis using Excel, mySQL, Teradata, Python, Tableau, Business Objects, JMP, R,Matlab, SPSS and SAP preferred.

Experience with Teradata, SQL, Tableau preferred.

Fluency in SQL or other programing languages (Python, Java, and/or C++). ETL Software preferred.

Development experience with at least one scripting language (PHP, Perl, Python, etc.)

Applied Machine Learning experience (regression analysis, time series, probabilistic models, bayesian statistics)


Description

- Provide analytical reporting and analytics to the operations team and external partners

- Ability to operate in a fast paced, rapidly changing environment

- Ability to rapidly learn and adapt to business changes

- Create and maintain reports, create and manage data models, leverage data across complex hierarchies using multiple data sources

- Leverage process improvement techniques to drive improvements in data quality

- Detail oriented and self-motivated individual able to function effectively when working

independently or in a team

- Ability to maintain poise and a positive attitude in a challenging environment

- Excellent communication and presentation skills

- Perform testing to support system implementations and upgrades

- Leverage industry best practices for data analysis and share across the operations

community


Education & Experience

- BS/MS/PhD in Data Mining, Statistics, Machine Learning, Computer Science, Operations Research or related field.


Role Number: 200282992


Show more Show less"
2816172859,Technology Engineer (Data Engineer),PNC,2021-11-16,United States,"Durham, NC",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Banking, and Financial Services","Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. We work together each day to foster an inclusive workplace culture where all of our employees feel respected, valued and have an opportunity to contribute to the company’s success.

As a Technology Engineer (Data Engineer) for PNC's Security Analytics Hub, you will have the opportunity to work fully remote. Our team focuses on producing data driven insights into multiple areas of risk facing the bank, including cybersecurity and physical security.

Day To Day Responsibilities

Acquire/map datasets that align with our business partner needs
Develop algorithms that shape data into useful and actionable information
Build, test, and maintain database pipeline architectures
Collaborate with management to understand and meet company objectives
Form new data validation methodologies and data analysis tools
Ensure continued compliance with data security policies and governance

Technical Qualifications

Education: BS/BA in technical discipline
5+ years of Python development
5+ years of experience with development/decomposition of complex SQL (RDMS Platforms)
3+ years of experience with test-driven development. Continuous Integration/ Development (e.g. GIT, Jenkins, Maven)
3+ years with CRON/Shell Scripting
Experience with utilization of REST API and/or EDPI
Hands on experience with project management tools such as JIRA, Confluence
Ability to work with end users (BI analysts, data scientists, etc.) to solve technical issues
Experience working in an Agile Team construct
Extensive knowledge of databases, data warehouses, systems integrations, and data flows is mandatory for this role.
Additionally, candidates should be well-versed in data architecture, data development, with a proven history of providing effective data solutions.

Required Skills To Be Considered For This Role

Coding: Proficiency in coding languages is essential to this role. Common programming languages used by the team include SQL, Python.
Relational and non-relational databases: You should be familiar with both relational and non-relational databases, and how they work (Teradata, Oracle, etc).
ETL (extract, transform, and load) systems: Moving data from databases and other sources into a single repository, like a data warehouse.
Data storage knowledge: As solutions are designed, when to use a data lake versus a data warehouse, for example.
Automation and scripting. Candidate should be able to write scripts to automate repetitive tasks (e.g. Cron jobs, Linux, shell scripting).
Big data tools: Understanding of Hadoop, MongoDB, and Kafka helpful, but not required.
Data security: Securely managing and storing data to protect it from loss or theft per PNC guidelines.

Job Description

Leverages technical knowledge and industry experience to design, build and maintain technology solutions. Assists with selecting appropriate platforms, integrates and configures solutions.
Develops software components and hardware for new and emerging technology projects; aligns these with business strategies and objectives.
May provide consultation on common issues and best practices for junior staff.
Provides a systematic analysis on client requirements within the traceability framework and resolves any functional problems encountered.
Ensures quality of project deliverables while maintaining compliance with relevant standards and processes.

PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:

Customer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
Managing Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.

Competencies

Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.

Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.

Effectiveness Measurement – Ability to measure the quality and quantity of work effort for the purpose of improvement.

Emerging Technologies – Knowledge of and ability to design, apply and evaluate new information technologies for business environments in order to improve work productivity and accuracy.

Industry Knowledge – Knowledge of the organization's industry group, trends, directions, major issues, regulatory considerations, and trendsetters; ability to apply this knowledge appropriately to diverse situations.

IT Industry: Trends & Directions – Knowledge of and ability to analyze marketplace experiences, developments and trends related to the function of Information Technology (IT).

IT Standards, Procedures & Policies – Knowledge of and the ability to utilize a variety of administrative skill sets and technical knowledge to manage organizational IT policies, standards, and procedures.

Planning: Tactical, Strategic – Ability to contribute to operational (short term), tactical (1-2 years) and strategic (3-5 years) planning in support of the overall business plan.

Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Work Experience

Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

Education

Bachelors

Additional Job Description

COMPENSATION

Base Salary

$55,000 to $142,600

Role

Placement within the compensation range is based on the specific role and the following factors

Where a person is paid in the compensation range is aligned to their experience and skills.

– Lower in range –Building skills and experience in the job

– Within the range–Experience and skills align with proficiency in the role

– Higher in range –Experience and skills add value above typical requirements of the role

– Compensation Range may vary based on Geographic Location

INCENTIVE

Role is incentive eligible with the payment based upon company, business and individual performance.

Benefits

PNC offers employees a comprehensive range of benefits to help meet your needs now and in the future. Depending on your eligibility, options for full-time employees include medical/prescription drug coverage (with a Health Savings Account feature); dental and vision options; employee and spouse/child life insurance; short- and long-term disability protection; maternity and parental leave; paid holidays, vacation days and occasional absence time; 401(k), pension and stock purchase plans; dependent care reimbursement account; back-up child/elder care; adoption assistance; educational assistance and a robust wellness program with financial incentives. To learn more about these and other programs, including benefits for part-time employees, visit pncbenefits.com > New to PNC.

Disability Accommodations Statement

The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com.

The Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.

Equal Employment Opportunity (EEO)

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.

California Residents

Refer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.
Show more Show less"
2804282377,Data Engineer,"HomeVestors of America, Inc., the “We Buy Ugly Houses® people",2021-11-12,United States,"Dallas, TX",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","The Data Engineer position will be a key part of our IT Team, responsible for managing the tools, systems, processes, and data that drive our business. This position will ensure the integrity of our data through development, analysis, troubleshooting, reporting, and cleansing. The successful candidate will interface with the rest of the business, documenting and gathering data requirements for new tools and necessary reports.

Responsibilities
Know The System
Quickly become familiar with our systems. Ensure they meet business requirements & industry standards.
Become adept at Collecting, Organizing, and Analyzing data from our different systems.
Learn and be able to troubleshoot the flow of data between systems.
Maintain The System
Develop, build, and maintain our data management systems.
Interface with other departments to define reporting requirements. Discover ways to utilize data to improve business results.
Design, build, and present reports in Salesforce & Wave that are easy to understand.
Utilize reports to build dashboards for end users.
Draw conclusions based on analysis. Present the results, and work with stakeholders to build next steps.
Develop & run queries for the purposes of reporting, troubleshooting, and maintaining.
Execute data extraction, storage, manipulation, processing, and analysis.
Install, test, and maintain disaster recovery systems.
Safeguard the System:
Build/recommend processes to keep data clean.
Cleanse data when necessary.
Establish guidelines and standards for data accuracy.
Grow the System
Research and make recommendations on new tools and technologies.
Assist in building a data solid data reporting system to help track and grow the business

Requirements

2+ years Data Engineer Experience
2+ years SQL/NoSQL Technologies (Mongo, PostgreSQL, MSSQL)
Bachelor degree in related field or equivalent experience
ETL Management/Maintenance
Data Modeling Experience
1+ year experience with Salesforce Reporting
Strong Excel Skills
Strong Business Intelligence Experience

Preferred

System integrity experience ensuring quality of data
Einstein Analytics (Tableau CRM)
Experience with other BI Tools such as Tableau & PowerBI

Personal Attributes

Strong communication skills (both written and oral)
Solution Driven
Ability to perform complex analysis, and present the results in simple terms
Self-paced with good time management abilities.

HomeVestors is America’s #1 Home Buyer, a real estate investment franchisor, headquartered in Dallas, TX. Known as the ""We Buy Ugly Houses®"" company, HomeVestors® trains and supports its franchisees in building businesses based on buying, rehabbing, selling and holding residential properties. HomeVestors makes a positive impact in more than 170 markets nationwide.
Show more Show less"
2824750920,Big Data Engineer,Diverse Lynx,2021-12-02,United States,"Irving, TX",Information Technology,Contract,IT Services and IT Consulting,"Role Big Data Engineer

Location- Dallas, TX/ Tampa, FL Remote until Pandemic

Type Contract/Fulltime W2/C2C

Client TCS

Job Description

We are looking for a Big Data Engineer that will work on the collecting, storing, processing, and analyzing of huge sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Responsibilities

Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities
Implementing ETL process
Monitoring performance and advising any necessary infrastructure changes
Defining data retention policies

Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.
Show more Show less"
2789631008,Data Engineer,Zoom,2021-12-03,United States,"Massachusetts, United States",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2667397131,Data Engineer (Open to Remote),Olive,2021-11-15,United States,"Seattle, WA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Hospitals and Health Care","Description

Olive’s AI workforce is built to fix our broken healthcare system by addressing healthcare’s most burdensome issues -- delivering hospitals and health systems increased revenue, reduced costs, and increased capacity. People feel lost in the system today and healthcare employees are essentially working in the dark due to outdated technology that creates a lack of shared knowledge and siloed data. Olive is designed to drive connections, shining a new light on the broken healthcare processes that stand between providers and patient care. She uses AI to reveal life-changing insights that make healthcare more efficient, affordable and effective. Olive’s vision is to unleash a trillion dollars of hidden potential within healthcare by connecting its disconnected systems. Olive is improving healthcare operations today, so everyone can benefit from a healthier industry tomorrow.

Our Infrastructure team is looking to add a DataOps Engineer and continue to advance the cloud capabilities and services/systems for our internal engineering teams. As part of our engineering team, you’ll be responsible for ensuring Olive’s data runs smoothly through our architecture. You’ll help keep our data infrastructure up to date, and use new and existing tools to solve technical problems. At Olive, automation, reliability and efficiency are part of everything we do.

Requirements
Support customers, engineering efforts, and internal departments in SOA environment.
Architect and build high-scale infrastructure for rapidly growing web applications.
Foster proactive and cooperative relationships within the project team.
Exercise independent judgment in selecting methods and techniques for obtaining solutions.
Build specialized data-layer services for data-intensive parts of the system.
Analyze applications and make the necessary changes to optimize performance.
Diagnose and resolve issues promptly and in accordance with maintainability goals.
Work with a variety of technical and non-technical people.
Embrace changing requirements.
Create and maintain efficient, reliable infrastructure with code
Drive automation using popular cloud orchestration, configuration management, and CI/CD system
Design and implement:
Solutions to support data lake and data warehousing
Data quality check frameworks
Alerting and monitoring for overall data stack
Scalable data pipelines
Preferred programming and scripting languages include: SQL, Python, Java, Bash

Qualifications

4+ years of Data Engineering experience
A strong understanding of operating systems, networking, and software engineering fundamentals
Experience using AWS or other virtualized infrastructure
Experience managing a container-based microservice architecture, including orchestration, service-discovery, monitoring, and debugging
Proficient in a scripting language (Bash, Python, Ruby, Perl, PowerShell, etc.)
Experience orchestrating infrastructure using CloudFormation, Terraform, or other similar tooling.
Experience building Linux and Windows systems (AWS Linux 2, Ubuntu, CentOS, ContainerLinux, etc.)
Strong experience with SQL and No-SQL databases (MySQL, PostgreSQL, Oracle, MongoDB, SQL Server)
Data warehousing and data engineering experience
Experience with Data Lakes (Lake Formation/Snowflake)
Experience with Big data solutions like Spark/Hadoop
Deploying or managing infrastructure across AWS AZs and regions.
Show more Show less"
2795318204,"Data Engineer - Experian Health - SQL/Python/Azure desired, REMOTE role (anywhere in the US)",Experian,2021-11-16,United States,"Franklin, TN",Analyst,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Company Description

At Experian Health, our employees have the opportunity to shape more than products – they shape the future of U.S. healthcare. Experian Health is a pioneer for innovations leading the way in revenue cycle management, identity management, patient engagement, and care management for hospitals, physician groups, labs, pharmacies and other risk-bearing entities. Our success relies on people who are given the freedom to imagine new frontiers in the rapidly changing healthcare space and push the boundaries of innovation. Help us realize our vision of applying data for good and changing the healthcare landscape for the better – for all of us.

Job Description

SQL Data Software Development Engineer

The engineer will work as part of a team to develop advanced analytical solutions for Experian Health clients, including building new software product initiatives for healthcare organizations. Must possess engineering and programming skills to solve and automate the data wrangling challenges from both an internal and client perspective to build systems which deliver actionable business insights. Looking for an agile professional willing to mentor teammates to accomplish bigger goals. Experience working with large analytical data warehouses and ETL platforms on cloud systems like Azure is required, with additional on the job training available.

Responsibilities

Will work as part of a team to write code for advanced analytical solutions for Experian Health clients, including building new product initiatives for healthcare organizations.
Produce data marts and data pipelines.
Must be able to understand and develop data architecture and integration to devise data ingest and extract strategies.
Will need to understand Experian Health data structures and business objectives to extract and organize relevant data.
Must be able to communicate ideas and analysis results effectively both verbally and in writing to a technical audience.
Support healthcare consulting organization and product development group by providing data and engineering expertise.
Oversee development of reporting architecture for enhancing platforms and processes.

Qualifications

Knowledge, Experience & Qualifications

This position requires a highly motivated, energetic, and positive person with:

Bachelor’s degree in Computer Science, Software Engineering, Data Science, or other engineering discipline required.
Fluency in SQL, Python, and knowledge of other computer languages.
A proven track record for executing complex data extraction and ETL projects.
Expertise in relational databases, data warehousing, data storage principles for analytics, indexing and query optimization
Ability to create appropriate data architectures and pipelines.
Understands software development principles and operations.
Experience with Azure or similar cloud infrastructure required.
Experience with Data Factory and Synapse Analytics is a big plus.
Experience with Hadoop is a plus.
Demonstrated ability to communicate ideas and engineering results effectively both verbally and in writing to technical audiences.
Healthcare patient access or revenue cycle management industry experience is a plus.
Good knowledge of Microsoft desktop tools such as Excel and Word.

Additional Information

Experian is an Equal Opportunity Employer. Anyone needing accommodation to complete the interview process should notify the talent acquisition partner. The word ""Experian"" is a registered trademark in the EU and other countries and is owned by Experian Ltd. and/or its associated companies.

EOE including Disability/Veterans.

Experian is proud to be an Equal Opportunity and Affirmative Action employer. Our goal is to create a thriving, inclusive and diverse team where people love their work and love working together. We believe that diversity, equity and inclusion is essential to our purpose of creating a better tomorrow. We value the uniqueness of every individual and want you to bring your whole, authentic self to work. For us, this is The Power of YOU and it ensures that we live what we believe.
Show more Show less"
2816517599,Data Engineer,"KMM Technologies, Inc.",2021-12-02,United States,"Washington, DC ",,Contract,,"Propose new ways of representing data in PowerBI.
3+ years of work experience with ETL, and business intelligence big data architectures.
3+ years of experience with the Hadoop ecosystem and big data ecosystems (Kafka, Cassandra, etc.) or any NoSQL stores.
3+ years of hands-on Spark/Scala/Python development experience.
ETL Design and Development in the big data platform in Hadoop using technologies such as Scala, Spark, Python, Oozie, and more to support a variety of requirements and applications.
Warehouse Design and Development – Set the standards for warehouse and schema design
Implement end to end Data Lake solution in on premise as well as on a cloud environment preferably AWS.
Experience with core competencies in Data Structures, Rest/SOAP APIs, JSON, etc.
Expert in writing SQL.
Show more Show less"
2824801158,Celonis Data Engineer,Enowa,2021-12-02,United States,"Malvern, PA","Information Technology, Consulting, and Engineering",Full-time,"IT Services and IT Consulting, Computer Software, and Management Consulting","Enowa is seeking extraordinary talent to join our process mining team. The requirement is for individuals who have a deep understanding of the table structures of SAP modules (MM, SD, FI, CO) and are comfortable connecting to an arbitrary data source, extracting data and transforming it. 




Ideal Candidates are:

US Citizens or Green Card holders
Open to travel
True business consultants who understand their primary job is to be helping customers achieve their objectives through efficient business processes
Excellent communicators who understand the importance of communication in a consultant’s job
Team players who are willing to share their special expertise with fellow team members




Specific openings are for individual with the following qualifications:

Bachelor (required) or master’s degree
ABAP/4 experience (5+ years)
Report Writing
Data Analytics
SQL (deep, HANA SQL preferred)
Vertica SQL
PQL (must have willingness to learn and certify)
Process understanding in at least 2 SAP modules (MM, SD, FI, CO preferred)




We offer the opportunity to grow within our company and will provide the training and support to ensure success in this position. Our work environment is relaxed and casual however we value a good day's work. 

Show more Show less"
2798287729,Data Engineer,Jetty,2021-10-19,United States,"New York, NY",Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","Welcome to Jetty, the financial services platform on a mission to make renting a home more affordable and flexible. We've built multiple financial products that benefit both renters and property managers - and we're just getting started.

As we continue to grow and expand our reach, we are looking to expand our data organization by hiring a Data Engineer. As a Data Engineer, your goal is to cultivate a data-informed culture and create insights that will be leveraged across the entire organization. You have experience executing at a high level, solving complex problems, and delivering solutions with real business impact - and you're excited by the opportunity to apply those principles to a brand new, best in class function.

Role & Responsibilities

Build / Support our modern data stack (Snowflake / Fivetran / DBT / Tableau)
Implement the Five Pillars of Data Observability
Write ELT code using modern software engineering practices (Git, automated testing and deployments)
Build and maintain data pipelines to support various business processes and reporting (Fivetran / AWS Lambdas)
Document our data models in a user friendly way for our business stakeholders
Partner with the Product Engineering team to ensure we are capturing the data we need from our applications for analytics and to iterate on our development practices for the data analytics team.
Be an enthusiastic evangelist of our modern data stack (Fivetran / DBT / Snowflake / Tableau)
Be the resident resource on building standard reports and BI dashboards


Experience & Qualifications

5-7 years of experience working in a data / analytics engineering role
High proficiency in Snowflake / Fivetran / dbt / Tableau
High proficiency in SQL and Python
Ability to collect, interpret, and synthesize inputs from various parts of the business into data model requirements
Ability to simplify without being simplistic - ability to communicate complex topics and actionable insights in a compelling way that can be understood by a variety of audiences
Inherent curiosity and analytical follow-through — you can't help but ask ""why?"" and love using data and logic to explore potential solutions
Ability to balance ""Rigor"" and ""Scrappiness"" — you know the difference between 80/20 and giving something 110%; as well as when each is appropriate.
Deep understanding of the first and second order effects of reporting — you know the power of presenting the right data to the right people at the right time
Experience in a data/analytics function at a high-growth startup managing multiple stakeholders and delivering actionable insights


About Jetty

Jetty's integrated suite of products help property managers increase lease conversions, improve resident retention, reduce bad debt, and boost NOI. For renters, Jetty decreases the financial burden of moving into a new home and offers greater flexibility with how and when to pay rent.

Jetty has raised more than $70M from investors including Khosla Ventures, Ribbit Capital, Citi and Valar, and has a highly collaborative team working remotely around the country. To learn more about Jetty, visit jetty.com.

Jetty is firmly committed to building a team as diverse as our Members. We are proud to provide equal employment opportunities for all candidates regardless of race, ancestry, citizenship, sex, gender identity or expression, religion, sexual orientation, marital status, age, disability, or veteran status.

Benefits & Perks

Health, dental, and vision insurance through Aetna & MetLife
401(k) through Betterment
Optional life and disability coverage, HSA & FSA
20 days of PTO + 12 holidays, ""Jetty Winter Break,"" and unlimited sick days
Generous parental leave policy
Flexible work schedules to accommodate remote work
Stipends to cover WFH set-up, monthly childcare, and monthly phone/internet bill
Show more Show less"
2812355037,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"Dallas, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2822172775,Data Engineer & Analyst,EPB,2021-12-04,United States,"Chattanooga, TN",Information Technology,Full-time,IT Services and IT Consulting,"Are you looking for an opportunity to join a company that values people and innovation while placing the highest priority on enhancing the lives of their customers and community? Are you a motivated, passionate, and highly skilled technical and engineering talent with a compelling urge to serve a meaningful purpose and to make a difference? At EPB, we put our customers, employees, and community first. We are dedicated to developing diverse, high-performing people who are passionate about what they do. If this sounds like you, we invite you to learn more about how you can join our team and grow with us.

PURPOSE

EPB is adding a Data Engineer & Analyst to the Advanced Analytics team. The hire will work with data from internal electric and fiber-related systems as well as external data. The successful candidate will turn data into information, information into insight, and insight into business decisions. The hire will conduct full lifecycle analysis to include requirements, design, testing, and delivery. He/she will also monitor performance and quality control plans to identify improvements.

Duties And Responsibilities

Gather analytic requirements from business and operational stakeholders, design analytic approach, implement approach using a variety of tools, develop visualization/dashboards, communicate and present findings and actionable insights to business stakeholders and non-technical audiences
Take ownership of data quality, data reliability, and ranges of uncertainty around analytic results
Partner with various departments to define core metrics; to measure and optimize impact and efficiencies; to identify opportunities, assess risk potentials and explain trends; to drive customer and revenue growth
Apply strong business judgment to data analysis, make and defend meaningful conclusions and recommendations
Build, maintain, and communicate detailed reporting, visualization, and other tools to deliver business insights and to drive business actions.
Continuously improve the quality and accessibility of our analytical framework and data reporting infrastructure
Use statistical methodologies to create algorithms for analyzing large data sets
Inspect, clean, transform, model, and integrate data from a variety of sources
Perform root cause analysis on data anomalies to identify areas for business and operational process improvements
Implement specified quality assurance procedures to ensure accuracy of data, results, written reports, and presentation materials
Create appropriate documentation that allows stakeholders to understand the duplicate or replicate the analysis if necessary
Create and maintains a data dictionary and meta data.
Serve as an organizational consultant on matters relating to analytics by providing expertise to assist users in meeting their needs
Serve as a resource to other analysts for training and coaching.

Qualifications

BS/MA in Mathematics, Statistics, Computer Science, Electrical Engineering, or related field. (An equivalent combination of training and experience may be considered.).
A minimum of 5 years of experience in the data engineering, business analysis, and/or data science fields (Master's degree can substitute for 2 years of experience).
Strong database and SQL skills (Snowflake, Oracle, PostgreSQL, etc.).
Experience with tools such as Python, R, and Java
Experience with data integration tools such as Talend, Informatica, and DataStage
Experience with Tableau, PowerBI, Cognos or other BI reporting tools.
Strong Microsoft Office (particularly Excel) skills.
Experience with DevOps and Continuous Integration/Delivery (CI/CD) concepts and tools.

Certifications And/Or Other Requirements

A self-learner and starter, willing to dig, with the ability to work independently or with teams.
Ability to think creatively to solve complex problems.
Ability to efficiently communicate data analytics methods and complex problems to non-technical teams and stakeholders.
Ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in using cloud-based infrastructure, such as AWS/Azure/Google Cloud a plus
Experience with Snowflake or other cloud data warehousing services a plus
High-level written and verbal communication skills.

Benefits

You'll enjoy competitive compensation including an outstanding benefits and perks that fit your life, including:

Health, Dental, Vision and wellness plans for you and your family - including a free on-site health clinic and on-site exercise facilities
Educational assistance programs and programs centered on career development to help you reach your personal and career goals.
Financial savings programs that help you plan your future - 401K, Plus a Pension Program
Volunteer Opportunities

Who We Are

Recognized by J.D. Power among the best in the country for customer satisfaction four years running, EPB is one of America's largest publicly-owned energy providers. EPB is also the pioneering communications company that surprised the nation by being the first to offer gigabit speed internet services comprehensively to all residents and businesses in our market-four years before Google Fiber launched its first deployment. EPB delivers internet speeds of up to 10 gigabits per second as a standard offer to both homes and businesses along with television and telephone services.

With the fiber optic network as the communications backbone we deployed the most advanced and automated smart grid power distribution system in the U.S. As a result, EPB has become a major research partner for the U.S. Department of Energy and Oak Ridge National Laboratory for field-testing technology and best practices including the deployment of cutting-edge smart grid equipment, micro-grid control systems, integrated storage, and much more.

A GREAT PLACE TO CALL HOME

EPB is located in Chattanooga, TN, a city that Outside Magazine called the ""Best Ever."" Built along both sides of the Tennessee River in a valley surrounded by mountains, Chattanooga is well known for its scenic beauty and outdoor recreation along with having the world's fastest internet which earned it the name ""Gig City."" Chattanooga also offers award-winning, downtown living, a thriving food scene, and a surprisingly low cost of living with no state income tax. As a result, Liviability.com includes Chattanooga among its Top 100 Best Places to Live and Top 10 Downtowns.
Show more Show less"
2812774164,"Software Engineer, Data Infrastructure",DoorDash,2021-11-29,United States,"San Francisco, CA",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Come help us build the world's most reliable on-demand, logistics engine for delivery! We're bringing on experienced engineers to help us further our 24x7, global infrastructure system that powers DoorDash’s three-sided marketplace of consumers, merchants, and dashers.

The Data Infrastructure team manages DoorDash's massive database and makes data accessible for teams driving decision making, machine learning, and experimentation. The team is relatively small, so there's an opportunity for impact where you can help grow the team and shape the roadmap for data infrastructure at DoorDash.

What You’ll Do

Work on our data pipeline, ETL systems, and real-time data
Come up with solutions for scaling data infrastructure
Help all departments of the company have access to our data
Collaborate in a dynamic startup environment
Improve logistics by taking on cutting-edge, technical problems

What We're Looking For

B.S., M.S., or PhD. in Computer Science or equivalent
5+ years of experience with CS fundamental concepts and OOP languages like Java and Python
Experience working with databases (e.g. SQL) and data infrastructure
Experience in big data technology like Presto, Snowflake, Hadoop, Airflow, Kafka
A passion for analyzing data to inform decisions
Experience improving efficiency, scalability, and stability of system resources

Why You’ll Love Working at DoorDash

We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies.
We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day.
We are learners - We’re not afraid to dig in and uncover the truth, even if it’s scary or inconvenient. Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute.
We are customer-obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility.
We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.
We offer great compensation packages and comprehensive health benefits.

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly and always learn and reiterate to support merchants, Dashers and the communities we serve. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods. Read more on the DoorDash website, the DoorDash blog, the DoorDash Engineering blog, and the DoorDash Careers page.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. Our leaders seek the truth and welcome big, hairy, audacious questions. We are grounded in our company values, and we make intentional decisions that are both logical and display empathy for our range of users—from Dashers to Merchants to Customers.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

Pursuant to the Colorado Fair Pay Act, the base salary range in Colorado for this position is $136,000 - $182,750, plus opportunities for equity and commission. Compensation in other geographies may vary. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

If you need any accommodations, please inform your recruiting contact upon initial connection.


Show more Show less"
2820369119,Data Engineer,Pine Park Health,2021-12-03,United States,"Oakland, CA ",,Full-time,,"Welcome to Pine Park Health!




We're building a new model for caring for seniors. Pine Park Health stands-up micro-clinics in senior living communities, providing safer, more convenient urgent and primary care. We're building a value-based care model where we can invest in the health outcomes of our patients.




We are a well-funded startup backed by First Round Capital, Google’s AI fund, and Y Combinator—and we’re growing fast. We've gone from 0 to 20+ care sites in the past year, seen 10x patient growth, and are just getting started.




We’re looking to expand our motivated, multi-disciplinary team of operators, engineers, and clinicians. If you share our drive for mission-driven care, and love collaborating with others to realize a dream and scalable vision, join us! We’re building a company to improve the way healthcare is delivered to older adults now and for decades to come.




Our Core Values

Stay focused: Pine Park Health is intensely focused on our goal: to build a new kind of primary care model and company for seniors, providing consistently high-quality care and reducing hospitalizations.
Be an owner: Own a process, goal, or patient experience all the way to the outcome. Prioritize follow-through and earn the trust of those we work with. Solve problems with process: Pine Park Health is built on the idea that the best way to solve a repeating problem is with a repeatable process. We aim for consistent rigor and rely on building systems and processes for a high-quality experience and to minimize preventable errors.
Commit to learning: We are constantly seeking to learn without ego. We stay curious and open-minded. We believe great ideas come from everywhere.
Care for patient outcomes: We care. Constantly. We focus on the human beings at the center of our care, and their long-term goals and outcomes. We build to improve patient outcomes. All decisions should be made in service of this.




The Role

This role will be one of our first team members on our Data Engineering team dedicated to driving results through Data Analytics and is a unique opportunity to build a function from scratch. You will build and oversee the deployment and operation of solutions and software to capture, manage, store and utilize structured and unstructured data from internal and external sources. You will have the opportunity to establish and build processes and structures based on business, data governance and technical requirements to channel data from multiple inputs, route appropriately and store using any combination of distributed (cloud) structures, local databases, and other applicable storage forms as required. You will have the ability to select or develop and implement tools to cleanse, organize and transform data and to maintain, defend and update data structures and integrity on an automated basis. You will enforce design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements. You will Reframe business requests to fit the unasked need, articulating clear and trusted recommendations for data engineering solutions and work across different functional teams to implement and monitor data pipelines as well as have project ownership.




What You’ll Do

Partner with our Product, Clinical, and Operations teams to design data-driven care delivery workflows that consistently deliver remarkably personalized patient care. To this end, you will occasionally spend time inside Assisted Living Facilities (ALFs) shadowing our Growth, Ops & Care Delivery teams to gather context required to make excellent technical design decisions.
Lead the effort to implement a de novo data infrastructure ( instrumentation, ETL, mesh architecture, warehouse, BI/reporting (Looker) and web services) to enable the care delivery workflows you help design.
Understand our ‘no/low code’ approach to growth & care delivery applications at the ‘top of our stack’. Then devise a capture/instrumentation strategy to pull relevant data from Salesforce, Monday.com, Elation, and other operational applications, in order to: Enable actionable analyses/insights for the business, Trigger operational cues for our care delivery team through heuristics & modeling, Facilitate efforts to build a data driven culture and cadence at Pine Park Health.
Support efforts to devise a threat model for Pine Park Health. Lead our corresponding strategy, evaluate solutions and execute a plan to protect our patient and partner data; including coverage for: HIPAA, SOC2, HITRUST, PCI, disaster recovery, abuse/security, etc.




What We’re Looking For

Someone with a history of living our core values
Bachelor's degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
5+ years of Data Engineering experience in a variety of settings like healthcare, early & later stage companies, regulated environments, etc.
Experience with statistical modeling and data analysis on large/complex, data-sets in close partnership with cross-functional teams. This includes root cause analysis on anomalous data.
Experience creating data pipelines & ETL jobs to combine disparate data sources and automating dashboards & analytical tools to identify changes in business metrics.
Familiarity with tools & standards like: Airflow, Azkaban, BigQuery, BitBucket, Cassandra, DataGrip, EC2, FHIR, Fivetran, Git, Github, Google Analytics, Google Cloud, HL7, Hadoop, Kafka, Looker, Luigi, Node.js, NoSQL, MixPanel, Python, PostgreSQL, PyCharm,
Redshift, S3, SPAD, Spark, SQL, stata, Storm, Tableau and any additional Tools Preferred. 
A penchant for writing clean, well-structured, code




The Benefits

Medical, dental, and vision coverage
Flexible spending accounts
Mental health stipend
Professional development allowance
Generous paid time off

 

Our mission at Pine Park Health is to provide the highest safety and quality of life for our patients who are at high-risk from COVID-19. To support this mission, we require vaccination for all employees and require proof of vaccination (at least first dose with plans to complete second dose) before hiring.

Pine Park Health is an equal opportunity employer — we aim to recruit, hire, develop, compensate, and promote regardless of of race, religion, country of origin, gender, sexual orientation, age, marital status, veteran status, or disability.

Show more Show less"
2815091038,Data Engineer,Olea Edge Analytics,2021-11-01,United States,"Austin, TX",Information Technology,Full-time,IT Services and IT Consulting,"Are you interested in working for an AI & Analytics start-up that has figured out its product market fit and its pricing model? How about a start-up that has also determined its customer base and one that when the customer uses it, they make more money? If this sounds interesting read on….

What do we do?

Olea develops AI & Analytics to improve the water ecosystem around us. Our products promote economic fairness and water conservation while driving a profitable and robust business that positively impacts our employees and communities we serve.

We are growing fast and need a Data Engineer that knows how to work with large, complex data sets and solve difficult non-routine analysis problems. These problems will directly impact the economic model for water across the United States and eventually the world. The data sets you work with will be used by top executives in the water industry and beyond.

Successful candidate will have many of the following skills:

We are a start-up. As a start-up we’ve learned that it’s impossible for an individual to know everything. We also know learning new technologies and methodologies is key to being a successful staff member at Olea. Although we don’t expect you to know everything on this job description, you do need to be willing to learn about those technologies that you don’t know in a deep and meaningful way.

Create and maintain optimal data pipeline architecture while also implementing monitoring of the pipelines to ensure timely delivery of data.
Assembling large, complex sets of data that meet non-functional and functional business requirements
Identifying, designing and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using Google Cloud products and SQL technologies
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Building analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition
Working with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues
Working with stakeholders including the Executive, Product, Data and Design teams to support their data infrastructure needs while assisting with data-related technical issues


Qualifications:

Bachelor’s degree in a quantitative discipline (e.g., Statistics, Operations Research, Bioinformatics, Economics, Computational Biology, Computer Science, Mathematics, Physics, Electrical Engineering, Industrial Engineering) or equivalent practical experience. Master’s degree preferred
Minimum 3 years in Data Engineer role
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building data warehouses and familiarity with star schema and best practices in Business Intelligence applications
Design and implement ETL procedures for intake of data from both internal and outside sources; as well as ensure data is verified and quality is checked
Strong analytic skills related to working with unstructured datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment
Experience with data pipeline and workflow management tools: Airflow, Dataflow, DataPrep, Spark, Kafka, Airflow, etc.
Experience with Google Cloud cloud services: GCE, GKE, App ENgine, Cloud Run, Cloud Function
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL)


Olea Edge Analytics provides a comprehensive benefits package including health, dental, vision.

Olea Edge Analytics is an Equal Employment Opportunity and Affirmative Action employer. We are committed to diversity and building a team that represents a variety of backgrounds, perspectives, and skills. We do not discriminate and all decisions we make are made based on qualifications, merit, and business need. Our goal is to be one global diverse team that is representative of our customers, in an inclusive environment where we can continue to innovate and grow together.

Powered by JazzHR

rEeQBzsWV4
Show more Show less"
2818888792,Data Engineer,DISYS,2021-12-03,United States,United States ,Information Technology,Contract,IT Services and IT Consulting,"PYTHON EXPERIENCE REQUIRED




As a Senior Data Engineer in the Engineering Enablement organization, you will develop and oversee the best practices around data enablement with highly efficient and scalable code. The engineer will oversee the data integration work for Engineering Enablement, including developing a data model, maintaining a data warehouse and analytics environment, and writing scripts for data extraction/integration into Snowflake. A successful candidate is self-motivated, with the drive to excel and exceed commitments. You thrive in a fast-paced atmosphere where wearing multiple hats is encouraged. You learn new skills and technology quickly. You have strong collaboration/communication skills, as you will be working with multiple teams and other software engineers to create solid data standards that others across client can use and follow.




Technology We Use:

Python, Terraform, Amazon Web Services, SnowFlake
Your Role:
Passionate and flexible Engineer that will design, develop and maintain scalable code.
Design, develop and test data pipelines and data transformations for variety of data-sources.
Build complex data products using multiple technologies across all phases of the development lifecycle including design, coding, and testing in an Agile environment.
Develop, document, and communicate best practices and patterns around ETL.
Subject Matter Expert in data modeling and extraction for Engineering Enablement.
Ensures all documentation and knowledge bases are updated to help encourage good collaboration within and outside of our group.
Collaborate with Lead Engineers and Architects to implement and maintain the standards and consistency for the data-pipelines and best practices
Collaborate with business partners and leadership to develop road maps and strategies.
Qualifications:
Required:
BA/BS degree in Computer Science or equivalent combination of industry related professional experience and education.
5+ years of data engineering experience
What We Look For:
Experience in Python for scripting and automation.
Strong analytical and problem-solving skills.
Experience in data warehousing, data modeling, and data extraction
Sharp communicator who can break down and explain complex data problems in clear and concise language.

Show more Show less"
2779437390,Data Engineer,Carbon Direct,2021-11-04,United States,"Seattle, WA",,Full-time,,"Carbon Direct Inc. is building the world’s largest Carbon Dioxide (CO2) management platform, a critical tool in the battle against climate change.

We are unique in our science-first approach to carbon management, and in our scale. We employ over 50 of the world’s leading carbon scientists, manage hundreds of millions of tonnes of CO2 emissions annually, and are trusted by leading companies like Microsoft, Shopify, and Alaska Airlines.




Carbon Direct is a mission-driven company and we measure our success in tonnes. Our firm is making a difference today. We help our clients—many of the world’s largest companies—make rapid transitions towards carbon-free operations with top scientists, unequaled datasets, and proprietary insights. We are committed to further scaling our climate impact work through innovative products and revolutionary technologies. Both the climate and carbon markets are at a critical inflection point. This is a career defining opportunity and we are looking for motivated individuals to join us.




At Carbon Direct, you will work in conjunction with the world’s top climate scientists, technologists, and commercial leaders to drive change on a global scale. We operate in a fast paced environment, rapidly innovating to meet rising demand for carbon management solutions in the race to net zero. Our team is open-minded, supportive, diverse, and inclusive. We value sustainability, wellbeing, and a healthy work-life balance, and as a remote team we welcome applicants from anywhere.




What We're Looking For

We are hiring the founding members of our software team! We are looking for adaptable, enterprising, and experienced professionals. If you are looking for an opportunity to apply your engineering expertise in the rapidly growing climate tech industry, then this is the job for you!




Role

You will be an essential member of our engineering team. You will help the business harness data, identify trends, and build powerful data tools that enhance our carbon management platform capabilities. You will put the user first, prioritize business impact, and pursue engineering excellence. You will actively participate in discussions about strategy, architecture, and planning fusing your engineering experience and commercial awareness. You should be able to work autonomously on engineering tasks when required, but you will frequently work alongside industry scientists, data scientists, and software engineers on collaborative projects.




Responsibilities

Build great data pipelines

You combine knowledge of data analytics and computer programming to design, implement, and operate data flows.
You build cost optimized, scalable and performant data solutions for storage, processing, materialization, and access
You work to improve data reliability, quality, and performance (e.g., efficiency, correctness, freshness, consistency).
You are aware of modern programming techniques and best practices, and you apply these to the solutions you build.
You are capable of using various technologies to create purpose-built solutions for unique problems.

Support product development and business growth

You take pragmatic decisions balancing between business outcomes, product wins, design goals, and engineering excellence.
You primarily contribute to the team as a data engineer. But, you are not shy about working outside of your discipline to help the team succeed.

Help us shape a culture of engineering excellence

You document your software system designs, specifying tradeoffs, performance, and constraints and conducting thorough reviews.
You apply reliability engineering practices to ensure the systems you own are well-monitored, performing, and scaling as intended.
You triage, mitigate, and resolve root causes when your systems misbehave, following-up to maximize learning and minimize risks.
You ensure your software behaves as expected, working with others to improve test coverage, code quality, and conduct code reviews.

Be a team player

You invest in others, proactively sharing knowledge to help colleagues grow and participating in recruitment efforts to shape the team.
You identify engineering challenges and coordinate solutions, empowering others to contribute and improve outcomes.
You are capable of effectively collaborating with colleagues from diverse professional backgrounds (e.g., science, tech, product, marketing, ...).
You have a point of view but remain open-minded. You welcome diverse perspectives, and encourage others to generate and explore new ideas.
You learn forever and nurture those around you. You role-model by inviting and freely giving well-intentioned, constructive feedback.




Qualifications

5+ years of professional experience building data products
You are competent in at least one programming language (e.g., JavaScript, Python, Go)
You are competent with data analysis tools (e.g., Tableau, Looker)
You have experience performance tuning database queries
You have experience in database development, SQL, NoSQL, and data warehousing.
You have experience integrating and managing data sets from multiple sources
You have experience building and optimizing ETL pipelines
You have experience creating data visualizations
You have experience testing and maintaining data architectures
You have experience working with cloud infrastructure providers
You have experience mentoring more junior data engineers and data analysts
You have a track record of identifying and acquiring new and relevant skills
You have a passion for writing and maintaining excellent code
You have a laser focus on shipping and driving business outcomes
You can articulate engineering constraints to non-experts.
You are an excellent communicator and cross-functional team builder.
You build strong relationships while working with a fully-remote, global team.
You thrive in a fast-paced, outcome-oriented professional environment.
Passion for addressing climate change is critical.
Experience building new products and platforms is a strong plus.
Experience working in the climate technology space is a strong plus.




How to Apply

Does this role sound like a good fit? Interested candidates should submit a cover letter and CV via apply@carbon-direct.com.




This is a full-time opportunity. We are a remote team and candidates from all geographies are encouraged to apply. For this role, we strongly prefer candidates in North or South American time zones, but it is not a hard requirement. We also have physical offices in New York City and Seattle, and give a slight preference to applicants in those geographies. Applications are being reviewed on a rolling basis.




Equal Opportunity Employer

We adhere rigorously to our equal employment opportunity policies in connection with all employment decisions, including hiring, compensation and promotion.




Carbon Direct is an equal opportunity employer and does not discriminate on the basis of race, color, gender, religion, age, sexual orientation, national or ethnic origin, disability, marital status, veteran status, or any other occupationally irrelevant criteria. Diverse perspectives and experience enhance the way Carbon Direct selects and approaches the climate crisis, as well as the creativity and applicability of Carbon Direct's advisory and investment work.

Show more Show less"
2819117162,Data Engineer II,Belcan,2021-12-02,United States,"Seattle, WA",Information Technology,Full-time,"IT Services and IT Consulting, Construction, and Staffing and Recruiting","Details

A Data Engineer II job in Seattle, WA is currently available through Belcan. To be considered for this role candidate develop methods and metrics that provide insights to business leaders and HR leaders

Description

Do you love working with different data types from free text to telemetry, uncovering unknown insights about customers, and developing actionable insights? The AWS Sales, Marketing, and Support (SMS) HR Team is looking for an experienced Business Intelligence Engineer to set up and scale analytics sources and methods. In this role, you will have the freedom to innovate and create lasting impact on the customer experience. Our team accelerates and de-risks the trajectory of the AWS SMS organization. In this role, you will build a service that inspects, measures, and drives improvements for Client""s most critical asset - our people - and presents recommendations to senior leaders in order to influence and drive changes that ultimately better serve our customers.

AWS Sales, Marketing, and Support (SMS) Team is looking for a self-driven BIE with broad technical and data management skills who will identify and onboard new data sources, conduct analytics using SQL and Python, and build lightweight tools and methods for others to replicate and scale their work. You should have expertise in the design, creation, management, and business use of large datasets. Your solutions are testable, maintainable, and mindful of resource usage. You should be able to apply statistical methods (e.g. regression) to difficult business problems and understand these methods"" assumptions and limitations. You will need excellent business and communication skills to work with business leaders and HR leaders on ambiguous problems in a fast-paced environment.

What you""ll do:

Develop methods and metrics that provide insights to business leaders and HR leaders
Recognize and adopt best practices in reporting/analysis: data integrity, test design, analysis, validation, and documentation
Write quality code to retrieve and analyze data
Develop pragmatic analyses and choose applicable solutions that add value to the business
Understand data resources and know how, when, and which to use (and which not to use)
Use advanced analytical techniques to solve business problems
Continue to move forward in the face of ambiguity and imperfect data. Find a solution around the problem that still maintains a high analytical bar. You do not suffer from 'analysis paralysis'.
Ensure that decisions are based on the merit of their unbiased analytical results, not the proposer. Stay 'true to the data'.
Communicate analysis results and techniques, both verbally and in writing, clearly and confidently to peers and business partners.

Basic Qualifications

Bachelor""s degree in Engineering, Math, Finance, Statistics or a related discipline
3+ years hands-on analytics work experience, with proven quantitative orientation.
2+ years"" experience with SQL, ETL, Data Warehouse solutions and databases
Experience with statistical analytics and programming languages such as Python, R, etc.

Preferred Qualifications

Master""s degree or higher in Statistics, Data Science, or an equivalent quantitative field
5+ years of industry experience working as a BIE or related specialty
Background designing successful analytics solutions from start to finish
Experience communicating results and business impact of analytical deep dives to senior leadership
Knowledge of or background with public cloud services

Belcan is a leading provider of qualified personnel to many of the world's most respected enterprises. We offer excellent opportunities for contract/temporary, temp-to-hire, and direct assignments in the engineering, IT, and professional fields. We are the employer of choice for thousands worldwide. Our overriding goal is to provide quality staffing solutions that help people, organizations, and communities succeed. Belcan is a team-driven Equal Opportunity Employer committed to workforce diversity. For more information, please visit our website at http://www.belcan.com.
Show more Show less"
2820124704,Data Engineer/Python,Motion Recruitment,2021-12-04,United States,"San Diego, CA",Information Technology,Full-time,Staffing and Recruiting,"A full-service marketing company in San Dieo is looking for a Senior Data Engineer. They work with top clients like Citibank, Yellow Pages and NordicTrack. The ideal candidate will have experience with Python, Spark, Hadoop, and AWS.

If you are local to the area and want to work with an innovative company that rewards hard work, apply now!

Required Skills And Experience

3+ years of experience as a Data Engineer
Experience with Python programming language
Experience with Spark and Hadoop
Experience with AWS
Desired Skills & Experience

BS/master’s in computer science or equivalent
Excellent communications skills both written and verbal
Experience with SQL
The Offer

Competitive Salary

You Will Receive The Following Benefits

Medical Insurance & Health Savings Account (HSA)
401(k)
Paid Sick Time Leave
Pre-tax Commuter Benefit

Posted By: Julie Bennett
Show more Show less"
2818686508,Data Engineer,"Miracle Software Systems, Inc",2021-12-02,United States,"Atlanta, GA",,Full-time,,"Hello!!

We, Miracle Software Systems, Inc. is looking for Data Engineer for W2 contract engagement at our GA location.




Position: Data Engineer

Location: Atlanta, GA




Primary Skills:  GCP, SQL, Cloud




Must have skills:

Good understanding of GCP platform and data services like BigQuery, Dataflow, Cloud Pubsub, Cloud functions, Cloud SQL, and including engines like GAE, GCE, and GKE  
SQL skills include advanced skills like performance-tuning, clustering, Indexing, modeling, database optimizing, etc.
Ability to handle huge datasets and perform quick data analysis to extract insights from raw data for sharing with clients with storytelling  
Should be able to code (Python preferred) to write new applications (cloud functions, dataflow, etc.) and also a lot of existing running workloads needs frequent updates, patches  
Good client interaction and communication skills
Must know CICD concepts as almost all pipelines are automated via the CICD approach by using Concourse technology under the hood  
Must know PowerShell scripting  
Domain-specific knowledge infrastructure, VMWare space (VMs, Datastore, and Hosting servers) 
Ability to work under high pressure and customer demanding environment with tight deadlines
Show more Show less"
2777776720,Data Engineer,CoStar Group,2021-11-19,United States,"Atlanta, GA",Information Technology,Full-time,"IT Services and IT Consulting, Leasing Non-residential Real Estate, and Research Services","Job Description

Data Engineer – CoStar Group (Atlanta)

Overview

The Analytics team is responsible for the development of CoStar's customer-facing Real Estate Analytics products. We think big, creating innovative data-intensive applications that take the vast amount of data collected by our CoStar Research teams to create a fast, reliable and intuitive analytics platform for our customers. We are a collaborative group with a mix of big data, API/platform and front-end skills, and we are growing rapidly to help invent the future of Real Estate Analytics.

We are searching for an experienced Data Engineer to join our Atlanta team. We have the industry's largest set of Commercial Real Estate property data, which lets us create innovative products while solving challenging data engineering problems such as high-volume data ingestion, data cleansing, real-time modeling/publication, and high-performance, high-availability consumption of all this information. This role will collaborate closely with technical leadership, product owner and other developers, while also giving you independence and ownership of your work. As a senior member of the group, you will have the opportunity to help drive the technical strategy and architecture of our platform.

Responsibilities

Designing, building, testing and deploying scalable, reusable and maintainable applications that handle large amounts of data.
Taking full ownership of your work, from development and testing, to eventual deployment and support in production.
Collaborating with other engineers, product owners, designers, and leadership.
Becoming a trusted team member in matters of technical architecture, design and code.
Advocating for evolution and improvement - both technical and non-technical - within our teams. Includes new tech, tools and best practices.
Gaining a deep understanding of the CoStar business, including the Analytic products.

Basic Qualifications

Bachelor’s degree, preferably in Computer Science/Engineering
5+ years of professional software development experience
Cloud computing experience with AWS
Experience solving Big Data batch and real-time data processing problems
Experience with large-scale analytics and data processing engines such as Apache Spark
Experience with streaming technologies such as Kafka and RabbitMQ
Experience with relational and column store databases, such as SQL Server, Redshift, Cassandra
Knowledge of Python data science tools, such as SciKit, NumPy, TensorFlow
Strong math and analytical skills

Overview Of Company

Founded in 1987, CoStar Group is the leading provider of commercial real estate information, analytics, and online marketplaces. Our suite of online services enables clients to analyze, interpret and gain unmatched insight on commercial property values, market conditions and current availability. Behind some of the most well-known brands in the industry, CoStar Group includes CoStar, the largest provider of CRE research and real-time data; LoopNet, the most heavily trafficked mobile and online real estate marketplace; Apartments.com, the premier rental home resource for renters, property managers and owners; STR, the leading provider of performance benchmarking and comparative analytics to the hotel industry; BizBuySell, the largest online marketplace for businesses-for-sales; and Lands of America, the leading operator of online marketplaces for rural real estate.

Headquartered in Washington, DC, CoStar Group maintains offices throughout the U.S. and in Europe, Canada, and Asia with a staff of over 4,300 worldwide.

What’s In It For You

Working at CoStar Group means you'll enjoy a culture of collaboration and innovation that attracts the best and brightest across a broad range of disciplines. In addition to generous compensation and performance-based incentives, you'll be supported in both your professional and academic growth with internal training, tuition reimbursement, and an inter-office exchange program.

Our Benefits Package Includes (but Is Not Limited To)

Comprehensive healthcare coverage: Medical / Vision / Dental / Prescription Drug
Life, legal, and supplementary insurance
Commuter and parking benefits
401(K) retirement plan with matching contributions
Employee stock purchase plan
Paid time off
Tuition reimbursement
Complimentary gourmet coffee, tea, hot chocolate, prepared foods, fresh fruit, and other healthy snacks

CoStar Group is an Equal Employment Opportunity Employer; we maintain a drug-free workplace and perform pre-employment substance abuse testing


Show more Show less"
2786200429,Big Data Engineer,Gallin Associates,2021-11-04,United States,"Atlanta, GA",Engineering and Information Technology,Full-time,"Construction, Staffing and Recruiting, and Hospitals and Health Care","Job Description

The successful candidate must have Big Data engineering experience and must demonstrate an affinity for working with others to create successful solutions. Join a smart, highly skilled team with a passion for technology, where you will work on our state of the art Big Data Platforms (Cloudera). They must be a very good communicator, both written and verbal, and have some experience working with business areas to translate their business data needs and data questions into project requirements. The candidate will participate in all phases of the Data Engineering life cycle and will independently and collaboratively write project requirements, architect solutions and perform data ingestion development and support duties.

Required

Skills and Experience:
8+ years of overall IT experience
3+ years of experience with high-velocity high-volume stream processing: Apache Kafka and Spark Streaming
Experience with real-time data processing and streaming techniques using Spark structured streaming and Kafka
Deep knowledge of troubleshooting and tuning Spark applications
3+ years of experience with data ingestion from Message Queues (Tibco, IBM, etc.) and different file formats across different platforms like JSON, XML, CSV
3+ years of experience with Big Data tools/technologies like Hadoop, Spark, Spark SQL, Kafka, Sqoop, Hive, S3, HDFS, or Cloud platforms e.g. AWS, GCP, etc.
3+ years of experience building, testing, and optimizing ‘Big Data’ data ingestion pipelines, architectures and data sets
2+ years of experience with Kudu and Impala
2+ years of experience with Scala (and/or Python) and PySpark/Scala-Spark
2+ years of experience with NoSQL databases, including HBASE and/or Cassandra
Knowledge of Unix/Linux platform and shell scripting is a must
Strong analytical and problem solving skills

Preferred (Not Required)

Experience with Cloudera/Hortonworks HDP and HDF platforms
Experience with NIFI, Schema Registry, NIFI Registry
Strong SQL skills with ability to write intermediate complexity queries
Strong understanding of Relational & Dimensional modeling
Experience with GIT code versioning software
Experience with REST API and Web Services
Good business analyst and requirements gathering/writing skills

Education

Bachelor’s Degree required. Preferably in Information Systems, Computer Science, Computer Information Systems or related field
Show more Show less"
2794667292,Data Engineer - GCP,BigRio,2021-11-16,United States,"Boston, MA",,Contract,,"Role: Data Architect & Data Engineer-GCP

Location: 100% Remote/ WFH

Duration: 6 Month Engagement/ C2H

 

About us: BigR.io is a remote-based, technology consulting firm with headquarters in Boston, MA. We deliver software solutions ranging from: custom development, software implementation, data analytics, and machine learning/AI integrations. We are a one-stop shop that attracts clients from a variety of industries because of our proven ability to deliver cutting-edge and cost-conscious software solutions. With extensive domain knowledge, BigR.io has teams of data architects, data engineers, software engineers, web developers, and consultants who deliver best-in-class solutions across a variety of verticals. Our diverse industry exposure equips us with invaluable tools, tricks, and techniques to tackle complex software and data challenges.

 

About the Job:

The Data Team designs, builds, and maintains the integrated platform that securely procures and links critical business data from disparate internal and external sources. This involves assimilating all structured, unstructured, and semi-structured data. The Data Engineer will touch all aspects of the data operation, in particular, data infrastructure, to ensure a robust, efficient, and consistent foundation for enterprise consumption & application development.

 

Responsibilities:

Design with MicroServices in AWS and GCP

Architect the migration from AWS to GCP - ELT/ETL skills

Skilled in implementing GCP BigQuery

Build robust, scalable, and fault-tolerant ETL pipelines that allow flexibility and efficiency with minimum overhead and maintenance

Responsible for data integrity and consistency and quality of new releases

Provide mentorship and technical leadership to junior data engineers of the team

Work with other architects and engineers to define, execute, and update core data systems while maintaining a high level of availability and transactional correctness..

Help define future technical directions for data systems in collaboration with senior management, product management, and stakeholders.

 

Minimum Job Qualifications:

10+ years of full-time professional experience in architecting, building and optimizing ETL pipelines and data warehouse to onboard and streamline data cleansing, transformation, standardization and aggregation processes with thoughtful design mindset centered around flexibility, robustness, computing efficiency and maintenance

Excellent and proven abilities in:

Analytic skills

GCP architectural skills

Data governance

Security

Data Modeling

Proven track record of owning data integrity and QA, with an exceptional attention to detail

Expert at data modeling and system design

Expert in designing GCP environments.

Comfort in working in a fast-paced environment with moving targets and changing priorities

Proven ability to speak both business and technology, and effectively liaison with both teams

Demonstrated expertise in Information Architecture, Data Engineering, and data warehousing

Strong experience designing distributed systems for scale and high availability.

Extensive experience in designing microservice based applications and data pipelines, concepts of ETLs.

Deep experience with AWS and GCP

 

Preferred Job Qualifications:

Direct experiences with GCP BigQuery

Hands-on experiences with web analytics, 3rd party augmentation data, and A/B testing is a plus

Experience in hosting, provisioning and maintaining database servers in cloud environment, preferably GCP, is a plus

Show more Show less"
2803178084,Data Engineer,Landing,2021-11-17,United States,"Birmingham, AL",Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","About the Role:

We are looking for an awesome Data Engineer to help us measure and improve data quality and consistency across Landing. You will be working on our Pricing and Availability team, partnering with multiple departments to engineer tools that leverage up to date information on pricing and availability.

This is a great opportunity to grow your career. In addition to further improving your technical skills, you'll have the opportunity to learn various facets of data engineering.

About the Team:

You will be joining a team of talented engineers with a passion for data quality and integrity. We have an endless list of exciting projects to complete, tests to implement, and systems to build to help Landing scale to be a world class platform for living.

What You'll Do:

Focus on all things data quality.
Work in a small, cross-functional, dynamic engineering team to unlock the potential of Landing's technologies and the teams who leverage it
Be the subject matter expert in API development and Web Scrapes; understand our existing platform landscape and how to optimize it
Build integrations with 3rd party APIs to provide additional user acquisition funnels
Build reporting systems to track and measure the results of web scrapes
Play an integral part and directly contribute to Landing's growth as a company
Implementing a quality control framework for ensuring data consistency


What You Need:

2+ years experience in API Development or equivalent education
2+ years of experience in creating, tuning and maintaining web scrapes or equivalent education
2+ years using Python or another object oriented language or equivalent education
Proficient in integrating with 3rd party APIs
Experience with version control, open source practices, and code review.
Adept at learning new technologies
Ability to improvise and develop creative solutions when common approaches fail. Understand the trade-offs in employing different engineering solutions to a problem, valuing pragmatism over idealism
Ability to distill complex problems into manageable pieces
A strong desire to document and share work done to aid in long term support
Documents, analyzes and proposes process changes or re-engineering approaches based on an understanding of technical problems and solutions as they relate to current and future state business and technical environments


Nice to Have:

Proficiency in SQL
AWS Certified
Previous experience in a startup environment
Data Governance experience
Ability to work in a fast paced environment with little supervision
Be able to speak and translate between technical and non-technical terminology and ideas without compromising contextual details.


About Us:

Landing is revolutionizing apartment living by providing our members the most streamlined end-to-end platform with access to tens of thousands of furnished and unfurnished apartments in over 200 cities, and counting, that renters can book in just minutes. Our flexible leases allow members to realize more freedom and opportunities in life. Switching between apartments is simple, and does not require a security deposit, broker fee, or additional months' rent. You can manage every part of the Landing experience in a single, centralized app, which includes paying rent or scheduling regular cleanings with the touch of a finger.

Our headquarters, located in Birmingham, Alabama, is supported by our San Francisco, California office as well as Landing employees who live and work all over the country. In addition, Landing manages distribution centers across the U.S. that work to deliver and manage furnishings within our tailored homes. Our host network, comprising roughly 2,000 professionals, complement these areas by working directly with members to ensure their happiness and maintain comfort.

Join our rapidly expanding team to work on product, design, supply chain, operations, marketing, engineering, interior design, sales, legal, people, and finance to create more freedom and opportunities for renters across the U.S.

Our Leadership Principles:

At Landing, we use our Leadership Principles every day - whether we're discussing new projects, deciding the best solutions for our members, or brainstorming a new product feature. We believe these shared values foster the best results.

Landing is a dynamic, fast moving, customer first organization whose core values are authenticity, ownership, a service-first mindset, and entrepreneurship. To be successful in creating the best experience for both our members and team members, we're building a culture that thinks big, is hands-on, and solves problems at hyper warp speed. We are doers that do more with less and we're constantly looking to raise the bar. Come enjoy the journey with us as we shake up the way people think about renting!

Benefits & Perks:

Landing aims to create a workplace that fosters both personal and professional growth. Our benefits include, but are not limited to:

Solid compensation package + stock options
Comprehensive benefits - medical, dental, and vision + pre-tax commuter & FSA
We've got you covered with our 401(k) plan
Feel relaxed with super generous paid-time-off
Grow with us - opportunities for upward mobility
Explore & travel comfortably - 7 free nights in a Landing home per year
Live with Landing - employee perks for temporary or indefinite stays


Landing provides equal opportunities for everyone that works for us and everyone that applies to join our team, without regard to sex or gender, gender identity, gender expression, age, race, religious creed, color, national origin, ancestry, pregnancy, physical or mental disability, medical condition, genetic information, marital status, sexual orientation, any service, past, present, or future, in the uniformed services of the United States (military or veteran status), or any other consideration protected by federal, state, or local law. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Show more Show less"
2787235749,"Data Engineer-Business Intelligence-Las Vegas, NV",UnitedHealthcare,2021-11-10,United States,"Las Vegas, NV",Information Technology,Full-time,"Insurance, Financial Services, and Hospitals and Health Care","UnitedHealthcare is a company that's on the rise. We're expanding in multiple directions, across borders and, most of all, in the way we think. Here, innovation isn't about another gadget, it's about transforming the health care industry. Ready to make a difference? Make yourself at home with us and start doing your life's best work.(sm)

Primary Responsibilities

Assess, analyze, and design data flows
Deploy code using standard and non-standard methodology
Adhere to data management processes and capabilities
Ensure proper data mapping from source to target within transactional systems
Work with database teams to evaluate and establish physical database requirements
Ensure data/analytical accuracy through testing and verification processes
Write queries and SQL database code for data analysis and discovery to generate reports/visualizations
Design grids, dashboards, and automated reports using business intelligence software
Collaborate with business partners to ensure report and data standardization
Interact and coordinate between end-users, expert team, development, and QA team and suggesting key enhancements and changes to the business rules
Serve as a Subject Matter Expert on business data and consult with business owners on the characteristics, attributes, and limitation of the data
Lead the projects for complete SDLC with in depth new and existing Business Intelligence capabilities
Maintain database for timely refreshes to ensure information is not outdated
Develop processes for data manipulation to meet end user’s requirements (technically skilled/backed by continuous hands-on experience)
Develop Data Warehouse working with Data Migration, Data Conversion, and Extraction/Transformation/Loading using relational database software (Oracle, SQL Server, etc.)

You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Required Qualifications

3+ years of experience with relational database system development and SQL language (MS Access, Microsoft SQL Server, Oracle)
3+ years of experience performing data analysis and reporting
3+ years of experience in Microsoft Office software (Excel, Access, Word, Outlook)
Full COVID-19 vaccination is an essential requirement of this role. UnitedHealth Group will adhere to all federal, state, and local regulations as well as all client requirements and will obtain necessary proof of vaccination prior to employment to ensure compliance

Preferred Qualifications

1+ years of experience in Business Intelligence software (Tableau, Power BI, Microstrategy, etc.)
Experience with loading large, analytical, and operational data structures including data requirements, data mapping, requirements and specification, data delivery and performance tuning
Experience working with a structured application development process in the health care industry
Experience in a data integrations development and operations department
Experience in report design, structure, and visual appearance
Experience with healthcare data, applications, business processes and best practices

To protect the health and safety of our workforce, patients, and communities we serve, UnitedHealth Group and its affiliate companies now require all employees to disclose COVID-19 vaccination status prior to beginning employment. In addition, some roles require full COVID-19 vaccination as an essential job function. UnitedHealth Group adheres to all federal, state, and local COVID-19 vaccination regulations as well as all client COVID-19 vaccination requirements and will obtain the necessary information from candidates prior to employment to ensure compliance. Candidates must be able to perform all essential job functions with or without reasonable accommodation. Failure to meet the vaccination requirement may result in rescission of an employment offer or termination of employment.

Careers at UnitedHealthcare Employer & Individual. We all want to make a difference with the work we do. Sometimes we're presented with an opportunity to make a difference on a scale we couldn't imagine. Here, you get that opportunity every day. As a member of one of our elite teams, you'll provide the ideas and solutions that help nearly 25 million customers live healthier lives. You'll help write the next chapter in the history of health care. And you'll find a wealth of open doors and career paths that will take you as far as you want to go. Go further. This is your life's best work.(sm)

Nevada Residents Only: The salary range for Nevada residents is $71,400 to $127,400. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you’ll find a far-reaching choice of benefits and incentives.

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.

Job Keywords: Data Engineer, Business Intelligence, Las Vegas, NV, Nevada
Show more Show less"
2637413790,Data Engineer,Meredith Corporation,2021-12-04,United States,"Stamford, CT",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Job Title
Data Engineer

Job Description

Data Engineer

Company

For over 20 years we have connected people with their passions, products with engaged customers, and our multi-channel clients—including some of the world’s largest consumer brands—with innovative marketing programs.

We believe great technology empowers organizations. At Synapse Group, we're using technology to reinvent subscription and consumer relationships, and building creative products that impact millions of people.

Stamford, CT candidates preferred, but we are open to remote accommodations for the right person.

Remote available in these states based on candidate’s location: AZ, CA, CO, CT, FL, ID, IL, MD, NC, NJ, NY, OR, PA, TN, TX

Offices in Los Angeles, CA and Stamford, CT. Synapse Group, Inc. is a Meredith company.
Opportunity for Impact

If you are obsessed and excited about providing quality data to the business and other teams, then this is the role for you. You want to “Free the Data”!
You'll work with an exceptional group of data engineers and data scientists on a wide array of technologies to help all teams be successful.
This is a mature organization operating at large scale that is also in the midst of a transformation. You'll be able to have an impact throughout the organization by advocating for and implementing meaningful change.
Role and Responsibilities (What You'll Do)

Build some amazing things, learn, have fun!
Leverage your technical expertise to constantly raise the bar and ensure the team delivers extraordinary results – focusing on creating value, continuous improvement and collaboration
Strive to thoroughly understand customer, business and stakeholder needs, and provide effective solutions to meet those needs
Dive deep into data technology via end to end hands-on contributions to data projects, including ETL, reporting, analysis and development
Develop and maintain data warehouse and application data models
Perform technical analysis and hands-on support of ad hoc requests for information from business stakeholders and other data related help as needed
Build real and effective partnerships between your teams and others throughout the company
Write automated unit, integration, regression, performance and acceptance tests and monitor performance in production, tuning as needed
Professional Qualifications (What You Have)

You have 4+ years of data system design and development experience in data-related positions including enterprise data warehouses, data lakes, data modeling, ETL, query optimization, and data engineering design patterns inclusive of structured and unstructured data
You have seen many projects through from end to end and had a major role in its creation, development and maintenance
You communicate clearly and effectively with technical and non-technical audiences
You care deeply about customer privacy, data, design and quality
You have strong analytical skills and are results-driven
Good understanding of Data Engineering domain future roadmap
You know many of these technologies and are eager to learn the rest quickly – SQL mastery, Python, Oracle (PL/SQL), Apache Spark, related AWS data technologies (such as Redshift, Lambda, Step Functions, EMR, Athena, Glue, Airflow, Data Pipeline, etc.), ETL technologies (such as Pentaho), BI technologies (such as MicroStrategy, Business Objects, Tableau, Qlik), Java (bonus), Scala (bonus)
B.S. in Computer Science (or equivalent degree or work experience)
Personal Characteristics (Who You Are)

Highly effective at creating collaborative relationships across an entire organization
High energy, accountable, data driven, and action-oriented with a history of getting things done in complex environments
Results oriented, tenacious, but with the ability to know when to push harder and when to look for alternative approaches – knowing when it matters and when it doesn’t
Both accepting of other people’s ideas and confident in your own
Values integrity, humility, creativity, open-mindedness, collaboration, creating value and continuous improvement

It is the policy of Meredith to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, Meredith will provide reasonable accommodations for qualified individuals with disabilities. Accommodation requests can be made by emailing Meredith.Human.Resources@meredith.com.

Meredith participates in the federal E-Verify program to confirm the identity and employment authorization of all newly hired employees. For further information about the E-Verify program, please click here: http://www.uscis.gov/e-verify/employees
#NMG#
Show more Show less"
2816065682,Data Engineer,Technogrips Technologies,2021-12-02,United States,United States,,Full-time,,"

We have a job opportunity for the role of Data Architect with one of our client based in USA as a remote role.

Skills:----
Must have, Data Architect to design OLTP solutions.
Strong understanding of SQL and data access patterns for transactional systems.
Worked with Product Managers to analyze requirements for new solutions and features.
Strong Design conceptual and logical data models (hands-on experience using tools like ERwin, PowerDesigner, ER-Studio) for relational database implementation (MySQL, Oracle).
Collaborate with Java Engineers to design microservices to meet solution requirements.
Expert knowledge of SQL and procedural extensions in Oracle and/or MySQL environments.
Basic Java knowledge is desirable.
Experience with Coach Product and Engineering teams in the creation and maintenance of corporate metadata (Data Catalog) for custom solutions created.
Corporate Data Management experience is desirable.

Show more Show less"
2803556086,Data Engineer,EXL,2021-11-18,United States,"Hartford, CT",Information Technology,Full-time,IT Services and IT Consulting,"Hartford, CT, USA

Virtual Req #1811

Thursday, October 28, 2021

Overview

EXL (NASDAQ: EXLS) is a leading operations management and analytics company that designs and enables agile, customer-centric operating models to help clients improve their revenue growth and profitability. Our delivery model provides market-leading business outcomes using EXL’s proprietary Business EXLerator Framework™, cutting-edge analytics, digital transformation and domain expertise. At EXL, we look deeper to help companies improve global operations, enhance data-driven insights, increase customer satisfaction, and manage risk and compliance. EXL serves the insurance, healthcare, banking and financial services, utilities, travel, transportation and logistics industries. Headquartered in New York, New York, EXL has more than 32,000 professionals in locations throughout the United States, Europe, Asia (primarily India and Philippines), South America, Australia and South Africa. For more information, visit www.exlservice.com.

EXL is hiring for a Data Engineer!! Remote work is possible!

Roles And Responsibilities

Assembling large, complex sets of data that meet non-functional and functional business requirements
Identifying, designing and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies
Building analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition
Working with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues
Working with stakeholders including the Executive, Product, Data and Design teams to support their data infrastructure needs while assisting with data-related technical issues
Ability to build and optimize data sets, ‘big data’ data pipelines and architectures
Ability to perform root cause analysis on external and internal processes and data to identify opportunities for improvement and answer questions
Excellent analytic skills associated with working on unstructured datasets
Ability to build processes that support data transformation, workload management, data structures, dependency and metadata

Other Skills

An understanding of US Healthcare system preferable.
Good communication skills and efficient collaborator.
Should be flexible in terms of timings

Qualifications

5+ Year of experience in data migration, SAS & SQL knowledge

EEO/Minorities/Females/Vets/Disabilities

Please be aware that EXL requires all employees to be vaccinated for COVID-19. This position will require the successful candidate to obtain and show proof of a vaccination. EXL is an equal opportunity employer, and will provide reasonable accommodation to those individuals who are unable to be vaccinated consistent with federal, state, and local law.

Other details

Pay Type Salary

Apply Now
Show more Show less"
2780583031,Data Engineer,Pylon Solutions Group,2021-11-10,United States,"Greenwood Village, CO",,Full-time,,"Pylon Solutions Group

 

A Data Engineer is responsible for onboarding operational data into an enterprise level systems that use machine learning to correlate monitoring and service delivery data to provide rapid detection and response to service layer anomalies, causation identification and proactive anomaly prevention through digital fingerprinting.




MAJOR DUTIES AND RESPONSIBILITIES:

Actively and consistently leads and supports all efforts related to data acquisition, data processing and data governance for the operational intelligence system:

Responsible for liaising with the data source teams to design the data flow from the data source system to the operational intelligence system.
Establish resiliency and monitoring of each data acquisition flow.
Collaborate across multiple teams to establish data correlation rules.
Establish data management and data governance rules per data source to ensure data ingest and processing integrity.
Data cataloging and metadata management.
Work with peers and operational intelligence customers to establish advanced machine learning models.
Automation of data acquisition and management processes.
Administer applicable data security rules.
Identify gaps and develop action plans to remediate data ingest and data processing issues.
Develop, implement and tune processes to streamline data gathering and analysis.
Effectively communicate project expectations, timelines, milestones and deliverables in a timely and clear fashion.
Understands and participates in the creation of business cases for data ingestion.




REQUIRED QUALIFICATIONS:

Skills/Abilities and Knowledge:

Extremely fluent in reading, writing, speaking and understanding English.
Strong ability to document and present complex data in an easy-to-understand manner to support critical system design.
Advanced critical thinking skills.
Attention to detail.
Experience with RDBMS, Key-Value and NoSQL data storage systems.
Knowledge of query tools and/or statistical software.
Demonstrated ETL skills.
Understanding of machine learning and artificial intelligence principles for data processing systems.
Experience with or understanding of RHEL, TCP/IP networking, VMware, Oracle, MySQL, AWS, Kafka, Splunk, OP5, Application Dynamics, Prometheus, Grafana, GitHub, Ansible.
Experience with Vitria a plus.
Knowledge of enterprise level monitoring systems (i.e.; network monitoring, server monitoring, application monitoring, storage monitoring, etc.).
Ability to demonstrate company values, maintain a positive demeanor, encourage different points of view and work thru complex issues.




Education:

Bachelor's degree or equivalent experience required.

 

Related Work Experience:

1-5+ years of experience in telecom enterprise systems.
1-3 years of experience with data analytics / data science.




Show more Show less"
2804268839,Big Data Engineer,LGZ New Media,2021-10-24,United States,"Beaverton, OR",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Responsibilities

Develop and extend a recently started data platform to support big data pipelines in the consumer data space
Drive/remain responsible for development of end-to-end for specific components
Contribute to project discussions, collaborate directly with architect team and present results to key stakeholders
Design, build and continuously enhance the project codebase
Act as an onsite-timezone force multiplier for a distributed team of engineers and managers
Write detailed design documentation, present decisions and motivate these
Work inside a team of industry experts on the cutting edge Big Data technologies to develop solutions for deployment at massive scale
Design data infrastructure with privacy and security being cross-cutting concerns
Set coding and deployment best practices

Requirements

+6 years experience designing and coding platform solutions for Big Data pipelines
+3 years of experience working with event-messaging systems - Kafka is a big plus
+2 years coded and deploying services running on Kubernetes
Python and Spark knowledge is required
Experience working with AWS
Experience with enterprise data warehouse
Strong understanding of the challenges in building end-to-end big data pipelines for a large variety of use-cases at scale
Strong communication skills
Show more Show less"
2808117664,Data Engineer,Deckers Brands,2021-11-25,United States,"Irvine, CA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2801547913,Data Engineer,Fisher Investments,2021-11-16,United States,"Plano, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Overview

The Opportunity:

As a Workforce Analyst at Fisher Investments, you will help improve our workforce through employee related insights to help build and further a diverse, engaged workforce. Reporting to the Workforce Analytics Manager, you will partner with leaders in Human Capital and across the business to improve people performance and planning through the discovery, interpretation and communication of meaningful patterns in workforce-related data. Through these insights and optimization, you will help the firm achieve its long-term strategic goals.

The Day-to-Day:

Construct data queries from multiple data sources to aggregate, model and prepare information for analysis
Be an expert on data flows from Human Capital data systems to data consumers and identify improvements in the data pipeline
Recommend business process or system enhancements to improve data quality and reporting capabilities
Help implement reporting from Human Capital data systems (Workday, iCIMS, etc.)
Create new service opportunities to further our goal of supporting the firm's talent development and management
Perform analysis on employee related datasets to find actionable insights that support essential decision makers
Adhere and maintain the Human Capital data governance model through proper documentation of data processes and definitions


Your Qualifications:

2+ years of experience in a quantitative or consulting based role using analytics and visualizations to solve business problems
Experience working with data visualization tools (Tableau, Looker, PowerBI, etc.)
Experience with SQL for querying and modeling data
Experience creating reporting in common Human Capital Management Systems (Workday, iCIMS, etc.)
U.S. candidates must be fully vaccinated as defined by the medical community against COVID-19 and provide proof of such vaccination by date of hire


Why Fisher Investments:

At Fisher Investments, we work for a bigger purpose: bettering the investment universe. From unmatched service to unique perspectives on investing, it's the people that make the Fisher purpose possible. And we invest in them by offering exceptional benefits like:

100% paid medical, dental and vision premiums for you and your qualifying dependents
A 50% 401(k) match, up to the IRS maximum
20 days of PTO*, plus 9 paid holidays
8 weeks paid Primary Caregiver Parental Leave
Back-up Child Care Program available, offering up to 10 days annually
A cumulative learning and development framework customized for every employee
An award-winning work environment - we're Great Place to Work Certified, and Top Workplace winners from The Oregonian


We take great pride in our inclusive culture. We value the different perspectives and unique skills you bring to the team – it makes us all better. Success at Fisher Investments is motivated by results, a collaborative mindset and a commitment to accomplishing great things – so if you are ready to do that, we are ready for you! Apply today to be a part of a team environment where you make a difference in the lives of people by bettering the investment universe.

California employees accrue up to 17 days of PTO and 3 days of sick time per year.


FISHER INVESTMENTS IS AN EQUAL OPPORTUNITY EMPLOYER
Show more Show less"
2827126323,Data Engineer,Meta,2021-12-04,United States,"Menlo Park, CA",Information Technology,Full-time,Internet Publishing,"Meta Platforms, Inc. (Meta), formerly known as Facebook Inc., builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps and services like Messenger, Instagram, WhatsApp, and Novi further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. To apply, click “Apply to Job” online on this web page.


Design, build, and launch data pipelines to move data across systems and build the next generation of data tools that generate business insights for a product
Analyze user needs and software requirements to determine workability and to offer support for end users on data usage
Design, architect, and develop software and data solutions that help product and business teams make data-driven decisions
Rethink and influence strategy and roadmap for building efficient data solutions and scalable data warehouse plans
Design, develop, test, and launch new data models and processes into production, and provide support
Leverage homegrown extract, transform, and load (ETL) framework as well as off-the-shelf ETL tools, as appropriate
Interface closely with data infrastructure, product, and engineering teams to build and extend cross platform ETL and reports generation framework
Identify data infrastructure issues and drive to resolution
Master’s degree in Computer Science, Engineering, Mathematics, Physics, or related field and 24 months of experience in the job offered or in a data analytics or computer-related occupation. Experience must include 6 months involving the following:
Data ETL (Extract, Transform, Load) design, implementation, and maintenance on a large scale
Programming in Python, Perl, Java, or PHP
Internet technologies: HTTP, HTML, CSS, or JavaScript
Writing SQL statements
Analyzing large volumes of data to provide data driven insights, gaps, and inconsistencies
Data warehousing architecture and plans
Informatica, Talend, Pentaho, dimensional data modeling, or schema design
Map Reduce or MPP system
Hadoop, HBase, or Hive


Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.

Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
Show more Show less"
2807492118,Data Engineer - Product,Stitch Fix,2021-11-25,United States,United States,"Research, Analyst, and Information Technology",Full-time,"Apparel and Fashion, Internet Publishing, and Retail","About The Team

The data engineering team is a small, nimble group of data engineers that drive the company toward clean and informative data. As a member of the data engineering team, you’ll help power data science, ETLs, self-service data, and tools to make us efficient and facilitate scalable decision-making. As a team, we are driven by the thrill of building tools to help our colleagues use data with less friction, which ultimately increases the velocity at which the business can progress!

About The Role

Senior IC position on the data engineering team, within our Algorithms organization, focusing on our client and marketing data infrastructure, optimization and scalability
You will build and own large additions to our data engineering framework, charged with finding ways to create and improve scalable and reliable tables and central data pipelines
Work in a collaborative, production-facing codebase that has close coupling with engineering systems
You will build and own scalable, efficient, and well-tested data engineering solutions using Spark, Amazon S3, and a mature collection of in-house technologies.
You will be involved in the day-to-day operations of the team, including maintaining and improving our current tools & scripts and supporting full-stack data scientists
You will have autonomy to help shape the future of data engineering at Stitch Fix by bringing your ideas on improving and automating what we do and how we do it

You’re Excited About This Opportunity Because You Will...

Work with teams of world-class data scientists and engineers on how to solve data and business problems in a scalable way
Be part of a team which has high visibility across the organization
Contribute ideas and direct the team’s investment to impactful directions
Contribute to a culture of technical collaboration and scalable development

We Get Excited About Candidates Who Have…

5+ years of fully independent project experience with significant contributions.
Experience in building out scalable data engineering capabilities
Exceptional coding and design skills in Python and SQL
Experience in Spark optimization and an understanding of data storage with Amazon S3
Experience in working autonomously and taking ownership of projects.
Ability to think globally, devising and building solutions to meet many needs rather than completing individual projects or tasks
Strong prioritization skills with business impact in mind
Strong cross functional communication skills that help simplify and move complex problems forward

YOU’LL LOVE WORKING AT STITCH FIX BECAUSE…

We are a group of bright, kind and goal oriented people. You can be your authentic self here, and are empowered to encourage others to do the same!
We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation
We are a technologically and data-driven business
We are committed to our clients and connected through our vision of “Transforming the way people find what they love”
We love solving problems, thinking creatively and trying new things
We believe in autonomy & taking initiative
We are challenged, developed and have meaningful impact
We take what we do seriously. We don’t take ourselves seriously
We have a smart, experienced leadership team that wants to do it right & is open to new ideas
We offer competitive compensation packages and comprehensive health benefits
You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day

About Stitch Fix

At Stitch Fix, we’re about personal styling for everybody and we believe in both a service and a workplace where you can be your best, most authentic self. We’re the first fashion retailer to combine technology and data science with the human instinct of a Stylist to deliver a deeply personalized shopping experience. This novel juxtaposition attracts a highly diverse group of talented people who are both thinkers and doers. All of this results in a simple, powerful offering to our customers and a successful, growing business serving millions of men, women, and kids. We believe we are only scratching the surface on our opportunity, and we’re looking for incredible people like you to help us carry on that trend.

Please Review Stitch Fix's Recruiting Privacy Policy Here

https://www.stitchfix.com/privacy/usrecruitingprivacy


Show more Show less"
2812354065,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"San Francisco, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2814493092,Data Engineer - Instrumentation,Expedia Group,2021-11-06,United States,"Dallas, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Travel Arrangements","Data Engineer, Instrumentation

Expedia Group is one of the largest online travel companies in the world, with an extensive brand portfolio that includes some of the world’s leading online travel brands. Collectively, our brands cover virtually every aspect of researching, planning, and booking travel. The Expedia Group portfolio serves both leisure and business travelers alike!

The Travel Partners Group ( TPG ) is responsible for building and developing relationships with supply partners around the world, to constantly align our product offering to our customers’ demand. With more than 240,000 properties worldwide, TPG is driving innovation in the development and management of a highly complex and fast-moving inventory.

Global Partner Marketing ( GPM ) is a newly formed organization that brings together what were formerly disparate B2B channel marketing functions (email, web, social, and events) into a single entity supported by an in-house creative team.

We’re Progressing From “start-up” Mode, Aggressively Building Out Our Team With Results-oriented Goals To Build a World Class B2B Marketing Org That Will Drive The GPM Goals Of

We’re looking for a Data Engineer - Instrumentation to be part of a rapidly growing marketing infrastructure and automation team within GPM.

Acquisition– adding new hotel and vacation rental partners
Engagement – deepening the relationship we have with existing hotel and vacation rental partners
Satisfaction– keeping hotel and vacation rental partners happy
Efficiency – reducing the sales cycle and taking on tasks to give time back to our sales force (Market Management)

What You’ll Do

Become the GPM expert on EG custom tracking libraries
Help implement clickstream and third party libraries/APIs on GPM owned sites
Instrument third party services such as AEM, Facebook, LinkedIn, DV 360, Criteo and Marketo with data from the Expedia Data lakes
Program business rules and marketing triggers

Who You Are

Bachelor’s degree; or equivalent related professional experience
3+ years of development experience, particularly in using marketing acquisition technologies to deliver automation multiple channels and drive operational efficiencies
Extensive experience with JavaScript based tracking services such as Google and Adobe Analytics
JavaScript, jQuery, Java/C++/Python
AWS
Experience with streaming systems/queues such as Kafka or SQS
Ability to take marketing concepts/requirements and translate them into functional specifications
Solid understanding of basic principles of data, how data is structured and organized and how it flows between systems

# L1-SA21

About Expedia Group

Expedia Group (NASDAQ: EXPE) powers travel for everyone, everywhere through our global platform. Driven by the core belief that travel is a force for good, we help people experience the world in new ways and build lasting connections. We provide industry-leading technology solutions to fuel partner growth and success, while facilitating memorable experiences for travelers. Expedia Group's family of brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Vrbo®, Egencia®, trivago®, Orbitz®, Travelocity®, Hotwire®, Wotif®, ebookers®, CheapTickets®, Expedia Group™ Media Solutions, Expedia Local Expert®, CarRentals.com™, and Expedia Cruises™.

© 2021 Expedia, Inc. All rights reserved. Trademarks and logos are the property of their respective owners. CST: 2029030-50

Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. This employer participates in E-Verify. The employer will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization.
Show more Show less"
2798094469,Data Engineer,Amazon,2021-11-18,United States,"Austin, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

The Treasury Technology team has an opportunity to be part of something big! Come work with the Treasury Risk Management (TRM) teams, our expanding technology organization of Product Managers, TPM’s, BI & Data Engineers to support automation and build scale into our systems and processes. Our team builds productivity tools in lieu of hiring additional operational headcount. The Treasury Technology team is looking for a Data Engineer to develop and support Treasury business intelligence, operations reporting and management systems.

About The Team

The Treasury Technology team is responsible for innovating, architecting, and building, global and scalable technology solutions that transform the Treasury Risk Management (TRM) experience. This team and the solutions we build are a critical component in TRMs continued growth.

Innovation is at the center of this team. As a Data Engineer on the Treasury Technology Team you will have an opportunity to collaborate with a team of customers, product managers, data engineers, and software development engineers in developing automated data solutions that will scale with the growing Treasury Risk Management (TRM) organization.

As a Data Engineer, you should be experienced in the architecture of DW solutions for the Enterprise using multiple platforms. You should excel in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business analysts and engineers to determine how best to design the data warehouse for reporting and analytics. You will be responsible for designing and implementing scalable ETL processes in the data warehouse platform to support the rapidly growing and dynamic business demand for data, and use it to deliver the data as service which will have an immediate influence on day-to-day decision making. You should have the ability to develop and tune SQL to provide optimized solutions to the business.


Basic Qualifications

3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL

Preferred Qualifications

Demonstrated strength in SQL, python/pyspark scripting, data modeling, ETL development, and data warehousing
Experience in translating business needs into technical requirements
5+ years of industry experience as a Data Engineer in Treasury of Risk Management
Authoritative in ETL optimization, designing, coding, and tuning big data processes
Experience in designing and implementing data engineering solutions with AWS data technologies

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon.com Services LLC

Job ID: A1780314
Show more Show less"
2808117667,Data Engineer,Deckers Brands,2021-11-25,United States,"Boulder, CO",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2800796012,Data Engineer,AllazoHealth,2021-11-19,United States,"New York, United States",,Full-time,,"Location: Headquarters is NY/NJ metro; would consider remote or hybrid 




Allazo Health Corp. is one of the fastest-growing healthcare technology companies that leverages artificial intelligence to enable major healthcare stakeholders to dramatically improve patient outcomes and medical costs by influencing patients to adopt healthier behaviors, including medication adherence, therapy initiation, disease management, and wellness programs. 

Our proprietary and proven AI platform, AllazoEngineTM, applies behavioral science, machine learning, and data mining to a streamlined patient data set in order to predict likely patient behaviors, gaps, and opportunities; prioritize patients for program focus; and recommend the most effective customized patient programs and communications.  Our customers are innovative Fortune 100 companies in the Pharma, Pharmacy, and PBM/Payer sectors. 




Position: Data Engineer / Senior Data Engineer

We seek an experienced data engineer with a background in data warehouse modeling and ETL development.




Requirements:

3-5 years of experience in advanced SQL
Experience with statistical analyses
Experience in SSIS, Talend or any other ETL tools.
Experience with analysis to support Business Intelligence applications
Relevant experience working with healthcare claims data (pharmacy preferred) and/or healthcare quality metrics (i.e., HEDIS) 
Developing optimized queries to work with large data sets
Experience in performance tuning and reports development
Ability to understand complex data
Experience with creating complex functions, scripts, and stored procedures to conduct ad hoc analysis and create reporting packages 
Demonstrated success in high growth and early-stage environment
Demonstrated GSD “Get Stuff Done” attitude and results
Strong influencer and communicator across all levels of the organization
Detail and metric-oriented
Proficient in Microsoft Office and technology




Responsibilities:

Help manage technical planning for all client implementations to ensure the data team is successfully meeting deadline and project deliverables
Develop internal and external client reporting using SSRS, SSMS, R, Tableau and other report generating software systems
Communicate to stakeholders on key data insights in an easy to follow manner
Actively and consistently provide necessary analytics to enhance customer experience
Identifying areas of opportunities and providing machine learning solutions to enhance our AI platform
Build client reporting from performance monitoring to ad hoc requests
Provide planning and continuous development of the database architecture




Benefits:

Highly competitive compensation package including salary, commissions, and equity stock options
Health benefits
Flat organizational style which empowers everyone in the company to help achieve both company and personal goals
Weekly team events and continuous focus on building team relationships and collaboration as company growth rate accelerates




Show more Show less"
2819248305,Data Engineer,Massachusetts General Hospital,2021-11-30,United States,"Boston, MA",Information Technology,Full-time,"Non-profit Organizations, Wellness and Fitness Services, and Hospitals and Health Care","The Research Software Engineer will join the Psychosis Risk Evaluation, Data Integration and Computational Technologies: Data Processing, Analysis and Coordination Center (PREDICT-DPACC), where they will be part of a diverse interdisciplinary team with broad expertise spanning computer science, neuroscience, psychology, psychiatry, neuropsychology, cognitive neuroscience, neuroimaging, bioinformatics, biostatistics, epidemiology, and neurophysiology. This project will provide management, direction, data processing and coordination for new multisite data collection networks, as well as develop and apply stratification tools to identify and validate biomarkers to predict outcome trajectories in individuals at high risk to develop psychosis.

This position joins the data management, processing and archiving team. The successful candidate will help develop, deploy and maintain the bioinformatics infrastructure of the PREDICT-DPACC.

Relevant activities include, but are not limited to the following:

Design, implement, test, maintain and support applications to capture, manage, archive and monitor multi-site, multi-modal study data. Applications may include but are not limited to study monitoring systems, data management systems, workflow execution and monitoring systems, interactive viewers, and reporting tools.
Support web and application server configuration and deployment.
Support data engineering efforts, including database and API design, data extraction/transformation/load, and data aggregation/integration.
Containerize and deploy software and workflows on local high performance computing platforms and cloud computing infrastructure (AWS).
Regular, direct interaction with engineers and scientists from within and outside the DPACC to assist them with data management and analysis.
Other duties as assigned.

Required

Bachelor’s Degree in Computer Science, Mathematics, Physical Sciences, Engineering, or related field
2+ years of experience in full stack web development
Excellent programming skills in JavaScript (ES6+) and Python.
Experience with JavaScript libraries for interactive data visualization (e.g. d3, Recharts, Charts.js).
Ability to work in an interdisciplinary, diverse, and international team in a highly collaborative and intellectually challenging environment.
Excellent oral and written communication skills

Preferred

Master’s Degree in Computer Science, Mathematics, Physical Sciences, Engineering, or related field
Experience with at least one web framework for building single-page web applications (e.g., React, Angular, Vue)
Experience with JavaScript libraries for compiling, minifying, bundling, packaging, and testing JavaScript code (e.g., npm, yarn, babel, webpack, rollup, mocha, jest)
Experience with SQL and NoSQL databases and database management systems (e.g., PostgreSQL, MongoDB, CouchDB)
Experience in REST and RPC programming, designing HTTP APIs, deploying web services, and configuring web servers (e.g., Apache, NGINX)
Experience with user authentication and session middleware (e.g., Passport.js, express-session)
Experience with Linux container engines (e.g., Docker, rkt) and container orchestration systems (e.g., Kubernetes)
Experience working in a software development team, including agile methodology, unit testing, continuous testing and integration, code reviews, version control, release management, packaging, and distribution

Primary Location

MA-Charlestown-MGH Charlestown HealthCare Center

Work Locations

MGH Charlestown HealthCare Center

Job

IT/Health IT/Informatics-Engineer

Organization

Massachusetts General Hospital(MGH)

Schedule

Full-time

Standard Hours

40

Shift

Day Job

Employee Status

Regular

Recruiting Department

MGH Psychiatry

Job Posting

Nov 29, 2021
Show more Show less"
2819099462,"Data Engineer, Cloud Analytics",Federal Reserve Bank of St. Louis,2021-11-30,United States,"St Louis, MO",Information Technology,Full-time,"Capital Markets, Banking, and Financial Services","Company

Federal Reserve Bank of St. Louis

We are looking for a Data Engineer for a cutting-edge cloud-based big data analytics platform. You will report to a Manager and be a part of an agile cloud engineering team responsible for to developing complex cloud native data processing capabilities as part of an AWS-based data analytics platform. You also will work with data scientists, as users of the platform, to analyze and visualize data and develop machine learning/AI models.

Responsibilities


Develop, enhance, and troubleshoot complex data engineering and data integration capabilities using python, R, lambda, Glue, Redshift, EMR, SAS, Sagemaker and related AWS data processing services.
Collaborate with other software developers, database architects, data analysts and data scientists on projects to ensure optimal data delivery and align data processing architecture and services across multiple ongoing projects.
Perform other team contribution tasks such as peer code reviews, database defect support, and occasional backup production support.
Work closely with the DevOps team to build and release software, ensuring the process follows appropriate change management guidelines.


Qualifications


Bachelor's degree with a major or specialized courses in Information Technology or commensurate experience
2 years related experience with a combination of the following:
Experience designing and building data processing pipelines and streaming
Experience with big data and common tools (Hadoop, Spark, etc.)
Experience with relational SQL databases, especially PostgreSQL
Experience with AWS cloud services: EC2, S3, RDS, Redshift, Glue, Lambda, Step Functions
US Citizen
All Federal Reserve Bank of St. Louis employees must be fully vaccinated against COVID-19, unless the Bank grants an accommodation based on a medical condition or sincerely held religious belief.


Benefits

Our organization offers benefits that are the best fit for you at every stage of your career:

Pension plan, 401K, Comprehensive Insurance Plans, Tuition Reimbursement Program, Onsite Wellness & Fitness Center, Backup Dependent Care (Child & Adult), and more


Ranked as the #2 Top Workplace in the St. Louis Region in 2020, the Federal Reserve Bank of St Louis is committed to building an inclusive workplace, where employees' diversity—in age, gender, race and ethnicity, sexual orientation, gender identity or expression, disability, and cultural traditions, religion, life experiences, education and socioeconomic backgrounds—are recognized as a strength. Learn more about the Bank and its culture; check out our Careers Site.

The Federal Reserve Bank of St Louis is an Equal Opportunity Employer.

Full Time / Part Time

Full time

Regular / Temporary

Regular

Job Exempt (Yes / No)

Yes

Job Category

Information Technology

Work Shift

First (United States of America)

The Federal Reserve Banks believe that diversity and inclusion among our employees is critical to our success as an organization, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. The Federal Reserve Banks are committed to equal employment opportunity for employees and job applicants in compliance with applicable law and to an environment where employees are valued for their differences.

Privacy Notice
Show more Show less"
2758733531,Data Engineer II,Walmart,2021-12-03,United States,"Bentonville, AR",Information Technology,Full-time,"IT Services and IT Consulting, Financial Services, and Retail","Position Summary... What You'll Do...

Data Engineer II

Problem Formulation: Identifies possible options to address the business problems within one's discipline through analytics, big data analytics, and automation.
Applied Business Acumen: Supports the development of business cases and recommendations. Owns delivery of project activity and tasks assigned by others. Supports process updates and changes. Solves business issues.
Data Source Identification: Understand the appropriate data set required to develop simple models by developing initial drafts. Supports the identification of the most suitable source for data. Maintains awareness of data quality.
Data Transformation and Integration: Identifies and understands suitable extraction software. Reviews data from a quality perspective based on the guidelines given. Supports data processing.
Data Modeling: Profiles and analyzes source system data to determine data relationships, design constructs, consistency, and quality. Integrates data into existing physical data models. Defines the relational tables, primary and foreign keys, and stored procedures to create a data model structure. Identifies data entities and describes their relationships as a model. Builds a basic physical schema and objects based on a provided logical model. Creates proofs of concept to support design patterns.
Code Development and Testing: Writes code to develop the required solution and application features by using the recommended programming language and leveraging business, technical, and data requirements. Test the code using the recommended testing approach.
Data Governance: Supports the documentation of data governance processes. Supports the implementation of data governance practices
Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function.
Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices; supporting and aligning efforts to meet customer and business needs; and building commitment for perspectives and rationales.
Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders; identifying business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes, and new responsibilities.
Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans; using the Open Door Policy; and demonstrating and assisting others with how to apply these in executing business processes and practices.

What You’ll Do

Direct root cause analysis of critical business and production issues.
Bring new ideas for product enhancement.
Promote and support company policies, procedures, mission, values, and standards of ethics and integrity.
Ability to learn and adapt new technologies, passion for continuous improvement.
Interact and work with multiple cross functional teams.

What You Need To Be Successful In The Role

Prior Data Engineering experience at a startup, or mid to large sized corp.
Proficient oral and written communication skills.
Prior experience developing or working, with hands on experience building, running and deploying application with Cloud technologies such as Microsoft Azure, Google Cloud Platform.
Ability to learn and adapt new technologies, passion for continuous improvement.
Exposure to continuous build and continuous integration tools.
Ability to deliver in Agile method (Kanban or SCRUM).
Knowledge about containerized cloud applications.
Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with data sets in the cloud.
Data Modeling: Analyzes data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models.
Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure.
Demonstrates expertise in writing queries across data sets to write data pipelines and data processing layers.
Expertise with Big Data Technologies Hadoop, HDFS, Hive, Spark Scala/PySpark, and SQL.

We’d Love To See

Expertise with RDBMS (Oracle, SQL Server, MySQL) with excellent understanding of transaction management and performance tuning.
Experience with distributed databases like Cassandra, Cosmos, MongoDB. Understanding of non SQL databases.
Experience using messaging systems like Kafka or ActiveMQ.
Understanding about consuming ReST APIs.

Minimal Qualification

Bachelor's degree in Computer Science or related field.
2 years’ experience in software engineering or related field.
Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor's degree in Computer Science or related field. Option 2: 2 years’ experience in software engineering or related field. Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Masters: Computer Science Primary Location...805 SE MOBERLY LN, BENTONVILLE, AR 72712, United States of America
Show more Show less"
2788318383,Data Engineer,SingleStore,2021-11-11,United States,"Seattle, WA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Position Overview

At SingleStore we're not just building a database company, we are defining the future of data management. As a Software Engineer on the Infrastructure Team, you will focus on continuing to build out and improve upon our product testing platform used by all software engineering teams at SingleStore, as well as being at the forefront of developing applications that will take our managed service (database as a service) product to the next level. Your expertise in building out cloud applications will drive technical decisions critical to both team and company success.

Role And Responsibilities

Build observable, high-performance applications that power our edge / hybrid cloud product, internal and external infrastructure, and our product test harness, ""Psyduck.""
Design and architect novel solutions to address cloud-scale problems, using bleeding edge container and scheduling technologies.
Automate workflows and test your own code to improve overall software quality
Manage project priorities, deadlines, and deliverables
Perform insightful code reviews for your team members
Guide broader product teams on cloud-scale practices (observability, security, performance and scalability.)

Required Skills And Experience

Experience with one or more general purpose programming languages including but not limited to: C/C++, Python, or Go.
Experience with containers with an emphasis on the Kubernetes ecosystem.
Deep interest and experience working on distributed systems, databases, networking, storage, and multi-tenant services, and Unix/Linux environments.
B.S. degree in Computer Science or a similar field

SingleStore is one platform for all data, built so you can engage with insight in every moment. Trusted by industry leaders, SingleStore enables enterprises to adapt to change as it happens, embrace diverse data with ease, and accelerate the pace of innovation. SingleStore is venture-backed and headquartered in San Francisco with offices in Portland, Seattle, Boston, Bangalore, London, Lisbon, and Kyiv. Defining the future starts with The Database of Now™.

Consistent with our commitment to diversity & inclusion, we value individuals with the ability to work on diverse teams and with a diverse range of people.

To all recruitment agencies: SingleStore does not accept agency resumes. Please do not forward resumes to SingleStore employees. SingleStore is not responsible for any fees related to unsolicited resumes and will not pay fees to any third-party agency or company that does not have a signed agreement with the Company.
Show more Show less"
2810922779,"Data Engineer, Tesla Energy",Tesla,2021-11-02,United States,"Fremont, CA",Information Technology,Full-time,"Renewable Energy Semiconductor Manufacturing, Motor Vehicle Manufacturing, and Utilities","Responsibilities

Analyze manufacturing, equipment and vehicle data and extract useful statistics and insights about failures in order to drive meaningful improvements to production quality and customer experience
Work effectively with engineers and conduct end-to-end analyses, from data requirement gathering, to data processing and modeling
Interpret data, analyze results using statistical techniques and provide ongoing reports
Monitor key product metrics, understanding root causes of changes in metrics
Identify, analyze, and interpret trends or patterns in complex data sets and depict the story via dashboards and reports
Maintain existing data visualizations, data pipelines and dashboard enhancement requests
Acquire data from primary or secondary data sources and maintain databases/data systems to empower operational and exploratory analysis
Automate analyses and authoring pipelines via SQL and Python based ETL framework
Drive underlying data systems improvement by working with key cross-functional stakeholders
Perform data quality validations to ensure data creation is as per the business needs and expectations
Work with management to prioritize business and information needs

Required Skills

Extensive experience writing software with Python
Experience with multiple data architecture paradigms (e.g. SQL, NoSQL, Kafka, Spark)
Experience and interest in frontend development, preferably with the Javascript React framework
Knowledge of various data communication protocols (e.g. REST API, Websockets)
Able to work under pressure while collaborating and managing competing demands with tight deadlines
A passion and curiosity for data and data-driven decision making

Desired Skills

Experience with open source machine learning libraries and frameworks (Tensorflow, Keras, etc)
Familiarity with continuous integration pipelines (Docker, Jenkins, Kubernetes)
Drive to introduce a predictive model to a production environment
Success building and tuning image classification models

Experience

MS in engineering, physics, mathematics, or equivalent.
3 - 5 years relevant experience.

Besides tangible skills, this position will also require the person to

Have high attention to details.
Show more Show less"
2794015372,Data Engineer 1,Providence,2021-11-10,United States,"Seattle, WA",Information Technology,Full-time,"Financial Services, Wellness and Fitness Services, and Hospitals and Health Care","Description

Providence is calling a Data Engineer 1 to one of our locations in the Seattle area, Portland, OR, or Irvine, CA.

We are seeking a Data Engineer 1 who will design and build modern data-centric software applications to support clinical and operational processes across all parts of the healthcare system. These applications leverage cloud computing, big data, data science, and modern software development methodologies and frameworks. Builds data pipelines and transformations, data enrichment processes, provisioning layers, and user interfaces to meet the requirements of key initiatives. Enjoys a fast pace and has a focus on regular delivery. Seeks simple solutions to complex problems through the use of modern and emerging methods and tools. Emphasizes sharing and enables collaboration with meticulous source control and documentation. Works closely with the Product, Platform, and Architecture teams to deliver on joint efforts.

In This Position You Will Have The Following Responsibilities

Design, build and deliver quantitative applications that improve operations and generate value.
Participate in DevOps, Agile, and continuous integration frameworks.
Stay abreast of emerging technologies, open source projects, and best practices in the field.
Data warehousing, big data, enterprise search, business intelligence, analytics, modern and mobile applications.
Build processes that are fault-tolerant, self-healing, reliable, resilient and secure.
Work effectively and in real-time with other developers, product managers, and customers to deliver on collective goals.
Actively participate in code reviews, support the overall code base, and support the establishment of standard processes and frameworks.
Take an open and transparent approach to the work by sharing code and expertise, by consulting peers for problem-solving, and by being a mentor to peers.

Qualifications

Required qualifications for this position include:

Bachelor's Degree in Computer Engineering, Computer Science, Mathematics, Engineering or equivalent education/experience,
1 year Related experience.

Preferred Qualifications For This Position Include

Master's Degree in Computer Engineering, Computer Science, Mathematics, Engineering or equivalent education/experience.
1-3 years Related experience.

About The Department You Will Serve.

Providence Shared Services provides a variety of functional and system support services for our Providence family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise.

We offer comprehensive, best-in-class benefits to our caregivers. For more information, visit

https://www.providenceiscalling.jobs/rewards-benefits/

Our Mission

As expressions of God’s healing love, witnessed through the ministry of Jesus, we are steadfast in serving all, especially those who are poor and vulnerable.

About Us

Providence is a comprehensive not-for-profit network of hospitals, care centers, health plans, physicians, clinics, home health care and services continuing a more than 100-year tradition of serving the poor and vulnerable. Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.

Schedule: Full-time

Shift: Day

Job Category: Analytics/Business Intelligence

Location: Washington-Renton

Other Location(s): Washington-Seattle, Oregon-Beaverton, Washington-Redmond, California-Irvine

Req ID: 321034
Show more Show less"
2815571666,Data Engineer (Remote optional),Petal,2021-11-02,United States,"New York, NY",Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","The Petal Mission

Petal’s mission is to bring financial opportunity and innovation to everyone.

We're pioneering a new approach to credit, by analyzing an applicant’s banking history, in addition to credit history, to determine their creditworthiness. We call this technology a Cash Score — and it takes into account income, spending, and savings. It’s currently helping thousands of people qualify for credit at better rates, even if they’ve never had it before.

We bring the same ingenuity to our credit card products. Our simple and intuitive app gives members access to credit score tracking, budgeting tools, subscription management, and automated payment options—everything they need to make financial progress.

Now more than ever, Americans need help improving their credit safely, responsibly, and affordably. If this sounds like something you’d like to be a part of, apply now, and let’s change this trillion-dollar industry together.

At Petal, we're looking for people with kindness, positivity, and integrity. You're encouraged to apply even if your experience doesn't precisely match the job description. Your skills and potential will stand out—and set you apart—especially if your career has taken some extraordinary twists and turns. At Petal, we welcome diverse perspectives from people who think rigorously and aren't afraid to challenge assumptions.

The Data Engineer role

Petal is at its heart a data company. And as Petal grows, we are looking for a data engineer to join us and help to continue building out and iterating on our existing data infrastructure and tools. You will have to tackle challenging data problems using cutting edge tools within the complex data landscape of a financial services company. You will be working closely with Product, Risk, Ops, and other stakeholders to develop data-driven, pragmatic software solutions to meet real business needs. As a member of a team that is still growing within Petal, you will have the opportunity to help shape the Data Engineering team’s identity and footprint. The ideal candidate possesses strong technical skills, is comfortable working on ever-changing problems, works well cross-functionally, has a sharp eye for details, proactively owns and solves problems, and is always excited to learn.

As a Data Engineer, you'll architect, design, and implement the next-generation of financial services products. We're looking for engineers with deep industry experience that can bring fresh ideas they're looking to put into action.

Key Responsibilities

Write high-quality, well-tested, observable code that runs smoothly in production and elevates the standards across the team
Run and support a production data platform that supports the business
Organize data from disparate sources making it accessible and usable across the team (e.g., Data Science, Analytics)
Collaborate with various Petal stakeholder teams (e.g., product, analytics, operations, risk, compliance) and third-party technology vendors (e.g. credit bureaus, credit processors, bank data aggregators)
Teach across the broader engineering organization to improve best practices and influence system design


Characteristics Of a Successful Candidate

Experience working with data warehouses (we use Redshift and Postgres), building out robust data pipelines and backend systems.
Strong self-management, sense of ownership, and organization. Petal’s open and collaborative environment enables proactive and organized employees to really shine.
Value collaboration both within and outside of the team. You understand the value of collaboration within teams and the power of extending that collaboration across the company.
Be a quick, eager learner. Deep domain expertise in every aspect of Data Engineering isn’t expected, but be willing to learn and approach the learning with excitement.
Flexibility. Petal is a startup and with that comes changing business needs, and changing priorities; you should be able to take on these changes in stride.
Displays inclusivity, kindness, and humility. Our inclusive and collaborative culture is what makes Petal a great place to work. We need diverse people who embody our core values to make it even greater.
Weighs trade-offs and focuses on value delivery. A fast-paced startup demands making trade-offs that balance the near term and long term value add of solutions. At Petal, we design robust systems, but try not to let the perfect be the enemy of the good.
We're seeking someone with a bachelor's degree or above in a related field, or equivalent work experience.
Nice-to-haves:

Experience mentoring engineers.
Experience in financial services.
You've contributed to open source projects to scratch an itch instead of building solutions from the ground up.
Love of immutable state.
Love of idempotent operations.

These are all ""nice-to-haves"" --- we don't expect every candidate to hit every mark. Many of our engineers come from different backgrounds and career paths. We're committed to teaching anything you might need to learn on the job.

For our California employment information privacy statement, please click here.
Show more Show less"
2783839428,Data Engineer,Capital One,2021-11-27,United States,"New York, NY",Information Technology and Engineering,Full-time,"Banking, Financial Services, and Investment Banking","Locations: NY - New York, United States of America, New York, New York

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You’ll Do

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications

Bachelor’s Degree
At least 2 years of experience in application development
At least 1 year of experience in big data technologies

Preferred Qualifications

3+ years of experience in application development including Python, SQL, Scala, or Java
1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
2+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
1+ years experience working on real-time data and streaming applications
1+ years of experience with NoSQL implementation (Mongo, Cassandra)
1+ years of data warehousing experience (Redshift or Snowflake)
2+ years of experience with UNIX/Linux including basic commands and shell scripting
1+ years of experience with Agile engineering practices

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Job Category - Engineering, Technology
Show more Show less"
2816570577,Data Engineer,Bozzuto,2021-12-02,United States,"Greenbelt, MD",Information Technology,Full-time,Leasing Real Estate,"At Bozzuto, it’s all about experience. Whether it’s the experience you bring, gain or give, we want your journey to be exceptional. Guided by our core values of creativity, concern, passion and the pursuit of perfection, we create inspiring, engaging and vibrant communities.

Why do we do it? Because home is where aspirations are pursued and memories unfold. We believe in the power to impact the lives of the people we touch through the delivery of extraordinary experiences.




Primary Responsibilities:

We are seeking a self-motivated data-enthusiast who is inspired to build data solutions to maximize impact throughout the organization. We are a growing data engineering and analytics team so this role provides an opportunity to drive the development of our platform. The Data Engineer will be primarily responsible for managing all aspects of our data ETL pipeline infrastructure to wrangle and integrate data from disparate sources and formats into our central data warehouse and then clean/prepare it to be utilized by our internal team of data scientists and business analysts. You must be comfortable operating with a high degree of autonomy to execute on a strategic vision by taking initiative to implement creative and innovative solutions that achieve outcomes and goals. While there is a requirement to support the technical components of our infrastructure, you will interface on a daily basis with multiple cross-functional teams and stakeholders throughout the organization to understand business needs and translate those into technical requirements and data solutions.




As a Data Engineer your responsibilities include:

Use SQL to build and analyze datasets in our data warehouse for purposes of expanding our operations and financial data model
Implement data pipelines to ingest new data sets to our data warehouse using ETL software (Matillion), SQL and Python; training in Matillion software can be provided if demonstrated experience in other ETL platforms
Update and enhance a Power BI-based data model using DAX
Build and maintain Power BI visualizations using data model and other data sets
Interface with business and executive stakeholders across the organization to assess needs and requirements and set deliverables




What You Bring to Us:

Knowledge of SQL, preferably with experience in the Snowflake data warehouse platform
Experience building ETL pipelines, preferably on the Matillion platform
Experience with object-oriented programming languages, specifically Python with experience in pandas and Jupyter notebooks to wrangle and clean data
Knowledge and experience building toolsets on the AWS Cloud Infrastructure platform, particularly EC2, Lambda and Batch
2-5 years of demonstrated experience building data pipelines and delivering datasets for analytics to support business objectives
Analytical skills capable of extracting insights and value from raw data sources
Experience with Microsoft SQL Server and Analysis Services databases
Experience developing and supporting analytics data models, preferably using the Microsoft Power BI platform (Power BI / Data Flows) with in-depth experience designing measures and dimensions in DAX
Knowledge of Excel and Power Pivot / Power Query




What We Bring You:

In addition to an award-winning culture and amazing workspaces, Bozzuto offers a wide range of insurance options, financial programs, and benefits that let you and your family be healthy and plan for the future. Our benefits take into consideration everything from career development to retirement, family matters, health and wellness. Bozzuto is committed to doing everything it can to offer you quality benefits and healthcare coverage—including access to the best doctors and hospitals at an affordable price.




Bozzuto is proudly an Equal Opportunity Employer EOE/M/F/D/V.

Show more Show less"
2805253669,Big Data Operations Engineer - Automation,Zoom,2021-11-23,United States,"Austin, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","About The Team

We are looking for a Big Data Operation Engineer with strong automation skills to ensure smooth function of data pipeline, self-motivated to continuously find optimization and deliver excellent results leveraging various tools.

About The Role

Understand Big Data architecture and implement large-scale data processing environment
Design then implement highly effective automated methods to build and update big data infrastructure
Manage and operate Big Data application system stack on daily basis
Determine operation metrics to measure operation and service quality
Setup goals to effectively increase service quality to meet business and operation's requirements
Work with the Big Data engineers to ensure data ingestion, transformation and data at rest smoothly
Drive issue resolutions and root cause analysis with on-call duty
Monitor data performance and modify infrastructure

About You

3+ years of recent experience in data operation engineering
Bachelor's Degree or more in Computer Science or a related field
You will report to your hiring manager and work with different teams in the Zoom Meeting Vertical
You developer with python, shell scripting, and Java to automate infrastructure buildup and changes
You have experience with manageability and automation interface of AWS services
You are experienced in Cloudera CDH/CDP platform or AWS Cloud Services, e.g., EC2, EMR will be a big plus
You hold operation, production support, and troubleshooting experience
You have knowledge of system design and implementation towards infrastructure management and operations
You have programming experience in Ansible, Terraform, Chef (or any infrastructure as code), and will learn new programming languages to meet goals
You find satisfaction in a job well done, feel happy to help team members and solve complex issues together

Benefits

At Zoom, we care about our employees, their families, and their well-being. As part of our award-winning workplace culture and commitment to delivering happiness, our benefits program offers a variety of perks, benefits, and options to help employees maintain their physical, mental, emotional, and financial health; support work-life balance; and contribute to their community in meaningful ways.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram

Show more Show less"
2814240558,Data Engineer (100% Remote - Throughout US),Moody's Analytics,2021-11-05,United States,"Boston, MA",Information Technology,Full-time,Financial Services,"Role/Responsibilities

As a Software Engineer you will join a growing team of data engineering focused professionals designing, implementing and deploying solutions for a data factory that produces billions of predictions annually that help our customers make better, faster credit decisions.

In This Role, You Will

Automate ingestion of data in various formats from multiple providers
Develop bots that clean and normalize data
Create deployment scripts for your solutions
Instrument services to facilitate continuous monitoring of our data production processes

Qualifications

Demonstrated SQL fluency;
Demonstrated fluency with Python, PySpark and/or Scala;
Awareness of agile methodologies;
Strong interest in big data and serverless computing as demonstrated through an example you can share;
A Bachelor’s in Computer Science, Statistics, Mathematics, Operations Research or field with software engineering emphasis;
Strong problem solving skills;
Excellent written and oral communication skills;
Ability to work independently, ask for help after a reasonable effort and not ask same question again;

LOB/Cost Center

PA/Credit Analytics

Job Req ID

23790BR

Entity

Moody's Analytics (MA)

Line of Business

Predictive Analytics OU (EAAS OU)

Regular/Temporary

Regular

City

Alpharetta, Atlanta, Boca Raton, Boston, Charlotte, Chicago, Dallas, Hoboken, King of Prussia, Miami, New York, Newark, Omaha, PLANO, San Francisco, South San Francisco, Tallahassee, Walnut Creek, Washington DC

Job Category

Engineering & Technology

Job Sub Category

Software Engineering

Experience Level

Experienced Hire

Working at Moody's

Moody's (NYSE: MCO) is a global integrated risk assessment firm that empowers organizations to make better decisions. Our data, analytical solutions and insights help decision-makers identify opportunities and manage the risks of doing business with others. We believe that greater transparency, more informed decisions, and fair access to information open the door to shared progress. With over 11,000 employees in more than 40 countries, Moody's combines international presence with local expertise and over a century of experience in financial markets. Learn more at moodys.com .

Entity

Moody’s Analytics provides financial intelligence and analytical tools supporting our clients’ growth, efficiency and risk management objectives. The combination of our unparalleled expertise in risk, expansive information resources, and innovative application of technology, helps today’s business leaders confidently navigate an evolving marketplace.

EEO Policy

Moody’s is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, gender, age, religion, national origin, citizen status, marital status, physical or mental disability, military or veteran status, sexual orientation, gender identity, gender expression, genetic information, or any other characteristic protected by law. Moody’s also provides reasonable accommodation to qualified individuals with disabilities in accordance with applicable laws. If you need to inquire about a reasonable accommodation, or need assistance with completing the application process, please email accommodations@moodys.com . This contact information is for accommodation requests only, and cannot be used to inquire about the status of applications.

For San Francisco positions, qualified applicants with criminal histories will be considered for employment consistent with the requirements of the San Francisco Fair Chance Ordinance.

This position may be considered a promotional opportunity, pursuant to the Colorado Equal Pay for Equal Work Act.

Click here to view our full EEO policy statement. Click here for more information on your EEO rights under the law. Click here to view our Pay Transparency Nondiscrimination statement.

Securities Trading Policy (STP)

Candidates for Moody's Corporation may be asked to disclose securities holdings pursuant to Moody’s Policy for Securities Trading and the requirements of the position. Employment is contingent upon compliance with the Policy, including remediation of positions in those holdings as necessary.
Show more Show less"
2814555390,Data Engineer,edX,2021-11-01,United States,"Cambridge, MA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","We accept applications from remote employees in the following US states: CO, CT, ME, NH, NJ, NY and VT.

Your Impact

Data Engineering has built a best in class data platform leveraging tools such as snowflake, dbt_ and prefect. Now that the foundations have been laid the team is beginning to look toward what is next; and evolving our foundation to climb to the next rung of the analytics maturity model.

edX is looking to add a Data Engineer to set their vision on that next rung and to help us climb.

Your work will enable the Data group to evolve, automate and scale and impact edXers across the company as we keep the data flowing and enable edX to continue to mature as a data-driven organization - and achieve our potential to transform education for learners globally.

Your Team

The Data Engineering (DE) team’s work lies at the foundation of all that edX does. The accurate, timely and usable data that DE provides to the organization drives business reporting and decision-making, product innovation, customer-facing data offerings and more.

Data Engineering works alongside data analysts and scientists, product engineering, and business stakeholders across the organization to provide the data platform and technical solutions that enable edX to drive value from its data. If you are looking to make an outsized impact on an organization, Data Engineering at edX is the place for you.

You Will

Maintain and help improve Data Engineering’s best in class infrastructure
Be relentless in your distaste for toil; automating and removing processes and systems that are no longer serving their purpose
Build automation and tooling to help data move fast, we strive for idempotent, reproducible systems and results
Be data driven in your work, instrumenting the tools Data Engineering builds and tuning system performance
Rapidly diagnose and resolve faults with data services and pipelines as a member of an on-call rotation - ensuring the data flows throughout our ecosystem smoothly
Collaborate with peers in and out of the Data team to troubleshoot and propose and document solutions
Proactively communicate issues, status or roadblocks
Help optimize alerting, data processes and on-call rotations to reduce fatigue and improve efficiency of our operations

You Have

Experience in a dev-ops or site reliability engineering role or
Experience building efficient data pipelines, performance tuning, and integrating disparate data sources and types, including high volume semi-structured and unstructured data (e.g., JSON, etc.)
Understanding of cloud-based data warehousing and ELT/ETL techniques and processes
Experience working in AWS systems
Experience working in Python
Collaborative and pragmatic, with and enthusiasm for learning and continuous improvement

Preferred Experience

Experience with Snowflake and dbt_ (https://www.getdbt.com/)
Experience with pipeline data pipeline tools such as Prefect, Luigi or Airflow
Experience with or a desire to learn about Terraform and Kubernetes.
Experience master data management, data modeling and preparing data for analysis
Enthusiasm for Agile/Scrum processes

Why You’ll Like It Here

edX is collaborative at its core. You’ll work within your team and across the organization, allowing for continuous learning and discovery.
We’re on a mission to unlock our learners potential on a global level, seeking to create a more diverse, equitable and inclusive world.
We set outcomes that matter and provide value in all that we do, from building meaningful products to serving the edX community.

We understand that applying for a job can be intimidating. Applicants rarely meet every single job requirement, and we know there are many skills and backgrounds that will contribute to success in this role.

That’s Why We Provide New Employees With

Employee onboarding and training sessions
Personalized 30/60/90+ day plans
Individual quarterly and annual goals
Career pathways

And much more to support you in your personal journey at edX! That said, if this role looks like a great next step for you, please apply… even if you can’t “check every box.” We’d love to hear from you! edX is the education movement for restless learners. Together with our founding partners Harvard and MIT, we’ve brought together more than 38 million learners, the majority of top-ranked universities in the world, and industry-leading companies onto one online learning platform that supports learners at every stage. And we’re not stopping there—as a global nonprofit, we’re relentlessly pursuing our vision of a world where every learner can access education to unlock their potential, without the barriers of cost or location.
Show more Show less"
2756415960,Data Engineer,Heal,2021-10-01,United States,"Los Angeles, CA",Information Technology,Full-time,"Financial Services, Wellness and Fitness Services, and Hospitals and Health Care","Who We Are

The tech team fuels our vision to make healthcare frictionless and accessible to all through the power of telemedicine. We build and manage the systems that are paving the way towards this new future. Working cross-functionally with other departments, doctors and patients, we are able to create and implement tech that has a real impact on the lives of millions. (Did you know that an estimated 27 million lost their health insurance and jobs due to COVID-19?) Our team consists of engineers, product, qa, data analysts and product designers. We believe that tech has the power to reshape the way people receive and provide healthcare.

Who We're Looking For

We are looking for an experienced Data Engineer who is interested in working with a fast-growing team in building industry-leading health-tech services. You will be working on a small team using cutting-edge technology and tools to build and support infrastructure for our diverse environment owning and progressively improving Heal's data and analytics infrastructure.

You fight fires at scale and continually identify areas for process improvement in the production environment. You are a creative self-starter and strategic thinker who can work autonomously to develop innovative and scalable solutions.

YOUR DAY TO DAY

Design, develop and maintain cross-platform ETL processes (Airflow DAGs)
Organize and understand the domain to build/refine reportable warehouse with dimensions and facts
Make data and analytics easily accessible to product and revenue teams to enable data-driven decision making
Collaborate with multiple eng teams to set up event tracking and data models for new features/experiments
Leverage visualizations tools, power bi, quicksite, Metabase to develop core reports into the business
Work closely with various departments and product managers to understand their data requirements for existing and future projects and acquire/prepare that data, and provide self-service reporting for said data.
Develop guidelines, standards, and processes to ensure the highest data quality and integrity in the data stores residing on the Big Data platform
Work with IT and data owners to understand the types of data collected in various data stores and define the warehousing strategy to extract existing data into the Big Data platform


Your Skills & Accomplishments

Experience using data warehousing technologies and designing optimal reporting schemas.
Experience in extracting data from various relational and non-relational sources (Postgres, Mongo, DynamoDB, ElasticSearch, S3, etc..)
Strong knowledge of SQL
Experience in scripting languages (Python, Bash)
Proactivity and problem solving attitude
Keen business acumen to recognize and recommend cost-effective and scalable platform solutions that best meet our business needs
Enjoys exploring and learning new technologies and has demonstrated ability to quickly learn new technologies
Guide and mentor others on your team and beyond.
Are an amazing communicator (esp. in a remote environment).


PERKS

Competitive salary and stock options
Three weeks paid vacation
Competitive Medical, Dental and Vision plans
Parental leave for four weeks
FSA plans and company paid Short Term Disability
401k plan


About Heal

The current healthcare system is broken, full of friction, not accessible to the masses and treats patients as another number. At Heal, we understand that healthcare is personal, that's why we put patients front and center.

We are the undisputed market leader in doctor house calls, using technology to make experiences easy, efficient, trustworthy, and highly personal. We aim to create meaningful relationships between doctors and patients so people can worry less about the process and instead focus on their health.

In under 6 years, Heal has raised over $160m million in investment capital, delivered over 250,000 house calls and driven over $62 million in healthcare cost savings. Heal was named the 13th most disruptive private company in the U.S by the 2020 CNBC Disruptor 50 as we recently rolled out affordable flatrate Healthcare.

Join us toward creating the future of healthcare and helping millions across the nation
Show more Show less"
2817892751,Data Engineer II,Silicon Valley Bank,2021-12-03,United States,"Santa Clara, CA",Information Technology,Full-time,"Banking, Venture Capital and Private Equity Principals, and Financial Services","Be Part Of a Bank Like No Other.

When you work with the world&#39s most innovative companies, you know you&#39re making a difference.

Our clients are the game changers, leaders and investors who fuel the global innovation economy. They&#39re the businesses behind the next medical breakthroughs. And the visionaries whose new technologies could transform the way people live and work.

They come to SVB for our expertise, deep network and nearly forty years of experience in the industries we serve, and to partner with diverse teams of passionate, enterprising SVBers, dedicated to an inclusive approach to helping them grow and succeed at every stage of their business.

Join us at SVB and be part of bringing our clients&#39 world-changing ideas to life. At SVB, we have the opportunity to grow and collectively make an impact by supporting the innovative clients and communities SVB serves. We pride ourselves in having both a diverse client roster and an equally diverse and inclusive organization. And we work diligently to encourage all with different ways of thinking, different ways of working, and especially those traditionally underrepresented in technology and financial services, to apply.

Make Next Happen Now. For over 30 years, Silicon Valley Bank (SVB) has helped innovative companies and their investors move bold ideas forward, fast. SVB provides targeted banking services to companies of all sizes in innovation centers around the world. The Data Engineering team at Silicon Valley Bank is responsible for delivering data solutions that support all lines of business across the organization. This includes providing data integration services for all batch data movement, managing, and enhancing the data warehouse, Data Lake &amp data marts, and providing support for analytics and business intelligence customers. Do you get excited when you see data? Constantly looking for value in Data? If that is you, we are looking for you. As a Data Engineer, you will build, append and enhance our existing enterprise data warehouse. You will get an opportunity to closely work with business teams and other application owners, understand the core functionality of banking, credit, risk and finance applications and associated data. You will build data pipelines, tools, and reports that enable analysts, product managers, and business executives. Bachelor&aposs degree in Computer Science, Mathematics, Statistics, Finance, related technical field, or equivalent work experience 5+ years of relevant work experience in analytics, data engineering, business intelligence or related field, and 5+ years professional experience 2+ years of experience in implementing big data processing technology Hadoop, Apache Spark, etc. Experience using SQL queries, experience in writing and optimizing SQL queries in a business environment with large-scale, complex datasets Detailed knowledge of data warehouse technical architecture, infrastructure components, ETL and reporting/analytic tools and environments Hands on experience on major ETL tools like Ab Initio, Informatica / IICS, BODS and/or any cloud based ETL tools. Hands on experience with scheduling tools like Control-M, Redwood or Tidel. Expects good understanding and experience on reporting tools like Tableau, BOXI etc. Good understanding of Database and data warehouse concepts. Should have hands on experience on major DBs like Oracle, sqlserver, postgres. Should have awareness about no SQL DB. Hands on experience in cloud technologies (AWS /google cloud/Azure ) related to Data Ingestion tool ( both real time and batch based), CI/CD process, Cloud architecture understanding , Big data implementation. AWS certification is a plus and working knowledge of Glue, S3, Athena, Redshift is a plus. Preferred Qualifications Graduate degree in Computer Science, Mathematics, Statistics, Finance, related technical field Strong ability to effectively communicate with both business and technical teams Demonstrated experience delivering actionable insights for a consumer business Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.) Basic Experience with Cloud technologies Experience in banking domain is a plus

© 2021 SVB Financial Group. All rights reserved. SVB, SVB FINANCIAL GROUP, SILICON VALLEY BANK, MAKE NEXT HAPPEN NOW and the chevron device are trademarks of SVB Financial Group, used under license. Silicon Valley Bank is a member of the FDIC and the Federal Reserve System. Silicon Valley Bank is the California bank subsidiary of SVB Financial Group (Nasdaq SIVB).

Equal Employment Opportunity

Silicon Valley Bank is an equal opportunity employer and is dedicated to expanding its commitments and investments to create a more diverse, equitable and inclusive company culture and innovation ecosystem. We are strongly committed to the values and policy of equal employment opportunity across our employment practices.

Silicon Valley Bank is registered in England and Wales at Alphabeta, 14-18 Finsbury Square, London EC2A 1BR, UK under No. FC029579. Silicon Valley Bank is authorised and regulated by the California Department of Business Oversight and the United States Federal Reserve Bank authorised by the Prudential Regulation Authority with number 577295 and subject to regulation by the Financial Conduct Authority and limited regulation by the Prudential Regulation Authority. Details about the extent of our regulation by the Prudential Regulation Authority are available from us on request.
Show more Show less"
2810552341,Data Engineer,CDL 1000,2021-12-01,United States,"Chicago, IL",,Full-time,,"CDL 1000 is a 24-hour asset-based 3PL, a global supply chain company with advanced tracking and freight matching capabilities in Chicago, Illinois, and aggressively hiring across 48 states. We provide seamless, top-tiered logistic solutions nationwide, as well as in Canada. CDL 1000 focuses on building customized solutions for each client based on their individual needs and untapped potential.

When deciding what type of provider is the perfect fit for your business, weighing the pros and cons can be difficult when you have not had the experience of working with both. We sell our abilities on our premium service, reputation, execution, and experience for each client's needs. We recognize that it takes a grade A-team to get each job done flawlessly. Join our dream team today, and work with a high-profile clientele.

We are rapidly growing. As we embark on the next phase of our incredible expansion, we are looking for an exceptional Data Engineers to add fuel the growth of our new AI team.

We offer a generous salary based on experience and location.

We'd love to talk with you if...
-Degree or no degree; we choose whether your talent is a perfect fit.
-You've previously held Data Engineer Positions, Trading Crypto, Commodities, Shipping-- experience building a pipeline
-You're a direct communicator
-You're excited to work between the intersection of artificial intelligence/tech and logistics
-You're comfortable with fast-paced growth

Responsibilities
-Work directly with AI Director
-Build a data warehouse
-Implement automated processes
-Able to work well with multiple departments
-Creating and nurturing professional relationships
-Can build entire data processing pipeline

What We Value:
-Lead with Purpose - Leadership does not necessarily mean management. Everyone is a leader, no matter the role. Taking pride in your responsibilities with finding & executing solutions is critical.
-Focus on the 'Why'- The best solutions start with everyone understanding the problem and its impact. We've found that if someone understands the 'why,' they will produce an innovative 'what' and 'how.' If we cannot clearly explain the 'why,' we don't understand the problem ourselves.
-Bring a Sense of Humor - Our work environment is a lighthearted & optimistic place where employees are united by humor and camaraderie; we believe laughter is a great way to uplift employee morale and form bonds with each other.
-Collaboration - We won't thrive without recognizing others' strengths. Listen and evolve together, helping and supporting each other for the sake of a collective goal.

We Believe In The Following Workplace Norms:
-Honor Commitments, Your Word Matters - Specific, Measurable, Attainable, Relevant & Timely (S.M.A.R.T.) Asks & Answers.
-Allow O.K.R.s To Guide Us - Individual & Departmental O.K.R.s will largely impact success at CDL1000, Inc.
-Agree to Disagree & Commit -Voice concerns in a respectful & appropriate manner directly to your manager or the Executive Team.
-Assume Positive Intent - Always start from the idea that a person meant well or was doing their best, no matter what they say or do.

What We Are Offering You
-PTO
-401K
-Snacks and drinks, all the snacks.
-Paid Holidays
-Medical Benefits
-Dental Insurance
-Vision Insurance
-Life Insurance
-Supplemental Offering through Aflac
-Competitive Compensation Package

Interview Process
-Initial screening with the HR/Recruitment Directors — 30 minutes
-Video Call with the Director of the department — 30 minutes
-Video Call with your direct hiring Manager — up to 45 minutes
-In-office meeting with direct Manager — will also be meeting the team you’ll be working with to ensure it is a culture fit
-Final stage –review your offer letter!
Show more Show less"
2740440389,"Data Engineer, Business Intelligence",Foursquare,2021-11-13,United States,"New York, NY",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Foursquare is the leading independent location technology company, powered by our deep understanding of how people move throughout the world. Our solutions help businesses make smarter decisions, developers create more engaging experiences, and brands build more effective marketing strategies.

Foursquare’s platform includes Attribution, Audience, Proximity, Places, Pilgrim SDK and Visits. As the industry’s first and only accredited company for location data from the Media Rating Council (MRC), this foundation powers all our solutions — those that exist today and those we have yet to build. Over 14 billion consumer-verified place visit confirmations help us keep our map and models fresh and up-to-date, building a phone’s-eye-view of the world with 105 million unique places of interest worldwide.

About The Team

The BI team is responsible for integrating, synthesizing and interpreting critical business data. We provide support to the business by creating sophisticated reporting tools that the business can use on data-driven decisions and we deliver deep dive analysis to measure results of actions that we have taken or to answer challenging business questions.

About The Role

You are passionate about using your programming, and data wrangling expertise to create data tools that will help the analytics team answer product and business decisions questions. You are an excellent communicator that will provide thought leadership on metrics, features, and products to teams across the company. You have strong engineering experience and enjoy working in a rapidly changing environment. And most of all: you ship.

Responsibilities Of The Role

Creating and maintaining data pipelines using Python
Creating and maintaining frameworks for data ingestion
Write and tune SQL and other types of queries to support internal customer requests
Design, develop and test ETL, and ELT data workflows from a variety of big and small data sources.
Work closely with a range of stakeholders and team members to understand and finalize their business requirements for reporting and data aggregations
Design, develop and maintain analytical databases based on business requirements
Perform hands on implementation and maintenance of production ETL processes.
Support ad-hoc data analysis requests
Audit quality and repair data from data sources for accuracy

Qualifications

3+ years of industry experience maintaining production data warehouse and ETL pipelines and using data analytics to solve business problems
3+ years of experience in Python
Deep knowledge and hands-on experience with SQL
Understanding of database structure, design, theories and principles
Experience in Cloud environments
Able to rapidly learn new processes/subject areas
Willingness and ability to wrangle messy data
Degree in Computer Science preferred
Experience working independently solving a variety of business problems.
Good communication skills.

Nice To Have

Experience with Datorama and Tableau visualization tools
Experience with MPP databases
Experience in pyspark is a plus

Foursquare is proud to foster an inclusive environment that is free from discrimination. We strongly believe in order to build the best products, we need a diversity of perspectives and backgrounds. This leads to a more delightful experience for our users and team members. We value listening to every voice and we encourage everyone to come be a part of building a company and products we love.

Foursquare is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other characteristic protected by law.
Show more Show less"
2817890756,Data Engineer II,Silicon Valley Bank,2021-12-03,United States,"Santa Clara, CA",Information Technology,Full-time,"Banking, Venture Capital and Private Equity Principals, and Financial Services","Be Part Of a Bank Like No Other.

When you work with the world&#39s most innovative companies, you know you&#39re making a difference.

Our clients are the game changers, leaders and investors who fuel the global innovation economy. They&#39re the businesses behind the next medical breakthroughs. And the visionaries whose new technologies could transform the way people live and work.

They come to SVB for our expertise, deep network and nearly forty years of experience in the industries we serve, and to partner with diverse teams of passionate, enterprising SVBers, dedicated to an inclusive approach to helping them grow and succeed at every stage of their business.

Join us at SVB and be part of bringing our clients&#39 world-changing ideas to life. At SVB, we have the opportunity to grow and collectively make an impact by supporting the innovative clients and communities SVB serves. We pride ourselves in having both a diverse client roster and an equally diverse and inclusive organization. And we work diligently to encourage all with different ways of thinking, different ways of working, and especially those traditionally underrepresented in technology and financial services, to apply.

Make Next Happen Now. For over 30 years, Silicon Valley Bank (SVB) has helped innovative companies and their investors move bold ideas forward, fast. SVB provides targeted banking services to companies of all sizes in innovation centers around the world. The Data Engineering team at Silicon Valley Bank is responsible for delivering data solutions that support all lines of business across the organization. This includes providing data integration services for all batch data movement, managing, and enhancing the data warehouse, Data Lake &amp data marts, and providing support for analytics and business intelligence customers. Do you get excited when you see data? Constantly looking for value in Data? If that is you, we are looking for you. As a Data Engineer, you will build, append and enhance our existing enterprise data warehouse. You will get an opportunity to closely work with business teams and other application owners, understand the core functionality of banking, credit, risk and finance applications and associated data. You will build data pipelines, tools, and reports that enable analysts, product managers, and business executives. Bachelor&aposs degree in Computer Science, Mathematics, Statistics, Finance, related technical field, or equivalent work experience 5+ years of relevant work experience in analytics, data engineering, business intelligence or related field, and 5+ years professional experience 2+ years of experience in implementing big data processing technology Hadoop, Apache Spark, etc. Experience using SQL queries, experience in writing and optimizing SQL queries in a business environment with large-scale, complex datasets Detailed knowledge of data warehouse technical architecture, infrastructure components, ETL and reporting/analytic tools and environments Hands on experience on major ETL tools like Ab Initio, Informatica / IICS, BODS and/or any cloud based ETL tools. Hands on experience with scheduling tools like Control-M, Redwood or Tidel. Expects good understanding and experience on reporting tools like Tableau, BOXI etc. Good understanding of Database and data warehouse concepts. Should have hands on experience on major DBs like Oracle, sqlserver, postgres. Should have awareness about no SQL DB. Hands on experience in cloud technologies (AWS /google cloud/Azure ) related to Data Ingestion tool ( both real time and batch based), CI/CD process, Cloud architecture understanding , Big data implementation. AWS certification is a plus and working knowledge of Glue, S3, Athena, Redshift is a plus. Preferred Qualifications Graduate degree in Computer Science, Mathematics, Statistics, Finance, related technical field Strong ability to effectively communicate with both business and technical teams Demonstrated experience delivering actionable insights for a consumer business Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.) Basic Experience with Cloud technologies Experience in banking domain is a plus

© 2021 SVB Financial Group. All rights reserved. SVB, SVB FINANCIAL GROUP, SILICON VALLEY BANK, MAKE NEXT HAPPEN NOW and the chevron device are trademarks of SVB Financial Group, used under license. Silicon Valley Bank is a member of the FDIC and the Federal Reserve System. Silicon Valley Bank is the California bank subsidiary of SVB Financial Group (Nasdaq SIVB).

Equal Employment Opportunity

Silicon Valley Bank is an equal opportunity employer and is dedicated to expanding its commitments and investments to create a more diverse, equitable and inclusive company culture and innovation ecosystem. We are strongly committed to the values and policy of equal employment opportunity across our employment practices.

Silicon Valley Bank is registered in England and Wales at Alphabeta, 14-18 Finsbury Square, London EC2A 1BR, UK under No. FC029579. Silicon Valley Bank is authorised and regulated by the California Department of Business Oversight and the United States Federal Reserve Bank authorised by the Prudential Regulation Authority with number 577295 and subject to regulation by the Financial Conduct Authority and limited regulation by the Prudential Regulation Authority. Details about the extent of our regulation by the Prudential Regulation Authority are available from us on request.
Show more Show less"
2811276121,Data Engineer,MediaMath,2021-11-02,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","MediaMath helps the world's top brands deliver personalized digital advertising across all connected touchpoints. Over 9,500 marketers in 42 countries use our demand-side platform every day to launch, analyze, and optimize their digital advertising campaigns across display, native, mobile, video, audio, digital out of home, and advanced TV formats.

MediaMath initiated an industry-wide effort to create a 100% accountable, addressable and aligned supply chain through SOURCE ecosystem. SOURCE by MediaMath is a technical and commercial framework for agencies, brands, tech companies, and content owners designed to provide long-term sustainable solutions for a clean digital media supply chain with brand-safe, viewable inventory. MediaMath has offices in 15 cities worldwide and is headquartered in New York City.

Key Responsibilities

MediaMath’s Analytics Engineering team is currently seeking a Data Engineer with the knowledge, passion, and capability to build and work with complex datasets that are used by Analytics to discover and deliver insights that drive value for our clients. The Analytics team fulfils customers’ advanced analytics and reporting needs through custom reports and analyses, advanced statistical applications, predictive modelling and interactive web dashboards to help clients effectively manage campaigns and optimize performance. As the Data Engineer on the Analytics Engineering team within the Analytics team, you will support these initiatives through building, maintaining, and optimizing data infrastructure.

You Will

Become an expert in MediaMath data flows and the Analytics data infrastructure
Build, maintain, and own scalable data pipelines to support client data integration
Become a team SME in data munging and automated ETL processes
Work with Analysts to understand and leverage big data to solve client problems and needs
Ensure that data pipelines/systems adhere to team and company standards, and raise the bar on the standards when possible
Be a team player and bring the team and company forward by solving team and company priorities

You Are

Experienced in writing readable, re-usable code SQL and Python (our entire team uses Jupyter Notebook and Pandas!)
Experienced with distributed system technologies, Hadoop, HiveQL, and Spark SQL/PySpark
Experienced in implementing data pipeline health monitoring, alerting
Experienced with data infrastructure troubleshooting and working with system logs
Experienced developing data flow schematics/blueprints
Advocate for automation and building efficient, scalable solutions
Self-driven, with a hunger to learn and spread knowledge by teaching others
Excellent communication skills – ability to synthesize and communicate technical concepts, limitations, and requirements to client-facing teams and stakeholders

You Have

1 - 3 years of experience in building, troubleshooting, and optimizing production ETL pipelines - ideally held a Data Engineer position previously
Experience with data modelling, data integration, and working with disparate data sources, including APIs and relational databases
Experience partnering with client-facing teams to understand client needs and translate them to technical requirement

Nice-to-have’s

Experience with cloud computing technology, preferably AWS (EC2, S3, RDS, Lambda)
Experience working with REST APIs, web services, object-oriented technologies
Public GitHub repos or notebooks that illustrate the way you think about data
Exposure to ad-tech, digital marketing, or e-commerce industries

Why We Work at MediaMath

We are restless innovators, smart, passionate and kind. At the heart of our culture are six values that provide a framework for how we approach our work and the world: Teams Win, Scale + Innovation, Obsess Over Learning & Growth, Align then Execute, Do Good Better and Embrace the Journey. These values inform how we energize one another and engage with our clients. They get us amped to come to work.

Founded in 2007 as a pioneer in ""programmatic"" advertising, MediaMath is recognized as a Leader in the Gartner 2020 Magic Quadrant for Ad Tech and has won Best Account Support by a Technology Company for two years in a row in the AdExchanger Awards.

MediaMath is committed to equal employment opportunity. It is a fundamental principle at MediaMath not to discriminate against employees or applicants for employment on any legally-recognized basis including, but not limited to: age, race, creed, color, religion, national origin, sexual orientation, sex, disability, predisposing genetic characteristics, genetic information, military or veteran status, marital status, gender identity/transgender status, pregnancy, childbirth or related medical condition, and other protected characteristic as established by law.
Show more Show less"
2794017142,Data Engineer 1,Providence,2021-11-10,United States,"Beaverton, OR",Information Technology,Full-time,"Financial Services, Wellness and Fitness Services, and Hospitals and Health Care","Description

Providence is calling a Data Engineer 1 to one of our locations in the Seattle area, Portland, OR, or Irvine, CA.

We are seeking a Data Engineer 1 who will design and build modern data-centric software applications to support clinical and operational processes across all parts of the healthcare system. These applications leverage cloud computing, big data, data science, and modern software development methodologies and frameworks. Builds data pipelines and transformations, data enrichment processes, provisioning layers, and user interfaces to meet the requirements of key initiatives. Enjoys a fast pace and has a focus on regular delivery. Seeks simple solutions to complex problems through the use of modern and emerging methods and tools. Emphasizes sharing and enables collaboration with meticulous source control and documentation. Works closely with the Product, Platform, and Architecture teams to deliver on joint efforts.

In This Position You Will Have The Following Responsibilities

Design, build and deliver quantitative applications that improve operations and generate value.
Participate in DevOps, Agile, and continuous integration frameworks.
Stay abreast of emerging technologies, open source projects, and best practices in the field.
Data warehousing, big data, enterprise search, business intelligence, analytics, modern and mobile applications.
Build processes that are fault-tolerant, self-healing, reliable, resilient and secure.
Work effectively and in real-time with other developers, product managers, and customers to deliver on collective goals.
Actively participate in code reviews, support the overall code base, and support the establishment of standard processes and frameworks.
Take an open and transparent approach to the work by sharing code and expertise, by consulting peers for problem-solving, and by being a mentor to peers.

Qualifications

Required qualifications for this position include:

Bachelor's Degree in Computer Engineering, Computer Science, Mathematics, Engineering or equivalent education/experience,
1 year Related experience.

Preferred Qualifications For This Position Include

Master's Degree in Computer Engineering, Computer Science, Mathematics, Engineering or equivalent education/experience.
1-3 years Related experience.

About The Department You Will Serve.

Providence Shared Services provides a variety of functional and system support services for our Providence family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise.

We offer comprehensive, best-in-class benefits to our caregivers. For more information, visit

https://www.providenceiscalling.jobs/rewards-benefits/

Our Mission

As expressions of God’s healing love, witnessed through the ministry of Jesus, we are steadfast in serving all, especially those who are poor and vulnerable.

About Us

Providence is a comprehensive not-for-profit network of hospitals, care centers, health plans, physicians, clinics, home health care and services continuing a more than 100-year tradition of serving the poor and vulnerable. Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.

Schedule: Full-time

Shift: Day

Job Category: Analytics/Business Intelligence

Location: Washington-Renton

Other Location(s): Washington-Seattle, Oregon-Beaverton, Washington-Redmond, California-Irvine

Req ID: 321034
Show more Show less"
2825650544,Data Engineer,Planet Technology,2021-12-03,United States,United States,Information Technology,Full-time,Staffing and Recruiting,"We are looking for a Data Developer to join our growing team of data and analytics experts. In this role you will be responsible for expanding and optimizing our data products and services, including data modeling, data quality automation and alerting, data pipeline architecture and development, and automated data integration.




The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Developer will support our database architects, data analysts and report developers on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.




Responsibilities:




Build out and deploy extract, transform, and load ETL pipelines and data access services on a big data cloud platform
Support designing, building and maintaining scalable data platforms that use emerging big data technologies
Perform analytical exploration and examination of data from multiple data sources
Participate in enforcing data quality and governance best practices in the data platform
Work with a multi-disciplinary team consisting of data analysts, data engineers, developers and data consumers in an agile, fast-paced environment
Work with and support a team that is globally located
Make technical design and coding decisions under advisement of system architects and management
Work with a cross section of business stakeholders, data analysts and management to understand and document business requirements
Work with project managers and data architects to create and document technical project proposals that include estimates, planning and schedules
Participate in review processes that involve architecture, design and quality assurance to preemptively identify conflicts and ensure consistency of implementation
Participate in identifying, resolving and monitoring production support items as assigned
Perform functional and integration tests, develop testing scripts and guide others in testing of data solutions
Ensure strict adherence to documentation best practices and change control processes




Qualifications:




5+ years of direct experience in cloud data solution architectures, design and development including ETL, data warehousing, data lakes, and big data
5+ years of experience creating, executing, and documenting unit test plans for ETL and data integration processes and programs
5+ years of experience using SQL including development of stored procedures, functions, triggers and views
5+ years of direct experience using Snowflake and Snowflake utilities such as
5+ years of direct experience working in a cloud environment such as AWS, Azure or CGP
2+ years of direct experience with AWS EMR, Glue, Athena and S3
2+ years of direct experience with streaming data architectures and technologies for real-time and low-latency data process

Show more Show less"
2816358460,Cloud Data Engineer,HSK Technologies Inc,2021-11-30,United States,"Trenton, NJ",,Contract,,"Candidate should have prior experience with AWS and Azure.




Additional Cloud-based tools experience is considered to be important (see skills section)

Additional desired skills include experience with the following:

• Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.

• Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.

• Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.

• Strong analytic skills related to working with unstructured datasets.

• Build processes supporting data transformation, data structures, metadata, dependency and workload management.

• A successful history of manipulating, processing and extracting value from large disconnected datasets.

• Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.

• Strong project management and organizational skills.

• Experience supporting and working with cross-functional teams in a dynamic environment.

• We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:

• Experience with big data tools: Spark, Kafka, etc.

• Experience with relational SQL and NoSQL databases, including Postgres

• Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.

• Experience with AWS cloud services: EC2, EMR, RDS, Redshift

• Experience with stream-processing systems: Storm, Spark-Streaming, etc.

• Experience with object-oriented/object function scripting languages: Python, Java, etc.

Show more Show less"
2808116779,Data Engineer,Deckers Brands,2021-11-25,United States,"Tacoma, WA",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2825181532,Backend/Data Engineer,Mediaocean,2021-12-03,United States,"New York County, NY",Information Technology,Full-time,Computer Software,"Job Description

What You Will Do:

As a Backend Software Engineer on the Mediaocean team, you will be responsible for helping craft the future of our offerings - from the database layers to the APIs that surface our data and functionality to our users. A little about our team: we've built a large Python Flask application that is supported by an array of smaller services, and are in the process of adding further robustness to our systems by doubling down on service-based architecture. We integrate with a myriad of third-party APIs which require a rigorous attention to detail and creative solutions to ensure we handle all situations gracefully. We also design and build data engineering pipelines that enable large volumes of data to go through layers of ETL processing and analysis.

Responsibilities Will Include

Have autonomy to work on what matters and have an impact immediately
Build, test and ship well-engineered features and enhancements
Design, support, maintain and upgrade highly performant and tested APIs and internal services using tools like Python, Celery, Kubernetes, MySQL, Postgre, Mongo, Redis, AWS Redshift
Articulate a long-term vision for maintaining and scaling our systems
Work with other engineers, product managers, designers and company leadership to turn our vision into a concrete roadmap every quarter and to help develop an amazing experience for our agency & brand customers.

Who You Are

3+ years of experience in software engineering with strong sense of computer science fundamentals
You demonstrate strong critical thinking ability, such as you have a Computer Science degree, or prior work experience (in a technical role, or otherwise), went to a coding school, or you are self-taught, or some combination of the above
Proficiency in Python
Relational Databases - Postgre, MySql
NoSQL Databases - Mongo
Experience handling large amounts of data, building warehousing pipelines
Experience with large scale data warehousing tech like AWS Redshift is a plus

Why Mediaocean?

Full healthcare benefits (PPO & CDHP medical plans, dental, and vision) & 401k
New parents are offered six weeks paid leave
Open PTO; vacation/sick/religious observances/philanthropy opportunities
Professional development opportunities within our Learning & Development programs
Belong@Mediaocean affinity based groups of colleagues to create community
All of these benefits/perks are effective on the date of hire

We would hate to miss out on your application because you do not meet every requirement – transferrable skills and education will also be considered, so please do not hesitate to apply!

Mediaocean recognizes our true strength and value shine when all our team members feel there is space in the conversation for their voices, thoughts, ideas, perspectives, and concerns. Mediaocean is committed to being an equal opportunity employer, and we consider all applicants regardless of their age, race, color, gender, sexual orientation, ethnicity, religion, national origin, disability, or veteran status.
Show more Show less"
2788315173,Data Engineer 1,Providence Health & Services,2021-11-11,United States,"Renton, WA",Information Technology,Full-time,"Financial Services, Wellness and Fitness Services, and Hospitals and Health Care","Description

Providence is calling a Data Engineer 1 to one of our locations in the Seattle area, Portland, OR, or Irvine, CA.

We are seeking a Data Engineer 1 who will design and build modern data-centric software applications to support clinical and operational processes across all parts of the healthcare system. These applications leverage cloud computing, big data, data science, and modern software development methodologies and frameworks. Builds data pipelines and transformations, data enrichment processes, provisioning layers, and user interfaces to meet the requirements of key initiatives. Enjoys a fast pace and has a focus on regular delivery. Seeks simple solutions to complex problems through the use of modern and emerging methods and tools. Emphasizes sharing and enables collaboration with meticulous source control and documentation. Works closely with the Product, Platform, and Architecture teams to deliver on joint efforts.

In This Position You Will Have The Following Responsibilities

Design, build and deliver quantitative applications that improve operations and generate value.
Participate in DevOps, Agile, and continuous integration frameworks.
Stay abreast of emerging technologies, open source projects, and best practices in the field.
Data warehousing, big data, enterprise search, business intelligence, analytics, modern and mobile applications.
Build processes that are fault-tolerant, self-healing, reliable, resilient and secure.
Work effectively and in real-time with other developers, product managers, and customers to deliver on collective goals.
Actively participate in code reviews, support the overall code base, and support the establishment of standard processes and frameworks.
Take an open and transparent approach to the work by sharing code and expertise, by consulting peers for problem-solving, and by being a mentor to peers.

Qualifications

Required qualifications for this position include:

Bachelor's Degree in Computer Engineering, Computer Science, Mathematics, Engineering or equivalent education/experience,
1 year Related experience.

Preferred Qualifications For This Position Include

Master's Degree in Computer Engineering, Computer Science, Mathematics, Engineering or equivalent education/experience.
1-3 years Related experience.

About The Department You Will Serve.

Providence Shared Services provides a variety of functional and system support services for our Providence family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise.

We offer comprehensive, best-in-class benefits to our caregivers. For more information, visit

https://www.providenceiscalling.jobs/rewards-benefits/

Our Mission

As expressions of God’s healing love, witnessed through the ministry of Jesus, we are steadfast in serving all, especially those who are poor and vulnerable.

About Us

Providence is a comprehensive not-for-profit network of hospitals, care centers, health plans, physicians, clinics, home health care and services continuing a more than 100-year tradition of serving the poor and vulnerable. Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.

Schedule: Full-time

Shift: Day

Job Category: Analytics/Business Intelligence

Location: Washington-Renton

Other Location(s): Washington-Seattle, Oregon-Beaverton, Washington-Redmond, California-Irvine

Req ID: 321034
Show more Show less"
2679244818,Data Engineer II,Whole Foods Market,2021-11-24,United States,"Austin, TX",Information Technology,Full-time,"Food and Beverage Services, Manufacturing, and Retail","Whole Foods Market is looking for Data Engineers who are passionate and innovative and have a heart for Nourishing People and the Planet, to join the Data and Analytics Tech Apps (DATA) team. This team is closely aligned with our company's strategic goals. Our mission is to modernize and tackle some of our most complex and challenging data storage, moving, and reporting projects while providing innovative and stable technical solutions which advance the retail grocery industry.

This Role: Everyone on the team is expected to have an entrepreneurial spirit and be capable of wearing many hats in highly collaborative environment. As a WFM Data Engineer, you will help tackle and support a diverse landscape of technical data challenges, as we reduce reliance on some legacy technologies, continuing our migration to AWS. You will play a key role in translating business requirements into systems and concepts in partnership with technology leaders within the team, from Amazon, and across the business.

A Successful Candidate Will

Work with ambiguity. You are collaborative while independently trusted to design, implement, and deploy data solutions for which the logical data model and requirements might not be well defined, or the requirements are defined as code in a legacy system which requires some translation. You solve difficult problems generating positive feedback.
Have a desire to influence mid-size data solutions by enabling correct processes and access to data in the team's chosen architecture. You have established good working and mentoring relationships with teammates and peers. You recognize discordant views and take part in constructive dialogue to resolve them.
Be ready to advise your fellow Engineers, Product Managers, and Manager. Your work is consistently of a high quality (e.g., secure, testable, maintainable, low-defects, efficient, well documented etc.) and incorporates best practices. Your team trusts your work.
Show up with technical acumen. You have a solid understanding of data design patterns and approaches and how to best use them. You will understand and contribute to the team's data architecture mission and be insightful as to when to make technical trade-off decisions at dataset(s) level.
Build and optimize logical data models and data pipelines for difficult datasets. Your data model and code reviews for tend to be rapid and uneventful. You provide useful review comments for changes submitted by others.
Have the desire to make a lasting impact on analytics and self-service access to datasets, continually increasing business effectiveness. You focus on operational excellence, constructively identifying problems and proposing solutions, taking on projects that improve your team data tools, continually striving to making them better and easier to maintain. You can confidently train new teammates about your customers' needs, and your team's practices. You know how each of our tools are constructed, tested, operate, and how they fit into the bigger picture (The Everclear Proj ect) .
Be mindful of making improvements to your team's development processes. You establish automated processes which meet SLAs and define patterns which pass data compliance and certification standards.
Keep the lights on. While we are moving quickly into our future, we do have existing ETL and SQL platforms, for which you will be ready to learn about and contribute to their support .

Basic Qualifications

3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience scripting custom processes in Python, Java or equivalent
Degree in Computer Science, Engineering, Mathematics, or a related field or 7+ years industry experience
Relevant experience in analytics, data engineering, business intelligence, market research or related field
Experience gathering business requirements, using industry standard business intelligence tool(s} to extract data, formulate metrics and build reports
Experience using SQL, ETL and databases with large-scale, complex datasets
Curious and focused on continuous improvement (self and systems}

Preferred Qualifications

Graduate degree in computer science, business, mathematics, statistics, economics, or other quantitative field
Both technically deep and business savvy enough to interface with all levels and disciplines within the organization
Demonstrated ability to coordinate projects across functional teams, including Tech, product management, marketing, finance, and operations
Knowledge of Advanced SQL and a programming language
Experience with data visualization using Tableau or similar tools
Experience with large-scale data warehousing and analytics projects, including using AWS technologies- Redshift, S3, EC2, Data-pipeline and other big data technologies
Proven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teams

At Whole Foods Market, we provide a fair and equal employment opportunity for all Team Members and candidates regardless of race, color, religion, national origin, gender, pregnancy, sexual orientation, gender identity/expression, age, marital status, disability, or any other legally protected characteristic. Whole Foods Market hires and promotes individuals solely based on qualifications for the position to be filled and business needs.
Show more Show less"
2814235911,Big Data Engineer - FreeWheel (virtual or in office),FreeWheel,2021-11-05,United States,"Chicago, IL",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Internet Publishing, and Telecommunications","Comcast brings together the best in media and technology. We drive innovation to create the worlds best entertainment and online experiences. As a Fortune 50 leader, we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines. We are at the forefront of change and move at an amazing pace, thanks to our remarkable people, who bring cutting-edge products and services to life for millions of customers every day. If you share in our passion for teamwork, our vision to revolutionize industries and our goal to lead the future in media and technology, we want you to fast-forward your career at Comcast.

Job Summary

FreeWheel, a Comcast company, is looking for a Big Data Engineer to be responsible for the following: Planning and designing new software and web applications. Analyzes, tests and assists with the integration of new applications. Documents all development activity. Assists with training non-technical personnel. Has in-depth experience, knowledge and skills in own discipline. Usually determines own work priorities. Acts as a resource for colleagues with less experience.

Job Description

Core Responsibilities

At least 2-5 years of experience with designing, implementing, and maintaining data pipelines, building scalable and optimized enterprise data systems
Scale ETL pipelines and infrastructure to the next level
Production level experience with an ETL scheduling tool, data warehousing in AWS
Manage data ingestion using various methods to transform raw data into useful data systems
Grounded knowledge of SQL, Python, AWS and with a deeper understanding of at least one commonly used DB (Postgres, Athena)
Strong data analysis skills (writing complex queries, store procedures)
Develop tools supporting self-service data pipeline management (ETL)
Evolve data model and data schema based on business and engineering needs
Collaborate with project stakeholders to identify product and technical requirements. Conduct analysis to determine integration needs.
Other duties and responsibilities as assigned.

Company Description

FreeWheel, A Comcast Company, empowers all segments of The New TV Ecosystem. We are structured to provide the full breadth of solutions the advertising industry needs to achieve their goals. We provide the technology, data enablement and convergent marketplaces required to ensure buyers and sellers can transact across all screens, across all data types, and all sales channels, in order to ensure the ultimate goal – results for marketers. With offices in New York, San Francisco, Chicago, London, Paris, Beijing, and across the globe, FreeWheel, A Comcast Company, stands to advocate for the entire industry through the FreeWheel Council for Premium Video. For more information, please visit freewheel.com.

Employees at all levels are expected to

Understand our Operating Principles; make them the guidelines for how you do your job.
Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services.
Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences.
Win as a team - make big things happen by working together and being open to new ideas.
Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers.
Drive results and growth.
Respect and promote inclusion & diversity.
Do what's right for each other, our customers, investors and our communities.

Disclaimer

This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.

Comcast is an EOE/Veterans/Disabled/LGBT employer.

#freewheelproductjob #freewheelengineeringjob

Education

Bachelor's Degree

Relevant Work Experience

2-5 Years

Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details.
Show more Show less"
2813148341,Data Engineer - Remote,The Hartford,2021-10-31,United States,"Charlotte, NC",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

Come join The Hartford’s talented Sales and Distribution (S&D) IT team as Data Engineer to help drive the data vision aligned to the business strategy!! We are seeking a detail-oriented, results-driven Data Engineer to support projects in an agile environment. Successful candidates will demonstrate strong technical, analytical and interpersonal skills accompanied with proven experience in delivering quality technical solutions, as well as setting and executing on a strategic technical vision. In addition, candidates must have an aptitude to understand existing processes and systems and the desire to continually improve these processes and systems. They should be able to make decisions quickly in consultation with team members and build relationships, actively participate in team work, and understand the dynamics and critical nature of the business.

Responsibilities Of The Position Include

Assisting in designing and implementing application integration involving a range of applications from third party off premise cloud applications to on premise legacy applications
Understand and implement the technical vision for projects, or systems, keeping in mind cross-functional impacts, organizational impacts and architecture rationalization
Operate as a subject matter expert advocating for the software applications supported. Possess a depth and breadth of knowledge for the application’s business, technologies, integration.
Responsible for end to end technical solution, goes beyond borders to ensure success of overall technical solution. Works closely with vendor software providers to drive optimal solutions.
Directly develop application components and oversee technical deliverables from junior Developers through the software development life cycle
Proactively address technical issues and risks that could impact project schedule and/or budget
Work closely with stakeholders to design and document automation solutions that align with the business needs and also consistent with the architectural vision

Qualifications Of The Position Include

Bachelor’s Degree or equivalent work experience with at least three or more years of programming/systems analysis developing integration solutions
Experience with Microsoft SQL services, including SQL Server Integration Services (SSIS) and SQL Server Reporting Services (SSRS)
Experience with relational databases such as: Oracle, SQL Server, and PL/SQL
Ability to leverage native integration capabilities of commercial off-the-shelf software
Demonstrate skills in shaping and leading development of technical specifications
Strong problem solving and analysis skills
Demonstrated ability to complete tasks within established timelines
Attention to detail and ability to manage multiple priorities
High level of independence but is also a team player
Strong relationship building skills and communication skills - written and verbal
Enthusiastic, self-starter
Agile development framework and DevOps implementation experience a strong plus

Insurance acumen, Cloud and Talend is a strong plus

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$90,480 - $135,720

Benefits

Our company’s success is due to our employees’ dedication and passion for their work. They are our greatest asset. That’s why we are committed to offering employees and their families a comprehensive benefits package and award-winning well-being programs. By helping our employees achieve their full potential, we unlock our own. Visit https://www.thehartford.com/careers/benefits for details.

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

Data Engineer - GE08AE
Show more Show less"
2808348577,Data Engineer,Honeywell,2021-11-01,United States,"Tempe, AZ",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Join a team recognized for leadership, innovation and diversity

The future is what you make it. When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers and doers who make the things that make the future. That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings smart and safe and even making it possible to breathe on Mars. Working at Honeywell isn’t just about developing cool things. That’s why all our employees enjoy access to dynamic career opportunities across different fields and industries.

Are you ready to help us make the future?

Join a company that is transforming from a traditional industrial company to a contemporary digital industrial business, harnessing the power of cloud, big data, analytics, Internet of Things, and design thinking. You will lead change that brings value to our customers, partners, and shareholders through the creation of innovative software and data-driven products and services. You will work with customers to identify their high value business questions and work through their data to search for answers. You will be responsible for working within Honeywell to identify opportunities for new growth and efficiency based on data analysis.

Key Responsibilities

As a Data Engineer, you will be part of a team that delivers contemporary analytics solutions for the Data Management & Analytics function at Honeywell. You will build strong relationships with leadership to effectively deliver contemporary data analytics solutions and contribute directly to business success. You will develop solutions on various Database systems viz. Hive, Hadoop, SnowFlake, etc.

You will identify and implement process improvements – and if you don’t like to do the same thing twice, you will automate where possible. You are always keeping an eye on scalability, optimization, and process. You have worked with Big Data before, IoT data, SQL, Azure, AWS, SnowFlake

You will work on a team including scrum masters, product owners, data architects, data engineers/analyst, data scientists and DevOps. You and your team collaborate to build products from the idea phase through launch and beyond. The software you write makes it to production in sprints. Your team will be working on creating a new platform using your experience of APIs, microservices, and platform development.

YOU MUST HAVE

US Citizenship due to export control restrictions
Bachelor's degree in Computer Science, Engineering, Applied Mathematics, or other technical degree
4+ years of data warehouse experience including ETL and SQL

WE VALUE

Should have developed and deployed complex big data ingestion jobs in Talend/Informatica BDM bringing prototypes to production on Hadoop/NoSQL/MPP platforms.
Hands on experience with MapReduce, Pig/Hive, Spark, etc. and automation of data flow using NiFi and Airflow/Oozie.
Experience in developing and building applications to process very large amounts of data (structured and unstructured), including streaming real-time data (Spark, R/Python, Scala, Kafka, Spark streaming or other such tools).
Experience in working with at least one NoSQL system (HBase, Cassandra, MongoDB etc.). In-depth knowledge of schema design to effectively tackle the requirement.
Experience in writing complex SQL statements
Experience in working with cloud-based deployments. Understanding of containers & container orchestration (Swarm or Kubernetes).
Hands on experience in Cloudera, Hortonworks and/or Cloud (AWS EMR, Azure Data Lake Storage) based Hadoop distributions.
Good understanding of branching, build, deployment, CI/CD methodologies such as Octopus and Bamboo
Experience working with in Agile Methodologies and Scrum Knowledge of software best practices, like Test-Driven Development (TDD)
Effective communication skills and succinct articulation
Experience in building advanced analytics solutions with data from enterprise systems like ERPs, CRMs, Marketing tools etc.
Experience with dimensional modeling, data warehousing and data mining
Experience with machine learning solutions and data science methods promotion
Database performance management and API development
Technology upgrade oversight
Experience with visualization software, Tableau preferred.
Understanding of best-in-class model and data configuration and development processes
Experience working with remote and global teams and cross team collaboration
Consistently makes timely decisions even in the face of complexity, balancing systematic analysis with decisiveness

Additional Information

JOB ID: req259339
Category: Information Technology
Location: 855 S Mint St,Charlotte,North Carolina,28202,United States
Exempt
Must be a US Citizen due to contractual requirements.

Global (ALL)

Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, religion, or veteran status.
Show more Show less"
2812348745,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"Portland, OR",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2786179196,Data Engineer,Molson Coors Beverage Company,2021-11-09,United States,"Milwaukee, WI",Information Technology,Full-time,"Food and Beverage Services, Manufacturing, and Financial Services","Already an employee? You must apply through our internal portal: click here

Data Engineer

Date: Nov 9, 2021

Location:

Milwaukee, WI, US

Requisition ID: 18916

A Career In Beer And Beyond

Our purpose at Molson Coors Beverage Company is to brew beverages that unite people to celebrate all life’s moments. We’ve been brewing iconic brands for over 350 years and are now proud to be offering a modern portfolio that expands beyond the beer aisle.

We are Talent Brewers with our culture routed in our core Values. We believe in our brands and our people, and that diversity WITH inclusion is the key to a winning team culture. We want you to join our team of brand ambassadors who believe the world is full of untapped opportunities. So, if you get excited about making a real difference as part of a winning team like we do, we want to hear from you.

The Headlines

In the role of Data Engineer working in Milwaukee, WI you will be part of the Global IT Project Delivery Buisness Intelligence and Analytics team. You will decide the design and lead or directly perform the build, integration, and implementation data solutions in the data warehouse or in analytics platforms to provide solutions to the business.

The Responsibilities

Under the direction of the Data Engineering Manager, lead or directly participate in the design, development, deployment, and transition of solutions to address business requirements.
Determine the data needs, then retrieve, stage, and transform the data to enable the required advanced analytical insights and business intelligence solutions.
Provide flexible solutions in a rapid paced environment and react to changes in solutions as the analytics used in the business change.
Ensure standards are met so that solutions deployed have technical integrity and stability.
Serve as a subject matter expert for Informatica IICS and/or advanced analytic tools (Data Services, Informatica, Databricks, Python, etc.).
Experience in connecting to various data sources like SAP ECC \ HANA, SalesForce, Teradata, API’s etc.
Build cross-functional relationships with Business Stakeholders, Architects, Data Scientists, BI Managers, and Business Partners to understand data needs and help projects and agile teams deliver on those needs.
Responsible for requirement gathering, analysis and documentation.
Co-Ordinate with Onsite and Offshore team
Responsible for reviewing design and all project related deliverables to ensure adherence to standards and best practices
Responsible for making sure the requirements are defined and properly documented. Responsible for ensuring the final application meets the defined functional requirements. Coordinate with other Client business user groups and subject matter experts directly

The Other Qualifications

You have experience building end-to-end data solutions with focus on integration
You have a strong understanding of data and information architecture
You are proficient in Informatica Power Center or IICS
You are proficient in Data analysis techniques with SQL or another ETL/MDM tool experience is a plus
You have automation scripts development knowledge and execution
You have experience in Data Warehouse/ETL & BI concepts, testing methodologies.
You have experience with System Integration
Preferably you have a bachelor’s degree

Work Perks That You Need To Know About

Flexible work programs that support work life balance including a hybrid work model of 3 days in the office
We care about our People and Planet and have challenged ourselves with stretch goals around our key priorities
We care about our communities, and play our part to make a difference – from charitable donations to hitting the streets together to build parks, giving back to the community is part of our culture and who we are
Engagement with a variety of Employee Resource Groups, which can provide volunteer opportunities, leadership experience, and networking through the organization
Ability to grow and develop your career centered around our First Choice Learning opportunities
Participation in our Total Rewards program with a competitive base salary, incentive plans, parental leave, health, dental, vision, 401k option with incredible employer match, generous paid time off plans, an engaging Wellness Program, and an Employee Assistance Program (EAP) with amazing resources
On site Pub, access to cool brand clothing and swag, top events and, of course... free beer and beverages!
Work within a fast paced and innovative company, meeting passionate colleagues and partners with diverse backgrounds and experiences

At Molson Coors, the health and safety of our people is our number one priority. That’s why all offers of employment in the U.S. where legally permitted are contingent on the candidate showing proof of being fully vaccinated against Covid 19 (currently one dose of the Johnson & Johnson vaccine or two doses of the Pfizer or Moderna vaccine) to pass the pre-employment requirements. Individuals with medical issues or religious beliefs or practices that prevent them from getting the vaccine may request an exemption from the vaccine requirement.

At Molson Coors we seek diversity. Differing perspectives lead to challenging the expected, which keeps new ideas bubbling up. We’re an equal opportunity employer and invite applications from candidates from all backgrounds, race, color, religion, sex, sexual orientation, national origin, gender identity, age, disability, veteran status or any other characteristic. We take pride in celebrating our unique brew.

Nearest Major Market: Milwaukee
Show more Show less"
2789630063,Data Engineer,Zoom,2021-12-03,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2814555389,Data Engineer,edX,2021-11-01,United States,"Cambridge, MA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Your Impact

Data Engineering has built a best in class data platform leveraging tools such as snowflake, dbt_ and prefect. Now that the foundations have been laid the team is beginning to look toward what is next; and evolving our foundation to climb to the next rung of the analytics maturity model.

edX is looking to add a Data Engineer to set their vision on that next rung and to help us climb.

Your work will enable the Data group to evolve, automate and scale and impact edXers across the company as we keep the data flowing and enable edX to continue to mature as a data-driven organization - and achieve our potential to transform education for learners globally.

Your Team

The Data Engineering (DE) team’s work lies at the foundation of all that edX does. The accurate, timely and usable data that DE provides to the organization drives business reporting and decision-making, product innovation, customer-facing data offerings and more.

Data Engineering works alongside data analysts and scientists, product engineering, and business stakeholders across the organization to provide the data platform and technical solutions that enable edX to drive value from its data. If you are looking to make an outsized impact on an organization, Data Engineering at edX is the place for you.

You Will

Maintain and help improve Data Engineering’s best in class infrastructure
Be relentless in your distaste for toil; automating and removing processes and systems that are no longer serving their purpose
Build automation and tooling to help data move fast, we strive for idempotent, reproducible systems and results
Be data driven in your work, instrumenting the tools Data Engineering builds and tuning system performance
Rapidly diagnose and resolve faults with data services and pipelines as a member of an on-call rotation - ensuring the data flows throughout our ecosystem smoothly
Collaborate with peers in and out of the Data team to troubleshoot and propose and document solutions
Proactively communicate issues, status or roadblocks
Help optimize alerting, data processes and on-call rotations to reduce fatigue and improve efficiency of our operation

You Have

Experience in a dev-ops or site reliability engineering role or
Experience building efficient data pipelines, performance tuning, and integrating disparate data sources and types, including high volume semi-structured and unstructured data (e.g., JSON, etc.)
Understanding of cloud-based data warehousing and ELT/ETL techniques and processes
Experience working in AWS systems
Experience working in Python
Collaborative and pragmatic, with and enthusiasm for learning and continuous improvement

Preferred Experience

Experience with Snowflake and dbt_ (https://www.getdbt.com/)
Experience with pipeline data pipeline tools such as Prefect, Luigi or Airflow
Experience with or a desire to learn about Terraform and Kubernetes.
Experience master data management, data modeling and preparing data for analysis
Enthusiasm for Agile/Scrum processes

Why You’ll Like It Here

edX is collaborative at its core. You’ll work within your team and across the organization, allowing for continuous learning and discovery.
We’re on a mission to unlock our learners potential on a global level, seeking to create a more diverse, equitable and inclusive world.
We set outcomes that matter and provide value in all that we do, from building meaningful products to serving the edX community.

We understand that applying for a job can be intimidating. Applicants rarely meet every single job requirement, and we know there are many skills and backgrounds that will contribute to success in this role.

That’s Why We Provide New Employees With

Employee onboarding and training sessions
Personalized 30/60/90+ day plans
Individual quarterly and annual goals
Career pathways

And much more to support you in your personal journey at edX! That said, if this role looks like a great next step for you, please apply… even if you can’t “check every box.” We’d love to hear from you! edX is the education movement for restless learners. Together with our founding partners Harvard and MIT, we’ve brought together more than 38 million learners, the majority of top-ranked universities in the world, and industry-leading companies onto one online learning platform that supports learners at every stage. And we’re not stopping there—as a global nonprofit, we’re relentlessly pursuing our vision of a world where every learner can access education to unlock their potential, without the barriers of cost or location.
Show more Show less"
2814234946,Big Data Engineer - FreeWheel (virtual or in office),FreeWheel,2021-11-05,United States,"Boston, MA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Internet Publishing, and Telecommunications","Comcast brings together the best in media and technology. We drive innovation to create the worlds best entertainment and online experiences. As a Fortune 50 leader, we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines. We are at the forefront of change and move at an amazing pace, thanks to our remarkable people, who bring cutting-edge products and services to life for millions of customers every day. If you share in our passion for teamwork, our vision to revolutionize industries and our goal to lead the future in media and technology, we want you to fast-forward your career at Comcast.

Job Summary

FreeWheel, a Comcast company, is looking for a Big Data Engineer to be responsible for the following: Planning and designing new software and web applications. Analyzes, tests and assists with the integration of new applications. Documents all development activity. Assists with training non-technical personnel. Has in-depth experience, knowledge and skills in own discipline. Usually determines own work priorities. Acts as a resource for colleagues with less experience.

Job Description

Core Responsibilities

At least 2-5 years of experience with designing, implementing, and maintaining data pipelines, building scalable and optimized enterprise data systems
Scale ETL pipelines and infrastructure to the next level
Production level experience with an ETL scheduling tool, data warehousing in AWS
Manage data ingestion using various methods to transform raw data into useful data systems
Grounded knowledge of SQL, Python, AWS and with a deeper understanding of at least one commonly used DB (Postgres, Athena)
Strong data analysis skills (writing complex queries, store procedures)
Develop tools supporting self-service data pipeline management (ETL)
Evolve data model and data schema based on business and engineering needs
Collaborate with project stakeholders to identify product and technical requirements. Conduct analysis to determine integration needs.
Other duties and responsibilities as assigned.

Company Description

FreeWheel, A Comcast Company, empowers all segments of The New TV Ecosystem. We are structured to provide the full breadth of solutions the advertising industry needs to achieve their goals. We provide the technology, data enablement and convergent marketplaces required to ensure buyers and sellers can transact across all screens, across all data types, and all sales channels, in order to ensure the ultimate goal – results for marketers. With offices in New York, San Francisco, Chicago, London, Paris, Beijing, and across the globe, FreeWheel, A Comcast Company, stands to advocate for the entire industry through the FreeWheel Council for Premium Video. For more information, please visit freewheel.com.

Employees at all levels are expected to

Understand our Operating Principles; make them the guidelines for how you do your job.
Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services.
Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences.
Win as a team - make big things happen by working together and being open to new ideas.
Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers.
Drive results and growth.
Respect and promote inclusion & diversity.
Do what's right for each other, our customers, investors and our communities.

Disclaimer

This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.

Comcast is an EOE/Veterans/Disabled/LGBT employer.

#freewheelproductjob #freewheelengineeringjob

Education

Bachelor's Degree

Relevant Work Experience

2-5 Years

Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details.
Show more Show less"
2815633763,Big Data Engineer,Amazon Web Services (AWS),2021-11-27,United States,"Seattle, WA",Administrative,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Amazon Web Services (AWS) is looking for an innovative and passionate data engineer to architect and build new capabilities for our Investments Platform. A singular goal of this platform is to provide our field personnel with secure, highly available, scalable and performant solutions and services so that they can continue to provide excellent service to our customers. You will have the opportunity to join a dynamic team with diverse skill sets, be able to influence our technical direction and build exciting new capabilities that operate at Amazon scale.

We are looking for a hands-on Data Engineer with experience developing and delivering data platforms as we build the next iteration of our system. Come join a team at the beginning of a product life cycle and help define the way AWS does business with its key customers. As a Data Engineer in this team, you will be working on building and maintaining complex data pipelines, assembling large and complex datasets to generate business insights and to enable data driven decision-making. You will interface with several key stakeholders of this platform including our product, program leaders and with our key technical partners across AWS.

Core Responsibilities May Include

Design data schema and operate internal data warehouses and SQL/NOSQL database systems.
Design data models, implement, automate, optimize and monitor data pipelines.
Own the design, development and maintenance of ongoing metrics, reports, analytics, dashboards, etc. to drive key business decisions.
Analyze and solve problems at their root, stepping back to understand the broader context.
Manage Redshift/Spectrum/EMR infrastructure, and drive architectural plans and implementation for future data storage, reporting, and analytic solutions.
Work on different AWS technologies such as S3, Redshift, Lambda, Glue, etc. to provide new capabilities and increase efficiency.
Work on data lake platform and different components in the data lake such as Hadoop, Amazon S3 etc.
Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.
Must possess strong verbal and written communication skills, be self-driven, and deliver high quality results in a fast-paced environment.
Conduct rapid prototyping and proof of concepts.
Conceptualize and develop automation tools for bench marking data collection and analytics.
Interface with other teams to extract, transform, and load data from a wide variety of data sources using AWS big data technologies.

Inclusive Team Culture

Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance

Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded engineer and enable them to take on more complex tasks in the future.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the bias of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit: https://www.amazon.jobs/en/disability/us.


Basic Qualifications

Degree in Computer Science, Engineering, Mathematics, or a related field and 4-5+ years industry experience
Must have one year of experience in the following skill(s): (1) Developing and operating large-scale ETL/ELT processes; database technologies; data modeling (2) Experience with at least one relational database technology such as Redshift, RDS, Oracle, Postgres
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
3+ year of coding experience with modern programming or scripting language (Python, Scala, Java, C# etc.).
Advanced SQL and query performance tuning skills.
Experience with at least one massively parallel processing data technology such as Redshift, Spark or Hadoop based big data solutions

Preferred Qualifications

Master's/PhD degree in or Computer Science, Engineering, Mathematics or related discipline
Experience building data products incrementally and integrating and managing datasets from multiple sources
Query performance tuning skills using Unix/Linux profiling tools and SQL
Experience with AWS Tools and Technologies (Redshift, S3, EC2, Glue, Lambda, Sage Maker)
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role


Company - Amazon Web Services, Inc.

Job ID: A1823392
Show more Show less"
2798005581,"Data Engineer, WASE Hercules",Amazon,2021-11-18,United States,"Seattle, WA","Information Technology, Consulting, and Engineering",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

DESCRIPTION

Amazon Advertising is looking for a talented Data Engineer to help our Advertisers achieve success. Amazon Advertising operates at the intersection of eCommerce and advertising, offering a rich array of digital display advertising solutions with the goal of helping our customers find and discover anything they want to buy. We help advertisers reach Amazon customers on Amazon.com, across our other owned and operated sites, on other high quality sites across the web, and on millions of Kindles, tablets, and mobile devices. We start with the customer and work backwards in everything we do, including advertising. If you’re interested in joining a rapidly growing team working to build a unique, world-class advertising group with a relentless focus on the customer, you’ve come to the right place.

Key job responsibilities

The WorldWide Advertising Success Engineering (WASE) team is looking for a motivated Data Engineer who can build end-to-end data infrastructure. You will work with business and technology teams to develop scalable and innovative solutions that source terabytes of data, both batch and streaming, transform it into data structures relevant for making daily financial and product decisions, and expose it using tools that drive insights and actions. We’re a fast-growing team with a very high focus from business to grow, so there are lots of opportunities. No chance of getting bored here.

A day in the life

In This Role You Will

Partner with engineering, product, business and finance teams to create data pipelines and structures that provide key metrics and performance indicators.
Design, implement, and support an analytical data infrastructure providing ad-hoc access to large datasets and computing power.
Be responsible for the operation of data infrastructure and the quality of data sets.
Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency.

About The Team

We are a team of data-focused engineers within the Worldwide Advertiser Success Engineering (WASE) org, passionate about Big Data and finding novel ways to combine data and technology to build analytics and insights that are instrumental in the success of our advertisers.


Basic Qualifications

3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL

Preferred Qualifications

Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions, and data engineering strategy
Demonstrated ability in data modeling, ETL development, and data warehousing
Experience with querying and managing relational databases at petabyte scale
Experience with Big Data technologies, including Hadoop, Hive, and Spark
Experience using Business Intelligence reporting tools, including Quicksight, Tableau, and open source projects like Superset
Experience with AWS services, including Redshift, Lambda, EMR, and Glue
Experience with at least one modern programming language (Java, Python, Scala)
Experience with Redshift or other MPP data warehouse
Willingness to own all stages of development process: requirements, design, implementation, testing, and operational support

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon.com Services LLC

Job ID: A1802966
Show more Show less"
2818661595,Data Engineer,Alldus,2021-12-02,United States,United States,Information Technology,Full-time,IT Services and IT Consulting and Computer Software,"I'm currently partnering with a tech start-up that is driving AI performance optimization to help organizations reach their maximum delivery potential. The company was recently featured in CB Insights' 100 Most Promising Start-Ups, and they are searching for an experienced Data Engineer who is excited to play a pivotal role in the company's growth and development.




This fully-remote opportunity is open to candidates who possess a minimum of 2 years professional experience in…

…Python

…cloud environments (AWS, GCP, or Azure)

…machine learning platforms

…product-focused applications

…scaling in production environments

…CICD




MEGA bonus points if you have experience working with Kubernetes!

Show more Show less"
2810864228,Data Engineer,Iconic Technology Group,2021-11-23,United States,"Bedminster, NJ",Information Technology,Full-time,"IT Services and IT Consulting, Information Services, and Computer Software","Job Description

Job Title: Data Engineer

Job Location: Bedminster, NJ

Job Responsibilities

Design and support the database and table schemas for new and evolving sources of data being brought into the data warehouse
Create and support the Analysis Services
Monitor and troubleshoot performance issues
Define and promote the team’s design principles and best practices
Work with business teams to be able to define requirements for real time reporting

Required

Skills and Experience Required:

Very Strong in SQL (2012 or better): stored procedures, functions, views, joins, import/export data, and the ability to develop queries from SQL
Broad Knowledge of BIDS (Business Intelligence Development Studio) with heavy concentration in SSIS
Experience in Tableau and Power BI
Expertise in Excel and advanced excel skills, must be able to: connect to various data sources, conditional formatting, pivot tables & pivot reporting, functions & formulas, and sorting & filtering
Have the ability to identify data anomalies in a timely manner.
Previous Healthcare experience
Previous Fintech experience (banking, banking integrations, treasury, payments)

Desired

Visual Studio .NET
Additional Information

All your information will be kept confidential according to EEO guidelines.
Show more Show less"
2803480969,Data Engineer,DataStunt,2021-11-22,United States,United States,,Full-time,,"1-3 years of work experience in big-data applications.
Expertise in Java/ Python / Scala (either of them)
In depth knowledge of Apache Spark ( Core, SQL ) using Scala
Expertise in writing complex, optimized SQL queries
Proficiency with Linux/Unix
Understanding of workflow management components like Airflow or Oozie

GOOD TO HAVE: Sqoop, Hive, YARN, MapReduce, Spark Streaming, Azure, Data lake

Show more Show less"
2796602882,Data Developer,Spectrum,2021-10-19,United States,"Stamford, CT",Information Technology,Full-time,"IT Services and IT Consulting, Telecommunications, and Financial Services","Job Summary

Responsible for data engineering functions including, but not limited to: data extract, transformation, loading, integration in support of enterprise data infrastructures, data warehouse, operational data stores and master data management. Participate in multiple programs/systems as a project team member. Considered a subject matter expert for a single program/system. Diagnoses moderately complex issues.

Major Duties And Responsibilities

Actively and consistently supports all efforts to simplify and enhance the customer experience.

Implement data services, data structure/models and data movement infrastructures.

Implement concepts of programming such as data structures, error handling, data manipulation and I/O processing.

Provide preventative solutions and troubleshoot data job failures, including but not limited to error handling, data manipulation and I/O processing..

Implement database concepts and practices including definition and query language

Modify, enhance, and influence requirements and architecture specifications of data warehousing systems and/or processing infrastructure.

Work closely with the Insights team to design, implement, and support end-to-end data solutions across multiple platforms, environments, domains, and locations.

Participate in development of ETL processes, programs and solutions as per established standards.

Monitor and administer automated and manual data integration and ETL jobs to verify execution and measure performance.

Work closely with internal staff, vendors, consultants, and external partners to quickly identify and resolve data integration and ETL job issues.

Required Qualifications

Skills/Abilities and Knowledge

Ability to read, write, speak and understand English.

Experience with building use cases and providing development support to data scientists.

Experience with building use cases and providing development support to data engineers.

Experience with data lake - all data sources - building out data sets for uses cases.

Experience with building SQL/HIVE databases and tables.

Experience with querying and designing efficient warehousing structures.

Intermediate knowledge of data access methods from relational databases using SQL.

Intermediate knowledge of and hands on with web services (WSDL Soap, Restful) to access data from various source systems.

Knowledge of FTP/sFTP.

Excellent written and verbal communication skills.

Excellent analytical and troubleshooting abilities.

Education

Bachelor's degree or equivalent experience

Related Work Experience Number Of Years

ETL experience 3

Experience with SQL, Shell Script, Python, JSON 3

Data integration experience 1

Data visualization experience (Tableau, Alterx, Microstrategy) 1

Software engineering experience 1

Related Work Experience

PREFERRED QUALIFICATIONS

Experience with CSG and ICOMs billing systems and billing applications

Experience with order entry process and systems

WORKING CONDITIONS

Office environment

Our Commitment During COVID-19 Your health and safety is important to us, as such we’re using virtual recruiting tools to safely meet with qualified candidates. We are working in the office, following CDC guidelines.

Get to Know Us Charter Communications is known in the United States by our Spectrum brands, including: Spectrum Networks, Spectrum Enterprise and Spectrum Reach. When you join us, you’re joining a strong community of more than 95,000 individuals working together to serve more than 31 million customers in 41 states. Watch this video to learn more.

Who You Are Matters Here We’re committed to growing a workforce that reflects our communities, and providing equal opportunities for employment and advancement. Learn about our inclusive culture.
Show more Show less"
2807489328,Data Engineer - Product,Stitch Fix,2021-11-25,United States,"San Francisco, CA","Research, Analyst, and Information Technology",Full-time,"Apparel and Fashion, Internet Publishing, and Retail","About The Team

The data engineering team is a small, nimble group of data engineers that drive the company toward clean and informative data. As a member of the data engineering team, you’ll help power data science, ETLs, self-service data, and tools to make us efficient and facilitate scalable decision-making. As a team, we are driven by the thrill of building tools to help our colleagues use data with less friction, which ultimately increases the velocity at which the business can progress!

About The Role

Senior IC position on the data engineering team, within our Algorithms organization, focusing on our client and marketing data infrastructure, optimization and scalability
You will build and own large additions to our data engineering framework, charged with finding ways to create and improve scalable and reliable tables and central data pipelines
Work in a collaborative, production-facing codebase that has close coupling with engineering systems
You will build and own scalable, efficient, and well-tested data engineering solutions using Spark, Amazon S3, and a mature collection of in-house technologies.
You will be involved in the day-to-day operations of the team, including maintaining and improving our current tools & scripts and supporting full-stack data scientists
You will have autonomy to help shape the future of data engineering at Stitch Fix by bringing your ideas on improving and automating what we do and how we do it

You’re Excited About This Opportunity Because You Will...

Work with teams of world-class data scientists and engineers on how to solve data and business problems in a scalable way
Be part of a team which has high visibility across the organization
Contribute ideas and direct the team’s investment to impactful directions
Contribute to a culture of technical collaboration and scalable development

We Get Excited About Candidates Who Have…

5+ years of fully independent project experience with significant contributions.
Experience in building out scalable data engineering capabilities
Exceptional coding and design skills in Python and SQL
Experience in Spark optimization and an understanding of data storage with Amazon S3
Experience in working autonomously and taking ownership of projects.
Ability to think globally, devising and building solutions to meet many needs rather than completing individual projects or tasks
Strong prioritization skills with business impact in mind
Strong cross functional communication skills that help simplify and move complex problems forward

YOU’LL LOVE WORKING AT STITCH FIX BECAUSE…

We are a group of bright, kind and goal oriented people. You can be your authentic self here, and are empowered to encourage others to do the same!
We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation
We are a technologically and data-driven business
We are committed to our clients and connected through our vision of “Transforming the way people find what they love”
We love solving problems, thinking creatively and trying new things
We believe in autonomy & taking initiative
We are challenged, developed and have meaningful impact
We take what we do seriously. We don’t take ourselves seriously
We have a smart, experienced leadership team that wants to do it right & is open to new ideas
We offer competitive compensation packages and comprehensive health benefits
You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day

About Stitch Fix

At Stitch Fix, we’re about personal styling for everybody and we believe in both a service and a workplace where you can be your best, most authentic self. We’re the first fashion retailer to combine technology and data science with the human instinct of a Stylist to deliver a deeply personalized shopping experience. This novel juxtaposition attracts a highly diverse group of talented people who are both thinkers and doers. All of this results in a simple, powerful offering to our customers and a successful, growing business serving millions of men, women, and kids. We believe we are only scratching the surface on our opportunity, and we’re looking for incredible people like you to help us carry on that trend.

Please Review Stitch Fix's Recruiting Privacy Policy Here

https://www.stitchfix.com/privacy/usrecruitingprivacy


Show more Show less"
2799978109,Data Engineer-Remote,Cyma Systems Inc,2021-11-15,United States,Greater Hartford,,Full-time,,"Data Engineers EXPERT in SQL , Python
Below are the detailed requirements.
9- 10 Years experience in SQL Development
Expert in Python development

Location : Remote (100%)
Rate : C2C
No of. Positions : multiple

Bachelor’s or Master’s Degree in Computer Science, Information Systems or related field
Proficient in designing and developing complex ETL pipelines, leveraging Apache Spark, Airflow, MPP Databases such as Snowflake and Kafka
Proficiency in Python, SQL and Spark
Working experience in AWS Services (S3, EC2, etc), Git, Docker
Define technical requirements and implementation details for the underlying data warehouse and data marts
Show more Show less"
2822057343,Data Engineer,Federal Reserve Bank of St. Louis,2021-11-06,United States,"St Louis, MO",Information Technology,Full-time,"Capital Markets, Banking, and Financial Services","Company

Federal Reserve Bank of St. Louis

As a FRED Data Engineer on the FRED Agile team, you will report to the Manager of the Research Datadesk and will work with other data engineers, web developers, and subject matter experts. You will write production-ready Python and SQL code to support the data and metadata pipelines for existing and new data published through FRED and family. This includes the main FRED database, and other web applications such as archival ALFRED and map-based GeoFRED. You will help ensure that the data and metadata in FRED and family are up-to-date, accurate, and accessible.

All Federal Reserve Bank of St. Louis employees must be fully vaccinated against COVID-19, unless the Bank grants an accommodation based on a medical condition or sincerely held religious belief.

Responsibilities


Design and maintain databases and interfaces for working with databases;
Identify data sources, constructing data decomposition diagrams, providing data flow diagrams, and documenting the process;
Write Python code for database access, modifications, and constructions, including stored procedures;
Determine and design requirements through discussions with team members, business owners, and other stakeholders;
Validate data and make mass modifications to the data;
Build tools with analytics capabilities embedded to move to a more automated system;
Collaborate with team to ensure appropriate implementation of requirements; and
Coordinate testing and project activities with and between team members, business owners, and other stakeholders.


Qualifications

Bachelor’s Degree or commensurate experience.
1-3+ year’s relevant experience including experience writing production-ready Python code and some combination of the following:
Proven ability to meet commitments and deliver quality work in a fast paced environment
Experience writing production-ready SQL code
Experience with ETL (extract, transform, load) processes
Experience with Amazon Web Services (AWS)
Experience with PHP
Experience with Agile methodologies
Candidates with less experience may be considered at a lower job grade or salary.
All Federal Reserve Bank of St. Louis employees must be fully vaccinated against COVID-19, unless the Bank grants an accommodation based on a medical condition or sincerely held religious belief.


Benefits

Our organization offers benefits that are the best fit for you at every stage of your career:

Pension plan, 401K, Comprehensive Insurance Plans, Tuition Reimbursement Program Onsite Wellness & Fitness Center, Backup Dependent Care (Child & Adult), and more


Ranked as a Top Workplace, the Federal Reserve Bank of St Louis is committed to building an inclusive workplace, where employees’ diversity—in age, gender, race and ethnicity, sexual orientation, gender identity or expression, disability, and cultural traditions, religion, life experiences, education and socioeconomic backgrounds—are recognized as a strength. Embracing our diversity encourages employees to bring their valued perspectives to the table when generating ideas and solving problems, and promotes an environment where innovation and excellence thrive. Learn more about the Bank and its culture; check out our Careers Site.

The Federal Reserve Bank of St Louis is an Equal Opportunity Employer.

Full Time / Part Time

Full time

Regular / Temporary

Regular

Job Exempt (Yes / No)

Yes

Job Category

Information Technology

Work Shift

First (United States of America)

The Federal Reserve Banks believe that diversity and inclusion among our employees is critical to our success as an organization, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. The Federal Reserve Banks are committed to equal employment opportunity for employees and job applicants in compliance with applicable law and to an environment where employees are valued for their differences.

Privacy Notice
Show more Show less"
2681751976,Data Engineer,Procter & Gamble,2021-12-02,United States,"Cincinnati, OH","Project Management, Design, and Information Technology",Full-time,Manufacturing,"With Us You Will

Build data & analytics solutions in a cloud environment - Implement technical solutions to obtain, process, store and provide insights based on the processed data
Develop within existing designs of various solutions a cloud environment to help the business get valuable insights
Suggest and implement architecture improvements
Work on automation and optimization of internal processes in our environment
Influence the future of these new technologies and the ways in which P&G uses them
Have a possibility to work with multifunctional and multinational teams within and outside of P&G
Focus on key business cases development within Data & Analytics
Manage agile projects using cloud and hybrid solutions


Responsibilities

We are currently looking for a Data Engineer to join our Data & Analytics team in Cincinnati focused on Business Units specific deliverables. In this role, you will be responsible for building systems and solutions leveraging various Cloud components & tools. You will lead this architecture and actively code and adapt it to ensure it functions well.

Qualifications


Python and SQL programming skills
Cloud Understanding
English proficiency
Bachelor's degree in Computer Science, Computer / Systems / Industrial Engineering, Business / Management Information Systems or Software Development
Show more Show less"
2796931845,Data Engineer,Flow,2021-11-30,United States,San Francisco Bay Area,Information Technology and Engineering,Full-time,Internet Publishing and Financial Services,"About Flow

Flow solves the complexity of fund infrastructure. We connect information across investors, providers, investments and systems to realize our mission of empowering thought. Powered by dynamic tools and human centric interfaces, our cross platform SaaS technology networks and adapts to the myriad of ways funds operate to optimize productivity and increase time invested into making decisions. By bringing Flow to the $10 Trillion alternative asset market, we are able to increase the speed of decisions, the speed of capital and the speed of growth that serve as the lifeblood for all market based economies.




Our remote team of ~30 is distributed throughout the Americas (USA, Mexico, Canada, and Uruguay). Our small, but mighty team is backed by world-class investors. At Flow, we are building an environment that supports career growth and affords opportunities to work with great people and technology.




About You

Flow is seeking individuals who value personal growth. You value working for a startup because having a substantial impact on the company is important to you. You are hardworking but have expectations that there will be a balance between work and personal life. You are professional and know how to be productive without a lot of oversight. You are excited about the opportunity to actively help build a great team and great products. You take satisfaction in solving real-world problems. You consistently seek ways to grow and challenge yourself. You value teamwork and understand that in a great team, the whole is greater than the sum of its parts.




About The Role

Flow is seeking a strategic, action-oriented and well organized Data Engineer who will report to the Head of Analytics. Flow’s premier Data Engineer will be responsible for building the pipelines and tables that give analysts and data scientists structured data that is easily queryable. This hire will partner closely with product management and operations on deeply understanding their use cases to design the optimal database structure and tooling to support them. They'll also partner with DevOps as the implications of tool selection will impact the technical architecture and infrastructure.




Responsibilities

Manage and execute data warehouse plans across functional areas (sales, operations, product, etc.)
Build, develop, implement and execute extensible, reusable data pipelines consisting of multiple data sources and integrations. Implement web service endpoints with defined SLAs.
Monitor data consumption patterns and develop enhancements to ensure pipelines adapt to evolving data schema and analytics use cases.
Collaborate with data consumers to define and catalog use cases to ensure adherence to data governance standards and ethical/legal guidelines.
Maintain and optimize workloads in various deployment stages and data environments to ensure optimal performance as data volume and variety increase.




Skills & Abilities

3+ years of experience as a Data Engineer or in a similar role with specific experience in dimensional data modeling, ETL development, and Data Warehousing
2+ years experience scripting in Python including full stack (Flask or Django)
Strong analytical skills related to working with unstructured datasets.
Advanced experience in SQL including optimizationBachelor’s degree in CS or related technical field
Experience with Redshift and other AWS cloud services: S3, EC2, EMR, RDS, etc.
Basic DBA skills




Nice-to-haves

Experience with tools optimized for high data volume: Hadoop, Spark, Kafka, etc
Server management and administration including basic scripting
Experience in at least one business intelligence reporting tool (Quicksight, Tableau, Superset, etc.)




Thank you for your interest in exploring the possibility of working at Flow. We look forward to speaking with you!




At Flow, we don’t just accept differences — we celebrate them, we support them, and we thrive on them for the benefit of our employees, our customers, and our community. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. If you’re good at what you do, come as you are. The more inclusive we are, the better our work will be. Flow is proud to be an equal opportunity workplace.

Show more Show less"
2778649710,Data Engineer - 2015,"KIOXIA America, Inc.",2021-11-04,United States,"Seattle, WA",Information Technology,Full-time,"IT Services and IT Consulting, Appliances, Electrical, and Electronics Manufacturing, and Computer Software","Company Description

KIOXIA America, Inc. (formerly Toshiba Memory America, Inc.) is the US-based subsidiary of KIOXIA Corporation, a leading worldwide supplier of flash memory and solid state drives (SSDs). From the invention of flash memory to today’s breakthrough BiCS FLASH™ 3D technology, KIOXIA continues to pioneer cutting-edge memory solutions and services that enrich people's lives and expand society's horizons. The company's innovative 3D flash memory technology, BiCS FLASH™, is shaping the future of storage in high-density applications, including advanced smartphones, PCs, SSDs, automotive and data centers

Job Description

If you are a creative thinker, obsessive about pushing the envelope, always ready for the next challenge, joining KIOXIA’s Business Generation Team is the logical next step in your career. Data is essential to our team - we bridge the gap between business and data. KIOXIA is seeking a savvy pipeline-centric Data Engineer who is gifted at telling insightful data stories by gathering insights, creating engaging analytic models, and designing intelligent automation to showcase persuasive business solutions which will enable us to drive towards a data-driven digital organization.

Beyond technical prowess, you’ll need the social aptitude to communicate highly complex data trends to internal customers and leadership in a way that’s easy to understand. Our ideal candidate will be as versatile as the project requires you to be, you’ll never be bored! Come in wearing your propeller hat and be the blueprint for bringing data to life.

Responsibilities

Gather insight, help define strategies through data transformation, create tangible design expressions and transform the essence of these ideas into compelling business solutions are the factors for success.
Develop ETL data pipelines using SSIS, Talend, or similar solutions to produce intelligent and fast-performing solutions that support business processes.
Scope, define and manage the development of transfer of data from any source to any target as for business requirements.
Develop the data infrastructure to allow the business to adopt and develop a web-based application to expedite, modernize, and digitize business processes.
Consult, adopt, and lead the business as it transforms into a digital framework – web applications, real-time analytics, anomaly detection, digital workflows, DB and applications security, and uniform user management.
Collect requirements directly from business users and manage vendors to deliver a project within timeline and budget.
Formulate and collaborate over the creation of technological roadmaps that deliver comprehensive digital transformation
Deploy best in class approaches to data/reports cataloging to support a self-service utilization of those resources
Manage vendors, through the selection process, contract negotiation, budget and timeline control, to final deliverable release

Qualifications

Minimum of 3-5 years of crafting and presenting cohesive and persuasive business approaches and strategies through data transformation.
Bachelor’s degree in computer science, information technology, engineering, or equivalent. Or a Master’s degree in statistics, applied math, or related discipline is a plus.
Minimum of 3 years of experience with SQL, 3NF, and dimensional modeling and data visualization/exploration tools
Experience building or maintaining ETL processes
Data Pipeline design using tools such as SSIS or Talend
Familiarity with BI, visualization, and reporting tools
Knowledge of data sets optimization methodologies and Data Warehousing Modernization
Experience automating business processes (preferred)
MSFT Data Engineer or DevOps certification (preferred)

Additional Information

Req# 2015;

All your information will be kept confidential according to EEO guidelines.


Show more Show less"
2819511552,Data Engineer,Everplans,2021-12-02,United States,"Saranac Lake, NY",Information Technology,Full-time,Financial Services,"Everplans is on a mission to help people better prepare for the future by getting their lives organized today.

We're an NYC-based startup technology company recently acquired by National Guardian Life Insurance Company (NGL) that helps people organize, share, and keep all the critical information, wishes, and documents they need, and that their family may need, up-to-date and at their fingertips. Through a combination of original content, a personalized guidance engine, and an intuitive digital vault, people can say goodbye to sticky notes around the computer, old file folders underneath the bed, and out-of-date paperwork.

Everplans is primarily distributed via financial professionals to their clients, through insurance and financial services organizations to their policyholders and customers, and as a benefit employers can offer their employees.

About The Position

We want to make actionable data-driven insights easily accessible to every employee at Everplans. We are looking for a disciplined data engineer to help us create and maintain data sets to build dashboards and visualizations which let the data speak, inform key strategic decisions, and measure the success of our goals.

You Should Have

A disciplined and impassioned approach to data, letting data speak for itself even if it can challenge currently received notions.
An extreme attention to detail, and the ability to internalize the final outcome, and synthesise usable data, regardless of inconsistencies and contradictions in the primary data.
The confidence and maturity to own the correctness of the synthesized datasets.
A belief in our mission, and a passion to make an impact in our users’ lives.
A collaborative mindset and be someone who enjoys socializing their ideas with peers.
An interest in improving the team at large, and helping your colleagues succeed.
An outcome-oriented mindset.
Curiosity and joy for technology. You should be able to adapt as trends and needs change.

Your Day-to-Day

Participate in methods and work processes to ensure clean and correct data used for analysis.
Work directly with business stakeholders to formulate questions about user behavior, core business performance, and other data-driven insights.
Create best-practice reports based on data analysis and visualization needs.
Proactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance and user-engagement, investigating and communicating areas for improvement in efficiency and productivity.
Create and maintain datasets from our transactional database, eventlog “click stream”, and third party tools.
Oversee and maintain ETL system.
Evaluate and leverage tools both for data-analysis, and visualization for business users in the organization
Own the Data Dictionary, and be the key source of truth of where data lives, what data should be used, and which data is sanctioned for correctness and wide use.

Requirements

Business analysis skills.
Ability to query and extract data from operational systems or data warehouse.
Experience working with BI tools or visualization platforms.
Proficiency with Python, MongoDB, and SQL (or equivalent experience).

Nice To Haves

Experience with Python/Jupyter Notebooks.
Experience with Looker and LookML
Practical experience in statistical analysis.
Experience with AWS
Interest/curiosity in other areas of our tech stack.
Ability to create simple visualizations and key company wide dashboards.

Larger Platform Tech Stack

Front: React/Redux/Javascript/Babel.js
Back: Ruby on Rails/RSpec/Node.js/Python
Middle: Rust/Node.js
ETL: Python/Ruby/LookML
Workflow: Git / Automated tests with a CI life cycle.
Architecture: Middle tier/microservices, backed by a RESTFul JSON API

While we have offices in the Flatiron district of NYC, we are actively evolving our culture to embrace a remote workforce.

Everplans is an Equal Opportunity Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.
Show more Show less"
2822666146,Data Engineer,"IDR, Inc.",2021-12-01,United States,United States,Information Technology,Full-time,Staffing and Recruiting,"IDR is looking for talented data engineers to join one of our top clients! If you are a data engineer that is looking to join a great team, this is the role for you!

Top Skills:

• Bachelor’s degree in Computer Science or related field

• 1-3+ years of experience with both relational database design (SQL), non-relational (NoSQL) databases, big data, real-time technologies

• Fluency in Scala and/or Java programming languages

• Strong OO & FP design patterns, data structure, and algorithm design skills?

• Extensive experience developing Apache Spark applications




Nice to Have Skills:

• Experience with software containerization, such as Docker

• Experience developing and / or consuming web interfaces (REST API) and associated skills (HTTP, web services)?







Why IDR?

20+ Years of Proven Industry Experience in 4 major markets
Employee Stock Ownership Program
Dedicated Engagement Manager who is committed to you and your success
Medical, Dental, Vision, and Life Insurance
Show more Show less"
2814486466,Data Engineer,Airtable,2021-12-01,United States,"San Francisco, CA",Engineering,Full-time,Computer Software,"Airtable's unique approach to enabling end-user software creation has struck a chord with users across many industries and use cases. Our accelerating present and future growth, coupled with our ambitious product surface area, brings many challenges. Data engineering can play a critical role in understanding how people use the open-ended toolkit that Airtable offers, thereby enabling our team to improve users' experience and accelerate their rate of success.

As one of the first data engineers at Airtable, you'll make an enormous contribution to our burgeoning data engineering efforts. You'll design and build systems that will enable analytics, experimentation, and user-facing features.

What You'll Do

Help architect, build, and scale our initial data engineering platform, with an eye on security and privacy.
Work closely with the rest of engineering, as well as other stakeholders from our growth, sales, marketing, and product teams, to understand the data needs of the business and produce systems that enable better product and growth decision-making.
Work on the data collection pipeline across the entire stack, from client-side event logging to ETL. Systems you'll touch may include data warehousing using MPP databases (e.g. RedShift or Vertica), workflow systems (e.g. Airflow or Luigi), streaming data processors (Kinesis, Kafka, etc.), and distributed data processing systems (Spark, Hadoop, etc.).
Ensure that our business-critical data is accurate and correct.

Who You Are

You're passionate and thoughtful about building systems that enhance human understanding.
You have professional experience working with modern data storage and processing technologies, and you've wrangled enough data to understand how often the complex systems that produce data can go wrong.
You can write clear, correct code in at least one programming language, and are willing to become effective in others as needed to get your job done.
You communicate with clarity and precision in written form; experience communicating with graphs and plots, or at least understanding how to enable other people to do this, is a big bonus.
You may have experience administering modern large-scale data management systems such as ELK.
Show more Show less"
2816926623,Data Engineer,Walker & Dunlop,2021-11-30,United States,"Chicago, IL",Information Technology,Full-time,"Banking, Financial Services, and Leasing Real Estate","Department

Information Technology

Ready to bring your whole self to work every day? At Walker & Dunlop, we didn’t get to where we are by hiring ordinary individuals. We got here by hiring the exceptional! WD is looking for individuals who are caring, collaborative, driven, insightful, and tenacious to join our team!

Walker & Dunlop ’ s mission is to deliver the best borrower experience of any commercial real estate lender in the world, and we are achieving this goal by leading the industry in data science and technological innovation.

The technology team at W&D has a creative and entrepreneurial culture – everyone on the team interacts directly with customers, and we all contribute to product development and planning. A commitment to innovation and a passion for disrupting the old-fashioned real estate industry are our highest priorities!

What You Will Be Doing

Design, develop and own data pipelines in Google Cloud that power internal analytical tools that are transforming how W&D does business
Drive the collection and refinement of new data sources and continually improve upon existing data integrations
Develop a solid understanding of the features and data sources needed to successfully analyze and execute real estate finance transactions
Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals to design, develop, test, and support new features
Maintain coding, compliance, and security standards
Proactively learn existing software frameworks and code bases
Participate in pair programming, code review, and design decisions
Present possible technical solutions to various stakeholders, clearly explaining your decisions and how they address real user needs, and incorporating user feedback in subsequent iterations

What We ’ Re Looking For

Bachelor’s or master’s degree in computer science
3-5 years of experience in full stack Python development (Vue.js/React/Angular, Flask/Django/Falcon, PostgreSQL/MySQL/SQL Server)
You have proficient software development knowledge, with experience building, growing, maintaining a variety of products, and a love for creating elegant applications
You have an entrepreneurial mindset and are product-oriented
You are curious and willing to continue learning in data engineering, but also in data science, frontend, and backend technologies

Technologies We Use

Python 3 (critical)
Python packages for data processing or ML, such as scikit-learn, numpy, beautifulsoup, matplotlib, nltk, pandas (critical)
PostgreSQL / BigQuery (or similar, critical)
Modern Devops i.e. Docker, GitHub Actions, Google Cloud, CI/CD (preferred)
Vue.js (or similar frontend framework, helpful)

What to expect your first 6 months?

At 30 days – You’ll have familiarized yourself with how the existing data integrations work, how this data is used across our suite of products and developed code to ingest and clean a new data source.
At 90 days – You’ll have a working knowledge of the domain and a deeper understanding about the problem-space. You’ll have a good idea of the value provided by your tasks and have implemented / refined a couple of them.
At 180 days – You’ll be able to use a scientific approach to identify and propose new features or improvements that would benefit the project and collaborated with the team to implement them. You’ll be able to code an automated data pipeline that ingests, cleans, and stores new data sources within the Google Cloud environment. You will have enough real estate domain expertise to be able to read through a new dataset and understand if there are any issues. You will take full ownership of the correctness of this data and understand its importance within the organization.

Still reading? Then we think you should apply!

EEO Statement

Walker & Dunlop is an equal employment opportunity employer and does not discriminate based on race, color, national origin, religion, gender identity, sexual orientation, sex, age, disability, veteran or military status, genetic information, or any other characteristic protected by applicable law.

SPAM

Please be wary of recruitment scams. An indication of a scam might be a request for sensitive or bank information at the time of application or emails coming from a non walkerdunlop.com email address. Please call us at 301.215.5500, if you have any concerns about information requested during or after the application process.
Show more Show less"
2604238370,Data Engineer (mid-level),Built Technologies,2021-11-20,United States,"Nashville, TN",Information Technology,Full-time,IT Services and IT Consulting,"Built is a growth-stage company at the intersection of FinTech and PropTech. We are on a mission to change the way the world gets built with technology and services that streamline the $1.3T U.S. construction industry. We strive to empower lenders, owners, builders, and vendors with innovative software, payment products & services that enable participants to manage risk, maximize productivity and collaboration to ensure better cost management as capital flows into and throughout the construction industry. Founded in 2015, Built now serves more than 140 of the top financial institutions in the US and Canada, including 35+ of the top 100 US construction lenders.

In addition to our recent $125M Series D funding and $1.5B valuation, we’re proud to have been named one of Forbes’ Top 100 Startup Employers in America for 2021. Bringing on the “best talent in the world” is at the forefront of our continued growth trajectory—and we want you to be part of it.

Built’s Insights team is hard at work on the product features that enable our clients and customers to get the most out of their data within Built. This includes data warehousing, in-app reporting, secure scheduled report delivery, and ad-hoc report generation where necessary. In addition to client needs, the Insights team is also instrumental in helping Built make sense of all of its internal data, allowing internal stakeholders to make informed, data-driven product decisions.

In this role, you will:

Help build the foundation for the future of reporting at Built
Ship features that enable clients and internal stakeholders to get the most out of their data
Provide data that helps drive product decisions
Participate in design and architectural conversations around data warehousing and report generation/building
Encourage and build up your teammates

Success in this role will be defined by...

Delivering the right solution at the right time with integrity
Participating in driving our data warehousing and report generation architecture forward
Communicating and collaborating with both technical and non-technical team members to arrive at negotiated decisions.
Working across languages, environments, and teams to create the best solution from the information currently available

Experience with these technologies will be helpful:

MySQL
Python (3.6+), JavaScript
ETL processes
Looker or similar Business Intelligence platform (Power BI, Tableau, etc)
Snowflake
Rundeck
GoCD
AWS tooling

In addition to tech skills, it's important to:

Be a good communicator
Possess a strong focus on customers, both internal and external
Be able to work across teams to accomplish goals
Have a dedication to the quality and ownership of your work product
Have empathy and support for your teammates

Perks:

The rare opportunity to radically disrupt an industry

Competitive benefits including uncapped vacation; health, dental & vision insurance; and 401k

Holistic compensation package including base salary, bonus, and equity

Flexible Hours

Learning grants to support your professional development

Our company is made up of passionate people who are driven in a variety of disciplines—and each of them bring their unique perspective to everything they do. Creating a safe and inclusive workplace is critical to the success of our company and of our employees, so it’s our aim to recruit, hire and promote without bias against race, color, religion, sex, sexual orientation, gender identity, marital status, veteran status or any other status protected by applicable law. As we learn and as we grow, we’re committed to ensuring that these ideals are at the forefront of everything we do.
Show more Show less"
2769522083,Big Data Engineer - Remote Work,"VHB Global, Inc.",2021-10-22,United States,"Herndon, VA",Engineering and Information Technology,Full-time,Strategic Management Services,"Big Data Engineer

Location: Remote

You should be able to effectively communicate with both technical and business stakeholders for requirements analysis, and will be highly proficient in the technical architecture, design, and development of database design. You must be a driver and help clients truly understand the data and how it moves.

Essential Duties & Responsibilities
Design and perform all activities related to big data architecture solutioning components between environments during development and deployment.
Work with Business Analysts and leads to transition the functional understanding of development assignments to themselves and developers they supervise.
Design, code and component test Hadoop components using Nifi and Kylo.
Provide Project, ITE, ODTR and Production support including analyzing incidents and identifying root cause.
Update status of assignment in sprint plan tool.
Work with Data Lake development leads along with Business Analyst Lead and Reporting lead to manage sprint plan and backlog.
Work closely with Contractor Program Manager, Lead Business Analyst and Lead Tester to size and plan work.
Other duties as assigned.
Work with Data Scientist to curate datasets for AI/ML initiatives.

Knowledge, Skills, And Abilities
Experience with Big Data technologies including Hadoop, Hive, Nifi, Spark, Databricks and/or Kylo.
Exhibit exceptional technical skills in database architecture, database design and ETL/ELT.
Displays knowledge of the proper way to adhere to the Software Development Life Cycle (SDLC).
Demonstrate tool expertise in front end and backend tools.
Excellent analytical and problem-solving skills to quickly recognize, isolate, and resolve technical problems.
Hands-on experience with implementation and support of a business intelligence reporting suite.
Understand business requirements and able to create/propose solutions.
Knowledge of SQL and Python.
Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and/or Software as a Service (SaaS)
Ability to work independently, prioritize tasks appropriately and adapt quickly to project changes.

Education, Experience, & Certifications
Minimum of 7-10 years of experience.
Bachelor’s degree in Engineering, Mathematics, Computer Science, Information Systems, Economics or Business, or equivalent.
Hold appropriate certifications.

Benefits
Great Culture focused on our customers and team members
VHB offers a compensation plan consisting of a competitive base salary
Employee Health coverage with Dental options
401k plan offerings
Paid holidays and vacation

Hold appropriate certifications.

Privacy Policy

VHB Global, Inc. is an industry leader, providing professional services including but not limited to: training specialists, linguists and field subject matter experts, in addition to operational and training support customers in the defense, intelligence, federal and commercial sectors.

VHB Global, Inc. is an Equal Opportunity Employer and supports diversity in the workplace. Applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, veteran status, marital status or sexual orientation.

Due to Federal Contract Regulations, U.S. Citizenship is required for these positions.
Show more Show less"
2807444732,Data Engineer,PIMCO,2021-10-31,United States,"Solana Beach, CA",Information Technology,Full-time,"Financial Services, Investment Banking, and Investment Management","General Information

Ref #: 30131

Functional Area: Technology

Employee Type: Full Time

Location: Solana Beach

Date published: 26-Jul-2021

About Us

We are PIMCO, a leading global asset management firm. We manage investments and develop solutions across the full spectrum of asset classes, strategies and vehicles: fixed income, equities, commodities, asset allocation, ETFs, hedge funds and private equity. PIMCO is one of the largest investment managers, actively managing more than $2.2 trillion in assets for clients around the world. PIMCO has over 3,070 employees in 22 offices globally. PIMCO is recognized as an innovator, industry thought leader and trusted advisor to our clients.

PIMCO is one of the world’s premier fixed income investment managers with thousands of professionals around the world united in a single purpose: creating opportunities for our clients in every environment. Since 1971, we have brought innovation and expertise to our partnership with the institutions, financial advisors and millions of individual investors who entrust us with their assets. We aspire to cultivate performance and leadership through empowering our people, diversity of thought, and a commitment to an inclusive culture that engages in our global communities.

Position Description

Is this role for you?

You are interested in having a pulse on anything data related while gaining insight from an aerial view. With a focus on providing best-in-class customer service to both our SMA clients and our internal operations team, you will face an array of interesting challenges from database development and data integrations to report development and BI solutions. You want to work on complex integrations, be a part of a continuous learning environment while being surrounded by a high performing team that works closely with one another. You are motivated by and enjoy solving business problems and seek roles where you can have an immediate impact on business users.

Our team helps the firm make intelligent decisions on both real-time trading technology and the data infrastructure that supports our proprietary applications and systems. We take pride in providing our clients a premium experience and we are committed to providing the robust reporting solutions that they require. In this environment, you can not only see how your work improves the firm’s operations every day, but also have the opportunity to experience dramatic and personal growth both intellectually and in your career progression.

What will you do?

As Part Of This Team, You Will Join a Talented Group Of Technology Professionals Who Enjoy Taking On Challenges, Such As

Working as part of a team to contribute to the design, development and management of various proprietary databases and applications.
Responsible for the entire lifecycle of development including requirements gathering, design, development, testing, and ongoing improvements.
Developing a business intelligence reporting framework for the SMA Operation group.
Establishing, designing and developing both internal and client facing reports.
Developing and managing complex data integrations between internal and external systems.
Providing production support for SMA data and reporting.
Working with business users to define requirements and help determine how reporting tools and features will be built.

Position Requirements

Possess a solid foundation in Microsoft SQL Server (2016+) database development and reporting.
2+ years of comparable experience..
Ability to write advanced SQL queries, views, stored procedures and functions.
Experience developing dynamic reports in SQL Reporting Services (SSRS).
Ability to work independently or with a team, plan work, and handle multiple assignments simultaneously.
Demonstrate great attention to detail and able to meet goals consistently and efficiently, while managing multiple efforts simultaneously.

Preferred Qualifications

Experience with data integration and ETL processes in SQL Integration Services (SSIS) or similar.
Experience with business intelligence tools such as SQL Server Analysis Services (SSAS), Power BI and Python will have a decided advantage.
Experiencing with Oracle (11g) PL/SQL development.

Benefits

PIMCO is committed to offering a comprehensive portfolio of employee benefits designed to support the health and well-being of you and your family. Benefits vary by location but may include:

Medical, dental, and vision coverage
Life insurance and travel coverage
401(k) (defined contribution) retirement savings, retirement plan, pension contribution from your first day of employment
Work/life programs such as flexible work arrangements, parental leave and support, employee assistance plan, commuter benefits, health club discounts, and educational/CFA certification reimbursement programs
Community involvement opportunities with The PIMCO Foundation in each PIMCO office
Show more Show less"
2814252714,Data Engineer,Five Below,2021-11-30,United States,United States,Information Technology,Full-time,Retail,"At Five Below our growth is a result of the people who embrace our purpose: We know life is way better when you are free to Let Go & Have Fun in an amazing experience, filled with unlimited possibilities, priced so low, you can always say yes to the newest, coolest stuff! Just ask any of our over 12,000 associates who work at Five Below and they’ll tell you there’s no other place like it. It all starts with our purpose and then, The Five Below Way, which is our values and behaviors that each and every associate believes in.




So if your heart is beating a little quicker and your smile is getting bigger now that you know what we’re all about, let’s just say your search for a one-of-a-kind experience that’s much more than a j-o-b just might be officially ending HERE. It’s all about culture at Five Below, making this a place that can inspire you as much as you inspire us with big ideas, super energy, passion, and the ability to make the workplace a WOWplace!




POSITION SUMMARY:




The Engineering team, organized by product groups, is responsible for the architecture, design, development and operations of all systems and applications supporting FiveBelow’s Retail footprint. The systems/apps are a combination of enterprise solutions and custom software which has to be thoroughly quality tested. Engineering Product groups at FiveBelow are aligned to the domain functions. Accordingly, we have Merchandising and Inventory Management, Stores and Digital, Logistics, BI and Data Platform, Ecommerce Engineering and Tools.




Fivebelow systems/applications supporting business functions are a combination of enterprise solutions and custom software built to create a seamless experience for our customers, driven by data assets at its epicenter. Fivebelow’s business and IT communities leverage internal and external data (SQL, NOSQL, structured, unstructured and streaming) to drive key decisions across merchandising and inventory management, Supply chain logistic, Stores, Digital, and all customer touch points.




The Enterprise Data Architecture team is accountable for building a data framework aligned with business processes that standardize the process of data collection, storage, transformation, distribution, and usage. The framework is created to secure sensitive data yet making the most relevant pieces accessible by authorized people at the right time. As part of the framework, our vision is to build tools that ensure all data assets meet defined data SLAs for security, integrity and quality. Fivebelow is looking for a Technical Lead who can be part of this amazing team, leading a group of engineers and data modelers to realize our vision of democratizing data with the highest degree of Quality standards.







Job Responsibilities:




Establish and Manage Data Standards and Tools for Operational and Analytical Data




Collaborate with business stake-holders, product owners to identify, analyze and profile operational data to set data standards for quality and completeness, establish and lead all aspects of data dictionaries, catalogs, data-flow-diagrams, measures, metadata and quality KPIs.
In partnership with Data & Analytics Leadership Committee, strategize, plan, prioritize, schedule and contribute to the development of appropriate tools to assess, monitor and implement data control points to meet defined SLAs for security, data integrity and data quality – aka a meta-driven, configurable Data Quality Framework with capabilities to report on data control points across our data platform, which includes SQL, NOSQL, structured, unstructured data in a multi-cloud hybrid footprint
Oversee, advise, and authorize the creation, design, development, and implementation/delivery of comprehensive end-to-end integration testing plans and their execution, while communicating the impact of system changes to key partners




Drive Consistency to Standards and Increase Data Quality and Utilization




Utilizing implemented data quality tools and standards, lead and ensure consistency to data standards and policies through identification, categorization and prioritization of data quality opportunities.
In partnership with Data & Analytics Leadership Committee, drive improvements in quality through data fixes, systematic improvements in systems/applications, or business process and behavioral changes
Utilizing implemented data catalogs, provide appropriately secure access to data to business and IT communities and drive improvements in data, enriching data with augmented attribution to increase data usage.
Assist data engineers and visualization engineers in building data visualizations of business processes and business outcomes/KPIs utilizing quality data




Qualifications:

Minimum 7 years of experience in mining information and data management, specifically in a retail footprint
Minimum 3 years mining data analysis and discovery, detecting data anomalies, trends, and gaps
Minimum 2 years experience with data modeling and data management tools to lead standard business definitions and metadata for the critical data elements
Familiarity with database architectures, SQL, NOSQL, structured, unstructured within large-scale data platforms in a multi-cloud hybrid footprint
Experience in automating data validations/data reconciliation between desperate data sources including relational and NoSQL DB's like MongoDB, flowing through real-time event streams/message based data pipelines
Experience integration Quality frameworks with CI/CD pipelines is desired
Experience working with Kafka, Databricks, Azure ESB a plus.
Selenium or selenium-like experience is a plus.
Experience with Software delivery leveraging agile and lean practices at scale is desired
Experience working with and leading onshore and offshore resources
Highest level of personal integrity, and the ability to professionally handle confidential matters and exude the appropriate level of judgment and maturity.
Exceptionally self-motivated and directed




Five Below is an Equal Opportunity Employer

Show more Show less"
2794098883,Data Engineer,Transcend Digital,2021-10-17,United States,"Los Angeles, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","We help cities meaningfully reduce emissions, congestion, and safety hazards by automating operations in the public right of way. We use computer vision deployed at the edge to guide planning decisions, autonomously charge commercial vehicles (Amazon, Postmates, etc.) for parking by the minute while also helping fleets save money by operating more efficiently and avoiding parking citations.

Our team is small but growing fast. We're currently looking for our primary Data Engineer, who will be a critical asset in designing, building, and implementing the data pipelines that form the foundation of our product. Given the size of the team and the fluid nature of technical roles in an early-stage organization, we're most interested in applicants who have killer data engineering skills, but aren't opposed to getting their hands dirty elsewhere in our stack.

We strongly encourage women and people from underrepresented groups to apply.

Responsibilities

Architect, build, and maintain flexible & scalable data infrastructure
Design and implement ML models to deliver predictive insights to our customers
Function as a leader, contributing towards establishing a culture of excellence as engineering team grows


Requirements

At least two years of professional software engineering experience, with proficiency in at least one major language (Python, Golang, Typescript preferred)
Bachelor's Degree in Computer Science or a related field
Strong familiarity with SQL databases
Experience building and maintaining a data warehouse in production
Experience designing, implementing, and maintaining extensible and scalable ETL pipelines
Strong machine learning skills: first-principles knowledge of canonical algorithms and experience using popular libraries such as Tensorflow and Pytorch
Applied statistics skills such as experimental design and hypothesis testing
Experience with data transformation tools like Spark or Hadoop
Experience deploying data services in the cloud (AWS preferred)


Preferred Skills/ Experience

Experience working with time-series and geospatial datasets
Experience working on IoT products


*Remote work acceptable*

Powered by JazzHR

8xEYVGTKeJ
Show more Show less"
2813667230,Data Engineer (Remote),The Athletic,2021-10-31,United States,United States,Information Technology,Full-time,"Marketing and Advertising, Online Media, and Internet Publishing","About Us

The Athletic is a direct-to-consumer digital sports media company committed to helping subscribers experience storytelling in a whole new way. Founded in 2016 and headquartered in San Francisco, The Athletic has over 500 full-time employees and covers more than 250 professional sports and collegiate teams in the US, Canada and the UK. The Athletic’s newsroom has produced thousands of in-depth articles along with more than 120 podcasts and premium video content. The Athletic is a remote-friendly company as we have offices in San Francisco, Los Angeles, London, and Melbourne.

About The Role

Our Data Engineering team owns the data infrastructure for our entire company. The team has built a modern data stack powering an analytics platform, product tools and features, and machine learning deployments, all hosted on AWS. The data eng team works closely with our product, engineering, data science, and analytics teams to build robust solutions to meet our growing data needs. You should be interested in building systems for scale, performance, and reliability. We all wear a lot of hats, so you’ll have the opportunity to work on database administration, ETL, microservice and model deployment, testing, experiments, and more depending on your interests. We’re a team of generalists and we’ll expect you to be one as well, interested in continuously learning new areas. Our team is always experimenting, and we trust and encourage our engineers to dream up and try out their own ideas and features.

Responsibilities

Work with Data Science, and Product teams to build and deploy features backed by machine learning and modern data toolsets.
Architect and build data pipelines to optimize for performance, data quality, scalability, ease of future development, and cost.
Build tools and data marts to enable analytics.
Identify and fix issues and reduce tech debt.
Investigate, debug, and fix user-reported production issues.
Requirements

Minimum 2 years data engineering experience.
Bachelor's degree in CS or relevant discipline.
Experience with Python, SQL, Docker, and cloud environment - AWS, GCP or Azure.
Experience with Redshift, Kubernetes, and Spark desired.
Experience in orchestrating/scheduling data pipelines.
Proficient in source code control systems.
Able to communicate results, outcomes and issues to different audiences.
The current team is largely based in San Francisco, CA, but this role can be based in a 100% remote capacity within the United States or Canada.
The Company is backed by Founders Fund, Evolution Media, Courtside Ventures, Comcast Ventures, Bedrock Capital, Advancit Capital, Y Combinator, and other leading investors. The Athletic is headquartered in San Francisco, California. The Athletic was awarded a 2020 Great Place to Work.

The Athletic Media Company is an equal opportunity employer and enthusiastically encourages people from all backgrounds and experiences to apply. The Athletic will consider all applicants without regard to race, religion, color, national origin, ancestry, physical and/or mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, transgender status, age, sexual orientation, military or veteran status, or any other protected characteristic under applicable law.
Show more Show less"
2817109922,Data Engineer,Robert Half,2021-12-02,United States,United States,Information Technology,Full-time,IT Services and IT Consulting,"Job Title: Data Engineers

Location: US Remote

Overview:

Client is seeking experienced Data Engineers with varying modern technology stack experience, who can adapt to new client environments and learn new technologies quickly.

We are looking for consultants with deep expertise in specific modern technologies, but we always want people to apply what they know, but if you don’t know a particular technology of interest, we provide vast opportunities to learn new capabilities.

Responsibilities:

Collaborate and work closely with team to build data platforms.
Maintain and manage Hadoop clusters in development and production environments.
Assemble large, complex data sets that meet functional/non-functional business requirements.
Work with team members and functional leads to understand existing data requirements and validation rules to support moving existing data warehouse workloads into a distributed data platform.
Create custom software components (e.g. specialized UDFs) and analytics applications.
Employ a variety of languages and tools to marry systems together.
Recommend ways to improve data reliability, efficiency and quality.
Implement & automate high-performance algorithms, prototypes and predictive models.

Qualifications:

Experience building data pipelines to connect analytics stacks, client data visualization tools and external data sources.
Knowledge of cloud and distributed systems principles
Experience with Python, R, sh/bash and JVM-based languages including Scala and Java.
Experience with Hadoop family languages including Pig and Hive.
Experience with high performance data libraries including Spark, NumPy and TensorFlow.
Experience building stream-processing applications using Storm, Spark-Streaming, Kafka and MQ.
Ability to manually and programmatically interact with relational and NoSQL databases
Intermediate SQL programming and query performance tuning techniques
2-3+ years in data engineering

Preferred: College degree or equivalent in technology-related field (computer science, engineering, information technology, etc.)

Practical education or experience in a technology related field – could include bootcamps and focused educational programs
Project experience in delivering technology solutions in a team-based environment, ideally Agile development

Client brings a fresh approach to consulting by rolling up our sleeves and working with our clients—collaborating to solve some of their most pressing business challenges. We deliver results. This is why many of the most well-known companies in the world trust us with their mission-critical projects and why working with us is for the smart, the talented, and the curious.

Life and work is not like your typical consulting job. Every team member plays an integral role in our company’s success, and we treat you that way, starting with our culture.

In our Dev Center, specifically, we like to say that we have the culture of a startup with the security of a 35+ year old company. By that, it's a casual, relaxed agile shop focused on helping you create your best work. (And - A casual dress code is just one part of that success.) The other side... Our consultants work in the cities in which they live, and you don’t have to worry about your job ending when a contract is up.

What We Commit to YOU

· We provide a multitude of training opportunities, including Lunch and Learns, evening classes, hackathons, and free access to Pluralsight and Safari libraries of online learning.

· You will get to work with some of the most innovative teams in the IT marketplace and solve real, business problems.

· We will invest in things that are important to you both professionally and personally.

· We will provide you with a team environment like no other – and we prove that, as we consistently rank as a Top Workplace in many of our locations as voted by our own employees.

· We will build a relationship with you to accelerate your Career.

· We provide some of the best benefits around.

We offer members:

· Excellent health, dental, and vision insurance.

· Revenue sharing and a 401(k) retirement savings.

· Life, disability, and long-term care insurance.

· Little to no travel.

· Robust career development and extensive training.

Show more Show less"
2731814335,Data Engineer,Samsung Electronics America,2021-12-02,United States,"Mountain View, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Title: Deep Learning Engineer – Knox Cloud Service

Company: Samsung Research America (SRA)

Lab: MPS

Location: Mountain View, CA

Position Summary

Looking for world class software engineers with ML & Big Data experience to join our technology innovation group focused on the rapid development of cloud based end-to-end mobile applications and services.

Samsung Knox Cloud Service team focuses on the development and research of large-scale production-level deep learning algorithms, models, and systems and aims at representing Samsung's leadership in large-scale machine learning products. The team productize wide range of Machine Learning algorithm from various Samsung Research teams and Research papers. This is an exciting and unique opportunity for a talented and hard-working deep learning engineer to get involved in envisioning, designing and implementing cutting-edge products with a growing team.

Come join the Samsung Knox Cloud Service team and help us shape the future role of Samsung in the machine learning domain!

Responsibilities

Explore cutting-edge technologies for our products
Design, develop, and productize deep learning algorithms for RTLS (Real Time Location System), Recommendation System and Business Intelligence
Productize Machine learning algorithms from Samsung Research teams or Research Papers
Create quick prototypes and proof-of-concepts
Design experiments, perform evaluations, and apply enhancements to our products

Requirements

3-5 years experience in the Machine Learning domain and 7+ years overall experience
Solid theoretical background in deep/machine learning
Hands-on experience of using deep/machine learning algorithms
Proficiency in data structures, algorithms and deep learning libraries (e.g., TensorFlow, Keras, and Pytorch etc.)
Strong programming skills with Python and/or Java
Excellent communication and interpersonal skills
Master or PhD degree in Computer Science or relevant fields

Preferred

Basic knowledge about Amazon Web Services and Google Cloud Platform
Basic knowledge of big data tools, data pipelines, RDBMS and NoSQL databases
Experience with Real time Location System, Indoor Positioning System, Computer Vision, Augmented Realty, Geomagnetic, PDR (Pedestrian Dead Reckoning), WIFI Networking, and Anomaly Detection System
Hand-on experience in Distributed Machine learning technologies like Spark ML, Ray.io, and Kubeflow

Samsung is committed to encouraging a diverse workplace and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) based on race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

If you have a disability or special need that requires accommodation, please let us know.
Show more Show less"
2812348751,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"Chicago, IL",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2798010280,"Big Data Engineer - Financial and Developer Services, Chronicle",Amazon,2021-11-18,United States,"New York, NY","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

DESCRIPTION

Ever wondered how Amazon offers the Earth's biggest selection and still manages to offer lower prices every day to our customers? Our consumer business teams work with a massive array of selling partners and business financial performance metrics to expand selection and drive costs lower. Given the rapid growth of our business, this requires our category leaders, financial analysts, account managers, site merchandisers and vendor managers to quickly analyze vendors, merchants, categories and brands, diving deep into data showing business efficiency down to the unit sale level. The technology that enables this has huge visibility and impact and is critical to Amazon's continued profitability and growth.

Innovation

We're working on the future. If you are seeking an environment where you can drive innovation. If you want to apply state-of-the-art software technologies to solve real world problems. If you want the satisfaction of providing visible benefit to end-users in an iterative fast paced environment, this is your opportunity. The responsibilities of this role will be key in paving the future of Amazon Consumer and transforming how we do business.

Key job responsibilities

You will be part of a team of creative, top-notch software developers to work hard, have fun, and make history. Software engineers at Amazon are more than just order takers; they see a problem and leverage innovative technology to address it. You will be working with very large data sets, well beyond the scalability limits of conventional relational databases. We're looking for people who innovate, love solving hard problems, and never take ""no"" for an answer.

Our team is within the Selling Partner Services organization and develops sophisticated tools for the Amazon Consumer businesses, supporting deep dive analysis, vendor negotiations and business planning towards enhancement at the bottom line. We also provide financial and operational reports to Amazon retail vendors worldwide.


Basic Qualifications

Bachelor’s degree or higher in an analytical area such as Computer Science, Physics, Mathematics, Statistics, Engineering or similar.
5+ years relevant professional experience in Data Engineering and Business Intelligence
3+ years in with Advanced SQL (analytical functions), ETL, DataWarehousing.
Strong knowledge of data warehousing concepts, including data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures, data modeling and performance tuning.
Advanced data analysis skills
Experience with AWS services including S3, Redshift, EMR
Knowledge of distributed systems as it pertains to data storage and computing
Ability to effectively communicate with both business and technical teams.

Preferred Qualifications

Experience on working with Big Data
Knowledge of Map Reduce, Spark and Presto
Experience providing technical leadership and mentoring other engineers for best practices on data engineering
Knowledge of software engineering best practices across the development life-cycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon.com Services LLC

Job ID: A1800723
Show more Show less"
2793846746,Data Engineer,Egen,2021-11-15,United States,"Naperville, IL",,Full-time,,"Our Data Platform Engineering teams build scalable data pipelines using Python and AWS, GCP, or Azure. The pipelines we build typically integrate with technologies such as Kafka, Storm, and Elasticsearch. We are working on a continuous deployment pipeline that leverages rapid on-demand releases. Our developers work in an agile process to efficiently deliver high value applications and product packages.




As a Data Platform Engineer, you will architect and implement cloud-native data pipelines and infrastructure to enable analytics and machine learning on rich datasets.




Show more Show less"
2816928195,Data Engineer,Walker & Dunlop,2021-11-30,United States,"Chicago, IL",Information Technology,Full-time,"Banking, Financial Services, and Leasing Real Estate","Department

Information Technology

Ready to bring your whole self to work every day? At Walker & Dunlop, we didn’t get to where we are by hiring ordinary individuals. We got here by hiring the exceptional! WD is looking for individuals who are caring, collaborative, driven, insightful, and tenacious to join our team!

Walker & Dunlop ’ s mission is to deliver the best borrower experience of any commercial real estate lender in the world, and we are achieving this goal by leading the industry in data science and technological innovation.

The technology team at W&D has a creative and entrepreneurial culture – everyone on the team interacts directly with customers, and we all contribute to product development and planning. A commitment to innovation and a passion for disrupting the old-fashioned real estate industry are our highest priorities!

What You Will Be Doing

Design, develop and own data pipelines in Google Cloud that power internal analytical tools that are transforming how W&D does business
Drive the collection and refinement of new data sources and continually improve upon existing data integrations
Develop a solid understanding of the features and data sources needed to successfully analyze and execute real estate finance transactions
Collaborate with interdisciplinary team of data scientists, software engineers and real estate professionals to design, develop, test, and support new features
Maintain coding, compliance, and security standards
Proactively learn existing software frameworks and code bases
Participate in pair programming, code review, and design decisions
Present possible technical solutions to various stakeholders, clearly explaining your decisions and how they address real user needs, and incorporating user feedback in subsequent iterations

What We ’ Re Looking For

Bachelor’s or master’s degree in computer science
3-5 years of experience in full stack Python development (Vue.js/React/Angular, Flask/Django/Falcon, PostgreSQL/MySQL/SQL Server)
You have proficient software development knowledge, with experience building, growing, maintaining a variety of products, and a love for creating elegant applications
You have an entrepreneurial mindset and are product-oriented
You are curious and willing to continue learning in data engineering, but also in data science, frontend, and backend technologies

Technologies We Use

Python 3 (critical)
Python packages for data processing or ML, such as scikit-learn, numpy, beautifulsoup, matplotlib, nltk, pandas (critical)
PostgreSQL / BigQuery (or similar, critical)
Modern Devops i.e. Docker, GitHub Actions, Google Cloud, CI/CD (preferred)
Vue.js (or similar frontend framework, helpful)

What to expect your first 6 months?

At 30 days – You’ll have familiarized yourself with how the existing data integrations work, how this data is used across our suite of products and developed code to ingest and clean a new data source.
At 90 days – You’ll have a working knowledge of the domain and a deeper understanding about the problem-space. You’ll have a good idea of the value provided by your tasks and have implemented / refined a couple of them.
At 180 days – You’ll be able to use a scientific approach to identify and propose new features or improvements that would benefit the project and collaborated with the team to implement them. You’ll be able to code an automated data pipeline that ingests, cleans, and stores new data sources within the Google Cloud environment. You will have enough real estate domain expertise to be able to read through a new dataset and understand if there are any issues. You will take full ownership of the correctness of this data and understand its importance within the organization.

Still reading? Then we think you should apply!

EEO Statement

Walker & Dunlop is an equal employment opportunity employer and does not discriminate based on race, color, national origin, religion, gender identity, sexual orientation, sex, age, disability, veteran or military status, genetic information, or any other characteristic protected by applicable law.

SPAM

Please be wary of recruitment scams. An indication of a scam might be a request for sensitive or bank information at the time of application or emails coming from a non walkerdunlop.com email address. Please call us at 301.215.5500, if you have any concerns about information requested during or after the application process.
Show more Show less"
2812350443,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2779853814,Data Engineer,Adobe,2021-11-05,United States,"Lehi, UT",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Job Summary

As part of the Data & Analytics team, the Data Engineer helps leaders and analysts throughout the organization access the data they need to further accelerate our growth. The team helps the business define analytics needs and translates that into actionable data models that are both robust and easy for business users to understand. This position will work closely with data architects, data analysts, and business groups to implement data modeling solutions to help better understand the business and contribute to a data driven culture.

Job Responsibilities

Work with business stakeholders to understand analytics needs
Architect solid data models which will provide actionable insights
Demonstrate the functionality and power of data models to the business
Improve overall robustness and efficiency of existing data marts
Gain a deep knowledge of data sources, definitions, and business metrics
Build data models that are easy to use and understand by business stakeholders
Design and build data models which combine multiple data sources
Express business definitions through SQL transformations and calculations
Develop SQL code optimized for performance
Document models, relationships, transformations, and definitions

Experience

Experience working with multiple business groups to meet their analytics needs
Strong understanding of data marts, data modeling, and related methodologies
Experience working with star schemas
Expert SQL programmer within a data warehousing environment
Advanced SQL functions including windowing
Experience with data lake or MPP database technologies
Experience developing data models for use in business intelligence tools
Experience building slowly changing dimensions
Experience with data validation
Exposure to Tableau, Power BI, Clik, Quicksight, or other BI tools

Bonus Skills

Experience with Presto, Redshift, Snowflake, Dremio, Vertica, Greenplum, or Netezza
Experience with scripting languages such as Python
Experience with Linux, crontab, and bash
Understanding of file formats like yaml, json, and xml
Working knowledge of code repositories (preferably Git)
Experience building sales funnel and marketing attribution data models
Understanding of Salesforce, Marketo, Netsuite, and other enterprise systems

Values Fit

To us, company values are more than just words on a wall; they best describe who we are and how we get our work done.

Genuine: We are sincere, trustworthy, and reliable.
Exceptional: We’re committed to creating exceptional experiences that delight our employees and customers.
Innovative: We’re highly creative and always striving to connect new ideas with business realities.
Involved: We’re inclusive, open, and actively engaged with our customers, partners, employees, and the communities we serve.

At Adobey, you will be immersed in an exceptional work environment that is recognized around the world. You will also be surrounded by colleagues who are committed to helping each other grow through our unique Check-In approach where ongoing feedback flows freely. If you’re looking to make an impact, we’re the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog.

[C


Show more Show less"
2816366406,Data Engineer,Cybernetic Search,2021-11-30,United States,"Oregon, United States ",Information Technology,Full-time,Staffing and Recruiting,"Cybernetic Search has partnered with a growing financial services company, which has just become the national leader in providing private credit, and which has ambitious plans to expand. They’re looking for Risk Data Engineer to join a well-established high-performing team due to growth and are working with Cybernetic Search exclusively.




This role is fully remote across the Continental US.




Your new role will involve:

Working with complex data sets to create and manage analytic and management reporting, which is critical to decision making across the Management team.
You will be creating and maintaining ‘optimal data’, including pipeline architecture. This can involve Optimal Extraction, Transformation, and Loading of such data – by leveraging data bricks notebooks, Apache Spark, SQL, Python, or Scala, alternatively using Microsoft Azure of open source tools if needed.
You will be working directly with Software Developers, Analysts, Database Administrators and data owners – so high-quality documentation about data structures is paramount. This will be kept in a shared data governance tool for the business and colleagues to access.
Automation – identify, design, and implement internal process improvement as you see fit. Ideally automating manual processes, optimizing data delivery, and making the companies infrastructure more scalable.
You will be working with stakeholders, so research and problem-solving skills within data is required to support the data infrastructure.




To be successful in securing your new role:

You will need to have several years prior experience as a Data Engineer – Minimum of 2 years
Key data technology required: SQL or relational databases, Python, data pipeline management such as SSIS, Azure Data Factory, or Apache Spark for batch and streaming.
Experience working with/ building / optimizing BIG DATA, such as pipelines architectures and data sets
Able to perform root analysis on internal/external data for improvements or specific business needs
Naturally, extreme attention to detail is paramount.




Benefits:

Salary between $100,000 to $140,000 DOE
Fully Remote Working
Competitive Bonus Structure
Comprehensive Health / Dental / Vision insurance
16 days PTO
401k up to 4% match
Learning and Development annual budget




We have a significant referral bonus scheme in place for anyone you refer whom we place.




For further information please send your resume and availability for a phone call to: BBarnes@cyberneticsearch.com

Show more Show less"
2804669048,Celonis Data Engineer,Saransh Inc,2021-11-23,United States,United States,"Project Management, Information Technology, and Engineering",Contract,"IT Services and IT Consulting, Computer Software, and Computer and Network Security","Celonis Data Engineer

Responsible for the technical setup of the Celonis Execution Management System and connection of processes. Must be able to map business goals with data, write SQL to connect a process to Celonis, configure data jobs, loads, and models, and validate data. Must have strong SQL skills and experience with ETL processes.

Show more Show less"
2822308882,Data Engineer,Kforce Inc,2021-12-01,United States,"Houston, TX",Information Technology,Full-time,"Packaging and Containers Manufacturing, Package and Freight Delivery, and Warehousing and Storage","Responsibilities

Kforce's client in the maritime space is looking for a Data Engineer in Houston, TX. Summary: The Data Engineer will work on solving AI/ML problems for clients in the Marine/Government/Energy industries, using Python and other technologies. Key Tasks:

Data Engineer will build data ingestion pipelines from external data sourcing
Import data from plat files, Excel or IoT data
As a Data Engineer, you will apply Machine Learning algorithms
Create output and then visualized through PBI

Requirements

Python - programming
XML - structured and unstructured data
Experience working in an agile environment
Self starter

Team Structure

The team consists of 4-6 people group
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

Salary: $130,000 - $140,000 per year
Show more Show less"
2811889327,Data Engineer,The Hanover Insurance Group,2021-10-30,United States,"Howell, MI",Information Technology,Full-time,Insurance,"For more than 160 years, The Hanover has been committed to delivering on our promises and being there when it matters the most. We live our values every day, demonstrating we CARE .

Our Commercial Lines Operations team is currently seeking a Data Engineer in our Howell, MI, or Worcester, MA location.

This is a full time, exempt role.

POSITION OVERVIEW:

Data engineering is the aspect of data science that focuses on practical applications of data collection and analysis. This role primarily will become proficient with all internal & external data produced and consumed by The Hanover Group.The engineer will understand where the data is, basic data models and architecture, how to access and obtain data and how to manipulate and work with data to produce output – which may be reports, datasets or self-service reports.

IN THIS ROLE, YOU WILL:

Provide support to complex business/technical processes and tools for multiple products, requiring the use of technical solutions across multiple departments or lines of business, with minimal supervision.
Has aptitude to develop and learn multiple technical business systems enterprise wide.
Develop an understanding of business processes and the P&C Insurance business to translate requirements into analytical reporting.
Summarize information and effectively communicate analyses in writing and verbally to internal partners. Frequent communication with teammates and internal business partners will be necessary to succeed in this role.
Develop new tools and process enhancements to enable new capabilities and solutions to drive business value.
Manage various projects, meet deadlines, and handle multiple priorities in a fast-paced, ever-changing and evolving business environment
Establishing relationships with one or more business partners by building knowledge of business processes/drivers and technical systems.
Proactively research and apply Best Practices to technology solutions.
Participate in the development of prototypes for various reporting, system and tools.
Develop code, tests, debugs and document working data and analytics systems to demonstrate the business value.
Apply proven data management techniques, application development methodologies and other technologies to produce comprehensive prototype solutions


WHAT YOU NEED TO APPLY:

Undergraduate degree with strong academic performance in a related field such as Data Science, Data Mining, Predictive Analytics, Business Analytics, Statistics, Mathematics, Economics, or Information Systems.
3-5 years of related analytical experience required.
Solid understanding of Microsoft Office 365 Suite.
Some insurance knowledge required.
Strong business and financial acumen.
Intellectually curious, self-motivated, and organized.
Solid analytical and problem-solving skills.
Strong communication and interpersonal skills.
Requires knowledge of programming and scripting languages related to data and integration.


This job posting provides cursory examples of some of the job duties associated with this position. The examples provided are not complete, and the position may entail other essential and job-related functions and responsibilities that employees will be required to perform.

CAREER DEVELOPMENT:

It’s not just a job, it’s a career, and we are here to support you every step of the way. We want you to be successful and fulfilled. Through on-the-job experiences, personalized coaching and our robust learning and development programs, we encourage you – at every level – to grow and develop.

BENEFITS:

We offer comprehensive benefits to help you be healthy, build financial security, and balance work and home life. At The Hanover, you’ll enjoy what you do and have the support you need to succeed. Benefits include:

Medical, dental, vision, life, and disability insurance
401K with a company match
Tuition reimbursement
PTO
Company paid holidays
Flexible work arrangements
On-site medical/wellness center (Worcester only)


EEO statement:

The Hanover values diversity in the workplace and among our customers. The company provides equal opportunity for employment and promotion to all qualified employees and applicants on the basis of experience, training, education, and ability to do the available work without regard to race, religion, color, age, sex/gender, sexual orientation, national origin, gender identity, disability, marital status, veteran status, genetic information, ancestry or any other status protected by law.

Furthermore, The Hanover Insurance Group is committed to providing an equal opportunity workplace that is free of discrimination and harassment based on national origin, race, color, religion, gender, ancestry, age, sexual orientation, gender identity, disability, marital status, veteran status, genetic information or any other status protected by law.”

As an equal opportunity employer, Hanover does not discriminate against qualified individuals with disabilities. Individuals with disabilities who wish to request a reasonable accommodation to participate in the job application or interview process, or to perform essential job functions, should contact us at: HRServices@hanover.com and include the link of the job posting in which you are interested.

Privacy Policy:

To view our privacy policy and online privacy statement, click here .

Applicants who are California residents: To see the types of information we may collect from applicants and employees and how we use it, please click here .

Apply Now
Show more Show less"
2825859944,Data Engineer,Connection,2021-12-03,United States,"Nashville, TN",Information Technology,Full-time,"IT Services and IT Consulting, Staffing and Recruiting, and Hospitals and Health Care","Connection has a fantastic opportunity through our Technical Staffing division for a Data Engineer. This is a permanent position with our end-client.

This is a remote position.

Responsibilities Include

Creating data mappings, building ETL interfaces, and helping to build reports and data visualizations
Manage and improve the process of data collection, ingestion, manipulation, and display for reporting processes
Develop ETL processes as part of data pipeline
Review existing datasets and design data models to organize data for further analysis
Perform data validation and quality testing
Build reporting data sources for visualization tools that can be used as source of truth for dashboards and reports.
Collaborate with data analysts and data scientists to develop necessary infrastructure to support reporting and data science objectives.

We Value

Understanding data warehouse structures (snowflake, star schemas)
AWS S3, Glue, python
Experience with rest API
Experience with data modeling to design models for the EDW
Snowflake Datawarehouse(preferred) or other cloud datawarehouse
Prior healthcare experience.
Show more Show less"
2808396269,Data Engineer,Advantis Global,2021-11-01,United States,"Sunnyvale, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","About This Opportunity

The Data Engineer will be joining Apple online stores team. You will be supporting a network application for Apple online stores

The Oppportunity For You

This is an exciting opportunity because you will be contributing to applicaitons have an imense amount of exposure with millions of users! Candidates must be highly skilled with Ansible and have stellar problem solving skills!

Must Haves

Hands-on experience with Apache Spark, Pyspark and pandas dataframe

Experience in Parquet file formats and common methods in data transformations

Experience in building/working on data pipelines

Expertise In Python, Shell ScriptingAdditional Skills

Coding skills in Java/Scala is a plus

Experience in AWS, Splunk is a huge plus

Experience in dependency driven job schedulers like Airflow
Show more Show less"
2808121156,Data Engineer,Deckers Brands,2021-11-25,United States,"Bend, OR",Information Technology,Full-time,"Apparel and Fashion, Manufacturing, and Retail","Job Title: Data Engineer

Reports to: Lead, Data Scientist

Location: Goleta, CA or remote in any of the following states: AZ, CA, CO, MA, NY, OR, TX, and WA

The Role

We are looking for a passionate Data Engineer with demonstrated knowledge of ETL workflows, cloud experience, a growth mindset, and an eye to scale. As a Data Engineer you will have the opportunity to expand our data ecosystem, collaborate in designing our future data infrastructure, and make decisions accessible throughout the organization. As a member of the Enterprise Analytics team, you will belong to a cross-functional Agile team who partners closely with business teams across Deckers.

Your Impact

The primary functions of this role, include but are not limited to:

Develop integrations with external resources (sFTP, API’s, etc.) to bring assets into the data warehouse
Create data pipeline monitoring automation
Produce custom datasets to enable Data Scientists and Data Analysts
Write and test production level code that can be deployed within our existing cloud framework
Collaborate in designing and developing the next generation of our AWS data infrastructure
Explore new data technologies

Who You Are

Passion for tackling ambiguous problem and creating tangible outcomes
Practiced in communicating complex projects to non-technical stakeholders
Desire to be in a cross-functional team where open-minded and transparent sharing is a tool for breaking down challenging problems
Thrives in a dynamic environment, maintaining composure and a positive attitude.

We’d love to hear from people with

BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
1-3 years of experience in a Data Engineering role
Strong coding and design skills in Python and SQL
Experience in designing and deploying cloud data infrastructure in AWS
Experience working in a Linux environment
Working knowledge of Git & Github

Bonus Points If You Have

Experience in a startup or owning a team road map
Experience utilizing distributed frameworks (i.e. Spark)
Experience utilizing containerization (Docker, ECR, ECS, etc.)
An understanding of leveraging data storage in Amazon S3

What We'll Give You –

Competitive Pay and Bonuses - We’ve created a variety of competitive compensation programs to foster career development, reward success and to show our employees just how much they’re valued.
Financial Planning and wellbeing - No matter what financial goals our employees have set, we want to help them get there. Our plans provide powerful ways to protect income, pay for expenses and invest in the future.
Time away from work - Sometimes we need time away to be with family, focus on our health or just simply recharge. Our plans support our employees’ needs to get out, get healthy and come back stronger than ever.
Extras, discounts and perks - Being a valued member of the Deckers Brands team means more than just a paycheck. From generous discounts to community-based programs, we offer a variety of cool extras
Growth and Development - Deckers Brands was built on the idea of pursuing passion. That’s why we offer extensive opportunities and support for personal and professional development.
Health and Wellness - There’s nothing basic about our comprehensive health and wellness programs and offerings. While at work and at play, we aim to support a healthy lifestyle.
Equal Employment Opportunity

All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.


Show more Show less"
2804558132,Data Engineer - Remote,The Hartford,2021-10-24,United States,"Charlotte, NC",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

The Hartford’s Enterprise Data Office (EDO) goal is to achieve greater business value through the use of data by simplifying the architecture, standardizing process and tools and building a data culture across the enterprise. The Data Architecture Practice within the Chief Data Office is looking for a Data Engineer to support line of business initiatives.Data Engineer will design, develop and maintain large scale data pipeline and data assets supporting premium/loss processing as well as sales/distribution lines of business leveraging on-prem and cloud technologies (AWS, Snowflake, APIs, Hyperledger blockchain)

Role Expectations

Design data collection systems, data analytics and other strategies that meets business requirements; Performing analysis to assess quality and meaning of data
Translate advanced business analytics problems into technical and data design approaches that deliver outcomes for stakeholders
Partner with business information and data architects to understand the business use cases that support and fulfill business and data strategy
Prototype high impact innovations, catering to changing business needs, by learning and leveraging new technologies (AWS Cloud, Big Data, Snowflake).
Integrate with Data Quality Services to ensure Quality data is Published to consumers.
Identify, analyze, and interpret trends or patterns in complex data sets
Possesses functional knowledge and skills reflective of a competent practitioner with the ability to deliver on work of varying technical complexity
Works closely with client management to identify and specify the complex business requirements and processes for diverse development platforms, computing environments (e.g., Cloud, host based, distributed systems, client server), software, hardware, technologies and tools
Coordinate activities with cross-functional IT unit stakeholders (e.g., database, operations, telecommunications, technical support, etc.)
Researches and evaluates alternative solutions and recommends the most efficient and cost effective solution for the systems design
Work within a self-organized scrum development team regarding all design and implementation

Qualifications

Bachelor’s degree with at least 2 years of applicable work experience.
Desired educational experience includes, but are not limited to: Computer Science, Engineering, IT, Management Information Systems, Data Analytics, Applied Mathematics, and Business.
Desire candidates with prior Data Engineer/ETL competencies and prior experience with successful enablement of Data Delivery initiatives.
Understanding of current and emerging IT products, services, processes and methodologies.
Analytical approach with a strong ability to uncover and resolve problems by delivering innovative approaches and solutions.
Strong ability to estimate project tasks and to deliver upon committed dates. Ability to develop and maintain systems according to a defined set of standards.
Ability to work as part of and with high performing teams.
Strong verbal and written communication skills
Preferable experience with large-scale data platforms using Big Data, cloud, and RDBMS technologies, such as Spark, Scala, Hadoop, EMR, Oracle, SQL Server, SQL, and NoSQL

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$90,480 - $135,720

Benefits

Our company’s success is due to our employees’ dedication and passion for their work. They are our greatest asset. That’s why we are committed to offering employees and their families a comprehensive benefits package and award-winning well-being programs. By helping our employees achieve their full potential, we unlock our own. Visit https://www.thehartford.com/careers/benefits for details.

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

Data Engineer - GE08AE
Show more Show less"
2818873178,Data Engineer,Cisco,2021-12-03,United States,"San Jose, CA",Other,Full-time,"Computer Hardware Manufacturing, Computer Software, and Computer Networking Products","As part of the Data & Analytics Office, the Data engineer will help to Design, build and oversee the deployment and operation of technology architecture, solutions and software of our Corporate Metrics which is core to the transformation of Cisco to recurring revenue business models.

8+ years of data engineering experience including developing and launching data products for cloud native and SaaS business models. BS/BE or Masters in CS, CE or MBA
Experience in developing roadmaps from concept to launch, managing requirements against that roadmap including collection, organization and prioritization
Experience in Data Driven Decision making, defining and driving objectives, key metrics and KPIs across the program
Ability to work well in a fast-paced, dynamic environment.
Experience working in a team environment with a documented software development process; ideally working within an Iterative or Agile methodology like Scrum and driving day-to-day technical and design direction for large scale systems.


High level Job Role

Establishes and builds processes and structures based on business and technical requirements to channel data from multiple inputs, route appropriately and store using any combination of distributed (cloud) structures, local databases, and other applicable storage forms as required.
Develops technical tools and programming that leverage artificial intelligence, machine learning and big-data techniques to cleanse, organize and transform data and to maintain, defend and update data structures and integrity on an automated basis.
Creates and establishes design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements.
Reviews internal and external business and product requirements for data operations and activity and suggests changes and upgrades to systems and storage to accommodate ongoing needs
Influence leadership across Sales, Customer Experience and Engineering to drive data instrumentation during product design and build.
Good Communication and Presentation Skills - ability to work with Cross Functional Remote Teams, build a network of trusted relationships, and present out well to the Executive Leadership Team


Attributes required for the role

Accountability
Candidate should be a results-oriented team player who leads by example, holds self-accountable for performance, takes absolute ownership, and champions all aspects of customer and project initiatives.
Efficient and Creative
Candidate should be able to think outside the box to find the optimal solution to problems.
Knowledge and experience in multiple functional areas including Product Management, Telemetry, Install Base and Customer lifecycle journey
Excellent data analysis skills with ability to understand complex data models and tie it to business outcome
Ambitious and talented individual who enjoys hard problems who have an appetite for learning new technologies
Excellent organizational and interpersonal skills.


Who You'll Work With

We are building a best-in-class team of hardworking, results-oriented problem solvers with the aim of enabling better data-driven decisions and thereby building business impact.
We operate as a startup work hard, learn every single day, focus on doing measurable and impactful work; and have lots of fun along the way.


Why Cisco

#WeAreCisco, where each person is unique, but we bring our talents to work as a team and make a difference powering an inclusive future for all.

We embrace digital, and help our customers implement change in their digital businesses. Some may think we’re “old” (36 years strong) and only about hardware, but we’re also a software company. And a security company. We even invented an intuitive network that adapts, predicts, learns and protects. No other company can do what we do – you can’t put us in a box!

But “Digital Transformation” is an empty buzz phrase without a culture that allows for innovation, creativity, and yes, even failure (if you learn from it.)

Day to day, we focus on the give and take. We give our best, give our egos a break, and give of ourselves (because giving back is built into our DNA.) We take accountability, bold steps, and take difference to heart. Because without diversity of thought and a dedication to equality for all, there is no moving forward.

So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture geek? Many of us are. Passion for technology and world changing? Be you, with us!
Show more Show less"
2811890290,Data Engineer,The Hanover Insurance Group,2021-10-30,United States,"Worcester, MA",Information Technology,Full-time,Insurance,"For more than 160 years, The Hanover has been committed to delivering on our promises and being there when it matters the most. We live our values every day, demonstrating we CARE .

Our Commercial Lines Operations team is currently seeking a Data Engineer in our Howell, MI, or Worcester, MA location.

This is a full time, exempt role.

POSITION OVERVIEW:

Data engineering is the aspect of data science that focuses on practical applications of data collection and analysis. This role primarily will become proficient with all internal & external data produced and consumed by The Hanover Group.The engineer will understand where the data is, basic data models and architecture, how to access and obtain data and how to manipulate and work with data to produce output – which may be reports, datasets or self-service reports.

IN THIS ROLE, YOU WILL:

Provide support to complex business/technical processes and tools for multiple products, requiring the use of technical solutions across multiple departments or lines of business, with minimal supervision.
Has aptitude to develop and learn multiple technical business systems enterprise wide.
Develop an understanding of business processes and the P&C Insurance business to translate requirements into analytical reporting.
Summarize information and effectively communicate analyses in writing and verbally to internal partners. Frequent communication with teammates and internal business partners will be necessary to succeed in this role.
Develop new tools and process enhancements to enable new capabilities and solutions to drive business value.
Manage various projects, meet deadlines, and handle multiple priorities in a fast-paced, ever-changing and evolving business environment
Establishing relationships with one or more business partners by building knowledge of business processes/drivers and technical systems.
Proactively research and apply Best Practices to technology solutions.
Participate in the development of prototypes for various reporting, system and tools.
Develop code, tests, debugs and document working data and analytics systems to demonstrate the business value.
Apply proven data management techniques, application development methodologies and other technologies to produce comprehensive prototype solutions


WHAT YOU NEED TO APPLY:

Undergraduate degree with strong academic performance in a related field such as Data Science, Data Mining, Predictive Analytics, Business Analytics, Statistics, Mathematics, Economics, or Information Systems.
3-5 years of related analytical experience required.
Solid understanding of Microsoft Office 365 Suite.
Some insurance knowledge required.
Strong business and financial acumen.
Intellectually curious, self-motivated, and organized.
Solid analytical and problem-solving skills.
Strong communication and interpersonal skills.
Requires knowledge of programming and scripting languages related to data and integration.


This job posting provides cursory examples of some of the job duties associated with this position. The examples provided are not complete, and the position may entail other essential and job-related functions and responsibilities that employees will be required to perform.

CAREER DEVELOPMENT:

It’s not just a job, it’s a career, and we are here to support you every step of the way. We want you to be successful and fulfilled. Through on-the-job experiences, personalized coaching and our robust learning and development programs, we encourage you – at every level – to grow and develop.

BENEFITS:

We offer comprehensive benefits to help you be healthy, build financial security, and balance work and home life. At The Hanover, you’ll enjoy what you do and have the support you need to succeed. Benefits include:

Medical, dental, vision, life, and disability insurance
401K with a company match
Tuition reimbursement
PTO
Company paid holidays
Flexible work arrangements
On-site medical/wellness center (Worcester only)


EEO statement:

The Hanover values diversity in the workplace and among our customers. The company provides equal opportunity for employment and promotion to all qualified employees and applicants on the basis of experience, training, education, and ability to do the available work without regard to race, religion, color, age, sex/gender, sexual orientation, national origin, gender identity, disability, marital status, veteran status, genetic information, ancestry or any other status protected by law.

Furthermore, The Hanover Insurance Group is committed to providing an equal opportunity workplace that is free of discrimination and harassment based on national origin, race, color, religion, gender, ancestry, age, sexual orientation, gender identity, disability, marital status, veteran status, genetic information or any other status protected by law.”

As an equal opportunity employer, Hanover does not discriminate against qualified individuals with disabilities. Individuals with disabilities who wish to request a reasonable accommodation to participate in the job application or interview process, or to perform essential job functions, should contact us at: HRServices@hanover.com and include the link of the job posting in which you are interested.

Privacy Policy:

To view our privacy policy and online privacy statement, click here .

Applicants who are California residents: To see the types of information we may collect from applicants and employees and how we use it, please click here .

Apply Now
Show more Show less"
2826722883,Big Data Engineer - Senior,AdventHealth,2021-12-03,United States,"Altamonte Springs, FL",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Hospitals and Health Care","Description

Big Data Engineer - Senior

AdventHealth Information Technology

Location Address: Inspiration Avenue, Altamonte Springs FL

Top Reasons To Work At AdventHealth Corporate

Great benefits
Immediate Health Insurance Coverage
Career growth and advancement potential
Award-winning IT Department

Work Hours/Shift

Full-Time, Monday - Friday

You Will Be Responsible For

Design, implement, test, deploy and support near real-time and batch data pipelines, using Hadoop infrastructure on an Oracle Big Data Appliance with a Cloudera Hadoop distribution
Design scalable and maintainable solutions, using Big Data tools such as Apache Spark, Apache Kafka, Apache NiFi and similar
Adopt and enforce best practices related to data ingestion and extraction of data from the big data platform.
Gather project requirements, meeting with project stakeholders and various operational and business teams
Work with Hadoop administrators to implement and support our enterprise security standards on a Hadoop cluster
Work with Hadoop administrators to propose, use and build monitoring tools on Hadoop cluster to optimize performance, provide high availability and meet job SLAs
Tune performance of Hadoop clusters, Kafka, Spark jobs, Hadoop MapReduce or similar
Work with the data warehouse, business intelligence and advanced analytics teams to evaluate their Big Data use cases and provide feedback and guidance
Escalate support issues with internal teams and vendors
Rotational on-call duty to support production environment
Qualifications

Knowledge And Skills Required

Strong software development and programming skills using Java, Python, Scala and other languages
Strong SQL and database development skills, using RDBMS such as Oracle, SQL Server, MySQL and PostgreSQL
Ability to proactively identify, troubleshoot and resolve live systems issues.
Troubleshooting Java applications
Understanding of system capacity, bottlenecks, basics of memory, CPU, OS, storage, and networks.
Hadoop development skills including HBase, Hive, Impala, Spark, Storm etc.
Hands on experience using message brokers such as Apache Kafka, RabbitMQ, ActiveMQ
Ability to schedule, configure and monitor jobs
Strong analytical and problem-solving skills with ability to clearly articulate solution alternatives.
Exceptional interpersonal skills to communicate both internally and externally and a team player.
Strong understanding of Hadoop design principals, cluster connectivity, security and the factors that affect distributed system performance
Experience working on Linux systems, including command line and scripting (bash, awk etc.)
Experience using standard SDLC tools like Git, Jenkins, Jira etc.
Flexible, open to suggestions, and eager to learn or share knowledge.
Orientation toward self-motivation, organization and attention to detail.
Ability to prioritize and work on multiple projects

Knowledge And Skills Preferred
Oracle, MySQL
Oracle Databases
Apache Impala, Apache Spark, Apache NiFi
Apache Kafka is a strong preference
Java, Python
Machine learning
HL7 interfaces

Education And Experience Required

BS degree in Computer Science or a related field
5 years experience full software development lifecycle with multiple programming languages such as Java, Python and Scala
Minimum 2 years experience Big Data, Hadoop and distributed systems
Experience in data warehousing and business intelligence

Education And Experience Preferred
Performance tuning in Big Data environments.
Minimum 10 years experience software development with Java and Python
Experience in Cloudera distribution of Hadoop
Healthcare industry experience

Summary

Responsible for design, implementation, testing and support of various Big Data projects and initiatives, using our Big Data environment. This position directly supports our new initiatives and will require designing near real-time pipelines using tools like Apache Spark, Apache Kafka, Apache NiFi and an ever-expanding suite of big data tools. This position reports to our Big Data Strategy manager and will perform as a part of our Enterprise Data Warehouse team within our Corporate analytics department.

This facility is an equal opportunity employer and complies with federal, state and local anti-discrimination laws, regulations and ordinances.
Show more Show less"
2795602042,Data Engineer,Pacific Gas and Electric Company,2021-10-18,United States,"San Francisco, CA",Information Technology,Full-time,"Construction, Oil and Gas, and Financial Services","Requisition ID # 118640

Job Category : Information Technology

Job Level : Individual Contributor

Business Unit: Information Technology

Job Location : San Francisco

Department Overview

At PG&E, the Data, Analytics, and Insights organization is focused on unlocking the value of PG&E’s data to support the company’s Wildfire Safety Program. As part of that focus, we focus on delivering data and AI/ML centric products to support these initiatives. Some of the products that are being delivered include Remote Inspections, AI Enabled Inspections, Vegetation Management through LiDAR capabilities, Transmission Line Asset Master, Electric Distribution Asset Master, Asset Risk Modeling, and a Cloud Native Foundational Platform.

A critical part of how we operate is to apply design thinking, work and observe the Agile development methodology, and co-location. Through these principles, we work as product teams to help deliver a valuable product to our business.

Position Summary

Designs, develops, modifies, configures, debugs and evaluates jobs for extracting data from various sources, implements transformation logic, and stores data in various formats fit for use by stakeholders. Collects metadata about jobs including data lineage and transformation logic. Works with teams, clients, data owners, and leadership throughout the development cycle practicing continuous improvement and support.

Position Responsibilities

Build high-performance data pipelines and prototypes that enable business use of the data.
Understands business requirements and applies them to complex software engineering and analysis.
Communicates (oral and written) recommendations with peers both inside and outside of the department.
Partners with team members to understand and incorporate standards information and requirements into work procedures.
Identifies, analyzes and provides feedback to departmental standards, norms, and new goals/objectives.
Analyzes existing applications and systems and formulates logic for new systems, devises logic procedures, logical database design, performs coding and tests/debugs programs with an operational mindset.
Works on complex data & analytics-centric problems having broad impact that require in depth analysis and judgment to obtain results or solutions.
Designs and deploys new complex Enterprise systems and enhancements to existing systems ensuring compatibility and inter-operability.
Resolves application programming analysis problems of broad scope within procedural guidelines. May seek assistance from the supervisor or more skilled programmers/analysts on various problems that cross multiple functional/technology areas.
Delivers best-in-class software as part of a software delivery team.
Understands the infrastructure that allows big data to be accessed and analyzed
Utilizes department standard issue tracking, source control, and documentation tools

Qualifications

BA/BS in Computer Science, Management Information Systems, or equivalent experience and/or field of study
Experience in data engineering, 2 years

Desired

Proven knowledge of software engineering principals such as unit testing, CI/CD, source control
Experience with at least one data engineering/ETL ecosystem such as Palantir Foundry, Spark, Informatica, SAP BODS, OBIEE
Show more Show less"
2732457287,Data Engineer (Remote),Truepill,2021-12-03,United States,"San Francisco, CA",Information Technology,Full-time,Computer Software,"At Truepill, we are building the future of healthcare. Through our digital health platform, we empower our partners to deliver world-class patient experiences. With nearly ten million prescriptions shipped, we’ve been included on Forbes’ “Next Billion-Dollar Startup” list and are proud to work with many of the world’s largest healthcare organizations. We never settle for how it’s done today. We invent how it will be done tomorrow.

None of this is possible without the right team driving us forward. We are committed to creating an environment focused on racial and gender equality, inclusion, empowerment, and respect. We believe that when our teams feel supported and inspired, they turn that creativity into innovation. The type of innovation that benefits all of our people, our partners, and our patients.

We encourage our team members to expand their horizons and bring their passion and curiosity to work, every day. Come join us. Let’s build something great together.

What You'll Be Doing

Design, build, launch, support, and maintain extremely efficient and reliable data pipelines to move data across a number of platforms
Partner with analytics consumers to improve existing datasets and build new ones
Ensure that data is valid, clean, and modeled for optimal use and that pipelines are monitored, durable, and have proper test coverage
Set up and improve BI tooling to help the team create dynamic tools and reporting
Partner with data scientists and other stakeholders to develop internal and external data products

What We're Looking For

3+ years of experience in a data engineering role with a focus on data warehouse technologies, data pipelines, and BI tools
Bachelor or advanced degree in Computer Science, Mathematics, Statistics, Engineering, or related technical discipline
Experience in the full data pipeline from extraction to grooming, modeling, loading, and dashboard creation/BI and in scaling and optimizing pipelines
Experience with modern data platforms like Redshift and Snowflake
Expert knowledge of relational SQL and NoSQL database systems and concepts
Experience with enterprise business systems like Netsuite
Experience with ETL pipeline tools like Airflow
Experience with Python or other batch processing/mining languages
Strong grasp of AWS and GCP services and their strengths/weaknesses
Experience working with healthcare data is a plus

Truepill is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.


Show more Show less"
2817118783,Data Engineer Developer,Sun Technologies,2021-12-02,United States,"Connecticut, United States",,Contract,,"Mandatory Requirements:

Bachelor’s degree in Computer Science, Systems Engineering, or related field with at least 9 years of professional experience with the below skills.
Experience in design or development of enterprise data solutions, applications, and integrations
 Knowledge of modern enterprise data architectures, design patterns, and data toolsets and the ability to apply them
Knowledge of local, distributed, and cloud based technologies and security measures to protect data
Has software engineering experience and experience building automations
Experience with GitLab or Jenkins
Experience with Neo4j Graph databases
Experience building data models
Experience in building ETL workflows to cleanse, transform, and store data
Experience building Tableau dashboard visualizations
Experience with HANA, Oracle, MySQL
Strong understanding of data virtualization
Strong problem solving, conceptualization, and communication skills
 Demonstrates willingness to learn, self-starter, and dependable

 

Desired Skills:

Experience working on an agile team under frameworks like Scrum, SAFe, or Kanban
Experience applying data security markings and access controls
ETL tools: SAP Data Services, Informatica, Tableau Prep, Altyrex, Pentaho (PDI) Kettle/Spoon (for ETL Processing)
Data Modeling (logical and physical): Erwin, HANA modeling
Database systems (SQL and NO SQL) – HANA, Oracle, SQL Server, MySQL, Neo4j, Big Data (DB2)
Data Virtualization: Tibco DV
Data Visualization: Tableau
Languages: Cypher, Angular, Kotlin, HTML/CSS, GraphQL, JSON, JavaScript, SQL, Python
Containers/Cloud Computing: AWS, OpenShift, OpenStack
CI/CD: Jenkins, Bit Bucket, Gitlab
Other: Logstash, Spring Boot, Gradle, Node JS, NPM, Data & REST APIs, Linux commands, POSTMAN, HANA WEB IDE, XS classic development
Experienced with HANA REST API implementation
Show more Show less"
2812809354,Data Engineer,Baker Tilly US,2021-10-31,United States,"Chicago, IL",Information Technology,Full-time,Financial Services,"Responsibilities

Baker Tilly has an incredible career opportunity for a Data Engineer to join our growing Enterprise Technology team.

The Data Engineer role will be focused specifically on Data Warehousing, Data Management, BI and Data Analytics. All supporting the need to define the businesses strategy and bring light and understanding to the vast amounts of data that Baker Tilly utilizes.

Responsibilities

Working within an agile environment to apply different data modeling techniques to build and maintain the firm’s data warehouse, while ensuring data integrity/quality within the environment.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Support the day-to-day sprint activities to assist in development of Azure Analysis Services environment.
Build Azure Data Factory pipelines to integrate data from outside systems in the firm Data Warehouse.
Utilize your scoping talents to help identify more areas within the business that our team can successfully impact for future projects.
Perform complex data analysis to find trends/patterns and reporting on the results in the form of dashboards, reports and data visualizations.

Qualifications

Strong understanding of data modeling, algorithms, and data transformation techniques.
Well versed in BI and data analytics, SQL, Python, R, the MS Stack, Azure and other cloud services.
Have at least 3 years of experience working within these technologies as well as other backend tech.
Have hands on experience in Microsoft business intelligence technologies.
Exhibit responsibility and accountability towards quality completion of projects and consistently hitting project timelines.
Strong verbal and written communication skills and are not ashamed to ask questions or raise concern on projects.
Outstanding customer service skills following proper business requirements and human resources expectations.
Disciplined to be able to work in a variety of business environments.
Maintained a Bachelor’s degree in Computer Science, Engineering, Math, Information Technology, or other related discipline or 10 + years of commensurate experience.

Overview

Baker Tilly US, LLP (Baker Tilly) is a leading advisory, tax and assurance firm, providing clients a genuine coast-to-coast and global advantage with critical mass and top-notch talent in major regions of the U.S. and in many of the world’s leading financial centers - New York, London, San Francisco, Los Angeles and Chicago. Baker Tilly is an independent member of Baker Tilly International, a worldwide network of independent accounting and business advisory firms in 148 territories, with 36,000 professionals and a combined worldwide revenue of $4.0 billion.

Many of Baker Tilly’s roles have the opportunity to work remotely. Please discuss with your talent acquisition professional to understand the requirements for an opportunity you are exploring.

Baker Tilly is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status, gender identity, sexual orientation, or any other legally protected basis, in accordance with applicable federal, state or local law.
Show more Show less"
2768759456,Data Engineer,Anheuser-Busch,2021-11-17,United States,Greater St. Louis ,Information Technology,Full-time,Food and Beverage Services,"Company




Budweiser, Bud Light. Stella Artois. Michelob ULTRA. That’s right, over 100 of America’s most loved brands, to be exact. But there’s so much more to us than our top-notch portfolio of beers, seltzers, and more. We believe our people are our greatest asset, and we’re looking for people like you to join our shared dream. We dream big to create a future with more cheers. Are you up for the Challenge?




Role Summary:




The US BEES product team is a part of the Anheuser-Busch Digital Sales function and works closely with our Sales and Global partners to provide an exceptional ordering experience for our wholesalers and retailers.

In this role, you will work at the intersection of understanding business problems so that you can build data assets to support products that empower teams to make data driven decisions. This will entail developing a deep understanding of existing processes, data that supports the processes, and high frequency iterations to ship aesthetically compelling data and reporting products. You will also have the opportunity to influence data architecture and technology to promote the quality and innovation necessary for industry changing data driven decisions at all levels of the company.




JOB RESPONSIBILITIES

Meaningfully relate data for our suite of BEES products
Routine interactions with Commercial, Product and Engineering teams to iterate quickly and continuously change / update / add data assets
Build data models using the latest cloud technologies that support fast, low maintenance and scalable problem solving.
Create sustainable data pipelines and support Product and the Front-End teams on all data needs.




Job Qualifications




Bachelor's degree in Computer Science or related S.T.E.M. field
Relevant real-world experience developing scalable Data Assets
Experience in building data models and designing user experiences on cloud technology
SQL and Python proficiency (Extra Credit: Databricks, Azure Data Lake / Synapse / Data Factory)




WHY ANHEUSER-BUSCH

Anheuser-Busch is here for the times that matter. The moments where we celebrate, defy challenges, dream of the brighter future we are building today– and all the moments in between. We are a company that brings people together for richer conversations, stronger communities, and a future with more cheers!




Challenge Accepted! Apply Today!




BENEFITS

Health benefits including Medical, Dental, Vision, Wellness and Tax-Advantaged Savings and Spending Accounts
Life Insurance and Disability Income Protection
Generous Parental Leave and FMLA policies
401(k) Retirement Savings options with a company matching contribution
Chance to work in a fast-paced environment among a company of owners
Free Beer!
Show more Show less"
2768491779,Software Engineer - Data (Fundera),NerdWallet,2021-11-30,United States,"New York, NY",Information Technology and Engineering,Full-time,"Computer Software, Internet Publishing, and Financial Services","NerdWallet SMB is on a mission to provide the tools, information, and insight people need to navigate small business financial decisions. As a fast growing company, we are preparing for a future of tremendous growth and transformation.

We are looking for an engineer to take ownership of the SMB data stack, from analytics and tracking all the way to BI reporting and insights.

Where you can make an impact:

Driving the data strategy of the NerdWallet SMB team, and owning the data stack end-to-end
Define process and drive implementation of event tracking on consumer-facing website and mobile applications using tools such as Mixpanel, Google Analytics
Implement and oversee data tracking and ingestion processes across all data sources, such as Salesforce, Postgres, Google Analytics, and Mixpanel
Monitor data stack health and make necessary infrastructure changes to support reporting needs long term
Integrate directly with the broader NerdWallet data stack and bridge the SMB (Fundera) stack as necessary

You are:

Able to develop and deliver Data services and systems that are reliable and scalable
Comfortable operating in a time-sensitive environment with competing deadlines, by appropriately prioritizing the short and long term paths based on an Agile development process
Self-starting and driven to find root-causes of reporting mismatches, and can query SQL datastores such as Snowflakes with ease
Comfortable interfacing directly with business stakeholders and non-technical teammates to deliver reporting and analytics needs

Your experience:

We recognize not everyone will meet all of these requirements. If you meet most of the criteria below and you’re excited about the opportunity and willing to learn, we’d love to hear from you.

Experience designing, building and operating robust data systems
Experience interfacing directly with product, BD, and marketing teams to collaborate on consumer conversion initiatives
Experience with the modern startup data stack and cloud providers such as AWS, Google Cloud, etc. and datastores such as Snowflake, Redshift, BigQuery
Experience working in ambiguous, fast-moving environments such as startups
Effectively work across team boundaries to establish overarching data architecture, and provide guidance to individual teams.
Strong working knowledge of relational databases and query building and high-performance query design (SQL).
Excellent communication skills, both written and verbal

Where:

This role will be based in New York, NY or remote (based in the U.S.).
We believe great work can be done anywhere. No matter where you are based, NerdWallet offers benefits and perks to support the physical, financial, and emotional well being of you and your family.

What we offer:

Work hard, stay balanced (Life’s a series of balancing acts, eh?)

100% paid premiums for medical, dental and vision for employees and their dependents
Rejuvenation Policy – Flexible Time Off + 12 holidays + Mental Health Days
New Parent Leave for employees with a newborn child or a child placed with them for adoption or foster care
Mental health support through Ginger.io
Paid sabbatical for Nerds to recharge, gain knowledge and pursue their interests
Health and Dependent Care FSA and HSA with monthly NerdWallet contribution
Weekly Virtual Bootcamp, Yoga and Mindfulness Meditation sessions
Monthly Wellness Stipend and Cell Phone Stipend

Have some fun! (Nerds are fun, too)

Nerd-led group initiatives – Intramural Sports, Employee Resource Groups for Parents, Diversity, Equity, and Inclusion, Women, LGBTQIA, and other communities
Hackathons, Happy Hours and team bonding across all teams and departments
Company-wide events like Little Nerds Day (aka bring your kids to work day, even if you're remote!) and our annual Charity Auction

Lifestyle (Be your best self - we’ll take care of the details)

Our Nerds love to make an impact by paying it forward – Donate to your favorite causes with a company match
WiFi stipend, work from home equipment stipend, and co-working space subsidy
Commuting stipend and catered breakfast, lunch and onsite barista for SF based Nerds
Anniversary recognition program – choose from different items and experiences

Plan for your future (And when you retire on your island, remember the little people)

401K with company match
Annual Enrichment Stipend for learning and development
Be the first to test and benefit from our new financial products and tools
Access to Rocket Lawyer for online legal support and resources

If you are based in California, we encourage you to read this important information for California residents linked here.

NerdWallet is committed to pursuing and hiring a diverse workforce and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of any characteristic protected by applicable federal, state or local law. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.


Show more Show less"
2826791645,BI Data Engineer-Work from home-eviCore,Cigna,2021-12-03,United States,"Franklin, TN",Business Development and Sales,Full-time,"IT Services and IT Consulting, Financial Services, and Hospitals and Health Care","Remote, Work from home, United States

Roles And Responsibilities

Build ETL processes to allow data to flow seamlessly from source to target using tools like DataBricks, Azure Data Factory and SSIS.
Load and enhance dimensional data models
Leverage code to apply business rules to ensure data is clean and is interpreted correctly by all business stakeholders, using tools like DataBricks, SQL, Scala, Spark, Python.
Perform peer code reviews and QA.
Participate in sprint ceremonies.
Provide on-call support to offshore operations team.
Train operations teams on the ETL (Extract, Transform and Load) processes being developed.
Troubleshoot and address issues with the data and/or the ETL process.
Fine tune existing code to make processes more efficient.
Maintain and create documentation to describe our data management processes.
Develop reports using various tools like Micro Strategy, Tableau and SSRS.
Support user questions on data management processes and results.

Minimum Required Skills

3+ Years building Big Data and Data Warehousing solutions.
Familiarity of Big Data Technologies including Kafka, Apache Storm, Spark Hive, Hbase, Spark, Pig, Map-Reduce, No-Sql Databases
Proficient in Database Concepts and Technologies including MS Sql Server, DB2 and Oracle
Knowledge of Data Modeling, Data Architecture & Data Governance concepts
Experience in working with implementations of Azure cloud data solutions a strong plus (ADLS, Data Bricks, Synapse, ADF)
Excellent written and oral Communications skills
Must be able to effectively communicate complex technical topics to a variety of audiences
Experience with Healthcare data is a plus

Minimum Education, Licensure And Professional Certification Requirement

Bachelor’s degree with relevant experience required.
Master’s Degree is a plus.

This role is Flex/WFH which allows most work to be performed at home or on occasion at a Cigna office location. Employees must be fully vaccinated if they choose to come onsite.

About Cigna

Cigna Corporation exists to improve lives. We are a global health service company dedicated to improving the health, well-being and peace of mind of those we serve. Together, with colleagues around the world, we aspire to transform health services, making them more affordable and accessible to millions. Through our unmatched expertise, bold action, fresh ideas and an unwavering commitment to patient-centered care, we are a force of health services innovation. When you work with us, or one of our subsidiaries, you’ll enjoy meaningful career experiences that enrich people’s lives. What difference will you make?

Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws.

If you require reasonable accommodation in completing the online application process, please email: SeeYourself@cigna.com for support. Do not email SeeYourself@cigna.com for an update on your application or to provide your resume as you will not receive a response.
Show more Show less"
2806408146,Data Engineer,Blockchain.com,2021-10-30,United States,"Miami, FL","Research, Information Technology, and Engineering",Full-time,"IT Services and IT Consulting, Internet Publishing, and Financial Services","Blockchain is the world's leading software platform for digital assets. Founded in 2011, we provide the largest production blockchain platform in the world, powering more than 50 million non-custodial wallets. We share the passion to code, create, and ultimately build an open, accessible and fair financial future, one piece of software at a time.

We are looking for a talented data engineer to join our Consumer Data Science team. The group is part of a larger DS team and focuses on customer analytics and modelling, informing all product decisions and creating models to improve efficiency, growth, and security. In order to do this, we use data from various sources, and of varying quality. Our ETL processes serve both the wider company (in the form of clean, simplified tables of aggregated statistics and dashboards) as well as the Data Science team itself (cleaning and processing data for analysis and modelling purposes, ensuring reproducibility).

We are looking for someone with experience in designing, building, and maintaining data pipelines and our data lake. As a data engineer, you will be involved in all aspects of data collection, cleaning and processing, ensuring quality and availability of data. You will collaborate closely with data scientists, platform, and front-end engineers, defining requirements and designing new data processes, as well as maintaining and improving existing ones. We are looking for someone who is passionate about high quality data and understands the impact they have in solving real-life problems. Being proactive in identifying issues, digging deep into their source, and developing solutions, are at the heart of this role.

What You Will Do


Maintain and evolve the current data lake infrastructure and look to evolve it for new requirements
Maintain and extend our core data infrastructure and existing data pipelines and ETLs
Provide best-practices and frameworks for data testing and validation and ensure reliability and accuracy of data
Complement our data scientists by providing a reliable, secure and maintainable modelling framework that can be used to easily deploy models to production
Design, develop and implement data visualization and analytics tools and data products


What You Will Need


Bachelor’s degree in Computer Science, Applied Mathematics, Engineering or any other technology related field
Previous experience working in a data engineering role
Fluency in Python
Previous experience with ETL pipelines
Experience working with Google Cloud Platform
In-depth knowledge of SQL and no-SQL databases
Experience with Git


Nice to have


Experience with Airflow or Google Composer
Experience with other programming languages, like Java, Kotlin or Scala
Experience with Spark or other Big Data frameworks
Experience with distributed and real time technologies (Kafka, etc..)


Compensation And Perks


Unlimited vacation policy; work hard and take time when you need it.
Apple equipment.
Full-time salary based on experience and meaningful equity in an industry-leading company
Benefits: dependant on employee location
Flexible hours and smart working options


Application


CV/Resume or Linkedin profile
Link to github, stackoverflow, personal website and/or blog (if applicable).


When you apply to a job on this site, the personal data contained in your application will be collected by one or more of the following subsidiaries of Blockchain Luxembourg S.A (each, a “Controller”):


Blockchain Access UK Ltd.
Blockchain (GB) Limited
Blockchain (US), Inc.
Blockchain (LT), UAB


You may contact our Data Protection Officer by email at dpo@blockchain.com. Your personal data will be processed for the purposes of managing Controller’s recruitment related activities, which include setting up and conducting interviews and tests for applicants, evaluating and assessing the results thereto, and as is otherwise needed in the recruitment and hiring processes. Such processing is legally permissible under Art. 6(1)(f) of Regulation (EU) 2016/679 (General Data Protection Regulation) as necessary for the purposes of the legitimate interests pursued by the Controller, which are the solicitation, evaluation, and selection of applicants for employment.

Your personal data will be shared with Greenhouse Software, Inc., a cloud services provider located in the United States of America and engaged by Controller to help manage its recruitment and hiring process on Controller’s behalf. Accordingly, if you are located outside of the United States, your personal data will be transferred to the United States once you submit it through this site. Because the European Union Commission has determined that United States data privacy laws do not ensure an adequate level of protection for personal data collected from EU data subjects, the transfer will be subject to appropriate additional safeguards under the standard contractual clauses.

Your personal data will be retained by Controller as long as Controller determines it is necessary to evaluate your application for employment. Under the GDPR, you have the right to request access to your personal data, to request that your personal data be rectified or erased, and to request that processing of your personal data be restricted. You also have to right to data portability. In addition, you may lodge a complaint with an EU supervisory authority.
Show more Show less"
2801658151,Data Engineer,Assurant,2021-11-17,United States,"Miami, FL",Information Technology,Full-time,Insurance and Consumer Services,"The Data Engineer reports to the Manager of Data Services and is responsible for developing Data Engineering solutions that conform to group standards, budgets and agreed estimated timelines. This role wrangles data in support of Data Science projects and constructs, tests, and maintains scalable data solutions for structured and unstructured data to support reporting, analytics, ML and AI.

Data Engineer assists with optimization the performance of bigdata eco-systems while assisting with research and building of proof of concepts to test out theories recommended by Senior and Lead Data Engineers.

Responsibilities

Gains a thorough understanding of the requirements and ensure that work product aligns with customer requirements
Works within the established development guidelines, standards, methodologies, and naming conventions
Builds processes to ingest, process and store massive amount of data
Assists with optimization the performance of bigdata ecosystems
Wrangles data in support of data science projects
Performs product ionization of ML and statistical models for Data Scientists & Statisticians
Constructs, tests, and maintains scalable data solutions for structured and unstructured data to support reporting, analytics, ML and AI
Assists with research and building of proof of concepts to test out theories recommended by Senior and Lead Data Engineers
Collaborates and contributes to identifying project risks, design mitigation plans, develops estimates
Contributes to the design, development of data-pipelines, and feature engineering of data solutions
Established processes or methods are still relied on however Data Engineer will be required to come up with creative solutions to problems. Senior teammates are still needed to provide oversight on solutions to complex problems

Basic Qualifications

Bachelor of Science in a related field required
5 years of design and development experience
5 years ETL (SSIS) experience
5 years of requirements gathering and data analysis using MS SQL Server

Preferred Experience

Knowledge of CRISP-DM methodology relevant to Data Engineering i.e: Data preparation and Deployment
Knowledge in Big Data technologies, concepts, and their applications for data processing
Advanced knowledge of Business Intelligence, Data Warehousing Knowledge in fundamentals of Machine Learning and Artificial Intelligence using Microsoft technologies
Performance tuning and code optimization in SQL
Data profiling and dimension modeling techniques and creation of logical and physical data models
Experience working with job scheduling tools
Experience with SQL, C#, .NET, Python, Linux Shell Scripting or MS Power Shell, R or SAS, Spark, Hive, Pig, NoSQL
Experience with Cloud Service Models: PaaS, IaaS, SaaS

Assurant is a global provider of lifestyle and housing solutions that help leading brands grow revenue, manage risk, and deliver a great experience for their customers. We protect, connect, and support over 300 million consumers worldwide, helping people get more value from their connected devices, vehicles, and homes. Assurant is a proud member of the Fortune 300, with decades of experience in the industries we serve.

For more information, please visit https://www.assurant.com/
Show more Show less"
2794693534,Data Engineer - Remote,UnitedHealthcare,2021-10-22,United States,"Houston, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Insurance","UnitedHealthcare is a company that's on the rise. We're expanding in multiple directions, across borders and, most of all, in the way we think. Here, innovation isn't about another gadget, it's about transforming the health care industry. Ready to make a difference? Make yourself at home with us and start doing your life's best work.(sm)

Come join the Business Insights division or the UHC Operations Analytics team whose mission is simple and audacious – make the healthcare system better for everyone by driving action with data and analytics. In our team, we are guided by the desire to mature our solutions to be more descriptive, predictive, and prescriptive in nature, while at the same time build the relationships needed to be a trusted advisor, working hand in hand with our business partners. Within this team you will be focused on Provider Data solutions – making sure we provider accurate and timely reporting and analytics suite to serve our provider operations teams.

Functions may include database architecture, engineering, design, optimization, security, and administration; as well as data modeling, big data development, Extract, Transform, and Load (ETL) development, storage engineering, data warehousing, data provisioning and other similar roles. Responsibilities may include Platform-as-a-Service and Cloud solution with a focus on data stores and associated eco systems. Duties may include management of design services, providing sizing and configuration assistance, ensuring strict data quality, and performing needs assessments. Analyzes current business practices, processes and procedures as well as identifying future business opportunities for leveraging data storage and retrieval system capabilities. Manages relationships with software and hardware vendors to understand the potential architectural impact of different vendor strategies and data acquisition. May design schemas, write SQL or other data markup scripting and helps to support development of Analytics and Applications that build on top of data. Selects, develops and evaluates personnel to ensure the efficient operation of the function.

You’ll enjoy the flexibility to telecommute* from anywhere within the U.S. as you take on some tough challenges.

Primary Responsibilities

Use your operational analytical skills to design/develop, program, maintain and publish reports
Make solid recommendations based on the analysis and provide explanations for reporting results for both internal operations and our customers
Self-directed and creative as you will deal with some very interesting and complex issues
Demonstrate an understanding of data modeling (relationships, data types, tables, etc.) and analytics concepts (queries, reporting, association of data sources)
Interpret requirements and translate them into data requirements (interfaces, data transformation, etc.) for complex projects
Collect and interpret data from various internal and external sources; prepares and compiles data
Demonstrate familiarity in using modeling and reporting tools and how to use them during the analysis process (e.g. SQL and/or Business Objects tools)
Design and/or develop specific databases for collection, tracking, and reporting to facilitate analysis
Design and develop network accessibility reports in Quest Analytics software packages.
Data mapping (e.g. between source and target databases; mapping screen fields to database columns)
Assist business and systems analysts with business rule and data integration
You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Required Qualifications

Bachelor’s Degree or equivalent experience
1+ year of customer Facing Experience (Including status updates, strategy discussions and managing complex/sensitive scenarios)
1+ year of experience Capturing Requirements, Documenting System/Process Changes, and/or Design/Thinking Experience
2+ years of experience Leading/Participating in a Project Delivery Environment
3+ years of Report Development & Analysis Experience
2+ years of experience with BI Tools (Tableau, Power Bi or Equivalent)
3+ years of Data Technology Experience (SQL Server, Salesforce, etc), or equivalent experience working with data
3+ years of ETL and Data Modeling Experience
1+ year of Experience working with Big Data/Cloud Technologies (Hadoop, MAPR Hive, Spark/Snowflake)
2+ years of experience with Productivity Suite (Excel, PowerPoint, Work)

Preferred Qualifications

3+ year of Healthcare Industry Experience
Health Insurance Experience

UnitedHealth Group requires all new hires and employees to report their COVID-19 vaccination status.

Careers with UnitedHealthcare. Let's talk about opportunity. Start with a Fortune 6 organization that's serving more than 85 million people already and building the industry's singular reputation for bold ideas and impeccable execution. Now, add your energy, your passion for excellence, your near-obsession with driving change for the better. Get the picture? UnitedHealthcare is serving employers and individuals, states and communities, military families and veterans where ever they're found across the globe. We bring them the resources of an industry leader and a commitment to improve their lives that’s second to none. This is no small opportunity. It's where you can do your life's best work.(sm)

All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy.

Colorado Residents Only: The salary range for Colorado residents is $64,800 to $116,000.. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you’ll find a far-reaching choice of benefits and incentives

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity / Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.

Job Keywords: Data Engineer, Remote, Telecommute, SQL, Data, Hiring Immediately, #RPO, work from home, work at home, WFH, WAH
Show more Show less"
2486210585,Data Engineer,Slalom,2021-09-09,United States,San Diego Metropolitan Area,Information Technology,Full-time,Management Consulting,"Job Title: Data Engineer

As a Data Engineer, you’ll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core cloud data warehouse tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies. In addition to building the next generation of data platforms, you’ll be working with some of the most forward-thinking organizations in data and analytics. 




Responsibilities

·      Work as part of a team to develop Cloud Data and Analytics solutions

·      Participate in development of cloud data warehouses and business intelligence solutions

·      Data wrangling of heterogeneous data and explore and discover new insights

·      Gain hands-on experience with new data platforms and programming languages (e.g. Python, Hive, Spark)




Qualifications

·      3+ years of related work experience in Data Engineering or Data Warehousing

·      Hands-on experience with leading commercial Cloud platforms, including AWS, Azure, and Google

·      Proven experience with data warehousing, data ingestion, and data profiling

·      Proficient in SQL

·      Strong aptitude for learning new technologies and analytics techniques

·      Highly self-motivated and able to work independently as well as in a team environment

·      Understanding of agile project approaches and methodologies

·      Proficient in a source code control system, such as Git

·      Proficient in the Linux shell, including utilities such as SSH




Preferred Experience

·      Familiarity with implementing analytics solutions with one or more Hadoop distributions (Cloudera, Hortonworks, MapR, HDInsight, EMR)

·      Familiarity with streaming data ingestion

·      Proficient in Python and/or Java

·      Consulting experience

· Familiarity or strong desire to learn quantitative analysis techniques (e.g., predictive modeling, machine learning, segmentation, optimization, clustering, regression)




Slalom is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.
Show more Show less"
2814064774,Data Engineer - Integrations,Nuna Inc.,2021-11-01,United States,"San Francisco, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Hospitals and Health Care","At Nuna, our mission is to make high-quality healthcare affordable and accessible for everyone. We are dedicated to tackling one of our nation's biggest problems with ingenuity, creativity, and a keen moral compass.

Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.

Nuna partners with healthcare payers, including government agencies and health plans, to turn data into learnings and information into meaning.

YOUR TEAM

Data Engineering is at the core of Nuna's promise to deliver exceptional and actionable data insights to our clients. We are responsible for the scalable comprehension, ingestion, cleaning, and deploying of client data on schedule - think of us as the heart muscle that pumps data throughout Nuna. And because quality and consistency are our hallmarks, we're more than a little obsessed with detail and process.

YOUR IMPACT

Data Engineering is a cross-functional team that supports Nuna's Enterprise Product Suite. We untangle messy and complex healthcare data and enable our Data Science and Analytics teams to perform and deliver exceptional analytics to our clients.

YOUR OPPORTUNITIES

Map, extract, transform and load data from source to target through multiple stages
Perform data quality assessment, measurement, and reporting
Collaborate with product managers, data scientists, data analysts and engineers to define user requirements and database design specifications for our clients' needs.
Analyze data feed requirements received from vendors, translate business requirements into technical design specifications.
Build out new API and functionality for data ingress/egress with our customers systems.
Use your knowledge of SQL to perform data analysis based on business requirements and data profiling reports.
Maintain and ensure monthly data updates are delivered on-time to our customers
Serve as a technical resource in resolving client issues related to database or other data issues
Work closely with client-facing teams
Work directly with clients and lead client calls when needed
Construction and automation of data pipelines


YOU BRING

Ability to use SQL for developing robust and scalable ETL pipelines.
Experience working with Python for API integrations and pipeline automation.
Experience working with data, preferably healthcare data, and databases.
Experience with data quality processes, data quality checks, validations, data quality metrics definition and measurement.
Ability to construct and debug complex SQL queries.
Ability to operate with cross-functional teams (e.g., implementation managers, data science, engineers, etc.).
Strong communication and teamwork skills.
BA/BS in statistics, math, data science, or computer science (or related field)


BONUSES

Healthcare experience is preferred.
Demonstrated track record working with data warehouse and ETL architectures and concepts plus.
Experience with cloud infrastructure (AWS, Azure, GCP) is preferred.


Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.
Show more Show less"
2812355041,Data Engineer - Location Flexible,Dropbox,2021-10-31,United States,"San Francisco, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Description


Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work.


Team Description


Our Engineering team is working to simplify the way people work together. They’re building a family of products that handle over a billion files a day for people around the world. With our broad mission and massive scale, there are countless opportunities to make an impact.








Role Description


In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you!

Responsibilities


You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models
You will help define/design data integrations, data quality frameworks and design/evaluate open source/vendor tools for data lineage
You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture


Requirements


BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients.
Experience designing, building and maintaining data processing systems
Experience working with either a Map Reduce or a MPP system on any size/scale



Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland).

Show more Show less"
2805786404,Data Engineer,NBCUniversal,2021-11-05,United States,"New York, NY",Information Technology,Full-time,"Broadcast Media Production and Distribution, Entertainment, and Media Production","Responsibilities

The Data & Analytics team (D&A) at NBCUniversal is looking for a passionate problem solver who’s looking to build the next generation of data pipelines and applications. Working across one or more of our main subject areas – research, marketing, engineering frameworks – the Data Engineer role is right for you if you’re a “hands-on” coder who can build and cleanse large datasets in order to report out actionable insights. As part of the global Operations & Technology organization, the D&A is focused on data and analytics strategies for the future. We support NBCU’s vast portfolio of brands - from broadcast, cable, news, and sports networks to film studios, world-renowned theme parks, and a diverse suite of digital properties. We take pride in supplying our business groups with data to advise and shape strategic business decisions related to our content.In the Data Engineer role, you’ll be working with internal stakeholders, data engineers, visualization experts, data scientists, and other technologists across the business. If you’re someone who loves to take large, disparate data sets and build them into flexible and scalable analytics applications and databases, you’ve come to the right place. Here you can create the extraordinary. Join us!


Collaborate with business leaders, engineers, and product managers to understand data needs.
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using cloud-native data engineering principles
Design, build, and scale data pipelines across a variety of source systems and streams (internal, third-party, as well as cloud-based), distributed/elastic environments, and downstream applications and/or self-service solutions
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Implement the appropriate design patterns while optimizing performance, cost, security, and scale and end user experience
Participate in development sprints, demos, and retrospectives, as well as release and deployment
Build and manage relationships with supporting IT teams in order to effectively deliver work products to production


Qualifications


5+ years of experience in a data engineering role
Direct experience with data modeling, ETL/ELT development principles, and data warehousing concepts
Knowledge of data management fundamentals and data storage principles
Experience in building data pipelines using Python/SQL or similar programming languages
Demonstratable experience in Airflow, Luigi or similar orchestration engines
General understanding of cloud data engineering design patterns and use cases
Bachelor's degree in Computer Science, Data Science, Statistics, Informatics, Information Systems or related field.
Desired Characteristics:
Analytical – You have experience in delivering data analytics solutions that promote data discovery
Experience with Snowflake, Amazon Web Services, or related cloud platforms a plus
Understanding of big data technology stacks (Hive / Spark etc) is a plus
Media-focused – Strong knowledge/passion for media including broadcast TV, digital, and film
Direct experience working with sources like Nielsen, Adobe Analytics, comScore, and other media/entertainment industry datasets a plus
Communicator – You have excellent verbal and written skills with the ability to communicate ideas effectively across all levels of the organization, both technical and non-technical
Action-oriented – You're constantly figuring out new problems and are regularly showing results with a positive attitude, always displaying ethical behavior, integrity, and building trust
Strong understanding of Agile principles and best practices
You’ve dealt with ambiguity and can make quality decisions in a dynamic, fast-paced environment

Sub-Business

Engineering

Career Level

Experienced

City

New York

State/Province

New York

Country

United States

About Us

At NBCUniversal, we believe in the talent of our people. It’s our passion and commitment to excellence that drives NBCU’s vast portfolio of brands to succeed. From broadcast and cable networks, news and sports platforms, to film, world-renowned theme parks and a diverse suite of digital properties, we take pride in all that we do and all that we represent. It’s what makes us uniquely NBCU. Here you can create the extraordinary. Join us.

Notices

NBCUniversal’s policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.
Show more Show less"
2792738642,Data Engineer,Capital One,2021-11-13,United States,"McLean, VA",Information Technology and Engineering,Full-time,"Banking, Financial Services, and Investment Banking","Locations: VA - McLean, United States of America, McLean, Virginia

Data Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You’ll Do

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies

Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems

Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake

Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community

Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment

Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications

Bachelor’s Degree

At least 2 years of experience in application development

At least 1 year of experience in big data technologies

Preferred Qualifications

3+ years of experience in application development including Python, SQL, Scala, or Java

1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)

2+ years experience with Distributed data or computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)

1+ years experience working on real-time data and streaming applications

1+ years of experience with NoSQL implementation (Mongo, Cassandra)

1+ years of data warehousing experience (Redshift or Snowflake)

2+ years of experience with UNIX Linux including basic commands and shell scripting

1+ years of experience with Agile engineering practices

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Job Category - Engineering, Technology
Show more Show less"
2816983823,Data Engineer II,American Family Insurance,2021-12-01,United States,"Madison, WI",Information Technology,Full-time,Insurance and Financial Services,"WI Madison

At American Family Insurance, we believe people are an organization’s most valuable asset, and their ideas and experiences matter. From our CEO to our agency force, we’re committed to growing a diverse and inclusive culture that empowers innovation that will inspire, protect, and restore our customers’ dreams in ways never imagined.

American Family Insurance is driven by our customers and employees. That’s why we provide more than just a job – we provide opportunity. Whether you’re already part of our team in search of a new challenge or new to our company and ready for what’s next, you’re in the right place. Every dream is a journey that starts with a single step. Start your journey right here. Join our team. Bring your dreams.

Job ID: R25728 Data Engineer II (Open)

Compensation may vary based on the job level and your geographic work location.

Compensation Minimum:85400 Compensation Maximum:141600 Summary: Job Family Summary Determines and builds the technical solution(s) to allow unstructured data to be structured and used by Data Scientists. Seeks to understand the data being worked with as its often unstructured data sets. Often are data gurus who prepare data for all stages of the modeling process including exploration, training, testing, and deployment. Job Profile Summary As a Data Engineer II, you’ll work on collecting, storing, processing and building Business Intelligence and Analytics applications within our big data platform. Presently, our team is constructing an enterprise data lake to enable analysts and scientists to self-service data at scale across American Family’s operating companies. We’re leveraging open source technologies like Spark, Python, Hadoop, and cloud native tools to curate high-quality data sets. You’ll also be responsible for integrating these applications with the architecture used across the organization. Adjacent responsibilities include establishing best practices with respect to data integration, data visualization, schema design, performance and reliability of data processing systems, supporting data quality, and enabling convenient access to data for our scientists and business users.

Job Description

Job Level Summary

Requires in-depth conceptual and practical knowledge in own job discipline and basic knowledge of related job disciplines
Solves complex problems
Works independently, receives minimal guidance
May lead projects or project steps within a broader project or may have accountability for on-going activities or objectives
Acts as a resource for colleagues with less experience

Primary Accountabilities

Perform exploratory data analysis to determine which questions can be answered effectively with a given dataset. Ability to analyze new (possibly unstructured) data sources to determine what additional value they may bring.
Design and develop highly scalable and extensible data pipelines from internal and external sources.
Work on cross-functional teams to design, develop, and deploy data-driven applications and products, particularly within the space of data science.
Prototype emerging technologies involving data ingestion and transformation, distributed file systems, databases and frameworks.
Design, build, and maintain tools to increase the productivity of application development and client facing teams.
Partner with business analyst to define, develop, and automate data quality checks.
Design and develop big data applications and data visualization tools.

Travel Requirements

This position requires travel up to 10% of the time.

Specialized Knowledge & Skills Requirements

Demonstrated experience providing customer-driven solutions, support or service.
In-depth knowledge of SQL and experience using a variety of data stores (e.g. RDBMS, analytic database, scalable document stores).
Hands-on programming experience in Python or java, with an emphasis towards building ETL workflows and data-driven solutions.
Experience with big data batch computing tools (e.g. Hadoop or Spark) and developing distributed data processing solutions.
Experience with cloud computing platforms (e.g. AWS, GCP, Azure)
Good data understanding and business acumen in the data rich industries like insurance or financial
Solid understanding of data modeling principles (e.g. dimensional modeling and star schemas).
Solid understanding of database internals, such as indexes, binary logging, and transactions.
Solid understanding of Infrastructure as Code (e.g. Docker, CloudFormation, Terraform, etc.)
Solid understanding of with software engineering tools and workflows (i.e. Jenkins, CI/CD, git).

Education and Licenses

Bachelor’s degree in computer science or related field, or equivalent combination of education and experience.
Additional Job Information:

When you work at American Family you can expect benefits that support your physical, emotional, and financial wellbeing. You will have access to comprehensive medical, dental, vision and wellbeing benefits that enable you to take care of your health. We also offer a competitive 401(k) contribution, a pension plan, an annual incentive, and a paid-time off program. In addition, our student loan repayment program and paid-family leave are available to support our employees and their families.Interns and contingent workers are not eligible for American Family Enterprise benefits.

We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.

Stay connected: Join Our Enterprise Talent Community !

Posted 4 Days Ago Full time R25728

At American Family Insurance, we know how hard our customers and employees work to achieve their dreams. That’s why, for over 90 years, we’ve made it our mission to protect those dreams. It’s all part of who we are and who we’ll always be – innovative, caring, agile, trustworthy, transparent and passionate. We’re a strong, forward-looking company and a proven leader in our industry. And if you’re looking to make a difference, we’re looking for you.

Join Our Enterprise Talent Community !


Show more Show less"
2798293688,Data Engineer,Tradesy,2021-10-19,United States,"Santa Monica, CA",Information Technology,Full-time,"Computer Software, Internet Publishing, and Retail","Tradesy is a peer-to-peer marketplace for buying and selling luxury fashion, enabling stylish customers to unlock the value in their closet to access affordable luxury. Our mission is to make fashion resale as simple, safe and stylish as retail- at scale. We have millions of passionate members, a product that people love, strong values centered around sustainability and equality, and a team culture that truly supports you- while giving you the freedom to work from wherever you are.

Tradesy is seeking an exceptionally talented Data Engineer who will develop robust data pipelines and build upon our data platform on Google Cloud. Our data platform powers analytics, forecasting, recommendations, fraud detection, and many other features at Tradesy.

The successful data engineer will leverage tools and build systems to deliver data to teams and applications. In addition, they will strive for excellence in code quality, architecture, and testing practices.

This role reports directly to the Data Engineering Manager.

You will:

Build batch and streaming data pipelines to power analytics and data driven applications
Work with our analysts and data scientists to test and scale complex analytics and machine learning algorithms
Work with our product and engineering teams to ensure we are capturing the right data
Learn new technologies to ensure we are using the proper tool for the job


You have:

Bachelor's degree or equivalent demonstrated experience in Computer Science
Coding proficiency in at least one of Java, Python, Go, Scala
2+ years of experience with SQL is required
2+ years of experience with a big data processing technology (ie. Spark, MapReduce, Apache Beam) is required
Experience with Apache Airflow or similar workflow manager is a plus
Experience scaling and productionizing machine learning models is a plus
Experience with streaming data pipelines is a plus
Experience designing and managing a data warehouse is a plus
Experience with Google Cloud technologies (BigQuery, BigTable, Dataflow, Dataproc, Cloud Functions, Datastore, PubSub) or similar cloud computing services is a plus


What to expect:

Apply through our website www.tradesy.com or any affiliate job boards:

You will receive a confirmation email
If we don't feel you meet the requirements for this position, we will send you an email informing you of the decision


If we think you meet enough of our criteria, one of our in-house Recruiters will reach out to schedule an introductory call.

Compensation and benefits:
Competitive salary
Commensurate with skill set, experience and the position. What you made at your last job should not dictate your worth. Tradesy is committed to a Basic Living Wage threshold and holds its own $50k Minimum Wage Standard for entry level positions
True Opportunity for Growth
We don't believe in time served or waiting for your manager to get promoted or leave. Carve out your own path, at your pace - there's room at the top for all of us
Comprehensive Health Benefits
Several options for Company Paid Medical, Dental, Prescription Drug and Vision Plans. Tradesy pays 100% of the premiums for individuals - great discounts if you want to add spouse/children/families
Wealth Benefits
401k option and Equity (stock options) because every employee should be an owner
Flexible Paid Time Off
We coordinate with each other to make sure work and play find a healthy balance.
Celebrate Diversity Paid Holiday Program
A combination of set and floating Company Holidays - so you can choose the days most meaningful to you
Designated Paid time off to serve (Jury Duty) and VOTE as well!
Mentorship opportunities
Grow within your field, gain valuable skills and experience in a new one or become a change agent for those around you - all on Company time
Paid Parental Leave -
For Moms, Dads and everything in between


Additional perks:

Remote Friendly Office - Work from the place that best works for you
Flexible Working Hours - night owl? Got kids/pets/family obligations? We value your output, not the clock
Virtual company-wide happy hours, Product demos, support groups and team events. Philanthropy and community outreach too. We are constantly finding news ways to stay meaningfully connected in this virtual world
Monthly Technology Reimbursement - $100 per month (tax free!) to help you stay connected and in touch
Free Health & Wellness App Subscription - Fitness, mindfulness, stretching, stress management, nutrition and so much more.
Show more Show less"
2814238984,Data Engineer (100% Remote - Throughout US),Moody's Analytics,2021-11-05,United States,"Washington, DC",Information Technology,Full-time,Financial Services,"Role/Responsibilities

As a Software Engineer you will join a growing team of data engineering focused professionals designing, implementing and deploying solutions for a data factory that produces billions of predictions annually that help our customers make better, faster credit decisions.

In This Role, You Will

Automate ingestion of data in various formats from multiple providers
Develop bots that clean and normalize data
Create deployment scripts for your solutions
Instrument services to facilitate continuous monitoring of our data production processes

Qualifications

Demonstrated SQL fluency;
Demonstrated fluency with Python, PySpark and/or Scala;
Awareness of agile methodologies;
Strong interest in big data and serverless computing as demonstrated through an example you can share;
A Bachelor’s in Computer Science, Statistics, Mathematics, Operations Research or field with software engineering emphasis;
Strong problem solving skills;
Excellent written and oral communication skills;
Ability to work independently, ask for help after a reasonable effort and not ask same question again;

LOB/Cost Center

PA/Credit Analytics

Job Req ID

23790BR

Entity

Moody's Analytics (MA)

Line of Business

Predictive Analytics OU (EAAS OU)

Regular/Temporary

Regular

City

Alpharetta, Atlanta, Boca Raton, Boston, Charlotte, Chicago, Dallas, Hoboken, King of Prussia, Miami, New York, Newark, Omaha, PLANO, San Francisco, South San Francisco, Tallahassee, Walnut Creek, Washington DC

Job Category

Engineering & Technology

Job Sub Category

Software Engineering

Experience Level

Experienced Hire

Working at Moody's

Moody's (NYSE: MCO) is a global integrated risk assessment firm that empowers organizations to make better decisions. Our data, analytical solutions and insights help decision-makers identify opportunities and manage the risks of doing business with others. We believe that greater transparency, more informed decisions, and fair access to information open the door to shared progress. With over 11,000 employees in more than 40 countries, Moody's combines international presence with local expertise and over a century of experience in financial markets. Learn more at moodys.com .

Entity

Moody’s Analytics provides financial intelligence and analytical tools supporting our clients’ growth, efficiency and risk management objectives. The combination of our unparalleled expertise in risk, expansive information resources, and innovative application of technology, helps today’s business leaders confidently navigate an evolving marketplace.

EEO Policy

Moody’s is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, gender, age, religion, national origin, citizen status, marital status, physical or mental disability, military or veteran status, sexual orientation, gender identity, gender expression, genetic information, or any other characteristic protected by law. Moody’s also provides reasonable accommodation to qualified individuals with disabilities in accordance with applicable laws. If you need to inquire about a reasonable accommodation, or need assistance with completing the application process, please email accommodations@moodys.com . This contact information is for accommodation requests only, and cannot be used to inquire about the status of applications.

For San Francisco positions, qualified applicants with criminal histories will be considered for employment consistent with the requirements of the San Francisco Fair Chance Ordinance.

This position may be considered a promotional opportunity, pursuant to the Colorado Equal Pay for Equal Work Act.

Click here to view our full EEO policy statement. Click here for more information on your EEO rights under the law. Click here to view our Pay Transparency Nondiscrimination statement.

Securities Trading Policy (STP)

Candidates for Moody's Corporation may be asked to disclose securities holdings pursuant to Moody’s Policy for Securities Trading and the requirements of the position. Employment is contingent upon compliance with the Policy, including remediation of positions in those holdings as necessary.
Show more Show less"
2818954612,Data Engineer,Eliassen Group,2021-11-29,United States,"Charlotte, NC",Information Technology,Full-time,IT Services and IT Consulting,"We're looking for a skilled and passionate Data Engineer. You will work collaboratively to ensure optimal data delivery architecture throughout ongoing projects and operations.

Due to client requirement, applicants must be willing and able to work on a w2 basis. For our w2 consultants, we offer a great benefits package that includes Medical, Dental, and Vision benefits, 401k with company matching, and life insurance.

Responsibilities of the Data Engineer:

Work across teams to deliver best-in-class solutions
Leverage programming tools to develop highly scalable interfaces and software components
Design, build, test, and deploy data pipelines that integrate data from multiple sources
Automate manual processes, check data quality, handle errors, and redesign infrastructure as needed
Ensure systems meet business requirements and industry best practices
Write data queries for ad hoc analysis

Requirements of the Data Engineer:

Bachelor's degree and at least 5 years of experience
Experience with data modeling
Experience with SQL, DDL, and Stored Procedures in SQL Server
Experience leading teams to deliver complex products
Experience developing solution architecture recommendations
Workflow scheduling tools such as CA ESP Automation
Familiarity with Agile methodology

Job ID: 361388

Show more Show less"
2522215501,Data Engineer,M9 Consulting Inc,2021-11-19,United States,"Mountain View, CA",,Contract,,"Title: Data Engineer

Location: Bay Area, CA (Remote)

Duration: 6 months




Required :   

Advance skills in big data technologies like Hadoop, Python, Spark, SQL.
Must have experience building data APIs.
5+ years of relevant experience in the field of Data Engineering
Bachelor’s in Computer Science or related disciplines
Knowledge of Data Structures and Algorithm.
Strong Python programming skills with ability to implement OOPs and functional programming. Knowledge of Scala/Java would be plus.
Strong knowledge on RDBMS and NoSQL databases with the ability to implement them from scratch. Knowledge of Graph databases will be a plus.
Strong expertise in building & optimizing data pipelines, architectures, and data sets.
Experience working with different file formats like Parquet, ORC, Avro, RC, etc.
Experience with big data infrastructure inclusive of MapReduce, Hive, HDFS, YARN, HBase, Oozie, etc.
Knowledge and experience of using orchestration frameworks like Airflow, Oozie, Luigi, etc.
Experience using Spark and building jobs using Python/Scala/Java.
Experience or Knowledge building stream processing platforms using Spark Streaming, Storm, etc. Knowledge of Kafka/Flink+Beam would be plus.
Knowledge of building REST API end points for data consumption.
Experience in building scalable data pipelines for both real time and batch using best practices in data modelling, ETL/ELT processes utilizing various technologies such as Spark, Kafka, Presto, SAP HANA, Airflow, informatica.
Perform Data analysis using Python, complex SQLs, and other tools.
Perform root cause analysis of issues from platform standpoint on Kubernetes, Containers, Hadoop, Spark, Hive, Presto
Excellent oral and written communication is a must.

 

Preferred:

Master's in Computer Science or related disciplines
Experience building self-service tools for analytics would be plus.
Knowledge of ELK stack would be a plus.
Knowledge of implementing CI/CD on the pipelines is a plus.
Knowledge of Containerization (Docker/Kubernetes) will be plus.
Experience working with one of the popular Public Cloud based platforms is preferred


Show more Show less"
2823379514,Big Data Engineer,Tranzeal Incorporated,2021-12-01,United States,"Sunnyvale, CA",Engineering and Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Title Big Data Engineer Location Sunnyvale, CA Duration 6+ Months contract

Skills Experience in building scalable, robust applications using Big Data technologies like Hadoop, Spark, Hive, Map reduce Big data and Java development skills

Java backend programming (Candidates with BOTH Big Data and Java experience and not just one). Proficient with SQL Experience with Scripting ndash Python, shell Nice to have - Experience with MySQL Nice to have ndash experience with Google Cloud Platform, BigQuery, Apache Nifi
Show more Show less"
2823291057,Big data engineer,"Georgia IT, Inc.",2021-11-07,United States,"Las Vegas, NV",Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Financial Services","Job Name : Big data engineer

Job Location : Las Vegas, NV

Job Type : Full Time

Job Authorization: US Citizen/ GC /EAD (H4/L2/TN) preferred

Immediate Relocation required from Day 1st.

Job Description

Perfect in Big-Data & Hadoop concepts

Should have Knowledge of Big Data tools Hive,Sqoop,Pig

Should have experience working with Apache Spark

Knowledge of Big Data ecosystem

Should have experience in optimizing Hadoop ETL jobs

Very good in advanced SQL queries (Join, Group by, Partition by, Indexing etc)

Should have knowledge and exposure to NoSQL databases

Able to Explore and analyse datasets with tools like Excel.

Good to have Knowledge in Banking Domain and risk Management system.

Excellent communication, analytical and inter-personal skills
Show more Show less"
2796939626,Data Engineer,TripleLift,2021-10-21,United States,Utica-Rome Area,Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","About TripleLift

TripleLift, one of the fastest-growing ad tech companies in the world, is a technology company with products at the intersection of creative and media. Its mission is to make advertising better for everyone — publishers, advertisers and consumers — by reinventing ad placement one medium at a time. With direct inventory sources, diverse product lines, and creative designed for scale, TripleLift is leading the next generation of programmatic advertising from desktop to television. Working with 90% of the publishers on the comScore 200, 100% of the brands on the AdAge 100, and 100% of the top 20 global DSPs, TripleLift has grown its revenue by high double digits since inception and has now recorded five years of accelerating profitability.

TripleLift, part of the Vista Equity Partners portfolio, has appeared on the Inc. 5000, Deloitte Technology Fast 500 and Crain's New York Fast 50 for four consecutive years, and has been on Business Insider’s list of Hottest Ad Tech Companies for the last two years. Find out more information about how TripleLift is shaping the future of advertising at triplelift.com.

The Role

TripleLift is seeking a Data Engineer to join a small, influential Data Engineering team. This hire will be responsible for expanding and optimizing our data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software engineers, product managers, business intelligence analysts and data scientists on data initiatives, and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities

Create and maintain optimal data pipeline architecture,
Explore and assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Spark, EMR, Kafka and other big data technologies
Work with stakeholders across different teams, including product managers, engineers and analysts to assist with data-related technical issues and support their data infrastructure needs.


Qualifications

Advanced working knowledge of Spark
Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 2+ years of experience in a Data Engineer role. They should also have experience using the following software/tools:
Experience with big data tools:Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases
Experience with data pipeline and workflow management tools: Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented and functional scripting languages: Python, Java,Scala, etc

Location

New York (Remote)

Benefits And Company Perks

100% Medical, Dental & Vision Plans
Unlimited PTO
401k, FSA, Commuter Benefits
Weekly Yoga & Bootcamp
Membership to Headspace (Meditation)
Ongoing professional development
Amazing company culture


Awards

We love celebrating our achievements. They remind us of our contributions making advertising work for everyone, and the TripleLifters who make it all possible. TripleLift is proud to be recognized by AdExchanger as Programmatic Power Player, Digiday as Best Ad Tech Platform, by Inc. as a Best Workplace for our culture and benefits, and among Inc’s Best in Business for our innovations and positive impact on the industry.

To check out more of our awards and distinctions, please visit https://triplelift.com/ideas/#distinctions

Diversity, Equity, Inclusion and Accessibility at TripleLift

At TripleLift, we believe in the power of diversity, equity, inclusion and accessibility. Our culture enables individuals to share their uniqueness and contribute as part of a team. With our DEIA initiatives, TripleLift is a place that works for you, and where you can feel a sense of belonging. At TripleLift, we will consider and champion all qualified applicants for employment without regard to race, creed, color, religion, national origin, sex, age, disability, sexual orientation, gender identity, gender expression, genetic predisposition, veteran, marital, or any other status protected by law. TripleLift is proud to be an equal opportunity employer.

TripleLift does not accept unsolicited resumes from any type of recruitment search firm. Any resume submitted in the absence of a signed agreement will become the property of TripleLift and no fee shall be due.
Show more Show less"
2791357310,Data Engineer,Picket Homes,2021-11-09,United States,"Seattle, WA",Information Technology,Full-time,"Computer Software, Internet Publishing, and Leasing Real Estate","Picket believes it should be easier to live where you want and love where you live, and we think that starts with a better way to rent. With innovative technology and a customer-first philosophy, we’re transforming the experience of renting a home at every stage of the value chain, from the way investors acquire and manage single-family rentals, to the quality, service, and flexibility residents enjoy when they live in them.

We are hiring smart and passionate people coming out of top Graduate programs who are flexible, eager, passionate, and customer-centric. We will sponsor H1B visas! Picket is venture funded, and founded by a team of entrepreneurs and executives from top technology, real estate, and investment companies.

ROLE

We are seeking an exceptional startup hybrid of quantitative analyst, data scientist, and software engineer to work closely with executives, real estate professionals, product managers, and engineers to build and implement dynamic models, algorithms, and analysis to predict fair market rental and sale prices, forward appreciation curves, and risk-adjusted investment projections through the incorporation of geo-spatial, financial, real estate, census, and any other relevant data sources, analytics and models. This person must embrace an unusual combination of advanced technologies and extreme pragmatism to solve hard problems quickly, iterating on improvement relentlessly.

Requirements

Expertise in Python or Kotlin
Proficiency in any core SQL db
Data analysis & visualization experience (NumPy, Pandas, Tableau, Excel, etc)
Data modeling implementations in Python, R, C++, or similar
Machine learning exposure is desired
Understanding of SW lifecycle including best practices in testing and deployment
Familiarity with Git, Linux, AWS, and other software tools and cloud services
Technical writing ability, including visual diagramming tools
MS degree from a top engineering university
EXPECTATIONS

In month one, complete company onboarding, and build your own development plan for ownership of an area in our “Inertia Decision Science” team.
Within first three months, research and implement new data sources for improving any part of our data science, adding sound thought, models, technology reviews, implementations, and other contributions. Also build out at least one new feature with another team member.
Within 6 months, build a roadmap for getting to higher quality predictions on financial models, separating economic assumptions from macro to micro, then commence executing on it.

Set sights on the following by the end of your first year:

Take ownership of a discrete high-priority set of models and continuously iterate on improving speed, accuracy, and comprehensiveness.
Help build out the team through recruiting, high-bar interviewing, onboarding, and teaching.
Gain full understanding of real estate, housing, geographies, and market characteristics to improve your decision-making and implementations.

CULTURE

Entrepreneurial: demonstrates passion for customers, innovation, adaption, risk-taking, and bouncing back from failure. Ideal candidate has built their own tech project, regardless of size or success. Self-determined: continuous self-learner, thrives in a vacuum, shows urgent ownership, operates autonomously, and delivers with discipline in office or remotely. Communicates frequently, efficiently, openly, and critically in all formats. Team Player: Ready to mentor, lead, and set a high bar for other team members, and conversely- ready to follow, learn from any, and correct misses.

OUR STACK

Our computing environment consists of common technologies. Time-to-market is a top consideration, so we launch quickly and leverage current team knowledge. Each separable functional product area and tech team will have some latitude in its tech choices, and we support and encourage cross-team sharing and migration as per product priorities and individual passions.

A background check is required for this position. Picket is an equal-opportunity employer that celebrates diversity and we welcome applicants from all backgrounds.

At Picket Homes, we are building something new and different - come build with us.
Show more Show less"
2754028516,Data Engineer,Axos Bank,2021-09-22,United States,Miami-Fort Lauderdale Area,Information Technology,Full-time,"Banking, Financial Services, and Investment Banking","Axos

Born digital, Axos Bank has reinvented the banking model and grown to over $14 billion in assets since our founding in 2000. With a broad and ever-growing range of financial products, Axos Bank is rated among the top 5 digital banks in the country! Axos Financial is our holding company and publicly traded on the New York Stock Exchange under the symbol ""AX"" (NYSE: AX).

We bring together human insight and digital expertise to anticipate the needs of our customers. Our team members are innovative, technologically sophisticated, and motivated to achieve.

Learn more about working here!

REMOTE*

Florida Residents Only

The Opportunity

You will be joining a high performing tech minded team that will work with some of the latest software products in support of an internal data solution.

The Role

Work with technical and business team to understand the business requirements, functional and technical specifications
Design, code, and maintain new and existing complex SQL stored procedures and functions
Performance tune existing stored procedures, tables, and indexes
Collaborate with other engineers to troubleshoot, repair, and performance tune databases
Review SQL code written by other developers to ensure compliance to coding standards and best practices as well as maximum performance
Create SSIS packages for data transformation, cleansing, caching, aggregation, staging, and transfer
Troubleshoot problems that may come up with database environments: performance issues; replication issues; or operational issues
Perform data analysis and data profiling tasks to provide support and recommendations for development and design decisions
Analyze and define data flow requirements and prepare applicable system documentation and operation manuals as needed
Support production data loads and ongoing refreshes of the database systems
Define, prepare, execute, and implement data validation and unit testing methods to ensure data quality
Maintain re-usable development standards that help implement each solution and/or enhancements to existing systems to meet current and future needs
Perform enhancements, bug fixes, and additional work when required

Are You A Fit?

3 years' working with relational DBs in a production environment and with Microsoft SQL Server
2 years' in SSIS packages and in a n Agile/SCRUM environment
Delivered high quality, high traffic, scalable database objects
SQL server design and development expertise
Excellent verbal and written communication skills, including ability to simplify complex concepts for technical and non-technical audience
Superior problem-solving skills, self-motivation, and the capacity to work under pressure and tight deadlines
Learn, acquire, and utilize new technologies, disciplines, and frameworks
Technical expertise in the areas of data profiling, data mining, and data analytics
Built reliable data ETL/ELT processes, query optimization, and dynamic SQL
Work well independently under minimal supervision with a track record of setting and meeting delivery commitments
Bachelor's Degree in Computer Science, Information Systems, Computer Engineering, or related field

Preferred

BigData
Banking

Apply directly for consideration as we are not using any outside agencies for any of our openings

Pre-Employment Drug Test

All offers are contingent upon the candidate successfully passing a credit check, criminal background check, and pre-employment drug screening, which includes screening for marijuana. Axos Bank is a federally regulated banking institution. At the federal level, marijuana is an illegal schedule 1 drug; therefore, we will not employ any person who tests positive for marijuana, regardless of state legalization.

Equal Employment Opportunity

Axos Bank is an E qual O pportunity employer. We are committed to providing equal employment opportunities to all employees and applicants without regard to race, religious creed, color, sex (including pregnancy, breast feeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship status, military and veteran status, marital status, age, protected medical condition, genetic information, physical disability, mental disability, or any other protected status in accordance with all applicable federal, state and local laws.

Job Functions And Work Environment

While performing the duties of this position, the employee is required to sit for extended periods of time. Manual dexterity and coordination are required while operating standard office equipment such as computer keyboard and mouse, calculator, telephone, copiers, etc.

The work environment characteristics described here are representative of those an employee may encounter while performing the essential functions of this position. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of this position.
Show more Show less"
2798272954,Data Engineer,"Sprout Social, Inc.",2021-10-19,United States,"Chicago, IL",Information Technology,Full-time,"IT Services and IT Consulting, Marketing and Advertising, and Computer Software","At Sprout Social, we build software used by 30,000 companies to create stronger relationships with their customers and create the world's most beloved brands. As a SaaS product used 24/7/365 by organizations of all sizes, sectors, and geographies, we consume and generate vast amounts of data which hold great potential to improve our business and products.

Relying on your experience with data warehousing and writing ETL pipelines, you will enable analytics and data science teams to provide critical insights and new product features to Sprout. Our systems touch and are used by all parts of Sprout's business, from integrating data from across Sprout's varying databases and partner APIs, to creating and maintaining the event service leveraged by Sprout's product teams. Our team uses a variety of technologies, including Python, Java, Spark, Redshift, Airflow, EMR, Elasticsearch, Docker, and Kinesis.

We're building diverse, collaborative teams that get the best results sustainably. Embedded as a member of the data science and analytics team, you will work in tandem with data analysts, data scientists and business stakeholders to define requirements for data warehousing and services. As a data engineer, you will ensure business stakeholders and data scientists get the data they need to drive reporting, analytics and machine learning at Sprout.

We're looking for a creative, collaborative, highly motivated, and inquisitive learner to build great software with us. If you confidently write data pipelines and warehouses that process and store terabytes, can write Python or Java-based services to serve up data, and are passionate about learning, we'd love to talk with you!

Qualifications

These are the minimum qualifications that our hiring team is looking for in this role:

2+ years working as a data engineer, including building and maintaining ETL pipelines and data warehousing.
2+ years conducting software development in Python and/or Java
Advanced SQL proficiency and experience with relational and non-relational databases.


Additionally, these are the preferred qualifications that would indicate a particularly strong candidate:

Programmatic development of ETL pipelines through software such as Airflow, Luigi, etc.
Experience using and deploying to cloud-based platforms such as AWS, Azure or Google Cloud.
Experience working with data scientists, analysts and other business stakeholders to define data warehousing needs.
Comfort with Git and the Linux command line.


Within 1 month, you will:

Complete Sprout's New Hire training program alongside other new Sprout team members.
Become familiar with data sources available in our data lake.
Learn about Airflow and our ETL processes.
Pair with our data engineers to learn about the libraries and processes owned by data engineering.
Begin meeting with data science and business analytics stakeholders to understand existing responsibilities and needs.


Within 3 months, you will:

Add data sources to our production data warehouse.
Modify and/or write new data pipelines using Airflow and push them to production.
Become familiar with our Java-based service used to store and process all events produced by Sprout's products.
Work with data science and business stakeholders to develop technical requirements for new data sources and services.


Within 6 months, you will:

Contribute to the development of new tooling to make it easier to pipe data between internal systems and external services.
Serve as on-call for support rotations.
Help deploy and manage software to make it easier analysts and analytics engineers to transform, manage, and provide visibility into data
Take ownership and improve existing ETL jobs in Airflow, processing hundreds of millions of data points a day.
Develop data processing pipelines using EMR and Spark.
Help develop and expand processes for monitoring and alerting around our data warehouse, ETL jobs and services.
Form a career growth plan with your manager and work towards it.


Within 12 months, you will:

Help develop new frameworks and libraries to allow stakeholders around Sprout to iterate more quickly on new ETL and data sources.
Help improve our existing deployment procedures.
Identify technical debt and performance bottlenecks within our systems, come up with a plan to improve the code, and get it pushed to production.
Create processes to improve the integrity of data stored in our data warehouse.
Expand your skills by learning from other engineers around Sprout.
Optimize Redshift tables for use in serving data into Tableau dashboards and data science models used by the whole company.
Surprise us! Use your unique ideas and abilities to change your team in beneficial ways that we haven't even considered yet.


Of course what is outlined above is the ideal timeline, but things may shift based on business needs and other projects and tasks could be added at the discretion of your manager.

About Sprout Social

Sprout Social powers open communication between individuals, brands and communities through elegant, sophisticated software. We are relentless about solving hard problems for our customers and committed to both customer and team success. Our team's shared belief in Sprout's mission promotes a culture of openness, empowerment and fun.

We're proud to regularly be recognized for our team, product and culture. Our benefits program includes:

Insurance and benefit options that are built for both individuals and families
Progressive policies to support work/life balance, like our flexible paid time off and parental leave program
High-quality and well-maintained equipment—your computer will never prevent you from doing your best
Wellness initiatives to ensure both health and mental well-being of our team
Ongoing education and development opportunities via our Grow@Sprout program, employee-led diversity, equity and inclusion initiatives and mentorship programs for aspiring leaders
Growing corporate social responsibility program that is driven by the involvement and passion of our team members
Beautiful, convenient and state-of-the-art offices in Chicago's Loop and downtown Seattle, for those who prefer an office setting


Whenever possible, Sprout wants to provide our team with the flexibility to work in the location that makes the most sense for them. For those that prefer an office setting, this role may be based in our Chicago or Seattle locations. If you prefer to work from your home, we can accommodate that for many locations across the United States. We are not set up in all states, however, so please take a look at the drop down box in our application to see whether your state is listed.

Sprout Social is proud to be an Equal Opportunity Employer and an Affirmative Action Employer. We do not discriminate based on identity- race, color, religion, national origin or ancestry, sex (including sexual identity), age, physical or mental disability, pregnancy, veteran or military status, unfavorable discharge from military service, genetic information, sexual orientation, marital status, order of protection status, citizenship status, arrest record or expunged or sealed convictions, or any other legally recognized protected basis under federal, state, or local law. Learn more about our commitment to diversity, equity and inclusion in our 2021 DEI Report.

If you need a reasonable accommodation for any part of the employment process, please contact us by email at accommodations@sproutsocial.com and let us know the nature of your request and your contact information. We'll do all we can to ensure you're set up for success during our interview process while upholding your privacy, including requests for accommodation. Please note that only inquiries concerning a request for reasonable accommodation will be responded to from this email address.

For more information about our commitment to equal employment opportunity, please click here (1) Equal Opportunity Employment Poster (2) Sprout Social's Affirmative Action Statement (3) Pay Transparency Statement.

When you apply for employment with Sprout Social, we will process your job applicant data, including your employment and education history, transcript, writing samples, and references as necessary to consider your job application for open positions. For more information about our privacy practices please visit our Privacy Policy. California residents have additional rights and should review the Additional Disclosures for California Residents section in our Privacy Policy.

Additionally, Sprout Social participates in the E-Verify program in certain locations, as required by law.
Show more Show less"
2799810656,Big Data Engineer,NCR Corporation,2021-11-17,United States,Atlanta Metropolitan Area ,Engineering and Information Technology,Full-time,IT Services and IT Consulting,"Position Summary & Key Areas of Responsibility:

We are looking for a passionate professional who can blend the fast-changing technology landscape of Cloud based Big Data & Advanced Analytics with the complex and high-impact space of IoT Analytics.




The Data Engineer II is responsible for partnering with business unit leaders within NCR to analyze, design, and deliver data products that enable NCR’s business. You will evaluate business questions, find the right data sets, ensure cleanliness of the data, and build scalable and clean solutions that can be deployed in a production environment. Along the way, you’ll partner with our Azure Infrastructure, Visualization, Advanced Analytics and Engineering teams consistently deliver quality data products.




Basic Qualifications:




Bachelor’s Degree in a Technical Discipline or equivalent work experience
Experience with medium to large scale data structures/data lakes
Ability to work with server/serverless database technologies (Azure Data explorer, Azure SQL and Kusto queries)
Design, Development and configuring datasets in Azure Data Explorer is a plus
Experience with both Streaming and Batch Data Ingestion (Lambda)
Must gave a good understanding of the Azure network, storage and various SaaS services
Must have DevOps experience having experience with tools like PagerDuty is a plus.
Must have experience on Streaming technologies (Kafka, Spark structured streaming, Databricks)
Must have experience with ETL technologies like Azure Data Factory.
Must have minimum of 5 years of overall Technology experience with at least 2 years of Big Data (Hadoop, Spark, and Azure HDInsights) experience.
Must have experience with Big Data toolsets: Hadoop echo system, Spark, Databricks and Azure based services
Experience working with data preparation and data quality
Good understanding of data governance and Data quality is a plus.
Embraces agile development principles (SAFe)
Ability to coordinate across multiple teams to solve complex problems

Show more Show less"
2779362990,Data Engineer -US Remote,Shift Technology,2021-11-01,United States,United States,Information Technology,Full-time,IT Services and IT Consulting,"At Shift Technology, we’re transforming insurance with AI. We help insurers fully automate more claims, deliver a great customer experience while protecting against risk and accurately identifying suspected fraud, making internal teams more effective and improving financial performance.

Since our launch in 2014 in Paris, we've raised over $320M with Tier 1 investors, opened offices in Boston, Tokyo, Singapore, London, Madrid, Mexico, Hong-Kong, and Sao Paulo, and currently work with more than 80 of the world’s leading insurers. If you are excited about joining a fast-growing Insurtech innovator with a passion for excellence and global culture, Shift is the place for you.

Skills

Shift Technology offers a unique opportunity to Data Engineers to accelerate their careers, improve their coding skills and have a high impact for our clients

Implement scraping and data retrieval pipelines such as web crawling websites with online vehicle ads to detect suspicious claims, crawl social media and public sites to spot discrepancies between claims and online activity, do entity resolution on lists of disbarred lawyers to detect fraud rings, etc.
Implement connectors with external solutions to provide in-box integration of our systems with other systems through APIs and data engineering ETLs.

The work is focused on implementing and maintaining data connectors, external data integration and helping building key showcases.

YOUR ROLE

Data Engineering for the pipelines of External Data, from the automation of their retrieval in external sources to their insertion into our data stores (SQL, ElasticSearch).
Designing new data pipelines, integrating new technologies to automate business tasks or deliver new functionalities.
Designing and implementing new connectors with external systems such as the integration of our solutions in market-leading solutions such as GuideWire.
Optimizing the robustness and performance of production pipelines as well as supervised the deployment of complex features to support client-facing Data Scientists. Learn about robustness patterns, code optimization techniques and large-scale deployment organization.

What We Are Looking For

Good programming skills, such as a degree in computer science and/or some coding work experience and you feel comfortable spending time writing and understanding code.
Ability to produce optimized and stable code which will smoothly run in a production context; you’re familiar with algorithm complexity assessment; you can write unit tests and integration tests; you think about potential problems and edge case.
Knowledge and experience using object-oriented concepts; you can design class diagrams and use common object-oriented design patterns naturally. C# knowledge is a plus.
Good practical spirit, eager to understand how new systems work, and able to troubleshoot and improve them; when hitting an unexpected problem, you are ready to dig in to solve the problem yourself.
Teamwork capabilities; you are comfortable working with others and you have good communication skills.

EEO Statement

At Shift we thrive to be a diverse and inclusive workforce. We hire and trust people without regard to race, color, religion, marital status, age, national or ethnic origin, physical or mental disability, medical condition, pregnancy, genetic information, gender identity or expression, sexual orientation, or other non-merit criteria. Shift is proud to be an Equal Opportunity Employer.
Show more Show less"
2796828314,Data Engineer,Health Gorilla,2021-11-13,United States,"Palo Alto, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Hospitals and Health Care","Health Gorilla is looking for a savvy Data Engineer to join our team. If you've ever wanted to get in on the ground floor, then this is the role for you.

As a Data Engineer, this role will require you to be responsible for every step of the data flow, where you will architect, build and manage databases, data pipelines, and data warehouses. The ideal candidate will have a successful track record of creating and maintaining an analytics infrastructure and pipeline that enables almost every other data function at the company. You while also keeping an eye out for trends or inconsistencies that will impact business goals.

You will work closely with software developers, product, and business teams to understand the data needs of the company.

Responsibilities and Duties

Create and maintain data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements
Optimize data delivery and redesign infrastructure for greater scalability
Build the infrastructure required for extraction, transformation, and loading of data from a wide variety of sources, which may include AWS technologies
Deploy analytic tools that utilize the data pipeline to assist the product and for internal stakeholders
Identify ways to improve data reliability, efficiency, and quality


Desired Skills And Experience

Background in computer science, engineering, applied mathematics, informatics or other quantitative, IT field
Experience with SQL and NoSQL databases, including MongoDB
Experience with ETL/ELT data pipeline and workflow management tools
Experience with AWS cloud services
Experience with building and optimizing 'big data"" data pipelines, architectures, and data sets
Strong analytic skills related to working with structured and unstructured data sets
Experience with programming languages, e.g. Python, Java, etc.
Ability to support and working with cross-functional teams in a dynamic environment
Strong project management, organizational, and communication skills


About Health Gorilla

Founded in 2014, Health Gorilla is a secure interoperability solution that enables the entire health care ecosystem – patients, payers, providers, digital health solutions, and labs – to seamlessly share health data and aggregate each patient's entire clinical history in one place. With enterprise-grade patient identity matching, an unparalleled patient index, and best-in-class security, the Health Gorilla network makes it easy for providers to pull their patient's information from any other clinical records system.

Headquartered in Silicon Valley, Health Gorilla works with health care organizations around the world, helping them gather the clinical data they need to deliver the best and most appropriate care for their patients.

Our Company Values

We build solutions for developers and providers who serve on the front lines of care delivery. In order to serve our customers, we uphold certain values as a team.

Commitment: We commit ourselves fully to our customers and, in many ways, we act as an extension of our customers.

Standards: We hold ourselves to the highest standards of integrity and honesty when it comes to supporting our customers, handling customer data, or building out new partnerships.

Learn More: We must remain bold with our ideas. We must continually explore new frontiers in interoperability and push the boundaries of what is possible, always in service of our customers.

Compensation And Benefits

We offer a variety of benefits that take compensation well beyond a paycheck. This includes traditional benefits and benefits you might not expect or know about, such as:

We offer employees a competitive salary, bonus program, and stock options, enabling everyone to reap the rewards of their work.
Health Gorilla offers comprehensive coverage, including health, dental, vision, disability, and life insurance.
401(K)
We have a flexible vacation policy, allowing you to work from home and take as much time off as you need.
Upbeat, casual and fun office environment and culture.
Company-sponsored events & happy hours.


Diversity

We believe that diversity creates a healthier atmosphere: Health Gorilla is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.
Show more Show less"
2794656858,"Data Engineer, Data Services",Braze,2021-11-16,United States,"Austin, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Who We Are

Braze delivers customer experiences across email, mobile, SMS, and web. Customers, including Burger King, Delivery Hero, HBO Max, Mercari, and Venmo, use the Braze platform to facilitate real-time experiences between brands and consumers in a more authentic and human way. And we do it at scale – each month, hundreds of billions of messages are sent to a network of over 3 billion active users through Braze.

Need more proof? Braze was named a Leader in the Forrester Wave™: Cross-Channel Campaign Management (Independent Platforms), Q3 2021, and was named to the Forbes Cloud 100 list for the fourth consecutive year. The company has also been selected as one of Fortune’s Best Workplace for Millennials in 2021, and was ranked #20 on Fortune’s Best Medium Sized Workplaces in 2021. Braze is certified as a Great Place to Work in the UK and the U.S. and is recognized as one of the UK's Best Workplaces for Women.

What We're Looking For

You are an engineer who loves working with data. The more data there is, the more excited you get. Data sources? The more, the better. Messy data doesn’t scare you. You want to learn and implement cutting edge technology that helps move, store, and analyze large and complex data sets. You are a data nerd. Or is it a data geek?

What You'll Do

Design, build, and manage efficient, fault-tolerant, and high-volume data pipelines
Build and maintain ETLs
Manage databases and tables
Design, build, and test solutions that touch every part of the data pipeline
Work with engineering to collect new data
Expose new data for downstream users to use
Enable more advanced analytics for Braze customers
Support the data services team with data tools

Who You Are

3+ years of data-focused, technical experience working with large and complex data sets
Experience with creating, monitoring, optimizing, improving, and scaling databases
Experience writing ETL/ELT
Working knowledge of Python and/or Ruby
Working knowledge of AWS, Azure, and/or Google Cloud
Working knowledge of Javascript
Security and privacy minded
Fast learner, self-starter, go-getter, intellectually curious, all that jazz
Bonus Points:
Familiarity with analytics technologies (i.e. Looker) a plus
Familiarity with non-relational databases (i.e. MongoDB) a plus
Familiarity with Snowflake a plus
Familiarity with Pandas a plus
Familiarity with Kafka is a plus

What We Offer

Competitive compensation that includes equity
Generous time off policy to balance your work and life, including paid parental leave
Competitive medical, dental, and vision coverage for you and your dependents
Collaborative, transparent, and fun loving office culture

If you are a California resident subject to the California Consumer Privacy Act, click here to understand how Braze processes your personal information and how you can exercise your rights.

If you are located in the EU or UK visit our privacy policy to understand how Braze processes your personal information and how you can exercise your rights.
Show more Show less"
2810800416,Data Engineer,Qwinix,2021-10-29,United States,"Denver, CO",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Who We Are

Qwinix is a cloud-native consultancy and Google Cloud Partner. Driven by a distinguished engineering core, Qwinix works with clients to modernize their infrastructure, develop powerful digital experiences and processes, and strategically adopt innovative cloud solutions.

We are on a mission to close the gap between next and now. Through great people and great technology, we are able to solve the world’s most pressing problems and build remarkable experiences, processes, and products for our clients.

We pride ourselves on fostering a growth-centric culture through every step of a Qwinix employee's journey. From comprehensive onboarding practices to career development incentives, we strive to help our employees build a brighter tomorrow for themselves and their clients.

Requirements

Minimum of 5 years of experience delivering data solutions on a variety of data warehousing, big data and cloud data platforms.

3+ years of experience working with distributed data technologies (e.g. Spark, Kafka, Flink etc) for building efficient, large-scale ‘big data’ pipelines;

Strong Software Engineering experience with proficiency in at least one of the following programming languages: Spark, Python, Scala or equivalent

Experience with building data ingestion pipelines both real time and batch using best practices

Experience with building streaming ingestion pipleline using Kafka streams, Apache Flink, or others

Experience with Cloud Computing platforms like Amazon AWS, Google Cloud etc.

Experience supporting and working with cross-functional teams in a dynamic environment

Experience with relational SQL and NoSQL databases, including Postgres, and Mongodb.

Experience with change data capture tools (CDC) preferred such as Attunity/goldengate

Experience with scheduling tools preferrable Control-M,Airflow or AWS Step functions.

Strong interpersonal, analytical, problem-solving, influencing, prioritization, decision- making and conflict resolution skills

Excellent written/verbal communication skills.

Location

Denver, Co.

We are dedicated to delivering quality customer service and, most importantly, compassionate support during times of need for their customers.

Qwinix is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, gender, religion, age, disability, veteran’s status, or any other classification as required by applicable law.
Show more Show less"
2816409096,Data Engineer,ViacomCBS,2021-11-02,United States,"New York, NY",Information Technology,Full-time,"Marketing and Advertising, Broadcast Media Production and Distribution, and Entertainment","Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from ViacomCBS, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream ViacomCBS Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.

Who you are

You are a problem solver, good communicator, and possess a strong sense of action and ownership. The perfect candidate for this role will use their skills in reverse engineering, analytics and creative experimental solutions to devise data and BI solutions. This engineer supports data pipeline development using disparate data sources. The ideal candidate will also work on data products solutions that include internal web applications and custom data visualization.

Key Responsibilities

Work with stakeholders and data engineering teams to provide data product solutions that support our partners.

Works with large volumes of traffic data and user behaviors to build pipelines that enhance raw data.

Able to break down and communicate highly complex data problems into simple, feasible solutions.

Extract patterns from large datasets and transform data into an informational advantage.

Ongoing development of technical solutions while developing and maintaining documentation, at times training impacted teams.

Contributing ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes.

Servicing multiple ad hoc requests in a timely manner

Ensuring regularity and standardization in data, metrics, and analysis.

Basic Qualifications

Master's degree in Statistics, Math, or Computer Science

1 to 3 years of commercial experience in a data engineer or data scientist role

Proficient in Python

Able to write SQL to perform common types of analysis.

Experience with Apache Airflow

Experience with a Python web framework such as Django or Flask.

Experience and comfort working with unstructured/non-standardized data

Familiar with a NOSQL database such as MongoDB.

Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc.

Experience with Docker and Kubernetes.

Familiarity with ELT/ETL concepts

Experience building and deploying application on a cloud platform (Google Cloud Platform preferred)

Additional Qualifications

Familiar with D3, Chart.js and creating web based interactive visualizations.

Familiar with Javascript, HTML, CSS and front end web development.

Familiar with Angular framework or React Library

Nice To Have

Can perform statistical analyses using tools such as R, Numpy/SciPy with Python

Experience with Adobe Analytics (Omniture)

ViacomCBS is an equal opportunity employer (EOE) including disability/vet.

At ViacomCBS, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. ViacomCBS is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.

If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.viacomcbs.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to viacomaccommodations@viacom.com. Only messages left for this purpose will be returned.
Show more Show less"
2805688677,Data Engineer,Hays,2021-12-01,United States,"Orlando, FL",Sales and Management,Full-time,Staffing and Recruiting,"Data Engineer – Perm – LA(Burbank or Glendale), SF, Seattle, Orlando, Bristol CT, Houston(Woodlands), NY, DC




The end client is unable to sponsor or transfer visas for this position; all parties authorized to work in the US without sponsorship are encouraged to apply.




An Entertainment Company is seeking a Data Engineer in LA(Burbank or Glendale), SF, Seattle, Orlando, Bristol CT, Houston(Woodlands), NY, DC.




Role Description




As a Data Engineer, you will develop custom data pipelines across a wide variety of technologies. You will have the opportunity to engineer high-performance and large-scale data engineer projects, ensure solutions support all functional and non-functional requirements and develop production grade, consumable data views. The Data Engineer will also participate in operational support and maintenance of products/services as well as coordinate and collaborate with offshore teams.




As a Senior Data Engineer, you will also participate in discovery processes with stakeholders to identify business requirements and expected outcomes. The Senior Data Engineer will also participate in operational support and maintenance of products and services as well as mentor junior team members.




As a Lead Data Engineer, you will also lead and mentor engineering teams and help grow a team of world-class engineers. The Lead Data Engineer will also be a DevOps guru, provide technical guidance and act as a point of escalation for cloud data projects, develop reusable patterns and frameworks as part of the engineering process as well as lead discovery processes with stakeholders.




• Design and engineer high-performance/large scale data engineering projects, producing maintainable and secure code with automated testing in a continuous integration environment.

• Develop production grade, consumable data views

• Ensure solutions support all functional and non-functional requirements

• Participate in operational support and maintenance of products and services

• Ability to participate in discovery processes with stakeholders to identify business requirements and expected outcomes

• Ability to mentor to junior team members

• Coordinate and collaborate with offshore teams




Skills & Requirements




• Relevant cloud data engineering work experience

• Ability to perform across multiple phases of development for multiple complex projects, including technical design, build, and end-to-end testing

• Passionate about delivering data engineering projects and features in a team environment

• Demonstrate the ability to quickly learn new technologies.

• Troubleshooting skills, ability to determine impacts, ability to resolve complex issues, and ability to exercise sound judgment and initiative in stressful situations.

• Strong oral and written communication and interpersonal skills.

• Fundamentals of data pipelining, ETL, data architecture, and the overall data lifecycle

• Cross-platform development languages: Python preferred (Java specialty OK)

• Snowflake data warehouse exposure and experience

• SQL and scripting proficiency

• Relational database and NoSQL (ex: MongoDB, DynamoDB, Redis, HBase, Cassandra) database experience

• Cloud technologies including AWS and Google Cloud Platform (GCP)




Why Hays?




You will be working with a professional recruiter who has intimate knowledge of the Information Technology industry and market trends . Your Hays recruiter will lead you through a thorough screening process in order to understand your skills, experience, needs, and drivers. You will also get support on resume writing, interview tips, and career planning, so when there’s a position you really want, you’re fully prepared to get it.




Nervous about an upcoming interview? Unsure how to write a new resume?




Visit the Hays Career Advice section to learn top tips to help you stand out from the crowd when job hunting.




Hays is an Equal Opportunity Employer.




Drug testing may be required; please contact a recruiter for more information.

Show more Show less"
2615016369,Big Data Engineer,System One,2021-06-29,United States,"Chevy Chase, MD",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Direct-Hire - Chevy Chase, MD

Eligible candidates must hold Permanent Residency or U.S. Citizenship due to the program supported.

Locals preferred or those that are able to relocate

For immediate interest, please send your resume to vhotvianska@altaits.com. 

Do you want to be part of the transformation that's accelerating a truly data-driven company? Are you ready to collaborate and innovate with a team responsible for changing the customer experience using the latest technologies?

As a Senior Big Data Developer on the IT squad, you'll thrive in a fast-paced, innovative culture that turns data into information and uses that information to drive action. One focus is our Single View of the Customer (SVOC) initiative. As part of this team you will be designing, creating, and populating customer centric data stores necessary for deriving valuable insights in real time to provide tailored customer experiences. As a senior developer you will have the opportunity to mentor more junior associates and help grow our team.



 



Qualifications



At least 3 years of programing experience in Java and Spring technologies 
At least 2 years of programming experience working with Spark on big data; including experience with data profiling and building transformations 
Experience with NoSQL databases such as HBase, Cassandra, or MongoDB 
Experience with streaming data and Kafka (or equivalent streaming tooling) 
Strong critical thinking, decision making, troubleshooting, multi-tasking and problem-solving skills  
Excellent verbal/written communication skills, including communicating technical issues to non-technical audiences  
A Bachelor's degree in a computer related field or equivalent professional experience is required 

 



Preferred Qualifications: 



Experience with GraphQL, web services, and container based deployments 
Experience tuning and monitoring using Dynatrace or Splunk 
Exposure to Graph Databases 
5-7 years of technology experience

 



NOTE: The safety of our associates, both current and future, is highest priority. At this time, most of our associates are working remotely due to the current COVID-19 pandemic. Candidates who are selected for this position will be trained remotely and must be able to work from home in a designated work area.  Once determines it is safe for associates to return to the office, candidates may be required to work in our Chevy Chase, MD office.



 



Benefits:



As a full time associate, you'll enjoy our Total Rewards Program* to help secure your financial future and preserve your health and well-being, including:



Premier Medical, Dental and Vision Insurance with no waiting period**
Paid Vacation, Sick and Parental Leave
401(k) Plan with Profit Sharing
Tuition Reimbursement
Paid Training and Licensures

 



*Benefits may be different by location.  Benefit eligibility requirements vary and may include length of service.



**Coverage begins with the pay period after hire date. Must enroll in New Hire Benefits within 30 days of the date of hire for coverage to take effect. 





ALTA IT Services, is an established leader in IT Staffing and Services, specializing in Agile Transformation Services, Program & Project Management, Application Development, Cybersecurity, and Data & Advanced Analytics.   We are an equal opportunity/affirmative action employer and considers qualified applicants for employment without regard to race, gender, age, color, religion, disability, veteran status, sexual orientation, or any other factor.

 
Show more Show less"
2766094777,Data Engineer,StockX,2021-09-30,United States,"Detroit, MI",Information Technology,Full-time,"Computer Software, Internet Publishing, and Financial Services","Help shape the next generation of ecommerce for the next generation of consumer.

As a Data Engineer, you will be empowered to leverage data to drive amazing customer experiences and business results. You will own the end to end development of data engineering solutions to support analytical needs of the business. The ideal candidate will be passionate about working with disparate datasets and be someone who loves to bring data together to answer business questions at speed. You should have deep expertise in the creation and management of datasets and the proven ability to translate the data into meaningful insights through collaboration with analysts, data scientists and business stakeholders.

Responsibilities

Design and build mission critical data pipelines with a highly scalable distributed systems architecture - including data ingestion (streaming, events and batch), data integration, data curation

Help continually improve ongoing reporting and analysis processes, simplifying self-service support for business stakeholders

Automation of end to end data pipeline with metadata, data quality checks and audits

Optimize the data pipelines to support BI and ML use cases

Support mission critical applications and near real time data needs from the data platform

Capture and publish metadata and new data to subscribed users

Work collaboratively with business analysts, product managers, data scientists as well as business partners and actively participate in design thinking session

Participate in design and code reviews

Qualifications

3+ years’ experience years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets

1+ years of experience in programming language like Python, Scala

1+ years' experience building with AWS or other cloud environments

Strong familiarity with batch processing and workflow tools such as AirFlow, NiFi

Strong business mindset with customer obsession; ability to collaborate with business partners to identify needs and opportunities for improved data management and delivery

BS/BA degree in Computer Science, Physics, Mathematics, Statistics or other Engineering disciplines

Nice To Have

Masters in Computer Science, Physics, Mathematics, Statistics or other Engineering disciplines

Experience with data visualization tools such as Tableau, Looker, PowerBI

About Us

Our global platform offers unprecedented access to current culture while our data-driven, bid-ask model provides buyers with the real-time visibility to know they’re getting a fair price. And, unlike other ecommerce sites, StockX hand-checks every purchase (20,000+ daily trades) at one of our regional authentication centers.

StockX’s special formula has rocketed the company to a multibillion dollar valuation, with 10M+ lifetime trades on the platform—more than half of those coming in the last year. And we’re just getting started.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. This job description is intended to convey information essential to understanding the scope of the job and the general nature and level of work performed by job holders within this job. However, this job description is not intended to be an exhaustive list of qualifications, skills, efforts, duties, responsibilities or working conditions associated with the position. StockX reserves the right to amend this job description at any time.
Show more Show less"
2808054251,"Data Engineer, Zoro",Zoro US,2021-10-31,United States,"Illinois, United States",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Company Summary

Zoro offers millions and millions of products — an endless aisle with everything you need to run your business. We offer fast and free shipping, no-hassle returns, and exceptional customer service. We’ve grown quickly in a short time and are continuing to do so while aggressively growing our revenue. We are excited to be a part of an award-winning culture — we have been named a Great Place to Work for multiple years in a row, among other local and national accolades. We think Zoro is a pretty amazing place to work and grow, and think you will too!

Primary Function

The Data Engineer will collaborate with various other IT groups, business partners and external service providers and play a key role in the design, development and operations of our new analytics platform, the “Zoro Data Platform (ZDP)”.

Duties And Responsibilities
Participate in Requirements Gathering: work with key business partner groups (e.g. Product Mgt) and other Data Engineering personnel to understand department-level data requirements for the ZDP
Design Data Pipelines: work with other Data Engineering personnel on an overall design for flowing data from various internal and external sources into the ZDP
Build Data Pipelines: leverage standard toolset and develop ETL/ELT code to move data from various internal and external sources into the ZDP
Support Data Quality Program: work with Data QA Engineer to identify automated QA checks and associated monitoring & alerting to ensure ZDP maintains consistently high quality data
Support Operations: triage alerts channeled to you and remediate as necessary
Technical Documentation: leverage templates provided and create clear, simple and comprehensive documentation for your development
Key contributor to defining, implementing and supporting:
Data Services
Data Dictionary
Tool Standards
Best Practices
Data Lineage
User Training

Qualifications

Strong ELT/ ETL designer/developer
Strong SQL
Strong Python
Structured & unstructured data expertise
Cloud environment development & operations experience (e.g. AWS, GCP)

Preference For Candidates Experienced With

Google Cloud Platform (GCP) and associated services; e.g. BigQuery, GCS, Cloud Composer, Dataproc, Dataflow, Dataprep, Cloud Pub/Sub, Metadata DB, Data Studio, Datalab, other
Other important Zoro tools: Apache Airflow (scheduler), Bitbucket and git (version control), Stackdriver (ops monitoring), Opsgenie (alert notification), Docker
Real-time data replication/streaming tools
Data Modeling
Excellent verbal and written communications
Strong team player

Success Criteria

Strong analytical thinking and problem solving skills
Superior communication and business-technical interaction skills
Positive, “get it done” attitude
Ability to multi-task and manage multiple activities with varying timelines

To Qualify, You Must Possess The Following Skills

Bachelor’s degree in computer science, management information systems, or a related discipline
5+ years hands-on ETL/ELT design/development experience
Key resource on team(s) that have delivered successful enterprise-level analytics platforms

Zoro Values And Inclusive Culture

We share a commitment to our Zoro values – Win & Lose Together (We prefer winning!), Take Ownership, We Are Transparent, and Aspire to be Customer-Obsessed. Everything we do at Zoro is centered around delighting our customers. It's a natural extension of our company culture and how we care for each other. We believe when we act in ways that are consistent with these values, we can solve any technical challenge that lies ahead of us. As a Zoro employee, you can expect to work with smart, energetic people, learn something every day, and be valued for your perspective.

Zoro is dedicated to fostering an environment where people of all backgrounds and beliefs are represented, and all team members can be confident that their experiences and perspectives are valued. Zoro aims to empower all employees to learn about, raise awareness, and promote diversity and inclusion through all of our workplace interactions.

Zoro is an Equal Opportunity Workplace and an Affirmative Action Employer.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.
Show more Show less"
2826937064,Analytics - DevOps Engineer,Dynamic Consulting Group,2021-12-04,United States,"Chicago, IL",Engineering and Information Technology,Full-time,Professional Training and Coaching,"What We’ll Bring

A work environment that encourages collaboration and innovation. We consistently explore new technologies and tools to be agile.
Flexible time off, workplace flexibility, an environment that welcomes continued professional growth through support of tuition reimbursement, conferences and seminars.
Our culture encourages our people to hone current skills and build new capabilities, while discovering their genius.
An environment where you will be involved with technology innovation activities such as research, evaluations, and prototyping

What You’ll Bring

Five or more years of hands-on experience in a system administration and/or software development profession
Proficiency working in a Linux-based environment, including scripting and system administration
Proficiency with one (or more) automation tools, such as Puppet, Ansible, or Chef
Experience working on teams operating under an Agile Scrum or Kanban delivery methodology
Experience working within CI/CD environments and a passion for automation and system quality
Experience managing an AWS based cloud environment running business critical applications

What We’d Prefer To See

Bachelor’s degree in Computer Science, Information Systems Management or equivalent experienceAt least seven years of hands on application development experience
Proficiency in one (or more) programming languages, such as Java or Python

Impact You’ll Make

You’ll operate as a member on one of the core teams responsible for enabling new features and optimizing our multi-petabyte platforms that support a diverse community of internal and customer based data scientists, statisticians, modelers, product developers and data strategists
Help to build the platforms and tools that support the Analytics communities of TransUnion
Implement and deploy leading-edge analytics environments including software, end-user tools and other services
Collaborate with product owners and team members on requirements and implementation approaches for addressing demand and challenges
Design and Develop tools and services enabling end-user productivity and system integrations
Partner with business resources to troubleshoot issues, manage capacity, and plan for the optimization and expansion of environments
Maintain and ensure availability and quality of systems

Job Qualifications

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, veteran status, marital status, citizenship status, sexual orientation, gender identity or any other characteristic protected by law.

No C2C or Sponsored Visa
Show more Show less"
2814241028,Big Data Engineer - FreeWheel (virtual or in office),FreeWheel,2021-11-05,United States,"San Francisco, CA",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Internet Publishing, and Telecommunications","Comcast brings together the best in media and technology. We drive innovation to create the worlds best entertainment and online experiences. As a Fortune 50 leader, we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines. We are at the forefront of change and move at an amazing pace, thanks to our remarkable people, who bring cutting-edge products and services to life for millions of customers every day. If you share in our passion for teamwork, our vision to revolutionize industries and our goal to lead the future in media and technology, we want you to fast-forward your career at Comcast.

Job Summary

FreeWheel, a Comcast company, is looking for a Big Data Engineer to be responsible for the following: Planning and designing new software and web applications. Analyzes, tests and assists with the integration of new applications. Documents all development activity. Assists with training non-technical personnel. Has in-depth experience, knowledge and skills in own discipline. Usually determines own work priorities. Acts as a resource for colleagues with less experience.

Job Description

Core Responsibilities

At least 2-5 years of experience with designing, implementing, and maintaining data pipelines, building scalable and optimized enterprise data systems
Scale ETL pipelines and infrastructure to the next level
Production level experience with an ETL scheduling tool, data warehousing in AWS
Manage data ingestion using various methods to transform raw data into useful data systems
Grounded knowledge of SQL, Python, AWS and with a deeper understanding of at least one commonly used DB (Postgres, Athena)
Strong data analysis skills (writing complex queries, store procedures)
Develop tools supporting self-service data pipeline management (ETL)
Evolve data model and data schema based on business and engineering needs
Collaborate with project stakeholders to identify product and technical requirements. Conduct analysis to determine integration needs.
Other duties and responsibilities as assigned.

Company Description

FreeWheel, A Comcast Company, empowers all segments of The New TV Ecosystem. We are structured to provide the full breadth of solutions the advertising industry needs to achieve their goals. We provide the technology, data enablement and convergent marketplaces required to ensure buyers and sellers can transact across all screens, across all data types, and all sales channels, in order to ensure the ultimate goal – results for marketers. With offices in New York, San Francisco, Chicago, London, Paris, Beijing, and across the globe, FreeWheel, A Comcast Company, stands to advocate for the entire industry through the FreeWheel Council for Premium Video. For more information, please visit freewheel.com.

Employees at all levels are expected to

Understand our Operating Principles; make them the guidelines for how you do your job.
Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services.
Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences.
Win as a team - make big things happen by working together and being open to new ideas.
Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers.
Drive results and growth.
Respect and promote inclusion & diversity.
Do what's right for each other, our customers, investors and our communities.

Disclaimer

This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.

Comcast is an EOE/Veterans/Disabled/LGBT employer.

#freewheelproductjob #freewheelengineeringjob

Education

Bachelor's Degree

Relevant Work Experience

2-5 Years

Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details.
Show more Show less"
2796602167,"Data Engineer, Observability",Chainlink Labs,2021-11-13,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Be the data engineer powering the solutions to a unique Observability challenge -- monitoring uptime and reliability of independent/3rd party oracle providers. Observability at Chainlink Labs is going through a transition from traditional time series-based monitoring toward an event-driven architecture and alerting approach. You will have a significant impact as we grow the Chainlink ecosystem and ensure the best experience for our customers by ensuring reliable uptime.

You’ll develop and build highly scalable, secure, and reliable software that will change the way smart contracts function at a fundamental level. You’ll have the opportunity to learn and master the latest research concerning distributed systems, cryptography, blockchains, game theory, consensus algorithms, and decentralized applications.

You will be given a high level of autonomy/ownership over your projects, the opportunity to expand your scope of knowledge, and the chance to help build the decentralized infrastructure of the future.

Your Impact

Lead the design and deployment of data pipelines that power our real time monitoring/observability services to detect and alert the team of needed action.
Make recommendations to ensure sufficient metrics are collected to create alerts with every new feature release.
Thinking creatively about attack vectors, possible failures, and disaster scenarios, modeling them in reproducible test environments, and developing fixes
Implementing resilient distributed systems to achieve extremely high reliability in a variety of blockchain environments
Responsibilities

3+ years of professional experience as a software developer / DevOps engineer or equivalent
Experience with Kafka required
Deep knowledge of go or Kafka Streams apps (including Java/the JVM) a plus
Experience administering Kafka Connect, Confluent Platform, and/or Kubernetes is a plus
Experience with test-driven development and the use of testing frameworks
Strong communication skills, specifically giving/receiving constructive feedback in a collaborative setting

Our Stack

Golang, Kafka, Postgres, Kubernetes, AWS

Our Principles

At Chainlink Labs, we’re committed to the key operating principles of ownership, focus, and open dialogue. We practice complete ownership, where everyone goes the extra mile to own outcomes into success. We understand that unflinching focus is a superpower and is how we channel our activity into technological achievements for the benefit of our entire ecosystem. We embrace open dialogue and critical feedback to arrive at an accurate and truthful picture of reality that promotes both personal and organizational growth.

About Chainlink Labs

Chainlink is the industry standard oracle network for connecting smart contracts to the real world. With Chainlink, developers can build hybrid smart contracts that combine on-chain code with an extensive collection of secure off-chain services powered by Decentralized Oracle Networks. Managed by a global, decentralized community of hundreds of thousands of people, Chainlink is introducing a fairer model for contracts. Its network currently secures billions of dollars in value for smart contracts across the decentralized finance (DeFi), insurance, and gaming ecosystems, among others. The full vision of the Chainlink Network can be found in the Chainlink 2.0 whitepaper. Chainlink is trusted by hundreds of organizations—from global enterprises to projects at the forefront of the blockchain economy—to deliver definitive truth via secure, reliable data.

This role is location agnostic anywhere in the world, but we ask that you overlap some working hours with Eastern Standard Time (EST).

We are a fully distributed team and have the tools and benefits to support you in your remote work environment.

Chainlink Labs is an Equal Opportunity Employer.


Show more Show less"
2788318394,Data Engineer,DivcoWest,2021-11-11,United States,"Boston, MA",Information Technology and Engineering,Full-time,Leasing Non-residential Real Estate,"COMPANY BACKGROUND

Founded in 1993, DivcoWest is a dynamic and growing multi-disciplinary real estate investment firm headquartered in San Francisco, with offices in Los Angeles, Menlo Park, Boston, Washington DC and New York City. Known for our long-standing relationships and track record of success in markets where innovation thrives, DivcoWest combines a vibrant entrepreneurial spirit with an institutional approach and a forward-thinking state-of-the-art technology infrastructure.




JOB SUMMARY

DivcoWest is searching for a Data Engineer to join our growing team of analytics experts. Our technology team is focused on delivering solutions that streamlines real estate operations, enhances the value of the real estate portfolio, and improves the experience of space and people’s everyday lives. Our dynamic technology team builds innovative products, implements state of the art technologies, provides service to facilitate technology operations at our corporate and property sites, and invests in real estate focused technology companies. 




The Data Engineer will be responsible for supporting the technology team’s focus by expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder who enjoys optimizing data systems and building them from the ground up. The hire must be self-directed, driven and comfortable supporting the data needs of multiple teams, systems and products. This role may be located out of our San Francisco, Los Angeles or properties.




ESSENTIAL DUTIES & RESPONSIBILITIES

Create and maintain optimal data pipeline architecture
Identify, design and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability
Design, develop, and deploy a high-volume ETL pipelining system to manage complex real-time, data collection
Work with stakeholders including the Executive, Data and Infrastructure teams to assist with data-related technical issues and support their data infrastructure needs
Cross-train with the rest of the data team members, to support business functions during team members absence
Stay current with developments in new market trends and innovations in technology, especially those related to commercial real estate




SKILLS AND ABILITIES

Advanced working SQL knowledge and experience working with relational databases
A successful history of manipulating, processing and extracting value from large disconnected data sets
Excellent oral and written communication skills, including the ability to explain technology solutions in business terms and translate business requirements into technical specifications
Proven analytical and problem-solving abilities with keen attention to details
Knowledge of commercial real estate operations an asset




TECHNICAL SKILLS

Microsoft SQL Server 2012 or Higher
Data warehouse design, development and maintenance, optimization for reporting and analysis
SQL Server Integration Services (SSIS) - ETL design, development and maintenance
SQL Server Analysis Services (SSAS) – OLAP cube design, development and maintenance
SQL Server Reporting Services (SSRS) – web enabled report design, development and maintenance
Strong Microsoft Excel skills including Visual Basic for Applications competency
Proficient designing, implementing custom REST-ful APIs for usage in integrations with cloud/web-based 3rd party applications
Adept at consuming 3rd party web-based APIs and integration end points (REST-ful, SOAP, SFTP file transfer, etc.)
Proficiency with Microsoft C#, .Net Framework preferred.
Familiarity with MRI real estate enterprise resource planning (ERP) system a plus




QUALIFICATIONS

Bachelor’s degree in Information Technology, Software Engineering, Computer Science or related field or higher
At least 4-5 years of experience in IT, preferably within 1 or more commercial real estate organizations
Experienced with systems integrations, business intelligence systems, and database management




DivcoWest aims to create environments that inspire ingenuity, promote growth, and enhance the health, happiness, and well being of all people. A disciplined code of ethics is at the core of all that we do. DivcoWest values our partners and our people and believe that the collective energy of a diverse team is what drives our creative ideas and solutions. In recognition of the dedication and hard work of DivcoWest's employees, the Company offers a comprehensive benefits package as well as an employee assistance program.




DivcoWest is an Equal Opportunity Employer. We are committed to building a team that represents a variety of backgrounds, perspectives and skills. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state or local law.




Please review our company Priviacy Policy in regards to the use of any personal information you provide us at: https://divcowest.com/privacy-policy.php

Show more Show less"
2800324091,Data Engineer,Roc360,2021-11-18,United States,New York City Metropolitan Area,,Full-time,,"Roc360 delivers innovative products that make it easy for everyone to renovate, own, or invest in homes. We are a leading capital provider to residential real estate investors, as well a pioneer in developing and applying cutting-edge data science to this field.




The data science team at Roc has worked to build and support a technology platform designed to help sellers, buyers, and investors. We tackle a wide range of problems, including classification, regression, and clustering; computer vision; entity resolution; experiment design and measurement; data QA and architecture. We work with numerical, categorical, geographical, language/text, and image data. We pride ourselves on our empirical mindset, our eagerness to research innovative approaches, and our commitment to best practices and responsibility. 




We are hiring for multiple skill sets and strengths, at different seniority levels.




Data Engineer




The data team is the backbone of Roc360’s investment strategy. As a Data Engineer, you will play a high-impact role by curating and connecting our data from the source, to the end users. This includes data ingestion, data transformation, and maintenance of the data platform for data scientists, data analysts, and other stakeholders at the company—toward the ultimate goal of building a first-rate data platform to support Roc’s operations and customer offerings.




This full-time role can be based in NYC or remote, and can be titled ""Data Engineer"" or ""Analytics Engineer"" depending on the skillset and preferences of the person who joins the team. We've posted the same role under both titles, you need only apply once.




As a Data Engineer, you will collaborate closely with the rest of the data team to:

Help build the data system from the ground up, including pipelines that efficiently ingest data from multiple sources and intelligently handle the scale and complexities of real-world data.
Implement processes and systems to supervise data quality, ensuring production data is always accurate and available for the teams that depend on it.
Gather requirements from the rest of the data team and other internal stakeholders to identify opportunities for improvements, set priorities, and execute.
Migrate existing pipelines and data to a unified data platform.




We are looking for someone with:

Experience connecting and transforming data for analytics platforms.
The ability to think and work through messiness and ambiguity in real-world data—think typos in address records, data collected under different standards from different datasets—for cleaning, deduplication, and entity resolution.
Enthusiasm for working as part of a cross-functional team, collaborating with engineers, scientists, analysts, and business stakeholders.
Excitement about introducing scalable development tools like source control, containers, and testing to a growing team of data scientists.
Experience building, deploying, and maintaining production data pipelines on AWS, Azure, Google Cloud Platform, or similar.
Proficiency in Python and SQL.
A “cautious adventurer” mindset in tackling new challenges, including those in unfamiliar subjects.




Roc360 is actively seeking candidates with unique and diverse work backgrounds to grow our team. We are especially excited to talk to you if have:

Experience building dashboards and automated reports.
Experience working with MPP cloud data warehouses like Snowflake, BigQuery, etc. and integrating them with BI tools.
Experience with one or more common data pipelining frameworks and workflow management tools (Airflow, MLFlow).
Experience working with Salesforce or other CRM data.
Experience working with real estate data, location data, or image data.




Roc360 is a global team of professionals committed to improving the residential real estate ecosystem. The core team has worked together for over 20 years, combining an entrepreneurial spirit, research-driven investment strategies, and a common-sense approach to lending. Now with 250 employees across 4 continents, we continue to seek collaborative and creative problem-solvers to grow the company. 




We offer our employees best-in-class benefits, including comprehensive health, vision, dental & retirement plans, including 401k matching.




Roc360 is an equal opportunity employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or veteran status.




Learn more about Careers at Roc360 here: https://www.roc360.com/careers

Show more Show less"
2813018548,Data Engineer,Vareto,2021-11-29,United States,United States,Information Technology and Engineering,Full-time,Computer Software,"Vareto is reimagining how companies evaluate the past and plan for the future. Today, companies make their most important decisions using spreadsheets, presentations, legacy tools, and countless meetings and emails. Executives make decisions with limited data, teams waste time aligning on metric definitions instead of collaborating, and analysts end up debugging Excel files instead of generating insights.




Vareto is building a next-generation planning and insights platform that changes all of that. Our product helps companies standardize their business data, derive and share insights, and build connected cloud-based financial plans - all so companies can make better, faster decisions.




We’re a remote-first team (hiring in the US, Canada, and Europe) and we’re backed by top investors and industry leaders.




As an early member of the engineering team, you will play a critical role in developing our data ecosystem and building the data foundation of the company. This includes everything from integrations and data APIs to data pipelines and automated testing. The ideal candidate will be excited about joining an early-stage company, building from scratch, and having an outsized impact on our team, customers, and the overall business.




What you'll do:

Collaborate with our Engineering and Growth team to prioritize and onboard customers' data connections through conception, research, implementation, and maintenance.
Evaluate updates to an existing integration to ensure data quality expectations are met.
Utilize and improve internal tools to transform customer data into web app-facing metrics - from raw data to customer-facing web pages.
Assist customers in connecting new integrations and assist the engineering team in prioritizing new connections.
Dive into customer data by debugging pipeline data quality issues and helping prioritize fixes.
Build the company you want to work at.




What we're looking for:

3+ years of software engineering experience
Ability to work with others to build and maintain data pipelines using technologies like Python, Airflow, Great Expectations, DBT, S3, and Snowflake/Redshift
Experience in creating and integrating web APIs and services using Python or similar languages
Knows how to manipulate data in many different environments and formats: Pandas, SQL, CSV, XML, JSON, etc.
A strong communicator who can articulate nuanced ideas clearly whether it's explaining technical decisions in writing or brainstorming in real-time
Bonus points if you have prior experience working at a startup




You may be a fit for this role if you:

Are pragmatic and care about the business impact of what you're building.
Can handle disagreements and engage thoughtfully with other perspectives, making compromises when needed.
Have a passion for upholding engineering best practices, from writing documentation to creating maintainable code.
Are not ideological about technological choices and understand that there's no ""one solution fits all.""
Are excited to mentor and learn from other engineers, and believe that no one is above code review.
Enjoy a flat, rapidly growing organizational structure without red tape.
Enjoy wearing multiple hats (bonus points if you like to dabble in product, design, presentations, business strategy, or other functional areas).




Is your experience close to what we’ve described but maybe you feel you’re missing a few of the requirements? We encourage you to apply anyway. We look for people with exceptional potential, and we know this can take many forms. We believe the highest performing teams include people with diverse backgrounds, perspectives, and life experiences.

Show more Show less"
2809708709,Data Engineer,CVS Health,2021-11-23,United States,"Hartford, CT",Information Technology,Full-time,"IT Services and IT Consulting, Financial Services, and Hospitals and Health Care","Job Description

Description/Fundamental Components:

Assists in the development of large-scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs

Applies understanding of key business drivers to accomplish own work

Uses expertise, judgment and precedents to contribute to the resolution of moderately complex problems

Leads portions of initiatives of limited scope, with guidance and direction

Writes ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processing

Collaborates with client team to transform data and integrate algorithms and models into automated processes

Uses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines

Uses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systems

Builds data marts and data models to support clients and other internal customers

Integrates data from a variety of sources, assuring that they adhere to data quality and accessibility standards

Required Qualifications

1-3 years of progressively complex related experience

Experience with bash shell scripts, UNIX utilities & UNIX Commands

COVID Requirements

COVID-19 Vaccination Requirement

CVS Health requires its Colleagues in certain positions to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, pregnancy, or religious belief that prevents them from being vaccinated.

If you are vaccinated, you are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status within the first 30 days of your employment. For the two COVID-19 shot regimen, you will be required to provide proof of your second COVID-19 shot within the first 60 days of your employment. Failure to provide timely proof of your COVID-19 vaccination status will result in the termination of your employment with CVS Health.
If you are unable to be fully vaccinated due to disability, medical condition, pregnancy, or religious belief, you will be required to apply for a reasonable accommodation within the first 30 days of your employment in order to remain employed with CVS Health. As a part of this process, you will be required to provide information or documentation about the reason you cannot be vaccinated. If your request for an accommodation is not approved, then your employment may be terminated.


Preferred Qualifications

Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources

Ability to understand complex systems and solve challenging analytical problems

Strong problem-solving skills and critical thinking ability

Strong collaboration and communication skills within and across teams

Knowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similar

Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment

Experience building data transformation and processing solutions

Has strong knowledge of large-scale search applications and building high volume data pipelines

Education

Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline.

Master’s degree or PhD preferred.

Business Overview

At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.
Show more Show less"
2805158409,Data Engineer,Habitat Energy,2021-11-23,United States,"Austin, TX",,Full-time,,"At Habitat Energy we bring together exceptionally talented and passionate people in the domains of energy trading, data science, software engineering and an in-depth understanding of flexible energy assets. Our aim is to maximise the value of large-scale flexible energy assets (eg, battery storage) so they are attractive investments, are deployed at scale and enable the energy transition. We are looking for smart, motivated people to join our team who share our belief that we can outperform the energy sector dinosaurs, have a positive impact on the planet and have fun doing it together.




Our models take thousands of decisions in the market each day, algorithmically dispatching one of the largest portfolios of merchant batteries in the UK - so we're looking for an outstanding engineer to bring their data expertise and allow us to continue to scale in the UK and internationally. While we really value curious generalists, specific responsibilities include:




Build and maintain real-time data streaming from numerous sources in the UK, Australia and USA
These include current and historical metrics describing the power system (e.g. demand, supply, the actions of specific generators/loads on the system)
Live asset data (e.g. <1second granularity battery data) for optimisation and long-term modelling
Support design, development and maintenance of our data architecture
Work as part of multidisciplinary teams to scope, develop and deliver new products and features
Improve internal tools for democratisation of our data
Communicate and document solutions and design decisions




We’re looking for someone who is a great fit for our company. We want people who take accountability, build trust and are innovative. We encourage you to apply even if you may not meet every requirement in this posting. We value diversity and our environment is supportive, challenging and focused on the consistent delivery of high quality, meaningful work.  

 

Requirements:

Python - 3+ years of experience with (at least) exposure to the following technologies: ORM (e.g. sqlalchemy), async.
Strong AWS skills in an 24/7 operational environment & knowledge of AWS data-related technologies
Expert in SQL(postgres) and experience in designing efficient data models
Expertise with at least one distributed data processing framework (e.g. Hadoop, Spark, Flink, Storm)
Experience working with time series data
You have experience with development, test and production environments, and knowledge and experience of using CI and CD.




When you apply for a job with us, we process some of your personal information. You can find out more about how we process your information in our candidate privacy policy.

Show more Show less"
2819575420,Data Platform Developer (Data Engineer),Miami HEAT,2021-12-04,United States,"Miami, FL",Information Technology,Full-time,"Marketing and Advertising, Retail, and Entertainment","Duties And Responsibilities Include But Are Not Limited To

The Miami HEAT are hiring for a Data Platform Developer that leads all aspects of the day-to-day building, implementing and supporting data solutions within the Microsoft Azure environment. An ideal candidate will work with internal partners, project and support teams to meet business objectives. Success in this role depends on creative problem solving and analytical skills, aggressiveness and sophisticated communication capabilities, as the individual will be required to apply all resources available to accommodate the organization’s’ goals. This position will require working closely with the Director, Data Engineering, members of the Business Strategy Division and other IT and business subject matter experts.

Design, develop and deploy data extraction, orchestration, transformation and loading solutions.
Build, configure, deploy and maintain databases.
Participate in development and maintenance of data warehouse.
Provide technical design, coding assistance to the team to accomplish the project deliverables as planned/scoped.
Build ER diagrams and write relational database queries.
Ability to talk to client and get the Business Requirements.
Brainstorming discussions, design, development, and implementation of data projects.
Gathering stakeholder needs and translating business requirements into data design.
Participating in the testing process and works to improve the quality and efficiency of data projects.

Desired Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Azure DevOps (2+ years of experience)
Azure Data Factory/Logic Apps (2+ years of experience)
Azure Service Bus (2+ years of experience)
Azure Storage/Data Lake (3+ years of experience)
Relational database and SQL language (4+ years of experience)
Azure Synapse (a plus)
AI/ML development (a plus)
Power BI Development (a plus)
Ability to work efficiently and collaboratively in a team environment and with employees of all levels/areas and create a shared sense of direction and community among the teams.
Demonstrable ability to transfer knowledge and stay aware of current trends and technical advancements.

Bachelor’s degree from an accredited program in Computer Science, Information Systems, Engineering or related academic field; MBA or M.S. in information technology preferred. 3-5 years of related experience or equivalent combination of education and experience required including experience handling sizable data warehouse and data platforms in an enterprise environment. Hands on developing and maintaining the data quality policies to require data integrity going through the data periodically and updating, standardizing, and de-duplicating records to create a single view of the data. Transformation of OLTP data to the Data Warehouse. Experience in T-SQL programming for writing Stored Procedures, User-Defined Functions, Triggers, Cursors, and Views. Programming Languages: Proficiency in C#, Python, WML, XML/XSL. Development Studios: Microsoft’s Visual Studio 2016 or greater, Azure Data Studio. Database Systems: Proficient in MS SQL Server and MySQL.

Successful candidate(s) will be required to comply with The HEAT Group Vaccination Policy.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender/gender identity, age, disability, marital status, sexual orientation, pregnancy, genetic information, national origin, citizenship status, veteran status, and any other legally protected status entitled to protection under federal, state, or local anti-discrimination laws. EOE & DFWP
Show more Show less"
2794011418,Data Engineer 1,Providence,2021-11-10,United States,"Renton, WA",Information Technology,Full-time,"Financial Services, Wellness and Fitness Services, and Hospitals and Health Care","Description

Providence is calling a Data Engineer 1 to one of our locations in the Seattle area, Portland, OR, or Irvine, CA.

We are seeking a Data Engineer 1 who will design and build modern data-centric software applications to support clinical and operational processes across all parts of the healthcare system. These applications leverage cloud computing, big data, data science, and modern software development methodologies and frameworks. Builds data pipelines and transformations, data enrichment processes, provisioning layers, and user interfaces to meet the requirements of key initiatives. Enjoys a fast pace and has a focus on regular delivery. Seeks simple solutions to complex problems through the use of modern and emerging methods and tools. Emphasizes sharing and enables collaboration with meticulous source control and documentation. Works closely with the Product, Platform, and Architecture teams to deliver on joint efforts.

In This Position You Will Have The Following Responsibilities

Design, build and deliver quantitative applications that improve operations and generate value.
Participate in DevOps, Agile, and continuous integration frameworks.
Stay abreast of emerging technologies, open source projects, and best practices in the field.
Data warehousing, big data, enterprise search, business intelligence, analytics, modern and mobile applications.
Build processes that are fault-tolerant, self-healing, reliable, resilient and secure.
Work effectively and in real-time with other developers, product managers, and customers to deliver on collective goals.
Actively participate in code reviews, support the overall code base, and support the establishment of standard processes and frameworks.
Take an open and transparent approach to the work by sharing code and expertise, by consulting peers for problem-solving, and by being a mentor to peers.

Qualifications

Required qualifications for this position include:

Bachelor's Degree in Computer Engineering, Computer Science, Mathematics, Engineering or equivalent education/experience,
1 year Related experience.

Preferred Qualifications For This Position Include

Master's Degree in Computer Engineering, Computer Science, Mathematics, Engineering or equivalent education/experience.
1-3 years Related experience.

About The Department You Will Serve.

Providence Shared Services provides a variety of functional and system support services for our Providence family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise.

We offer comprehensive, best-in-class benefits to our caregivers. For more information, visit

https://www.providenceiscalling.jobs/rewards-benefits/

Our Mission

As expressions of God’s healing love, witnessed through the ministry of Jesus, we are steadfast in serving all, especially those who are poor and vulnerable.

About Us

Providence is a comprehensive not-for-profit network of hospitals, care centers, health plans, physicians, clinics, home health care and services continuing a more than 100-year tradition of serving the poor and vulnerable. Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.

Schedule: Full-time

Shift: Day

Job Category: Analytics/Business Intelligence

Location: Washington-Renton

Other Location(s): Washington-Seattle, Oregon-Beaverton, Washington-Redmond, California-Irvine

Req ID: 321034
Show more Show less"
2809688256,Data Devops Engineer,wappier,2021-11-22,United States,"Boston, MA",Information Technology,Contract,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Opportunity Description

Job Purpose

As a senior software engineer you will work as an integral part of our Cloud Data

DevOps team within the Corporate Digital Data Architecture, Operations and

Governance Team. The ideal candidate has extensive DevOps knowledge and

experience and has previously been part of a DevOps team running an analytical

ecosystem in modern cloud-based big data systems in a fast-paced, agile

environment. The Data DevOps Engineer will focus on processing engine development as well as design, development, automation and optimization of its usage in each data platforms across the group.

Education Background:

Master’s degree in Computer Science, or equivalent Experience and Knowledge:
4 or more years working in DevOps, software development
2 or more years’ experience provisioning, operating, and managing AWS environments
Strong background in Linux/Unix administration and scripting
Strong background in Hadoop, Spark, Python, Java
Extensive experience with a public cloud provider, ideally Amazon Web Services
Strong understanding of Continuous Integration and Continuous Delivery and infra as code principles and practice
Ability to use a wide variety of open source technologies and cloud services
Research & investigative skills
Strong experience with SQL and NoSQL data stores
Software process automation with popular scripting languages (i.e. Python)
Experience developing code in at least one high-level programming language with code quality and code security at heart.
Experience in automation and testing via scripting/programming
Understanding of Agile and other development processes and methodologies
Source, build/release, and configuration management in a continuous integration & delivery environment
Application performance analysis and monitoring
Knowledge of best-practice security and networking techniques for an Internet-facing system


Highly Desired, Skills Include:

Experience with automation and configuration management using Ansible, or an equivalent
Terraform, Docker, Openshift
Java development experience
Technology vendor management
Amazon Web Services certification highly desired


Requirements

Key responsabilities

Liaise in a geographically dispersed team across the globe.
Participate in a continuous delivery pipeline to fully automate deployment of the highly available cloud data platforms that supports multiple teams/projects
Build tools for deployment, monitoring and operations. Troubleshoot and resolve issues in our development, test and production environments
Work with platform architects on software and system optimizations, helping to identify and remove potential performance bottlenecks
Stay up-to-date on relevant technologies, plug into user groups, understand trends and opportunities to ensure we are using the best possible techniques and tools
Understand, implement, and automate security controls, governance processes, and compliance validation
Design, manage, and maintain tools to automate operational processes
Show more Show less"
2797264355,Data Engineer,Amazon,2021-11-18,United States,"Dallas, TX","Information Technology, Consulting, and Engineering",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Are you a high-energy, highly skilled Data Engineer who wants to build and deliver using cutting edge technology that protects millions of people every day? Do you want to invent new technologies while collaborating with the very best software engineers, machine learning scientists and economists in the world? Do you want to push yourself and technology as far as they'll go with a group of smart and fun people?

We are looking for Data Engineers who want to solve some of most complex technical challenges and build solutions for measuring DSI (Downstream impact) to support Amazon's business decision making process which is driven by long term value for our customers . You will work closely with machine learning scientists, software engineers & economists building cutting edge models and predictive analytic solutions at a large scale to build solutions for DSI.

If this sounds like you and you have a history of working on high performance systems then we want you to join our Perfect Order Experience team!

You will be an integral part of an exceptionally talented team. As a DE, you will be responsible for designing and implementing scalable extract, transform, and load (ETL) processes. You will be creating and updating dashboards to provide business Intelligence reports. . You will be processing large data sets to support engineering efforts for DSI.


Basic Qualifications

Bachelor’s Degree in Computer Science/Engineering, Informatics, Mathematics, or a related technical discipline
4+ years of experience in data engineering, data science, business Intelligence or related field.
Extensive experience with demonstrated strength in ETL development, data modeling and data warehousing.
Expert level skills in writing and optimizing SQL queries.
Experience building data products incrementally, integrating and managing large data sets from multiple sources.
Knowledge of data management fundamentals and data storage principles.
Database design and administration experience with various RDBMS, such as MS SQL Server, PostgreSQL, MySQL, etc.
2+ years of experience in any of modern programming or scripting languages( Python, Scala or Java) etc.
Worked in collaborative environment and coached peer and junior engineers.

Preferred Qualifications

Master’s Degree in Data Engineering, Applied Data Science, Data and Web Science, or related certification
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.
Experience using business intelligence reporting tools (AWS QuickSight, Power BI, Tableau, etc.).
Experience architecting data solutions with AWS products including Big Data Technologies (Redshift, RDS, S3, Glue, Athena, EMR, Spark, Hive, etc.) and/or Microsoft Database Software Stack (SQL Server/SSIS/SSAS).
Worked on creating machine learning models and algorithms.


Company - Amazon.com Services LLC

Job ID: A1757886
Show more Show less"
2799774043,Big Data Systems Engineer - Remote,The OpenNMS Group,2021-11-09,United States,"Cary, NC",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Computer and Network Security","The OpenNMS group is looking for a systems engineer to join its growing team focused on growing our established world class open source network monitoring solution in use by numerous Fortune 500 companies. This is a key role acting as a technical liaison between customers and the Company, with a focus on addressing customer needs.

The Basics

In this role, you will bring your knowledge of system engineering and implementing big data applications to provide support for our enterprise customers OpenNMS network monitoring platform implementations.
You will leverage your experience in designing and implementing big data technologies using OpenNMS and other tools to address customer monitoring needs.
You will design, build, support, and help maintain production ready environments for OpenNMS and its major big data application dependencies.
You will be responsible for handling support questions and resolving customer issues.
Some travel may be required in the future (<25%)

What You Bring
A great attitude and a hunger for problem solving
Strong Linux and containerized environment skills
Design, implementation, and problem-solving knowledge of at least one of the following(for production-ready clusters):
Kafka
PostgreSQL
Cassandra
Elasticsearch
Cortex
Additional beneficial skills include knowledge of:
Grafana
Kibana
Flink
Kubernetes
Azure/AWS
Knowledge of OpenNMS and/or other Network Monitoring solutions is a plus (but don’t worry – we will train you on OpenNMS!)
Strong written and verbal communication skills and good interpersonal and collaborative skills
Strong independent work ethic and experience working in a dynamic culture

What We Bring

We offer competitive compensation, full benefits and some great perks. More importantly, we offer you the chance to work with a great team, focused on providing world class software-based solutions and services
Excellent benefits package including medical (HMO/PPO), dental, and vision, and a 401K with company matching so you can continue planning for financial wellness
Flexible Style Paid Time Off with 12 Paid Holidays
Employee discounts on things like, mobile products and services, gym memberships, and a variety of additional entertainment options

About OpenNMS

OpenNMS provides a highly reliable, scalable and comprehensive fault, performance and traffic monitoring solution that easily integrates with business applications and workflows to monitor and visualize everything in a network. The OpenNMS platform monitors some of the largest networks in existence, covering the healthcare, technology, finance, government, education, retail and industrial sectors, many with tens of thousands of networked devices. Our customers include three of the top 5 companies on the Fortune 100, as well as multiple large and multi-state health providers and one of the largest electronic medical record providers in the United States.

**Mandatory COVID-19 Vaccination status is required for all US and Canadian employees**
Show more Show less"
2803662334,Data Engineer,Lufthansa Industry Solutions,2021-11-17,United States,"Miami, FL","Project Management, Information Technology, and Product Management",Full-time,Airlines and Aviation,"Do you want to be the responsible for designing and implementing data-based solutions with existing and new customers? Are you ready to realize diverse and cross-sector customer projects with a focus on data management, data visualization and predictive analytics?

If so, your future is at Lufthansa Industry Solutions!

Tasks

Your responsibilities and duties may include:


Design efficient and robust ETL workflows on large datasets and create data warehouses that can be used for reporting or analysis by data scientists.
Use automated software frameworks for data collection, validation, blending, and modeling - ensure data is accessible and cleansed for further analysis.
Engineering and transforming data using Python and SQL.
Develop and maintain technical architectures for data analytics applications.
Define and perform proof of concept data analysis implementation and operationalization of data pipelines.
Continuous further development and scouting of methods and tools, as well as active knowledge transfer.
Performs all other duties assigned or required.


Benefits

Flight privileges, 15 Vacation Days, 401k plan, Commuter Benefits, Education, Employee Assistance Program, Family Policy, Flex Holidays, Healthcare, Life Insurance, Long Disability, Short Disability, up to 60 Sick Days

Behind the scenes

Welcome to Lufthansa Industry Solutions Miami

In our Americas office in Miami, FL we realize diverse and cross-sector customer projects with a focus on data management, data visualization and predictive analytics.

Data Engineer

Are you a result-oriented and customer focused IT professional that thrives working alongside an international team? If this sounds like you, we might have a job for you.

Requirements

The ideal Data Engineer must fulfill the following requirements:


An advanced degree in Computer Science, Engineering, Information Systems or equivalent; or equivalent knowledge and skills acquired through relevant professional experience.
In-depth knowledge of relational databases and batch and stream processing.
Know-how in Data Warehousing, Data Integration and Pipelines with Spark, PySpark, Scala, Java, Docker, Databricks, Glue, cloud-native DWH and Data Lake.
Experience with developing solutions on cloud computing services (AWS, MS Azure, etc.).
Strong customer and service orientation, very good communication/presentation skills at all levels.
Fluent in English.
Unrestricted willingness to travel.
CV/Resume required.
Company will not provide relocation assistance.
Applicants must be fully vaccinated against COVID19.


Company

About Lufthansa Industry Solutions BS GmbH

Lufthansa Industry Solutions is a service provider for IT consulting and systems integration. The Lufthansa subsidiary supports its customers in the digital transformation of their companies. The customer base includes companies within the Lufthansa Group as well as more than 300 companies in various industries. Headquartered in Norderstedt, Germany, the company employs more than 2100 people at several branches in Germany, Albania, Switzerland and the USA.

www.lufthansa-industry-solutions.com
Show more Show less"
2810303678,Data Engineer,Commonwealth of Massachusetts,2021-11-23,United States,"Boston, MA",Information Technology,Full-time,Government Administration,"- (21000A5G)

Description

About the Executive Office of Technology Services and Security:

The Executive Office of Technology Services and Security (EOTSS) is the state’s lead office for information technology. We provide enterprise level information technology services including: network management and security; computer operations; application hosting; desktop provisioning and management; and, modern and responsive digital services to 40,000 internal stakeholders plus the residents, business owners and visitors to the Commonwealth of Massachusetts.

About The Role

The EOTSS Data Team is hiring an experienced Data Engineer. As a data engineer, you will develop and maintain smart, secure data systems and pipelines, while building capacity for innovation in government.

Who We're Looking For

Engineers who develop, construct, test and maintain sound, secure data architectures that meet business needs
Team-oriented specialists who work collaboratively with business leaders, project managers, and analysts to build the right thing
Strategic thinkers who improve the functionality and value of the Commonwealth’s data system

What You'll Do

Stand up and maintain data infrastructure and data pipelines to process high volumes of complex data
Develop ETL processes and data warehousing efforts
Identify, design, and implement internal process improvements, automate manual processes, optimize data delivery, and re-design infrastructure for greater scalability
Build analytics tools to provide actionable insights into operational efficiency, service delivery, and policy evaluation
Uphold data processing, storage, and documentation standards
Deliver consistent and reliable processes and high-quality output on independent and team

projects

Knowledge, Skills & Abilities

Experience with the Linux stack (bash, git, package management etc.)
Experience with the AWS stack (EC2, lambda, batch, RDS, SQS)
Proficiency with Github and version control systems
Experience processing large quantities of data for analysis
Working, up-to-date knowledge of best practices for keeping data separated and secure
Experience with a team software development process: design, testing, coding, and peer reviews
Experience with continuous integration/continuous development (CI/CD) practices

Distinguished Qualifications

Experience with PostgresSQL and DynamoDB
Experience with current data science tools and methods
Proficiency in mainstream machine learning/deep learning frameworks: sklearn, tensorflow,
keras, etc.
Knowledge of machine learning theory and algorithms: SVM, random forest, gradient boosting methods, graphical models, bayesian methods, etc.

Qualifications

First consideration will be given to those applicants that apply within the first 14 days.

Please See Preferred Qualifications.

Executive Order #595: As a condition of employment, successful applicants will be required to have received COVID-19 vaccination or an approved exemption as of their start date. Details relating to demonstrating compliance with this requirement will be provided to applicants selected for employment. Applicants who receive an offer of employment who can provide documentation that the vaccine is medically contraindicated or who object to vaccination due to a sincerely held religious belief may make a request for exemption.

An Equal Opportunity / Affirmative Action Employer. Females, minorities, veterans, and persons with disabilities are strongly encouraged to apply.

Official Title: Sys Programmer/Sys Supv, Pdpp

Primary Location

: United States-Massachusetts-Boston-1 Ashburton Place

Job

: Information Systems and Technology

Agency

: Exec Office of Technology Services and Security

Schedule

: Full-time

Shift

: Day

Job Posting

: Nov 22, 2021, 9:10:56 PM

Number of Openings

: 1

Salary

: 73,194.86 - 120,408.98 Yearly

If you have Diversity, Affirmative Action or Equal Employment Opportunity questions or need a Reasonable Accommodation, please contact Diversity Officer / ADA Coordinator: Emily Hartmann - 6176608300

Bargaining Unit: 06-NAGE - Professional Admin.

Confidential: No
Show more Show less"
2817095658,Data Engineer,ListReports,2021-11-03,United States,"Orange, CA",Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","At ListReports®

As a 7-year-old technology company in the real estate space, our vision is to make buying and selling a home a truly delightful experience. With a powerful flywheel-driven business model, our culture is built upon helping people uncover their biggest strengths and using them to the fullest extent possible. We're also delightfully weird, which means that we take pride in being authentically ourselves. If this sounds like a place you'd find interesting – keep reading!

Are you a business and goal-minded Data Engineer? Our Data Science team is looking for a person to lead the technical execution of high-impact company projects, as well as scale our data science practice by providing a strong integration point between the Data Science team's work and the rest of the company's tech stack. A key part of this role will be mobilizing data to stakeholders in engineering, product, customer success, sales and marketing in order to accelerate the growth of our business.

We have adopted a permanent ""work from anywhere"" culture – meaning you have complete freedom to decide where you want to work (at home, at a coffee shop, co-working space, in our office in Orange, California once it reopens, or traveling the country in a vintage RV). As long as you've got a strong WiFi signal, you're good. Therefore, we are open to candidates in any location in the US.

Learn More About How We Work Here.

What you'll do at ListReports®

You'll work on (major) special projects needed within product development, engineering, and marketing to ensure there is a heavy business intelligence layer in every decision we make as we continue to grow. Ultimately, we're looking for a capable data developer who can work cross-departmentally.

Knowledge must-haves:

Python (including packages such as numpy, pandas, sklearn, matplotlib, tensorflow or pytorch, Plotly Dash, dask, etc.)
Git
AWS Cloud Services (including Lambda, EC2, S3, ElasticSearch, Sagemaker, DynamoDB, AWS RDS)
SQL databases (like MySQL) and nSQL databases (like MongoDB) as well as other structured and unstructured data sources


Knowledge nice-to-haves:

R: tidyverse, data.table, R Shiny, caret, etc.
Spark, PySpark, or SparklyR
Snowflake, Looker, or similar tools
Developing packages/libraries for Python and/or R
Productionalizing ML models in AWS
Javascript, HTML, CSS
Salesforce
Analytical tools and tag implementation


Specifically, we're also looking for:

Independence: You'll be the only Data Engineer on our data science team (for now), so you'll often have to operate without direct guidance and must have the confidence to do so. Our team also operates without a project manager, so organizational and time management skills are key.
Easy to work with: You'll be working cross-functionally with a lot of different players – primarily engineering but also product, customer success, sales, and marketing. You must be a strong communicator who is patient with people who don't understand things the way you do.
Speed: You are not a perfectionist, because speed matters. You'll have to take data tables and stand them up quickly so that our team can access the information and use it to accelerate growth quickly.


Because this is a new role in our data science team, we are looking for someone with about 5 (or more) years of experience. This role reports to our VP, Data Science and Analytics.

Equal Opportunity Employer: ListReports® is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.
Show more Show less"
2717095511,Data Engineer,Axos Bank,2021-08-22,United States,"Dallas, TX",Information Technology,Full-time,"Banking, Financial Services, and Investment Banking","Axos

Born digital, Axos Bank has reinvented the banking model and grown to over $14 billion in assets since our founding in 2000. With a broad and ever-growing range of financial products, Axos Bank is rated among the top 5 digital banks in the country! Axos Financial is our holding company and publicly traded on the New York Stock Exchange under the symbol ""AX"" (NYSE: AX).

We bring together human insight and digital expertise to anticipate the needs of our customers. Our team members are innovative, technologically sophisticated, and motivated to achieve.

Learn more about working here!

REMOTE*

Texas Residents Only

The Opportunity

You will be joining a high performing tech minded team who work with some of the latest software products in support of an internal data solution.

The Role

Work with technical and business team to understand the business requirements, functional and technical specifications
Design, code, and maintain new and existing complex SQL stored procedures and functions
Performance tune existing stored procedures, tables, and indexes
Collaborate with other engineers to troubleshoot, repair, and performance tune databases
Review SQL code written by other developers to ensure compliance to coding standards and best practices as well as maximum performance
Create SSIS packages for data transformation, cleansing, caching, aggregation, staging, and transfer
Troubleshoot problems that may come up with database environments: performance issues; replication issues; or operational issues
Perform data analysis and data profiling tasks to provide support and recommendations for development and design decisions
Analyze and define data flow requirements and prepare applicable system documentation and operation manuals as needed
Support production data loads and ongoing refreshes of the database systems
Define, prepare, execute, and implement data validation and unit testing methods to ensure data quality
Maintain re-usable development standards that help implement each solution and/or enhancements to existing systems to meet current and future needs
Perform enhancements, bug fixes, and additional work when required

Are You A Fit?

3+ years' working with relational DBs in a production environment and with Microsoft SQL Server
2+ years' in SSIS packages and in a n Agile/SCRUM environment
Delivered high quality, high traffic, scalable database objects
SQL server design and development expertise
Excellent verbal and written communication skills, including ability to simplify complex concepts for technical and non-technical audience
Superior problem-solving skills, self-motivation, and the capacity to work under pressure and tight deadlines
Learn, acquire, and utilize new technologies, disciplines, and frameworks
Technical expertise in the areas of data profiling, data mining, and data analytics
Built reliable data ETL/ELT processes, query optimization, and dynamic SQL
Work well independently under minimal supervision with a track record of setting and meeting delivery commitments
Bachelor's Degree in Computer Science, Information Systems, Computer Engineering, or related field

Preferred

BigData
Banking

Apply directly for consideration as we are not using any outside agencies for any of our openings

Pre-Employment Drug Test

All offers are contingent upon the candidate successfully passing a credit check, criminal background check, and pre-employment drug screening, which includes screening for marijuana. Axos Bank is a federally regulated banking institution. At the federal level, marijuana is an illegal schedule 1 drug; therefore, we will not employ any person who tests positive for marijuana, regardless of state legalization.

Equal Employment Opportunity

Axos Bank is an E qual O pportunity employer. We are committed to providing equal employment opportunities to all employees and applicants without regard to race, religious creed, color, sex (including pregnancy, breast feeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship status, military and veteran status, marital status, age, protected medical condition, genetic information, physical disability, mental disability, or any other protected status in accordance with all applicable federal, state and local laws.

Job Functions And Work Environment

While performing the duties of this position, the employee is required to sit for extended periods of time. Manual dexterity and coordination are required while operating standard office equipment such as computer keyboard and mouse, calculator, telephone, copiers, etc.

The work environment characteristics described here are representative of those an employee may encounter while performing the essential functions of this position. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of this position.
Show more Show less"
2789621990,Data Engineer,Zoom,2021-12-03,United States,"Pennsylvania, United States",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2809212152,Data Engineer,Thermo Fisher Scientific,2021-11-25,United States,"Boston, MA",Information Technology,Full-time,Biotechnology Research and Pharmaceutical Manufacturing,"When you are part of the team at Thermo Fisher Scientific, you’ll do important work, like helping customers in finding cures for cancer, protecting the environment or making sure our food is safe. Your work will have real-world impact, and you’ll be supported in achieving your career goals.

How will you make an impact?

Thermo Fishers Scientific is seeking a Data Engineer located at Carlsbad, CA to work with Digital Marketing and Data Architecture team to build Databricks-based Data Pipeline and bring data onto our enterprise level data platform for Data Science, Analytics and Digital Marketing needs. The data platform is primarily based on Oracle Exadata database, AWS Redshift and Databricks-based Delta technologies toward Lakehouse transition to enable Data Science, Data Analytics, Customer Analytics and Data Services for critical Application and Business enablement

What will you do?

Design, develop, test, deploy, support, enhance data integration solutions seamlessly to connect and integrate Thermo Fisher enterprise systems in our Data Science and Enterprise Data Platform.
Innovate for data integration in Apache Spark-based Platform to ensure the technology solutions leverage cutting edge integration capabilities.
Facilitate requirements gathering and process mapping workshops, review business/functional requirement documents, author technical design documents, testing plans and scripts.
Assist with implementing standard operating procedures, facilitate review sessions with functional owners and end-user representatives, and leverage technical knowledge and expertise to drive improvements.
Defining, designing and documenting reference architecture and leading the implementation of BI and analytical solutions.
Follow agile development methodologies to deliver solutions and product features by following DevOps practices.

How will you get here?

HS Degree required and 3-5 years of IT experience or BS degree e with major in computer science engineering (or equivalent) prefered

Experience, Knowledge, Skills, Abilities

Experience in Databricks, Data/Delta lake, Oracle, SQL Server or AWS Redshift type relational databases.
Experience in ETL (Data extraction, data transformation and data load processes)
3+ years working experience in data integration and pipeline development.
Excellent experience in Databricks and Apache Spark.
Data lake and Delta lake experience with AWS Glue and Athena.
2+ years of Experience with AWS Cloud on data integration with Apache Spark, Glue, Kafka, Elastic Search, Lambda, S3, Redshift, RDS, MongoDB/DynamoDB ecosystems.
Strong real-life experience in python development especially in pySpark in AWS Cloud environment
Design, develop test, deploy, maintain and improve data integration pipeline.
Experience in Python and common python libraries.
Strong analytical experience with database in writing complex queries, query optimization, debugging, user defined functions, views, indexes etc.
Strong experience with source control systems such as Git and Jenkins build and continuous integration tools.
Highly self-driven, execution-focused, with a willingness to do ""what it takes” to deliver results as you will be expected to rapidly cover a considerable amount of demands on data integration
Understanding of development methodology and actual experience writing functional and technical design specifications.
Excellent verbal and written communication skills, in person, by telephone, and with large teams.
Strong prior technical, development background in either data Services or Engineering
Demonstrated experience resolving complex data integration problems;
Must be able to work cross-functionally. Above all else, must be equal parts data-driven and results-driven.
Show more Show less"
2800032705,Data Engineer,Simpleview,2021-11-15,United States,United States,Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","ABOUT SIMPLEVIEW:

Simpleview is a software development, data analytics and digital marketing firm that supports destination marketing organizations to reach their tourism marketing goals with first-in-class digital products and services. We believe our customers -- towns, cities, states and nations across the globe -- have a role to play in creating great experiences for visitors, for the people who call them home and for businesses and workers who rely on travel to sustain their local economies.

We are looking to add to our professional, dedicated, and hardworking team an independent, talented, top-notch Data Engineer with a great work ethic who thrives in organizations that constantly adapt and evolve.

JOB SUMMARY:

The data engineer is responsible for developing and/or configuring data pipelines, interfaces, and automation tools in support of internal and third-party data warehouses. The data engineer collaborates with data managers, analysts, and scientists to automate data processes or make them more efficient, to improve data quality assurance and semantic interoperability, and to transform raw data into analysis-ready forms. Where processes already exist, the data engineer develops pipelines or other tools to automate data ingestion and standardization. Where possible, the data engineer elicits workflows and functional requirements from data scientists, data analysts, and external partners to help define or improve processes. The data engineer will be responsible for design, documentation, and maintenance of multiple data warehouses and data pipelines and will strive for continuous improvement and efficiency in these processes.

The most successful candidate will have extensive experience designing relational databases as well as knowledge of common analytical data platforms such as Google Analytics. They will have experience using one or more business intelligence / visualization platforms such as Tableau, Looker, etc. They will have experience with one or more of the major cloud data warehouse providers such as Snowflake, Redshift, or BigQuery. They will have experience working with one or more cloud ELT / ETL solutions.

The core mission of the data engineer is to understand client data needs and deliver solutions that are simple and approachable for the average person who has a question they want to answer.

RESPONSIBILITIES:

Develop and/or configure data pipelines, interfaces, and automation tools in support of internal and third-party data warehouses
Collaborates with data managers, analysts, and scientists
Elicit workflows and functional requirements from data scientists, data analysts, and external partners to help define or improve processes
Improve data quality assurance and semantic interoperability
Design, document, and maintain of multiple data warehouses and data pipelines
Strive for continuous improvement and efficiency


REQUIREMENTS:

BS Computer Science or 4 years experience in a related field
SQL wizardry


PREFERRED SKILLS/EXPERIENCE:

Experience developing custom ETL pipelines in python or nodejs
Experience with Apache Airflow or similar ETL solution
Experience with DBT
Experience with Fivetran
Experience with building and training machine learning models


WHO WE ARE LOOKING FOR:

Professionals with solid skills and solid principles
People who know the web like an old friend
Employees who thrive on problem solving and figuring things out
Someone other people want to work with (organized, easy-going, non-toxic)


WHAT IS IN IT FOR YOU:

Fulfilling work at a company that makes an impact in hundreds of communities across the globe
The ability to set a career trajectory and move along a growth path
Great co-workers, including geeks, parents, artists, gamers, veterans and average joes and janes
100% paid medical benefits for employees and short-term disability paid by the company + options for vision, dental, long-term disability & life
401(k) with employer match


This is a new and exciting division within the company and will have great opportunities to grow as it expands.

This position is available to both the Tucson-area and remote candidates. At this time, Simpleview can currently only employ remote staff who reside in the following U.S. states or Canadian province: Arizona, British Columbia, California, Colorado, Florida, Georgia, Idaho, Maryland, Michigan, Minnesota, Missouri, Nevada, New Mexico, North Carolina, Oregon, Pennsylvania, South Carolina, Tennessee, Texas, Utah, Virginia, Washington, and Wisconsin.

Qualified candidates, please apply by going online at:

Or submit your resumes at

Powered by JazzHR

PPpkuogUBP
Show more Show less"
2815636206,Big Data Engineer,Amazon Web Services (AWS),2021-11-27,United States,"Seattle, WA",Administrative,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Amazon Web Services (AWS) is looking for an innovative and passionate data engineer to architect and build new capabilities for our Investments Platform. A singular goal of this platform is to provide our field personnel with secure, highly available, scalable and performant solutions and services so that they can continue to provide excellent service to our customers. You will have the opportunity to join a dynamic team with diverse skill sets, be able to influence our technical direction and build exciting new capabilities that operate at Amazon scale.

We are looking for a hands-on Data Engineer with experience developing and delivering data platforms as we build the next iteration of our system. Come join a team at the beginning of a product life cycle and help define the way AWS does business with its key customers. As a Data Engineer in this team, you will be working on building and maintaining complex data pipelines, assembling large and complex datasets to generate business insights and to enable data driven decision-making. You will interface with several key stakeholders of this platform including our product, program leaders and with our key technical partners across AWS.

Core Responsibilities May Include

Design data schema and operate internal data warehouses and SQL/NOSQL database systems.
Design data models, implement, automate, optimize and monitor data pipelines.
Own the design, development and maintenance of ongoing metrics, reports, analytics, dashboards, etc. to drive key business decisions.
Analyze and solve problems at their root, stepping back to understand the broader context.
Manage Redshift/Spectrum/EMR infrastructure, and drive architectural plans and implementation for future data storage, reporting, and analytic solutions.
Work on different AWS technologies such as S3, Redshift, Lambda, Glue, etc. to provide new capabilities and increase efficiency.
Work on data lake platform and different components in the data lake such as Hadoop, Amazon S3 etc.
Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.
Must possess strong verbal and written communication skills, be self-driven, and deliver high quality results in a fast-paced environment.
Conduct rapid prototyping and proof of concepts.
Conceptualize and develop automation tools for bench marking data collection and analytics.
Interface with other teams to extract, transform, and load data from a wide variety of data sources using AWS big data technologies.

Inclusive Team Culture

Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance

Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded engineer and enable them to take on more complex tasks in the future.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the bias of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit: https://www.amazon.jobs/en/disability/us.


Basic Qualifications

Degree in Computer Science, Engineering, Mathematics, or a related field and 4-5+ years industry experience
Must have one year of experience in the following skill(s): (1) Developing and operating large-scale ETL/ELT processes; database technologies; data modeling (2) Experience with at least one relational database technology such as Redshift, RDS, Oracle, Postgres
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
3+ year of coding experience with modern programming or scripting language (Python, Scala, Java, C# etc.).
Advanced SQL and query performance tuning skills.
Experience with at least one massively parallel processing data technology such as Redshift, Spark or Hadoop based big data solutions

Preferred Qualifications

Master's/PhD degree in or Computer Science, Engineering, Mathematics or related discipline
Experience building data products incrementally and integrating and managing datasets from multiple sources
Query performance tuning skills using Unix/Linux profiling tools and SQL
Experience with AWS Tools and Technologies (Redshift, S3, EC2, Glue, Lambda, Sage Maker)
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role


Company - Amazon Web Services, Inc.

Job ID: A1823360
Show more Show less"
2807405855,"Software Engineer, Data Infrastructure",DoorDash,2021-11-25,United States,"Los Angeles, CA",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Come help us build the world's most reliable on-demand, logistics engine for delivery! We're bringing on experienced engineers to help us further our 24x7, global infrastructure system that powers DoorDash’s three-sided marketplace of consumers, merchants, and dashers.

The Data Infrastructure team manages DoorDash's massive database and makes data accessible for teams driving decision making, machine learning, and experimentation. The team is relatively small, so there's an opportunity for impact where you can help grow the team and shape the roadmap for data infrastructure at DoorDash.

What You’ll Do

Work on our data pipeline, ETL systems, and real-time data
Come up with solutions for scaling data infrastructure
Help all departments of the company have access to our data
Collaborate in a dynamic startup environment
Improve logistics by taking on cutting-edge, technical problems

What We're Looking For

B.S., M.S., or PhD. in Computer Science or equivalent
5+ years of experience with CS fundamental concepts and OOP languages like Java and Python
Experience working with databases (e.g. SQL) and data infrastructure
Experience in big data technology like Presto, Snowflake, Hadoop, Airflow, Kafka
A passion for analyzing data to inform decisions
Experience improving efficiency, scalability, and stability of system resources

Why You’ll Love Working at DoorDash

We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies.
We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day.
We are learners - We’re not afraid to dig in and uncover the truth, even if it’s scary or inconvenient. Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute.
We are customer-obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility.
We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.
We offer great compensation packages and comprehensive health benefits.

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly and always learn and reiterate to support merchants, Dashers and the communities we serve. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods. Read more on the DoorDash website, the DoorDash blog, the DoorDash Engineering blog, and the DoorDash Careers page.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. Our leaders seek the truth and welcome big, hairy, audacious questions. We are grounded in our company values, and we make intentional decisions that are both logical and display empathy for our range of users—from Dashers to Merchants to Customers.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

Pursuant to the Colorado Fair Pay Act, the base salary range in Colorado for this position is $136,000 - $182,750, plus opportunities for equity and commission. Compensation in other geographies may vary. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

If you need any accommodations, please inform your recruiting contact upon initial connection.


Show more Show less"
2798518155,Data Engineer,Amazon,2021-11-18,United States,"Santa Monica, CA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

WW Consumer Finance Technology team, responsible for implementation of technical solutions for process optimizations in WW Consumer Finance planning and reporting, is looking for a Data Engineer.

As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams within Global Customer Fulfillment Finance on various technical process optimization initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.

You will be responsible for designing and implementing an analytical environment using third-party and in-house tools, modeling metadata, building solutions for efficient data management. You will have an opportunity to work with leading edge AWS technologies.


Basic Qualifications

3+ years of experience as a Data Engineer or in a similar role
Degrees in Computer Science or related field
Experience in data modeling, data warehousing, and building data pipelines
Knowledge of SQL

Preferred Qualifications

Experience with SQL, Oracle, OLAP, Big Data Technologies
Understanding of Finance or other business area
Understanding of data infrastructure administration and optimization
Knowledge of scripting languages
Familiarity with Amazon Web Services and Microsoft Data Technologies
Knowledge of data warehousing concepts


Company - Amazon.com Services LLC

Job ID: A1531560
Show more Show less"
2805667692,Data Analytics Engineer,"American Honda Motor Company, Inc.",2021-10-25,United States,"Raymond, OH",Information Technology,Full-time,"Motor Vehicle Manufacturing, Banking, and Financial Services","Honda has a clear vision for the future in 2030, and it’s a joyful one. We are looking for people with the individual skills, courage, persistence, and dreams that will help us reach our future-focused goals. We are seeking diversity of thought and experience to drive innovation and help us make fully informed decisions.

In this role, you will be responsible to identify and resolve field quality problems quickly to ensure customer satisfaction and maintain quality competitiveness. This role will review multiple data sources to evaluate, summarize and draw conclusions to identify trends that lead to countermeasure activities. In your pursuit of impeccable quality, you set and execute the strategy, and manage customer and vendor relations. Your endless curiosity will drive innovative activities.

At Honda, our associates take pride in their responsibilities. A typical day for a Data Analytics Engineer will include:

Analyzing multiple data sources in detail to identify trends and problem indicators
Cleaning data to ensure proper classification of market problems
Looking for data trends not previously identified through deep understanding of the data
Transforming data using SQL, Python, etc. to identify trends that lead to actionable problems
Developing groupings of claims to support identification and classification of market problems
Effectively generating ideas and supporting building tools to automate analysis process
Utilizing predictive analytics (Forecasting) to support future growth to ensure action is taken at the appropriate time

To Bring The Future To Honda As a Data Analytics Engineer You Must Have

We are looking for qualified people with diverse backgrounds and experiences, open minds, and a disciplined work ethic.

A Bachelor’s Degree in Computer Science, Data Analytics, Mathematics or Engineering with strong engineering aptitude or equivalent experience
0-6 years of education or 3 months of co-op experience in analytical or information analysis
Strong problem-solving skills to ensure data is correct and responsible areas accept the results
Strong communication skills (written, verbal and visual) to ensure your analysis is clearly understood
Excellent attention to detail
Experienced in Microsoft Excel (Pivot tables, Vlookup, etc.)
Prioritization skills to manage workload and make sound decisions
Proficient using query languages such as SQL
Experience with common data science toolkits such as R & Python
Knowledge of data gathering, cleaning, and transforming techniques (desired)
Business intelligence (Qlikview, Power BI) programming (desired)
Applied statistics skills such as distributions, statistical testing, regression, etc. (desired)

Total Rewards

Competitive Base Pay
Medical, Dental, Vision
Bonus Program
401K Program
Honda Product Programs

Honda is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity and expression, age, disability, veteran status, or any other protected factor.

Honda Dev. and Mfg. of Am LLC
Show more Show less"
2793808006,Data Engineer,Maestro.io,2021-11-15,United States,Los Angeles Metropolitan Area,Information Technology and Engineering,Full-time,Internet Publishing,"Covid-19 Hiring Update

We’ve transitioned to a work-from-home model and we’re continuing to interview and hire during this time. This role is expected to begin as a remote position. We understand each person’s circumstances may be unique and will work with you to explore all options.




Overview

`We’re seeking a Data Engineer to join our rapidly growing team. This resource will be a key contributor on Maestro’s Big Data Engineering Team in support of Business Intelligence and Analytics efforts. This person will be responsible for the following:



What You’ll Do

Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements
Construct and execute queries against an enterprise-grade cloud data warehouse.
Perform analysis on various raw data sets to help inform Maestro business decisions.
Transform and model raw data for input into Business Intelligence tools and other applications.
Audit existing datasets to discover new trends that affect Maestro’s business goals.
Documenting new insights gained from querying and analyzing both new and pre-existing data in our cloud warehouse.
Create data processes for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Contribute to building analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.




What You’ll Bring

Preferably a Bachelor’s Degree or higher in Computer Science, Data Science, Engineering, or related field.
Experience in querying and analyzing large datasets in using one of the following: Hive, Spark, BigQuery, RedShift, Snowflake, or a similar platform.
Experience with Structured ETL, implementation and maintenance
Knowledge of SQL, or at least one of Python, R, Matlab, Java, C++, or a related language
Experience in using one of the following Big Data Frameworks/ Data processing using such as Spark or HDFS/MapReduce/Hive or AWS S3/ Redshift /Glue or Google Dataflow/BigQuery
A quick learning curve and ability to adapt to different work tools quickly.
Strong communication skills. An ability to translate data analytics into stories that help inform business decisions.




What will get you in the door immediately? All of the above plus the following:

Experience querying petabyte sized data warehouses.
Experience working with any cloud data warehouse.
Experience visualizing data using any BI tools, preferably cloud based reporting tools.




Perks

Aggressive compensation and stock options package
Atypical benefits package
Holiday soft closures
Education Reimbursement
Flexible work schedule
Flexible Time Off
Remote working options




At Maestro, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best.




About us

Maestro ’s mission is to grow the GDP of the creator economy. It empowers the 100M+ global creator market —from major enterprises to small businesses—with an interactive video platform to build strong communities and monetize passions. Customers can easily set up unique branded experiences, monetize in a variety of ways ranging from ticketing to subscriptions and e-commerce, and learn how to achieve their goals with powerful analytics.




Whether it’s an individual creator, a company creating a live extension of their brand, or a business looking to launch an interactive platform for a specific vertical, Maestro guarantees the most robust and customizable solution with the fastest time to market.
Show more Show less"
2817320561,Data Engineer,bp,2021-12-01,United States,"Houston, TX","Information Technology, Consulting, and Engineering",Full-time,"IT Services and IT Consulting, Computer Software, and Oil and Gas","Staff Data Engineer




ABOUT US

At bp, we’re reimagining energy for people and our planet. With operations working across almost every part of the energy system, we’re leading the way in reducing carbon emissions and developing more sustainable methods for solving the energy challenge.

We’re a diverse team of engineers, scientists, traders and business professionals determined to find answers to problems that must be solved. But we know we can’t do it alone. We’re looking for people who share our passion for reinvention to bring a new point of view, collaborative spirit, and to challenge our thinking in our ambition to achieve net zero!




ROLE SYNOPSIS

The Staff Data Engineer in Digital Customers & Markets will work on a variety of data engineering projects across our customer facing businesses. The individual will combine their technical expertise with strong discernment and data domain knowledge to add new value for bp by defining, building and supporting BigData & analytics products. The will lead teams and will also continue to be hands-on, for example writing and reviewing code, architecting distributed data systems and providing concrete, pragmatic insights in technical design reviews. Data Engineering & Data Management is a team at bp and the individual will contribute to building and networking within the team.




KEY ACCOUNTABILITIES

Leads, grows and develops a team of data engineers that writes, deploys and maintains software to build, integrate, manage, maintain, and quality-assure data at bp.
Creates positive engagement and drives an inclusive work environment with team and partners through the quality of interactions and collaboration across multiple business entities.
Effectively works with cross-disciplinary collaborators and partners across multiple business entities.
Architects and designs reliable and scalable data infrastructure.
Advocates for and ensures their team adheres to software engineering standard methodologies (e.g. technical design, technical design review, unit testing, monitoring & alerting, checking in code, code review, documentation),
Responsible for deploying secure and well-tested software that meets privacy and compliance requirements.
Responsible for service reliability and following site-reliability engineering standard methodologies: on-call rotations for services they oversee, responsible for defining and maintaining SLAs.
Actively contributes to improve developer velocity.
Actively mentors others.




ESSENTIAL EDUCATION

BS degree in computer science or related field




ESSENTIAL EXPERIENCE AND JOB REQUIREMENTS

Experience (typically 2+ years) leading, growing and developing a data engineering team of around 7-30 people
Deep and hands-on experience (typically 5+ years) designing, planning, productionizing, maintaining and documenting reliable and scalable data infrastructure and data products in complex environments
Development experience in one or more object-oriented programming languages (e.g. Python, Go, Java, C++)
Advanced SQL knowledge
Experience designing and implementing large-scale distributed systems
Deep knowledge and hands-on experience in technologies across all data lifecycle stages
Strong collaborator management and ability to lead large organizations through influence
Continuous learning and improvement approach
No prior experience in the energy industry required




DESIRABLE CRITERIA

Experience in retail and / or supply chain data
Experience in AWS and / or Azure native data platforms




WHY JOIN US

At bp, we support our people to learn and grow in a diverse and challenging environment. We believe that our team is strengthened by diversity. We are committed to fostering an inclusive environment in which everyone is respected and treated fairly.

There are many aspects of our employees’ lives that are important, so we offer benefits to enable your work to fit with your life. These benefits can include flexible working options, a generous paid parental leave policy, and excellent retirement benefits, among others!

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation

Show more Show less"
2794464902,Data Engineer,MemSQL,2021-11-11,United States,"Raleigh, NC",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

SingleStore is a cutting edge business leading a wave of disruption in the database space focussed on delivering a single platform for all data intensive applications.

Job Responsibilities

Translate business and functional requirements into robust, scalable, operable solutions that work well within the overall data architecture.
Design, develop, implement, test, document, and operate large-scale, high-volume and low latency applications.
Build integrations between multiple data sources from every corner of our business including Finance, Sales, Cloud, Product Telemetry, and others.
Designs data integrations and data quality framework.
Develops and maintains scalable data pipelines and builds out new API integrations.
Implement data structures using best practices in data modeling, ETL/ELT processes, and SQL.
Manage stakeholder communication, prioritization of tasks and on time solution delivery.
Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance.
Produce comprehensive, usable dataset documentation and metadata.
Design and develop operational and analytical reports as per the customer needs by using the tools.
Evaluate and make decisions around the use of new or existing software products and tools.
Mentor junior data engineers.


Basic Qualifications

3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL
Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline
4+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
Knowledge of data management fundamentals and data storage principles
A desire to work in a collaborative, intellectually curious environment


Preferred Qualifications

Experience with SingleStore as application developer or engineer
Strong SQL skills with experience in writing complex SQLs, materialized views, high performance queries.
Experience with AWS services such as S3 and RDS.
Experience with Tableau, Metabase, and other data visualization tools
Experience with Prometheus, PromQL, Grafana, and the Go programming language
Strong knowledge of data management fundamentals and data storage principles.
Experience in working and delivering end-to-end projects independently.
Strong written and verbal communication skills across diverse audiences.


SingleStore is one platform for all data, built so you can engage with insight in every moment. Trusted by industry leaders, SingleStore enables enterprises to adapt to change as it happens, embrace diverse data with ease, and accelerate the pace of innovation. SingleStore is venture-backed and headquartered in San Francisco with offices in Portland, Seattle, Boston, Bangalore, London, Lisbon, and Kyiv. Defining the future starts with The Database of Now™.

Consistent with our commitment to diversity & inclusion, we value individuals with the ability to work on diverse teams and with a diverse range of people.

To all recruitment agencies: SingleStore does not accept agency resumes. Please do not forward resumes to SingleStore employees. SingleStore is not responsible for any fees related to unsolicited resumes and will not pay fees to any third-party agency or company that does not have a signed agreement with the Company.
Show more Show less"
2809629410,Data Engineer (Alteryx / SQL),eClerx,2021-11-22,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","DATA ENGINEER (Alteryx/SQL)

_______________________________________________________________________________________

LOCATION: New York

HIRE TYPE: Full-time

VERTICAL: Financial Markets

_______________________________________________________________________________________

Role Summary

eClerx is looking for data engineering professionals with hands on experience with different data science processes using the following tools: Alteryx, Excel, SQL, Tableau, and Python.

The candidate should have previous experience at a financial services firm. They should have demonstrable knowledge of commonly traded financial products and how they are processed in the middle and back office of an investment bank.

In This Position, You Will

Key Responsibilities

Provide data wrangling services to make data (structured and unstructured), by transformations, normalization, and data mapping, consumable for a variety of downstream purposes such as applications, visualizations, and analytics
Design and model analytical methods based on the statistical methods. Validate, test, and deploy data models and analytical products/tools.
Identify opportunities to enhance standards and incorporate best practices in the areas of data wrangling, data visualization, and data integration
Research, troubleshoot and recommend solutions to complex business and technical problems. Prepare and communicate through effective presentations and written communications.
Perform hands-on data analysis using Tableau to process, model and visualize sizable volumes of data
Design and develop workflows in Alteryx that connect via SharePoint, SQL Server or other sources of data to combine and transform data in support of BI Reporting via Tableau
Work closely with business users to translate their requirements into technology solutions that leverage Tableau, Alteryx, SQL as appropriate
Query and join multiple tables in SQL databases to provide data needed to support analytics and/or process improvement
Prepare technical specifications and documentation for technology solutions in order to support downstream uses
Ensure quality solution delivery by performing end to end data validation on technology solutions
Support and/or Partner with end-users in leveraging Tableau/Alteryx for Exploratory Analysis

Eligibility Requirements

3+ years of related, hands-on experience with Alteryx Designer including using Predictive, Parsing, and Transform components
Experience using Alteryx Server as an Artisan strongly preferred
3+ years of related, hands-on experience with Tableau Desktop and Tableau Server
4+ years writing complex SQL queries and performing query optimization.
3+ years’ experience in a trade-related, technology position at a financial institution
Experience developing data models and analytical products for financial services firms
Experience in business analysis and working with diverse teams and competing interests for requirements gathering and analyzing technical trade-offs
Strong analytical, problem solving, and troubleshooting abilities
Strong oral and written communication skills with the ability to effectively communicate with both technical and non-technical audiences at all levels within technical and business organizations
Innovation minded, highly capable to think systematically, capable to redefine the solutions to overcome the competitors and solving problem
Self-driven, energetic, creative, with ability to work in international teams
Curious and willing to challenge existing solutions with innovative technology concepts

About EClerx

eClerx provides business process management, analytics, and automation services to a number of Fortune 2000 enterprises, including some of the world’s leading companies across financial services, cable & telecom, retail, fashion, media & entertainment, manufacturing, travel & leisure, software and high-tech. Incorporated in 2000, eClerx is one of India’s leading process management and data analytics companies and is today traded on both the Bombay and National Stock Exchanges of India. eClerx employs 11,000 people across its global sites in the US, UK, India, Italy, Germany, Singapore, and Thailand. For more information visit www.eclerx.com.

eClerx is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

eClerx is committed to protecting and safeguarding your personal data. Please find our policy here.


Show more Show less"
2824090486,Python Data Engineer,Sogeti,2021-12-02,United States,"Bridgewater, NJ",Information Technology,Full-time,IT Services and IT Consulting,"Primary Responsibilities/Requirements:

Perform data engineering to translate data into useful forms for analysis
Collect, prepare and analyze data
Analyze System Architecture with heterogenous sources
Must have 5+ years in data engineering
Must have experience with Python for analytics (ETL)
Must have experience with PostgreSQL
Must have experience with big data
Experience with CI/CD and AWS is nice to have
Show more Show less"
2781520039,Data Engineer - 72533,"Pinnacle Group, Inc.",2021-11-01,United States,"Austin, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Please note hiring Manager is Chuan Yang, please direct all follow up questions

to Chaun.

Data Engineer Contractor Job Description

Automate end-to-end ETL/ML pipelines with structural understanding of data products.
Automate, deploy and maintain ML pipelines into existing cloud resources.
Work with team members to assist with data-related technical issues and support their data product needs,

and maintain high-standard documentations

Required Skills

A background in computer science, engineering, mathematics, or similar quantitative field with a minimum of 2

years professional experience

Experience in implementing data pipelines using python, familiar with Pandas and Numpy
Experience with workflow scheduling / orchestration such as Kubernetes or Airflow
Extract Transform Load (ETL) experience using Spark, Kafka, Hadoop, or similar technologies
Experience with query APIs using JSON, ProtocolBuffers, or XML
Experience with Unix-based command line interface and Bash scripts
Experience with Postgres database, familiar with SQL scripting
Experience with Web or REST API development in Python

Optional Skills

Data visualization or web development skills a plus

Education

Bachelors in computer science or engineering; Masters preferred
Show more Show less"
2802392384,Data Engineer,Blink Health,2021-10-27,United States,"Kirkland, WA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Blink Health is a well-funded healthcare technology company on a mission to make prescription drugs more accessible and affordable for everyone. We're scaling up in a highly complex vertical to change the way Americans access the prescription drugs they need.

Our proprietary platform and supply chain allows us to offer everyone — whether they have insurance or not — amazingly inexpensive prices on over 15,000 medications. With the addition of telemedicine and home delivery for prescriptions, Blink is providing a life-changing experience for people all over the country and fixing how opaque, unfair and overpriced healthcare has become. We are a highly collaborative team of builders and operators who invent new ways of working in an industry that historically has resisted innovation. Join us!

About The Team

Blink Engineering strives to build trusted, highly observable, data-driven products to bring affordable, accessible healthcare to all Americans. We understand healthcare is the most complex system most of us will ever fix. We believe in solving this complexity through the use of simple, well-known technologies. We are a highly collaborative team that believes in owning outcomes over owning code and putting patients at the center of everything we do.

The Blink Health Data Engineering and Analytics team is a small team responsible for building infrastructure, frameworks and tooling to enable data-driven decisions; building and maintaining our data warehouse for security and scale. This role is central to building and executing on a robust and forward-looking data strategy for the company, and the successful candidate blends top-tier software engineering expertise with the ability to look ahead at what we need to build for the future.

About The Role

As Data Engineer, you will be a helping building our next generation of data tools and frameworks, in addition to developing and maintaining data products and infrastructure. You will proactively assess production DW support trends to determine and implement short- and long-term solutions, and be able to design for data integrity, reliability, and performance.

Required Experience

You have 4+ years hands-on experience and demonstrated strength with:
Python software development. You will be coding
Building and maintaining robust and scalable data integration (ETL) pipelines using SQL, EMR, Python and Spark.
Writing complex, highly-optimized SQL queries across large data sets.
Designing and maintaining columnar databases (e.g., Redshift, Snowflake)
Distributed data processing (Hadoop, Spark, Hive)
ETL with batch (AWS Data Pipeline, Airflow) and streaming (Kinesis)
Integration and design for Business Intelligence tools (e.g., Looker, QuickSight)
Creating scalable data models for analytics.
You have experience designing and refactoring large enterprise data warehouses and associated ETLs, with continuous improvement examples for automation and simplification across all aspects of the DW environment, inclusive of both engineering and business reporting.
Proven success with communicating effectively across diverse disciplines (including product engineering, infrastructure, analytics, data science, finance, marketing, customer support, etc.) to collect requirements and describe data engineering strategy and decisions.
Undergraduate or graduate degree in Computer Science
Show more Show less"
2822645126,Data Engineer,Intelerad Medical Systems,2021-12-01,United States,"Raleigh, NC",Information Technology,Full-time,Medical Equipment,"Company Description

Over the last 20 years, Intelerad has grown into a leader of the medical imaging software industry. Our distributed solutions play a vital role in the delivery of healthcare across 11 time zones and 3 continents. We take pride in being a world-class healthcare solutions company with more than 400 employees and over 1,000 customer sites. Our workplaces encourage growth and professional development.

We are Intelerad. Join us if you want to be the best version of yourself and make a difference in healthcare.

Job Description

The Data engineer will build data pipelines that transform raw, unstructured data into formatted data for analysis purposes. They are responsible for creating and maintaining the analytics infrastructure that enables almost every other data function. This includes architectures such as databases, servers, and large-scale processing systems.

Responsibilities

General

Identifies, designs, and implements internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
Working with internal stakeholders including the Executive, Product, Data and Design teams to support data infrastructure needs while assisting with data-related technical issues
Working with client stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Defines and designs data pipeline architecture and infrastructure for optimal extraction, transformation and loading of data from various data sources
Defines ingestion components to read data from data sources
Builds transformation functions for filtering and aggregation
Assembles large, complex sets of data that meet non-functional and functional business requirements
Builds analytical tools to utilize the data pipeline, providing actionable insight into key performance metrics
Prepares data for predictive and prescriptive modeling
Find hidden patterns using data
Use data to discover tasks that can be automated
Continuously works with data and analytics experts to strive for greater functionality in our analytical solutions.


Required

Qualifications

Bachelor's degree in Computer Science or related discipline; or equivalent work experience
Minimum 3 years experience in a Data Engineer role
Possesses a strong technical aptitude for data lakes, Microsoft Azure Data factory experience a plus
Demonstrated understanding and SQL experience with relational databases
Strong data discovery skills related to working with unknown datasets
Experience building and optimizing data pipelines, architectures, and data sets
Demonstrated understanding of creating load architectures for dimensional models and data marts


Desired Competencies

Graduate degree in information systems, informatics, statistics, computer science or another quantitative field.
2-3 Years experience with Microsoft Power BI
Experience performing root cause analysis to identify opportunities for improvement
Strong data discovery skills related to working with unknown datasets
Evidence of building processes supporting data transformation, data structures, metadata, dependency
Ability to prioritize and work under pressure in fast-paced ever-changing environment
Self-starter and able to support quality and results with minimal directional guidance
Strong project management skills
Strong analytical (quantitative and qualitative) capabilities and attention to detail/quality
Direct experience in a Data Engineer role in healthcare
Demonstrates ability to clearly communicate complex information at a consumable high level


Additional Information

All applicants meeting minimum qualifications will be required to complete a 30 minute online assessment as part of your application.
Show more Show less"
2825059245,Big Data Engineer,"Pyramid Consulting, Inc",2021-12-02,United States,"Irving, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Position : Big Data Engineer (PySpark or Spark-Scala)
Location : Dallas, TX (Remote until Covid)
Duration: Full Time Permanent  
                                                                                                                                              
Job Description:
 
Education: Minimum Bachelor’s degree in Computer Science, Engineering, Business Information Systems, or related field. Masters in Computing related to scalable and distributed computing is a major plus
 
Key Responsibilities:



Develop Big Data applications using PySpark or Scala-Spark on Hadoop, Hive and/or Kafka, HBase, MongoDB
Build Feature Engineering, Scoring / Machine Learning models
Deployment on Cloud platforms
 
Experience & Skillset
MUST-HAVE
Experience in PySpark or Spark-Scala developing Big Data applications on Hadoop, Hive and/or Kafka, HBase, MongoDB
Technical leadership and Onsite-Offshore coordination
Deep knowledge of Spark libraries on Python or Scala to develop and debug complex data engineering challenges
Experience in developing sustainable data driven solutions with current new generation data technologies to drive our business and technology strategies
Exposure in deploying on Cloud platforms
At least 4 years of development experience on designing and developing Data Pipelines for Data Ingestion or Transformation using PySpark or Spark-Scala
At least 5 years of development experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC), Resource Management, Distributed Processing and RDBMS
At least 4 years of developing applications in Agile with Monitoring, Build Tools, Version Control, Shell Scripting, Unit Test, TDD, CI/CD, Change Management to support DevOps
Prior experience on ETL or SQL or other Data technologies
GOOD-TO-HAVE
Banking domain knowledge
Hands-on experience in SAS toolset / statistical modelling migrating to Machine Learning models
Digital Marketing Machine Learning models and use cases
ETL / Data Warehousing and Data Modelling experience prior to Big Data experience
Deep knowledge on AWS stack for big data and machine learning
Show more Show less"
2821214702,Data Engineer,Byline Bank,2021-11-30,United States,"Schaumburg, IL",Information Technology,Full-time,Financial Services,"Byline is seeking a Data engineer to work on ByLine’s Data and Salesforce environment, Financial services cloud, NCino, Marketing cloud and Reporting. This person will also need to demonstrate knowledge of integration between on prem and cloud systems, object-oriented design and engineering efforts to improve user’s adaption of Salesforce platform for their daily use.

Areas of responsibility:

Meet business to determine functional and technical requirements.
Take lead in application design life cycle and support.
Be hands on in creating demos, proof of concept and solution wireframe.
Utilize best practices, for requirements gathering, bugs and back log management of tickets.
Provide technical assistance, end user support and documentation.
Act as point of contact for Salesforce platform issues and tickets.


Technical requirements:

Proven technical experience in Salesforce/Force.com development for 3-5 years.
Technical knowledge of Salesforce CRM and other similar cloud-based solutions like Oracle, SAP, Dynamics.
Direct work experience related to development, configuration and testing with Financial data, reporting and Fintech vendor services.
SSRS or Business Objects experience is required to create reports for end user.
Hands of use of Apex, Lightening components, Triggers, Workflow, process builder in Salesforce.
Demonstrated experience with SQL, TSQL, SSIS, relational databases and other ETL integration products.
Experience with web services (Rest, SOAP, JSON and XML)
Hands on experience with PowerBI or SSRS and Salesforce Reports and dashboard
Understand agile concepts and willingness to support ITIL process.
Salesforce certification preferred.
FIS or FServe Financial system background preferred.


PHYSICAL DEMANDS/WORK ENVIRONMENT: Usual office environment with frequent sitting, walking, and standing, and occasional climbing, stooping, kneeling, crouching, crawling, and balancing. Frequent use of eye, hand, and finger coordination enabling the use of office equipment. Oral and auditory capacity enabling interpersonal communication as well as communication through automated devices.
Show more Show less"
2787089424,Data Engineer,Covetrus,2021-11-24,United States,"Portland, ME",Information Technology and Engineering,Full-time,Veterinary Services,"RESPONSIBILITIES

Thrives in a fast moving environment, working on a variety of projects and technologies in an iterative, team based culture
Strong desire to learn new skills and adapt to new technologies while maintaining attention to detail
Converting product requirements into a well thought through, cleanly designed data integration solutions




EDUCATION

Bachelor's degree in computer science, computer programming, computer engineering or related field preferred, or comparable job-related experience and training.
2-5 years of relevant work experience




COMPETENCIES

Java development experience (2+ years)
Strong SQL knowledge
Relational databases (Snowflake, MySQL, Redshift)
NoSQL databases (MongoDB, DynamoDB)
Streaming/Messaging (Kafka, ActiveMQ, SQS)
Experience developing data migration processes




PLUSES

Python programming experience
API development, GraphQL
Amazon Web Services or Microsoft Azure exposure
CI/CD experience (Jenkins, Harness)
Experience in a data warehouse environment
ETL tools (e.g., Talend, Informatica, Datastage, Pentaho)

Show more Show less"
2800204667,Data Engineer,Fisher Investments,2021-11-15,United States,"Camas, WA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Overview

The Opportunity:

As a Workforce Analyst at Fisher Investments, you will help improve our workforce through employee related insights to help build and further a diverse, engaged workforce. Reporting to the Workforce Analytics Manager, you will partner with leaders in Human Capital and across the business to improve people performance and planning through the discovery, interpretation and communication of meaningful patterns in workforce-related data. Through these insights and optimization, you will help the firm achieve its long-term strategic goals.

The Day-to-Day:

Construct data queries from multiple data sources to aggregate, model and prepare information for analysis
Be an expert on data flows from Human Capital data systems to data consumers and identify improvements in the data pipeline
Recommend business process or system enhancements to improve data quality and reporting capabilities
Help implement reporting from Human Capital data systems (Workday, iCIMS, etc.)
Create new service opportunities to further our goal of supporting the firm's talent development and management
Perform analysis on employee related datasets to find actionable insights that support essential decision makers
Adhere and maintain the Human Capital data governance model through proper documentation of data processes and definitions


Your Qualifications:

2+ years of experience in a quantitative or consulting based role using analytics and visualizations to solve business problems
Experience working with data visualization tools (Tableau, Looker, PowerBI, etc.)
Experience with SQL for querying and modeling data
Experience creating reporting in common Human Capital Management Systems (Workday, iCIMS, etc.)
U.S. candidates must be fully vaccinated as defined by the medical community against COVID-19 and provide proof of such vaccination by date of hire


Why Fisher Investments:

At Fisher Investments, we work for a bigger purpose: bettering the investment universe. From unmatched service to unique perspectives on investing, it's the people that make the Fisher purpose possible. And we invest in them by offering exceptional benefits like:

100% paid medical, dental and vision premiums for you and your qualifying dependents
A 50% 401(k) match, up to the IRS maximum
20 days of PTO*, plus 9 paid holidays
8 weeks paid Primary Caregiver Parental Leave
Back-up Child Care Program available, offering up to 10 days annually
A cumulative learning and development framework customized for every employee
An award-winning work environment - we're Great Place to Work Certified, and Top Workplace winners from The Oregonian


We take great pride in our inclusive culture. We value the different perspectives and unique skills you bring to the team – it makes us all better. Success at Fisher Investments is motivated by results, a collaborative mindset and a commitment to accomplishing great things – so if you are ready to do that, we are ready for you! Apply today to be a part of a team environment where you make a difference in the lives of people by bettering the investment universe.

California employees accrue up to 17 days of PTO and 3 days of sick time per year.


FISHER INVESTMENTS IS AN EQUAL OPPORTUNITY EMPLOYER
Show more Show less"
2814297442,Data Engineer,Chewy,2021-11-30,United States,"Boston, MA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Our Opportunity

Chewy is looking for a highly motivated, independent, and dedicated Data Engineer to join our to join our exciting and fast-paced team in Fraud Detection & Prevention based in Boston, MA.

We’re looking for a strong engineer with a proven track record of building complex Data pipeline from ground up.

What You'll Do

Design and build Data Integration pipeline and platform, analytic solutions for Transactional system that enable Fraud Detection platform to analyze, prevent and add business value.

This data integration solutions would be expected to process large volume transactions in real time and in batch using opensource or cloud technologies.

Working with multiple data storage system, leverage data to design and implement pipeline for Trust & Safety.
Identify optimal solutions to efficiently scale the data flow agnostic of on-prem or cloud.
dentify critical KPIs to measure vendor performance and develop programs targeting improvement of those KPIs
Collaborate and work closely with both application engineer and data scientist on both functional and technical front.

What You'll Need

BS in Computer Science, Mathematics, Engineering, or Information Technology
3 – 5 years of experience working with data warehouses (Vertica and Hadoop preferred)
5 – 10 years of experience writing software in any of the following programming language (Java, Python, or Scala)
Experience in data warehouse design and data integration methodologies
Experience performing analytics to solve complex business problems
3 to 5 years of experience integrating data between operational databases, Datawarehouse using data integration tools.
Expert level knowledge of data integration and familiarity with common data integration challenges like converting data types, handling errors, and translating between different technology stacks
SQL expertise and the ability to work with many different database types including Postgres, SQL Server, Snowflakes and others as required
Able to work independently, own the requirements and deliverables, and produce an EDI solution end to end successfully
Able to work in a fast-paced environment and be comfortable being accountable for work products

Bonus

Experience designing analytic solutions in Vertica, Snowflake
Experience with the AWS ecosystem
Experience in reporting tool
Experience in ecommerce or large volume transactional systems
Experience with statistical methods and data science

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members.

If you have a disability under the Americans with Disabilities Act or similar law, or you require a religious accommodation, and you wish to discuss potential accommodations related to applying for employment at Chewy, please contact HR at chewy dot com

To access Chewy’s Privacy Policy, which contains information regarding information collected from job applicants and how we use it, please click here: https://www.chewy.com/app/content/privacy).
Show more Show less"
2801180987,Data Engineer,DivcoWest,2021-11-19,United States,San Francisco Bay Area,Information Technology and Engineering,Full-time,Leasing Non-residential Real Estate,"COMPANY BACKGROUND

Founded in 1993, DivcoWest is a dynamic and growing multi-disciplinary real estate investment firm headquartered in San Francisco, with offices in Los Angeles, Menlo Park, Boston, Washington DC and New York City. Known for our long-standing relationships and track record of success in markets where innovation thrives, DivcoWest combines a vibrant entrepreneurial spirit with an institutional approach and a forward-thinking state-of-the-art technology infrastructure.




JOB SUMMARY

DivcoWest is searching for a Data Engineer to join our growing team of analytics experts. Our technology team is focused on delivering solutions that streamlines real estate operations, enhances the value of the real estate portfolio, and improves the experience of space and people’s everyday lives. Our dynamic technology team builds innovative products, implements state of the art technologies, provides service to facilitate technology operations at our corporate and property sites, and invests in real estate focused technology companies. 




The Data Engineer will be responsible for supporting the technology team’s focus by expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder who enjoys optimizing data systems and building them from the ground up. The hire must be self-directed, driven and comfortable supporting the data needs of multiple teams, systems and products. This role may be located out of our San Francisco, Los Angeles or properties.




ESSENTIAL DUTIES & RESPONSIBILITIES

Create and maintain optimal data pipeline architecture
Identify, design and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability
Design, develop, and deploy a high-volume ETL pipelining system to manage complex real-time, data collection
Work with stakeholders including the Executive, Data and Infrastructure teams to assist with data-related technical issues and support their data infrastructure needs
Cross-train with the rest of the data team members, to support business functions during team members absence
Stay current with developments in new market trends and innovations in technology, especially those related to commercial real estate




SKILLS AND ABILITIES

Advanced working SQL knowledge and experience working with relational databases
A successful history of manipulating, processing and extracting value from large disconnected data sets
Excellent oral and written communication skills, including the ability to explain technology solutions in business terms and translate business requirements into technical specifications
Proven analytical and problem-solving abilities with keen attention to details
Knowledge of commercial real estate operations an asset




TECHNICAL SKILLS

Microsoft SQL Server 2012 or Higher
Data warehouse design, development and maintenance, optimization for reporting and analysis
SQL Server Integration Services (SSIS) - ETL design, development and maintenance
SQL Server Analysis Services (SSAS) – OLAP cube design, development and maintenance
SQL Server Reporting Services (SSRS) – web enabled report design, development and maintenance
Strong Microsoft Excel skills including Visual Basic for Applications competency
Proficient designing, implementing custom REST-ful APIs for usage in integrations with cloud/web-based 3rd party applications
Adept at consuming 3rd party web-based APIs and integration end points (REST-ful, SOAP, SFTP file transfer, etc.)
Proficiency with Microsoft C#, .Net Framework preferred.
Familiarity with MRI real estate enterprise resource planning (ERP) system a plus




QUALIFICATIONS

Bachelor’s degree in Information Technology, Software Engineering, Computer Science or related field or higher
At least 4-5 years of experience in IT, preferably within 1 or more commercial real estate organizations
Experienced with systems integrations, business intelligence systems, and database management




DivcoWest aims to create environments that inspire ingenuity, promote growth, and enhance the health, happiness, and well being of all people. A disciplined code of ethics is at the core of all that we do. DivcoWest values our partners and our people and believe that the collective energy of a diverse team is what drives our creative ideas and solutions. In recognition of the dedication and hard work of DivcoWest's employees, the Company offers a comprehensive benefits package as well as an employee assistance program.




DivcoWest is an Equal Opportunity Employer. We are committed to building a team that represents a variety of backgrounds, perspectives and skills. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state or local law.




Please review our company Priviacy Policy in regards to the use of any personal information you provide us at: https://divcowest.com/privacy-policy.php

Show more Show less"
2523004573,"Software Engineer, Data Infrastructure","Reddit, Inc.",2021-11-25,United States,"New York, NY",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Reddit is a network of more than 100,000 communities where people can dive into anything through experiences built around their interests, hobbies and passions. Reddit users submit, vote and comment on content, stories and discussions about the topics they care about the most. From pets to parenting, there’s a community for everybody on Reddit and with more than 50 million daily active people, it is home to the most open and authentic conversations on the internet. For more information, visit redditinc.com.

As a data engineer, you will build and maintain the data infrastructure tools used by the entire company to generate, ingest, and access petabytes of raw data. A focus on performance and optimization will enable you to write scalable / fault tolerant code while collaborating with a team of top engineers, all while learning about and contributing to one of the most powerful streaming event pipelines in the world.

Not only will your work directly impact hundreds of millions of users around the world, but your output will also shape the data culture across all of Reddit!

How You Will Contribute

Refine and maintain our data infrastructure technologies to support real-time analysis of hundreds of millions of users.
Consistently evolve data model & data schema based on business and engineering requirements.
Own the data pipeline that surfaces 40B+ daily events to all teams, and the tools we use to improve data quality.
Support warehousing and analytics customers that rely on our data pipeline for analysis, modeling, and reporting.


Qualifications

4+ years of experience writing clean, maintainable, and well-tested code.
Experience with Python and/or Scala.
Familiarity with large scale distributed real-time tools such as Kafka, Flink, or Spark.
Familiarity with ETL design (both implementation and maintenance).
Bonus points for experience with (or desire to learn) Kubernetes.
Excellent communication skills to collaborate with stakeholders in engineering, data science, and product.


Reddit is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, please contact us at ApplicationAssistance@Reddit.com.


Show more Show less"
2818417228,Data Engineer,"Fund That Flip, Inc.",2021-12-01,United States,New York City Metropolitan Area,Engineering and Information Technology,Full-time,Leasing Real Estate,"The Role: Data Engineer

As a Data Engineer, you would use our existing archetypes and design new ones to expand access to the data points afforded to Fund That Flip. You will also develop processes to ingest data from disparate sources in addition to internal applications. The role puts emphasis on ensuring the integrity of the collected data, helping improve our ETL processes, and maintaining these systems. We have a strong emphasis on test-driven development as well as autonomous quality control while learning and challenging yourself to develop our next generation of data segments.




Who are we?

Fund That Flip is an originator of market-leading loans for fix-and-flip, new construction, and rental properties. We also provide a platform for investors to earn passive income by investing in the real estate that we help finance.




Our data engineering team designs, builds and maintains the various systems that power our business intelligence and data science teams. We are working with “little data” today but are moving toward “Big Data” processing and analytics in the very near future.




The tech stack is heavily based in Ruby on Rails, with a focus on services-oriented APIs, cloud-based infrastructure (Heroku/AWS) tied together with a message bus (Kafka) as the backbone for the flow of information. Many of these services are in various stages of development as we begin our journey towards Big Data. Our team makes best efforts to follow the 12-factor app philosophy.




Who are you?

An ideal member of our data engineering team is a person that is always learning and striving to improve their craft. They would be comfortable working in, but maybe not an expert with any part of the platform — Ruby/Rails, Kafka/Kinesis, Heroku/AWS — and enjoy engaging with their colleagues within technology and the stakeholders that our data pipeline empowers. They may also bring some strong opinions and preferences to working with service-based architectures, database design, and/or cloud infrastructure.




Most importantly, they should be excited about working in a startup experiencing accelerating growth, looking to expand their capabilities and ownership of their work along with the team (i.e. Wear a few hats).




Responsibilities

Work with Business Intelligence SMEs to build new platform features and expand our data set.
Thoroughly document services, integrations, and APIs across the data pipeline.
Serve as an SME for support requests relating to the data infrastructure.
Address technical debt, squash bugs, and refactor to perfection (but not too perfect).
Strong adherence to 12-factor app design and TDD with an appreciation for +90% test coverage
Stay current on best practices and provide a voice to them within the Data and Engineering teams where relevant.




Qualifications:

Junior

2+ years of software engineering experience working with Ruby/Rails or similar language/framework
1+ Experience with relational databases (Postgres preferred)
Understanding of AGILE ceremonies and tools (Jira, Confluence)
Comfortable with Git and source control management
A healthy understanding of API development
The desire for continuous learning and improvement
Strong interpersonal and communication skills and a love for a collaborative environment
+ Gem design and development
+ Open-source contributions
+ Demonstrated knowledge of the CI/CD pipeline (CirlceCI, Github Actions, Jenkins, etc)
+ Familiarity with cloud infrastructure (Heroku, AWS, or Google Cloud)
+ SQL and/or ETL experience

Mid

4+ years of software engineering experience with emphasis on Rails conventions
2+ years experience with relational databases Postgres/SQL
Demonstrated knowledge of API development and microservice infrastructures
Git/Github is second nature to you
Demonstrated knowledge of the CI/CD pipeline (CircleCI, Github Actions, Jenkins, etc)
Familiarity with cloud infrastructure (Heroku, AWS, or Google Cloud)
The desire for continuous learning and improvement
Strong interpersonal and communication skills and a love for a collaborative environment
+ Experience with a message bus such as Apache Kafka or Amazon Kinesis
+ Understanding of asynchronous thread-safe programming and scalable systems
+ Docker
+ SQL expert or an ETL guru
+ ERD/Database design

Senior

6+ years of software engineering experience with emphasis on Rails conventions
4+ years experience with relational databases Postgres/SQL
2+ years working in API development and microservice infrastructures
You would be insulted if Git/Github was on this list
Ability to manage and maintain a CI/CD pipeline
Demonstrable ability to stand up a cloud infrastructure (Heroku, AWS, or Google Cloud)
Understanding of asynchronous thread-safe programming and scalable systems
The desire for continuous learning and improvement
Strong interpersonal and communication skills and a love for a collaborative environment
+ Experience with a message bus such as Apache Kafka or Amazon Kinesis
+ Understanding of asynchronous thread-safe programming and scalable systems
+ Docker
+ SQL expert or an ETL guru
+ ERD/Database design
Show more Show less"
2825649384,Data Engineer,Veeva Systems,2021-12-03,United States,"New York, NY",Engineering,Full-time,"IT Services and IT Consulting, Computer Software, and Pharmaceutical Manufacturing","Veeva [NYSE: VEEV] is the leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, our customers range from the world’s largest pharmaceutical companies to emerging biotechs. Veeva’s software helps our customers bring medicines and therapies to patients faster.

We are the first public company to become a Public Benefit Corporation . As a PBC, we are committed to making the industries we serve more productive, and we are committed to creating high-quality employment opportunities.

Veeva is a Work Anywhere company which means that you can choose to work in the environment that works best for you - on any given day. Whether you choose to work remotely from home or in our New York City office - it’s up to you.

As a Data Engineer on the New York Analytics engineering team, you will be a core contributor in building out next-generation systems and processes that allow us to ingest advertising data and prepare it for health analytics at an ever-increasing scale.

You will be responsible for the design and implementation of major subsystems, and work in collaboration with your peers and the wider engineering organization.

What You'll Do

Handle and provide feedback on ad-hoc data loads for experimental/pre-contract advertising feeds before implementing in our proprietary ingest platform.
Assist other Data Engineers with complex, large, and time-sensitive data tasks across a modern and evolving technology stack.
Work with Software Engineers to migrate custom and one-off implementations into code, collaborating on feature and functionality required with product managers.
Keep up to date on emerging technology solutions that impact the data and cloud computing domains, in particular on AWS.
Provide technical guidance and support to members of other teams across the company in your areas of expertise.
Actively work to develop technical and soft skills through training, event attendance, accreditation, and industry knowledge.

Requirements

2+ years of hands-on, directly relevant, Data Engineering experience.
Technically proficient in: Python, Relational Databases / SQL, Redshift or another MPP Data Warehouse, Linux
Experience designing and implementing systems using modern frameworks for ELT/ETL such as Apache Airflow.
Experience using AWS Database and Big Data tools – primarily we are interested in Redshift, RDS (MySQL & Postgres), and EMR.
College degree in Computer Science, Math, Systems Engineering or a similar technical field.
Learn More

Engineer Perspective: 3 Reasons to Consider Veeva
Engineering at Veeva

Nice to Have

Proficiency some of the following technologies: Additional Languages: Java, Scala, Containerization: Docker, Kubernetes, NoSQL: MongoDB, ElasticSearch, AWS: S3, RDS, Lambda, EC2, EKS, VPC, SQL, SNS, ELB, CloudFront, Implementation of a Data Lake / Lakehouse design paradigm
AWS Associate Architect or Developer certification. Professional or Specialty is a big advantage.
Perks & Benefits

Office conveniently located in midtown Manhattan and close to several major transportation hubs.
Fully stocked kitchen with snacks and beverages.
Fitness/wellness reimbursement.
Allocation for continuous learning and development.
Private roof deck and flexible working space.
Weekly happy hours and other social activities.

Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world. Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances. If you need assistance or accommodation due to a disability or special need when applying for a role or in our recruitment process, please contact us at talent_accommodations@veeva.com.
Show more Show less"
2728963193,Data Engineer,Delta Air Lines,2021-11-25,United States,"Atlanta, GA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Airlines and Aviation","The Data Engineer will play a key role on the Enterprise Data Services team, responsible for transforming data from disparate systems to provide insights and analytics for business stakeholders. You’ll leverage cloud-based infrastructure to implement technology solutions that are scalable, resilient, and efficient. You will collaborate with Data Engineers, Data Analysts, DBAs, cross-functional teams, and business leaders. You will architect, design, implement and operate data engineering solutions, using Agile methodology, that empower users to make informed business decisions.

You are self-motivated, work independently, and have direct experience with all aspects of the software development lifecycle, from design to deployment. You have a deep understanding of the full life data lifecycle and the role that high-quality data plays across applications, machine learning, business analytics, and reporting. Strong candidates will exhibit solid critical thinking skills, the ability to synthesize complex problems, and a talent for transforming data to create solutions that add value to a myriad of business requirements.

You have the demonstrated ability to lead and take ownership of assigned technical projects in a fast-paced environment. Excellent written and speaking communication skills are required as we work in a collaborative cross-functional environment and interact with the full spectrum of business divisions. You demonstrate insatiate curiosity and outstanding interpersonal “soft” skills. Ideal candidates have more than just knowledge or skill set, as they also have a “can do” mindset to find solutions.

This role may be located in Atlanta, GA or Minneapolis, MN
At least 3+ years of post-degree professional experience
Desired development experience building and maintaining ETL pipelines
Desired experience working with database technologies and data development such as Python, PLSQL, etc.
Solid understanding of writing test cases to ensure data quality, reliability and high level of confidence
Track record of advancing new technologies to improve data quality and reliability
Continuously improve quality, efficiency, and scalability of data pipelines
Knowledge of working with queries/applications, including performance tuning, utilizing indexes, and materialized views to improve query performance
Identify necessary business rules for extracting data along with functional or technical risks related to data sources (e.g. data latency, frequency, etc.)
Develop initial queries for profiling data, validating analysis, testing assumptions, driving data quality assessment specifications, and define a path to deployment
Familiar with best practices for data ingestion and data design
Embraces diverse people, thinking and styles.
Consistently makes safety and security, of self and others, the priority.
Where permitted by applicable law, must have received or be willing to receive the COVID-19 vaccine by date of hire to be considered for U.S.-based job, if not currently employed by Delta Air Lines, Inc.
Bachelor of Science degree in Computer Science or equivalent
Desired Airline industry experience
Show more Show less"
2798017651,Data Engineer,Amazon,2021-11-18,United States,"Santa Monica, CA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

WW Consumer Fin Tech (WWCFT) team is looking for an outstanding Data Engineer who is data-driven, uncompromisingly detail oriented, smart, efficient, and driven to help our business succeed. You have passion for technology. You are keen to leverage existing skills while trying new approaches. You are not tool-centric; you determine what technology works best for the problem at hand and apply it accordingly. You can explain complex concepts to your non-technical customers in simple terms.

As a Data Engineer, you will be working in one of the world's largest and most complex data warehouse environments. You will design, implement and support scalable data infrastructure solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests. You will be exposed to cutting edge AWS big data technologies. You should have excellent business and communication skills to be able to work with business owners and Tech leaders to gather infrastructure requirements, design data infrastructure, build up data pipelines and data-sets to meet business needs. You stay abreast of emerging technologies, investigating and implementing where appropriate.

Your major responsibilities will include

Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies.
Explore and learn the latest AWS technologies to provide new capabilities and increase efficiencies.
Designing and implementing complex pipelines and other BI solutions.
Work closely with business owners, developers, Business Intelligence Engineer to explore new data sources and deliver the data.


Basic Qualifications

Bachelor's degree in Engineering, Mathematics, or a related technical discipline
3+ years of industry experience in Data Engineering, BI Engineer, or related field with a track record of and extracting value from bigdata
Hands-on experience and advanced knowledge of Python etc.
Strong experience in distributed data Data and Data Warehousing

Preferred Qualifications

Masters in mathematics, statistics, economics, or other quantitative fields.
5+ years of experience as a Data Engineer, BI Engineer or related field in a company with large, complex data sources.
Experience working with AWS big data technologies ( )
Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.
Familiarity with solving data quality issues and auto detection algorithms

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon.com Services LLC

Job ID: A1607500
Show more Show less"
2798507902,Data Engineer - FinTech,Amazon,2021-11-18,United States,"Seattle, WA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Are you passionate about data? Does the prospect of dealing with massive volumes of data excite you? Do you want to build data engineering solutions that process billions of records a day in a scalable fashion using Amazon Web Services technologies? Do you want to create the next-generation tools for intuitive data access?

Amazon's Finance Technology team is seeking truly innovative Data Engineer to join the team that is shaping the future of the finance data platform. The team is committed to building the next generation big data platform that will be one of the world's largest finance data warehouse to support Amazon's rapidly growing and dynamic businesses, and use it to deliver the BI applications which will have an immediate influence on day-to-day decision making. Amazon has culture of data-driven decision-making, and demands data that is timely, accurate, and actionable. Our platform serves Amazon's finance, tax and accounting functions across the globe.

As a Data Engineer, you should be an expert with data warehousing technical components (e.g. Data Modeling, ETL and Reporting), infrastructure (e.g. hardware and software) and their integration. You should have deep understanding of the architecture for enterprise level data warehouse solutions using multiple platforms (RDBMS, Columnar, Cloud). You should be an expert in the design, creation, management, and business use of large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. The individual is expected to be able to build efficient, flexible, extensible, and scalable ETL and reporting solutions. You should be enthusiastic about learning new technologies and be able to implement solutions using them to provide new functionality to the users or to scale the existing platform. Excellent written and verbal communication skills are required as the person will work very closely with diverse teams. Having strong analytical skills is a plus. Above all, you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.

Our ideal candidate thrives in a fast-paced environment, relishes working with large transactional volumes and big data, enjoys the challenge of highly complex business contexts (that are typically being defined in real-time), and, above all, is a passionate about data and analytics. In this role you will be part of a team of engineers to create world's largest financial data warehouses and BI tools for Amazon's expanding global footprint.

Responsibilities

Design, implement, and support a platform providing secured access to large datasets.
Interface with tax, finance and accounting customers, gathering requirements and delivering complete BI solutions.
Model data and metadata to support ad-hoc and pre-built reporting.
Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.
Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.
Tune application and query performance using profiling tools and SQL.
Analyze and solve problems at their root, stepping back to understand the broader context.
Learn and understand a broad range of Amazon’s data resources and know when, how, and which to use and which not to use.
Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using AWS.
Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.
Triage many possible courses of action in a high-ambiguity environment, making use of both quantitative analysis and business judgment.


Basic Qualifications

3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL
Bachelor’s degree in CS or related technical field
3+ years experience in dimensional data modeling, ETL development, and Data Warehousing
Experience with Redshift and/or other distributed computing systems.
Excellent knowledge of SQL and Linux OS
SQL performance tuning
Server management and administration including basic scripting
Basic DBA tasks
Solid experience in at least one business intelligence reporting tools

Preferred Qualifications

Bacheakor's degree in Information Systems or a related field.
Knowledge of Big Data Solutions. Experience with Hadoop, Hive or Pig.
Experience with Redshift and other AWS services.
Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams.
Knowledge of a programming or scripting language (R, Python, Ruby, or JavaScript).
Experience with Java and Map Reduce frameworks such as Hive/Hadoop.
Strong organizational and multitasking skills with ability to balance competing priorities.
An ability to work in a fast-paced environment where continuous innovation is occurring and ambiguity is the norm.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon.com Services LLC

Job ID: A1456310
Show more Show less"
2782153112,Big Data Engineer,Amazon Web Services (AWS),2021-11-27,United States,"Seattle, WA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

DESCRIPTION

The AWS World Wide Revenue Operations (WWRO) Revenue technology team is responsible for publishing Daily Estimated Revenue (DER) and

monthly Amortized Sales Revenue (ASR). DER and ASR are used by downstream customers in AWS Finance, Accounting, Sales

Operations, Segmentation & Planning (S&P), Data & Analytics and Compensation to set quotas, manage sales goals, forecast,

and derive business insights. We collect and process billions of usage and billing transactions every single day and relate it to the largest data feed supported by Salesforce.com. We transform this raw data into actionable information in the Data Lake and make it available to our internal service owners to analyze their business and service our external customers.

We are truly leading the way to disrupt the big data industry. We are accomplishing this vision by bringing to bear Big Data technologies like Elastic Map Reduce (EMR) in addition to data warehouse technologies like Spectrum to build a data platform capable of scaling with the ever-increasing volume of data produced by AWS services.

You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build ETL to ingest the data into the data lake. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake. Above all, you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.

Location: This role open to these locations: Seattle & Dallas. Relocation offered from within the US to any of these locations.


Basic Qualifications

This position requires a Bachelor's Degree in Computer Science or a related technical field, and 3+ years of related employment experience.
3+ years of work experience with ETL, Data Modeling, and Data Architecture.
Expert-level skills in writing and optimizing SQL.
Experience with Big Data technologies such as Hive/Spark.
Proficiency in one of the scripting languages - python, ruby, linux or similar.
Experience operating very large data warehouses or data lakes.

Preferred Qualifications

Master's Degree in Computer Science or related field.
Proficiency in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
Experience with building data pipelines and applications to stream and process datasets at low latencies.
Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
Knowledge of Engineering and Operational Excellence using standard methodologies.
Meets/exceeds Amazon’s leadership principles requirements for this role.
Meets/exceeds Amazon’s functional/technical depth and complexity for this role.
Experience with AWS services including S3, Redshift, EMR and RDS.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon Web Services, Inc.

Job ID: A1803527
Show more Show less"
2811790135,Data Engineer - Python AWS,Data Concepts,2021-11-15,United States,"Richmond, VA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Data Concepts is seeking Data Engineers with strong Python and AWS experience.

Technologies
Python
Scripting experience is a must
Development
AWS
Lambda
ECS - including Docker
Exposure to DevOps tools: Automation: Ansible, Terraform, Jenkins, CICD
Node.JS is preferred
PySpark is preferred

Data Concepts specializes in executing project solutions with expertise in Java, Microsoft, Open Source, Analytics, Cloud and Mobile technologies, AWS, and Azure. Our consulting engagements comprise firm-fixed price projects, time & material engagements, and a managed service IT staffing model.

Expertise: Java, Microsoft, Mobile, Open Source, Microservices, and Big Data

Services: Strategy, Development, UI/UX Design, Modernization, Cloud, PMO, Network Engineering, Security Engineering, and Enterprise System Administration.
Show more Show less"
2786039695,Data Engineer,Genetesis,2021-11-04,United States,"Cincinnati, OH ",,Full-time,,"Job Title: Data Engineer (Software - R&D)




Summary: Challenging and rewarding software development role to support cutting edge research at Genetesis. This is a cross functional role by nature, where you will be required to operate between multiple engineering disciplines and adapt your/their set of expertise into engineering studies, reports, and recommendations. Furthermore, this role will necessitate the translation of research ideas into code for production use. Will provide technical support to one or more projects relating to Genetesis devices at an innovative, young, and growing company. Will work in a passionate, fast paced, and rewarding company with expectations to deliver quality work in a timely manner.




Duties and Responsibilities include the following. Other duties may be assigned. 

 

Develop data pipeline code from proof of concept through production and triage and resolve data pipeline bugs
Continually learning by reading the latest research papers to develop novel solutions to technical problems
Parse, filter, process, and organize large sets of clinical data in various formats (csv, json, binary files, etc.)
Communicate verbally and in writing progress and technical decisions to stakeholders
Mainly contributing to the further development/understanding of the CardioFlux Magnetocardiograph by writing and performing engineering studies and data analysis
Responsible for the translation of results from engineering studies/reports into technical requirements, proof of concepts, or production (equivalent) code
Designing and fleshing out technical specifications for studies you are responsible for, based off internal stakeholder needs
Writing clean, understandable and efficient code following company coding standards. Keeping your peer’s accountable via code reviews.
Use your technical expertise and knowledge of software development to drive or generate technical deliverables, engineering documentation, product requirements and test method development
Generate supporting documentation, reports, and implement testing during projects to support internal and external regulatory and quality demands
Work cross functionally with regulatory, quality, engineering, and clinical/product personnel to achieve company goals and initiatives, as needed
Work adaptively in a fast-paced small team environment with aggressive deadlines
Travel to offsite locations as required for prototyping, site deployments, and technical support




Experience and Skills:

2-5 years professional experience in software development
Bachelor’s Degree in Computer Science, Biomedical Engineering, or a related field
Fluent understanding of scripting programming languages: Python 3, Matlab, R, etc.
Fluent understanding of data analysis packages: Numpy, Pandas, etc. (or Matlab equivalents)
Fluent understanding of visualization packages: Matplotlib, seaborn, etc.
Basic knowledge of Jupyter Notebooks, ipynb
Basic understanding of cloud technologies: AWS, Azure, GCP, etc.
Proficient knowledge of operating systems: Linux/UNIX, Windows
Basic knowledge of statistical, mathematical, and analytical methods
Knowledge and familiarity of design and development processes for software engineering.
Strong organization, time management, communication, and strategic thinking skills
Show more Show less"
2786039695,Data Engineer,Genetesis,2021-11-04,United States,"Cincinnati, OH ",,Full-time,,"Job Title: Data Engineer (Software - R&D)




Summary: Challenging and rewarding software development role to support cutting edge research at Genetesis. This is a cross functional role by nature, where you will be required to operate between multiple engineering disciplines and adapt your/their set of expertise into engineering studies, reports, and recommendations. Furthermore, this role will necessitate the translation of research ideas into code for production use. Will provide technical support to one or more projects relating to Genetesis devices at an innovative, young, and growing company. Will work in a passionate, fast paced, and rewarding company with expectations to deliver quality work in a timely manner.




Duties and Responsibilities include the following. Other duties may be assigned. 

 

Develop data pipeline code from proof of concept through production and triage and resolve data pipeline bugs
Continually learning by reading the latest research papers to develop novel solutions to technical problems
Parse, filter, process, and organize large sets of clinical data in various formats (csv, json, binary files, etc.)
Communicate verbally and in writing progress and technical decisions to stakeholders
Mainly contributing to the further development/understanding of the CardioFlux Magnetocardiograph by writing and performing engineering studies and data analysis
Responsible for the translation of results from engineering studies/reports into technical requirements, proof of concepts, or production (equivalent) code
Designing and fleshing out technical specifications for studies you are responsible for, based off internal stakeholder needs
Writing clean, understandable and efficient code following company coding standards. Keeping your peer’s accountable via code reviews.
Use your technical expertise and knowledge of software development to drive or generate technical deliverables, engineering documentation, product requirements and test method development
Generate supporting documentation, reports, and implement testing during projects to support internal and external regulatory and quality demands
Work cross functionally with regulatory, quality, engineering, and clinical/product personnel to achieve company goals and initiatives, as needed
Work adaptively in a fast-paced small team environment with aggressive deadlines
Travel to offsite locations as required for prototyping, site deployments, and technical support




Experience and Skills:

2-5 years professional experience in software development
Bachelor’s Degree in Computer Science, Biomedical Engineering, or a related field
Fluent understanding of scripting programming languages: Python 3, Matlab, R, etc.
Fluent understanding of data analysis packages: Numpy, Pandas, etc. (or Matlab equivalents)
Fluent understanding of visualization packages: Matplotlib, seaborn, etc.
Basic knowledge of Jupyter Notebooks, ipynb
Basic understanding of cloud technologies: AWS, Azure, GCP, etc.
Proficient knowledge of operating systems: Linux/UNIX, Windows
Basic knowledge of statistical, mathematical, and analytical methods
Knowledge and familiarity of design and development processes for software engineering.
Strong organization, time management, communication, and strategic thinking skills
Show more Show less"
2750221678,Data Engineer,Minted,2021-11-20,United States,"San Francisco, CA",Information Technology,Full-time,"Marketing and Advertising, Internet Publishing, and Retail","Our Analytics team collectively possesses an incredibly diverse set of skills. The tools you come in with will enhance and expand our capabilities, and you will learn from the team to round out the things you are less familiar with on day one.

In addition to managing the data warehouse that serves as the backbone of the company's analytics, we build and maintain standalone applications that are used by everyone at the company. This means that you will have the opportunity to build full stack applications, untethered by the many of the development constraints of customer-facing systems. You will have rapid impact. Frequently.

Our stakeholders are manifold, and you will work with leaders from across the business to help them both define and gain visibility into their most important metrics. We need someone who is versatile, independent, and committed to transparency and productive collaboration. If you've ever lamented a software position that keeps you far from the business, then this is the right role for you!

Please note: our offices are currently closed, but we are looking for candidates interested in working from our San Francisco, CA office once it is safe to re-open.

You Will

Design and develop data models that power analytics for the entire company
Own high impact and high visibility engineering projects end to end
Build and extend internal tools that make the entire company more productive
Work with product engineers to design and implement streaming data pipelines for real time analytics

You Are

Fascinated by every part of the stack, and love learning new technologies and finding the right tool for the job
Obsessed with writing clean reusable code
Someone with the ability to juggle competing priorities in a fast-moving dynamic environment

You Have

3+ years professional experience as a data engineer or software engineer with an interest in moving into analytics and data infrastructure
Strong programming skills preferably in Python and Javascript
Familiarity with, or enthusiasm for learning and managing a data warehouse
Experience with SQL and database modeling
Technical design skills with an emphasis on distributed and/or cloud-based design and scaling
Experience working on and an understanding of both client-side and server-side code
Excellent written and verbal communication skills

Bonus Points For

Experience with Airflow, Luigi, or other open source ETL frameworks
Experience with Snowflake, Redshift or other cloud data warehousing systems
Experience with Amazon Web ServicesExperience with Docker, Ansible
Experience with Apache Flink, Apache Beam, or other streaming technologies
Experience with Looker, Tableau, or other BI tools
Experience working in a fast-paced, agile e-commerce environment
Experience with React, Next.js, Redux, or GraphQL

About Minted

Minted is a design platform bringing the best in independent design to consumers everywhere. The company's art, stationery, and textiles products have reached over 75 million homes worldwide.

Minted uses technology to bring unique, best-selling design to market at scale. Using its crowdsourcing technology, consumers are empowered to vote for the designs they love and want to see sold, ensuring that Minted always sells continuously fresh and trend-forward product. The winning designs are manufactured by Minted, enabling artists from around the world to share and sell their work while letting Minted do the rest. Since launch in 2007, the company has expanded to serve consumers in new categories including wall art, textiles, digital content and home decor, as well as serve major retailers and consumer products brands with data-backed design through licensing and wholesale partnerships.

Minted is headquartered in San Francisco, CA and currently employs 350+ full-time employees plus additional temporary workers during the holiday season. The company has raised over $300M from top-tier investors including Benchmark Capital, T. Rowe Price, Permira, Ridge Ventures, Technology Crossover Ventures, and Norwest Venture Partners. Angel investors include Marissa Mayer, Jeremy Stoppelman, Julia & Kevin Hartz, Yishan Wong, and more.

Minted is an Equal Opportunity Employer committed to inclusion and diversity. We welcome people of different backgrounds, experiences, abilities and perspectives and will consider all qualified applicants for employment in accordance with all state, local, and federal laws. Minted participates in the E-verify program. Minted's Job Applicant Privacy Policy .


Show more Show less"
2814238645,Big Data Engineer - FreeWheel (virtual or in office),FreeWheel,2021-11-05,United States,"Austin, TX",Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Internet Publishing, and Telecommunications","Comcast brings together the best in media and technology. We drive innovation to create the worlds best entertainment and online experiences. As a Fortune 50 leader, we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines. We are at the forefront of change and move at an amazing pace, thanks to our remarkable people, who bring cutting-edge products and services to life for millions of customers every day. If you share in our passion for teamwork, our vision to revolutionize industries and our goal to lead the future in media and technology, we want you to fast-forward your career at Comcast.

Job Summary

FreeWheel, a Comcast company, is looking for a Big Data Engineer to be responsible for the following: Planning and designing new software and web applications. Analyzes, tests and assists with the integration of new applications. Documents all development activity. Assists with training non-technical personnel. Has in-depth experience, knowledge and skills in own discipline. Usually determines own work priorities. Acts as a resource for colleagues with less experience.

Job Description

Core Responsibilities

At least 2-5 years of experience with designing, implementing, and maintaining data pipelines, building scalable and optimized enterprise data systems
Scale ETL pipelines and infrastructure to the next level
Production level experience with an ETL scheduling tool, data warehousing in AWS
Manage data ingestion using various methods to transform raw data into useful data systems
Grounded knowledge of SQL, Python, AWS and with a deeper understanding of at least one commonly used DB (Postgres, Athena)
Strong data analysis skills (writing complex queries, store procedures)
Develop tools supporting self-service data pipeline management (ETL)
Evolve data model and data schema based on business and engineering needs
Collaborate with project stakeholders to identify product and technical requirements. Conduct analysis to determine integration needs.
Other duties and responsibilities as assigned.

Company Description

FreeWheel, A Comcast Company, empowers all segments of The New TV Ecosystem. We are structured to provide the full breadth of solutions the advertising industry needs to achieve their goals. We provide the technology, data enablement and convergent marketplaces required to ensure buyers and sellers can transact across all screens, across all data types, and all sales channels, in order to ensure the ultimate goal – results for marketers. With offices in New York, San Francisco, Chicago, London, Paris, Beijing, and across the globe, FreeWheel, A Comcast Company, stands to advocate for the entire industry through the FreeWheel Council for Premium Video. For more information, please visit freewheel.com.

Employees at all levels are expected to

Understand our Operating Principles; make them the guidelines for how you do your job.
Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services.
Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences.
Win as a team - make big things happen by working together and being open to new ideas.
Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers.
Drive results and growth.
Respect and promote inclusion & diversity.
Do what's right for each other, our customers, investors and our communities.

Disclaimer

This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.

Comcast is an EOE/Veterans/Disabled/LGBT employer.

#freewheelproductjob #freewheelengineeringjob

Education

Bachelor's Degree

Relevant Work Experience

2-5 Years

Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details.
Show more Show less"
2797265101,Data Engineer,Amazon,2021-11-18,United States,"Bellevue, WA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Do you have a passion for wrangling large data sets, developing scalable solutions, and building high quality data services that impact business outcomes? Do you enjoy solving complex problems that enable end users to generate insights and make high impact business decisions? Do you like learning and developing innovative solutions, which deliver results? If the answer to these questions is affirmative, then this role in Strategic Sourcing may be the right next career step for you.

Strategic Sourcing is part of Supply Chain Optimization Technology (SCOT) - a centralized organization that owns automated systems for demand forecasting, inventory management, sourcing, inbound optimization, Fast Track promise and order fulfillment. Learn more here: https://www.youtube.com/watch?v=ncwsr1Of6Cw&feature=youtu.be

The Strategic Sourcing team works with vendor inputs/constraints, supply chain signals and other SCOT systems to execute a sourcing strategy, ultimately translating an optimal plan into real world execution by systematically connecting with suppliers. Sourcing owns and develops systems to systematically negotiate cost with vendors, determine the right inbound channel, optimize how we purchase inventory from our suppliers, and automate procurement by integrating with Vendor systems. Sourcing team aims to maximize supply availability and optimize for total sourcing cost that impacts both topline and bottom line of Amazon.

To be successful in this role, you should have broad skills in database design, be comfortable dealing with complex, medium to large data sets, and understand how self-service dashboards are built and used with your data sets. The successful candidate will have a passion for data and analytics, be a self-starter comfortable with ambiguity, have strong attention to detail, an ability to work in a fast-paced and entrepreneurial environment, and driven by a desire to innovate.

Key responsibilities

Synthesize business requirements into data platform architecture for use by business intelligence engineers, data scientists, and product managers.
Maintain and enhance existing data pipelines. Establish new scalable, efficient and automated processes for ingesting data.
Work with BIEs, product managers and data scientists to understand data needed for key business areas. Build data store and data pipelines to deliver the needed data.
Develop the end-to-end automation of data pipelines, making datasets readily-consumable by visualization tools, machine learning platforms, and daily/weekly/monthly reporting processes.
Define processes for optimized data retention, archival, and retrieval.
Enhance processes to help maintain data integrity, availability, and auditability.


Basic Qualifications

2+ years of experience analyzing and interpreting data and experience with Redshift, Oracle, NoSQL etc.
Experience with data modeling, data warehousing, and building ETL pipelines
Bachelor's degree in a quantitative/technical discipline such as Computer Science, Engineering, Statistics
1+ years of experience as a Data Engineer or in a similar role
Knowledge of distributed systems as it pertains to data storage and computing


Preferred Qualifications

PREFERRED QUALIFICATIONS

MBA or Master’s degree in Computer Science, Engineering, Statistics, Mathematics or related field.
Experience providing technical leadership and mentoring to other engineers for best practices on data engineering.
Knowledge of software engineering best practices across the development lifecycle.


Company - Amazon.com Services LLC

Job ID: A1670834
Show more Show less"
2769729511,Data Engineer,IntelliPro,2021-10-28,United States,"Los Angeles, CA",Information Technology,Full-time,Staffing and Recruiting,"Summary

We're a banking app on a mission to create financial opportunities that advance America’s collective potential. Our tools, include its debit card and spending account, help it's more than eight million customers bank, budget, avoid overdraft fees, find work and build credit. Being a disruptor to traditional banking experience, we are backed by Mark Cuban, Norwest Venture Partners, Section 32, and Financial Venture Studios, among many others. Join our team and be at the forefront of innovation and creativity!

We're looking for an experienced and passionate senior data engineer in our Data organization. This role will partner directly with product managers, engineers, marketing and other business partners across the business to design, develop and continuously improve the data infrastructure, pipeline and applications to collect, track and monitor various formats of data to enable data-driven decision and growth.

Key Responsibilities

Design, develop and deliver/implement data solutions to include: architecture design, prototyping of concepts to proof of concept, development of standards, design, and development of test plans, code and module design, development and testing, data solution debugging, and design and implementation
Optimize existing data pipelines and create new ones to manage data sets while learning the platforms from which we extract data; Develop and maintain third-party API processes for data pipelines
Design, implement and manage data warehouse solutions
Support and maintain data and database systems to meet business delivery specifications and needs. Document structure and processes
Enable analytics and data science to create data-driven insights and launch new models to scale the impact
Work with various business and engineering teams to ensure reliable, scalable, robust architecture for our data platform

Experience Required

BS in Computer Science, related technical field or equivalent practical experience. MS or PhD in databases, distributed systems is a plus.
5+ years of engineering experience with a focus on data.
Proficient with programming in one or more general purpose languages, including but not limited to Java, Scala, Python or JavaScript. Proficient with SQL programming. No-SQL is a plus.
Experience with Data Warehousing solutions such as MySQL, Snowflake, BigQuery, Redshift, or similar managed solutions. Proficiency with ETL tools.
Expert data modeling skills with experience tuning and optimizing for performance
Experience designing and operating data services & data pipelines. Experience with ML Ops is a plus.
Familiarity with GCP’s data tooling (e.g. Dataflow, CloudComposer, BigQuery, PubSub) or similar cloud tooling
Driven by delivering customer value and impact.
Excellent communication and analytical skills.
Show more Show less"
2795515539,Data Engineer 1,Travelers,2021-10-18,United States,"Hartford, CT",Information Technology,Full-time,"Law Practice, Legal Services, and Insurance","Company Summary

Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Target Openings

1

Job Description Summary

Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.

This position may be based 100% remotely or in one of our offices.

Primary Job Duties & Responsibilities

Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.

Minimum Qualifications

Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.

Education, Work Experience, & Knowledge

Good Python skills needed.
Experience working in an Agile environment.
Knowledge of AWS.
Six years of related experience
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.

Job Specific Technical Skills & Competencies

The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.

Employment Practices

Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.

To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
Show more Show less"
2821224834,Cloud Data Engineer - Remote,The Hartford,2021-11-06,United States,"Houston, TX",Information Technology,Full-time,"IT Services and IT Consulting, Insurance, and Financial Services","You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.

The Hartford is seeking a Cloud Data Engineer to be part of Cloud Engineer Transformation & Operations team

The Hartford is seeking a highly motivated and experienced hands-on data engineer to lead the efforts to transform and migrate our on premise platforms to AWS as well as lead new development efforts leveraging AWS services. The right candidate should be passionate for engineering- anything from simple solutions to complex problems to improve the developer experience for consuming cloud services. This position will be integral in activities related to the design, implementation, orchestration, automation, and maintenance of our cloud adoption journey. The ideal candidate should have a passion for automation and coding; be self-motivated, and able to work across teams; has the drive and ability to learn and adapt new and future technologies and be willing to experiment.

Responsibilities Include

Design and develop cloud based solutions in AWS that are scalable, highly available, fault tolerant and easily maintainable.
Build and support a robust continuous deployment framework for cloud solutions.
Effectively partner with subject matter experts and key stakeholders to drive the cloud enablement.
Collaborate with fellow developers to design, develop, implement and support complex business solutions.
Work with various service teams in EDO to design and build an end-end-end DevOps pipeline using a flavor of technologies, covering AWS & SaaS platforms and services
Know how applications should be engineered by following fault tolerant best practices, separation of duties, observability, and being operator friendly.
Striving for greatness and challenging the status-quo.

Qualifications

Familiarity with working in a hybrid cloud environment, focused on Data Ingestion, Analytics, AI technologies (preferable on AWS)
3+ years of software development experience and best practices
2+ years of Designing, developing and operating production workloads in AWS cloud infrastructure, with hands-on expertise in CICD / Container / Serverless / Streaming / Identity and Access Management services.
Hands-on experience writing infrastructure as code leveraging CloudFormation or Terraform and maintaining the continuous integration and deployment pipelines.
Working with agile development teams, methodologies and toolsets
Strong written and verbal communication skills

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$71,040 - $135,720

Benefits

Our company’s success is due to our employees’ dedication and passion for their work. They are our greatest asset. That’s why we are committed to offering employees and their families a comprehensive benefits package and award-winning well-being programs. By helping our employees achieve their full potential, we unlock our own. Visit https://www.thehartford.com/careers/benefits for details.

Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

Data Engineer - GE08AE
Show more Show less"
2812141048,Data Engineer,CGI,2021-11-03,United States,"Houston, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Management Consulting","Job Description

Job Description Data Engineer

Position Description

The Data Engineer manages one or more data engineering projects of moderate complexity. Leads or acts as key team member in defining and builds the data pipelines that will enable faster, better, data-informed decision-making within the business. Jointly designs and implements a new big data solution which supports high amounts and velocity of data and supports future growth. Identifies latest development, testing and deployment techniques to quickly deploy new releases to e.g. deploy new data pipelines and add data sources. Takes direct reports, when applicable, through Agile Framework and its respective tools. Influences stakeholders in adopting analyses / outcomes. Acts proactively to support the business to further professionalize their MI / Analytic reporting platform, using the ESSA approach. Opinions valued by business interface. Plays a prominent role in project related meetings etc. Utilises business partnering in order to gather, analyse and model data and key performance indicators of the highest complexity. Working as Data Engineering Lead to develop and deploy innovative big data platforms for advanced analytics and data processing. Works independently under broad managerial supervision.

This role is based in Houston, Texas.

Future Responsibilities:

Develop and deploy production-grade services, and data infrastructure emphasizing performance, scalability, and self-service.
Assume a leadership role in developing solutions with experience in continuous delivery, immutable deployments, containerization, and micro-service architectural patterns.
Are ""biased to action"" and not easily blocked by problems and difficulties, instead taking ownership.
Believe in monitoring, QA, and security as a first-class citizen in any data product.
Excited to build data platforms and tools that abstract implementation details for developers, analysts, and data scientists, enabling data transit.
Dedicated to automation, documentation, and collaboration at all stages of the engineering workflow.
Passionate about mentoring colleagues and educating the organization on data engineering best practices.
Maintain a firm understanding of the business long term goals and strategy to inform system implementation.


Required Qualifications:

Experience in productionizing various big data technologies using open source and cloud native platforms with working experience in AWS (required).
Hands of experience in messaging technologies i.e. Kafka, Orchestration tools i.e. Airflow, Apache Spark or Pyspark, Data visualization tools i.e. Dromio.
Expertise in at least two of the following languages – Python, Go, NodeJS


Soft Skills & Experience

Proven track record of building strong stakeholder relationships at different organisational levels
Able to produce high quality business-facing deliverables and activities to drive
Resilient and able to manage challenge and resistance
Results/outcomes oriented, business value focused
Confident and able to work in high-ambiguity work environment
Excellent oral and written presentation skills.


Your future duties and responsibilities

Required Qualifications To Be Successful In This Role

Build your career with us.

It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change—supporting our clients’ digital journeys and offering our professionals exciting career opportunities.

At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.

Be part of building one of the largest independent technology and business services firms in the world.

Learn more about CGI at www.cgi.com .

No unsolicited agency referrals please.

CGI is an equal opportunity employer.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com . You will need to reference the requisition number of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI’s legal duty to furnish information.

Skills

Node.Js
Python
Show more Show less"
2817332152,Data Engineer,Averity,2021-12-01,United States,United States ,Engineering and Information Technology,Full-time,Hospitals and Health Care,"How would you like to become a Data Engineer at one of the largest healthcare staffing companies in the country? The company is best in class, and was honored by the Association for Talent Development with the 2021 BEST award.




What's the Job?

As a Data Engineer with us, you'll be working on a modern tech stack including Python, SQL, Spark, and Azure. This position collaborates closely with our Data Scientists to ensure the Data group has appropriate data and can efficiently productionalize machine learning models.




Who Are We?

This company is #1 in travel nursing staffing space, and is growing enormously in terms of tech, data, and engineering team. The goal being over 200 by end of 2022. The company connects healthcare professionals with healthcare facilities across all 50 states. Diversity, equity, and inclusion is also the company mantra, celebrating different backgrounds and experiences.

For over a decade, this company has ranked in the nation's top 5,000 fastest growing companies with over 250% growth over a three year period.




What Skills Do I Need?

Fluency in Python, SQL
Experience with Spark or Databricks
Cloud experience, while we are on Azure, we're open to any of the big platforms (AWS, GCP, Azure)
Have worked with Data Scientists or been on a cross functional team in the past




Compensation:

$140,000-$160,000
Full Benefits Package (Vision, Dental, Health)
401(k) with matching
Several other company perks
Fully remote




What's in it For You?

This is great opportunity to take your talents to a leading organization where there is no ceiling to your career progression across any of our business arms. As a Data Engineer on our team, you will be involved in the upswing of new technology in an increasingly competitive space.

Show more Show less"
2825899528,Data Integration Developer,"Worldgate, llc",2021-12-03,United States,"Philadelphia, PA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Financial Services","Job Summary

We are seeking a Data Integration Developer to design and deploy solutions that feed complex applications to support a range of business units. You will use a variety of languages to deliver integrated implementations that drive key business processes, spanning typical business units (Student Information, Transportation, etc.) to both existing third party or home grown applications.

Employees are required to complete an attestation for their vaccination status and are expected to follow any preventative controls and measures to prevent the spread of COVID-19, including but not limited to: wearing a mask at any Worldgate/client facilities (if required), social distancing protocols, and ongoing testing (if required).

Essential Functions/Responsibilities

Understands and supports a common coding methodology; understands object-oriented programming.
Develops interfaces, reports and data structures that span multiple technologies, languages and/or databases.
Develops solutions that exhibit best practices for operational stability, particularly solutions that have dependencies on external applications (homegrown, third party or SAAS).
Provides support to other developers for database intensive applications; conversant in multiple database systems including Oracle (PL/SQL) or Microsoft SQL Server.
Evaluates third party applications for suitability and integration with existing systems.
Analyzes code to increase operating efficiency and/or adapts applications to new requirements.
Develops applications for internal customers, as well as extending existing applications to meet new requirements.
Establishes ownership over integration design, development, implementation and support.
Rapidly develops scope and estimates, as well as risk points for delivering complete technical solutions.
Produces design specifications for projects of various sizes from functional requirements.
Establishes documentation on coding standards; conducts peer code reviews to ensure developers are complying with set standards.
Reviews software packages for deployment and ensures that they adhere to the appropriate operational policies.Responsible to understand Worldgate’s values and behaviors (The Worldgate Way)
Ensure that my daily interactions with Worldgate internal and external parties align to Worldgate’s values and behaviors.

Key Competencies

Business Analysis
Technical Capacity
Problem Solving/Analysis

Education, Experience, & Certifications

Bachelor’s degree from an accredited college or university.
Four years of full-time, paid, professional experience in the programming field, at least three years of which have involved designing applications with relational databases utilizing at least two industry-recognized programming languages.
Willingness and flexibility to support 24/7 projects during off-hours, as needed.

Demonstrated Knowledge Of

SPECIFIC KNOWLEDGE, SKILLS, & ABILITIES:

ETL/ELT applied to an Operational Data Store architecture.
Enterprise class application design.
SQL and relational database management systems, including Oracle, PL/SQL and Microsoft SQL Server.
Development in multiple environments (operating systems, languages, etc.).
UNIX/Linux systems including shell scripting, SFTP, crontab.
Python development, maintenance and enhancements.
Familiarity with phased approach to software testing and deployment, i.e. Development, Test, Production.
Developing software interfaces and applications that allow two disparate systems to interact to facilitate a seamless business process.
Working with complex data analysis and data migrations, including source to target data mapping, transformation, transport and results reconciliation.
The complete software development lifecycle (SDLC): gathering requirements, analyzing requirements, designing a solution approach; developing code, testing, deploying and maintenance and support.
Knowledge of basic Enterprise data warehouse.
Application security practices and policies including encryption, RSA Keys.

Demonstrated Ability To

Work effectively as part of a development team.
Respond to emergency situations and to effect problem resolution processes.
Analyze and resolve complex problems.
Establish and follow development procedures.
Document code, create technical and basic user documentation.
Participate and contribute at meetings with users, business analysts and management.
Present ideas effectively, both orally and in writing.
Establish and maintain effective working relationships.

Worldgate provides equal employment opportunities to all employees and applicants.

Who We Are

Worldgate is a technology consulting firm specializing in solutions that enable our clients to meet and exceed their information technology goals.

What We Do

We partner with software providers who have specifically recognized your needs and have invested in software solutions that cater to the specific objectives and challenges of K-12 school districts and State & Local Government.

No other consulting services firm knows the unique IT-staffing needs of K-12 and Public Sector systems like Worldgate. For nearly 20 years we have worked with some of the nation’s top U.S school systems and municipalities to strategically and cost-effectively assemble teams of experienced Project Managers, Business Analysts, Trainers and other IT staff members. This has enabled our clients to focus on what is most important: their students, staff members, constituents and communities.

What We Are Doing Right

At Worldgate, we believe the most valuable component within our client’s enterprise is not expensive hardware or a sophisticated app - it’s the people behind it.

We believe our company is defined by our values, which shape and influence every decision.

What We Value

Our people and want our team members’ experience with Worldgate to be rewarding, empowering, and enjoyable.

Our clients and respect the opportunities they give us to innovate and serve.

Diversity and the positive change that a diverse workforce and client community can create.

Our communities and the opportunities we have to give back and create a better world.

Diversity, Equity And Inclusion

Worldgate is committed to creating and maintaining a workplace in which all employees have an opportunity to participate and contribute to the success of the business and are valued for their skills, experience, and unique perspectives. This commitment is embodied in company policy and the way we do business at Worldgate and is an important principle of sound business management.
Show more Show less"
2780737727,Big Data Engineer,Collabera Inc.,2021-11-05,United States,"Austin, TX",Information Technology,Full-time,IT Services and IT Consulting,"Complete REMOTE opportunity

Day to Day:







Project: Migration of legacy database, convert datasets into the spark






Attend Team meetings to track progress






Agile environment: daily stand up/ Two-week sprints






Pure development work: code reviews






Stories and task out work






Backlog work






Weekly reviews to track design status






Must Have:





3+ yrs. Of Big Data/ETL
2+ yrs. of Scala
2+ yrs. of Spark
Relational Data Bases- SQL
Communication/ Team Collaboration- Ask questions







AWS,Scala,Python,Spark,Remote,SQL,BigData,Big Data,Developer,Development ,migration ,data,azure,cloud
Show more Show less"
2797288459,Data Engineer,Amazon,2021-11-18,United States,"Dallas, TX","Information Technology, Consulting, and Engineering",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

We are looking for an outstanding Data Engineer who is data-driven, uncompromisingly detail oriented, smart, efficient, and driven to help our business succeed. You have passion for technology. You are keen to leverage existing skills while trying new approaches. You are not tool-centric; you determine what technology works best for the problem at hand and apply it accordingly. You can explain complex concepts to your non-technical customers in simple terms.

We are moving from traditional database technologies to near real time data processing and advanced reporting services built around natural language processing and machine learning.

You will help us analyze large amounts of data, discover and solve real world problems and build metrics and business cases to help business teams to make decisions. You should be motivated self-starter that can work independently in a fast paced, ambiguous environment.


Basic Qualifications

3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, scripting, data warehousing, and building ETL pipelines
Experience in SQL

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Preferred Qualifications

Experience in big-data using Hadoop, Hive, and other open-source tools/technologies
Familiar with AWS tools
Ability to work independently with minimum supervision
Experience in designing and building large data warehouse systems
Strong organizational and multitasking skills with ability to balance competing priorities
Good work experience in BI Reporting tools and databases in a business environment.


Company - Amazon.com Services LLC

Job ID: A1735235
Show more Show less"
2818737900,Data Engineer,Alldus,2021-12-02,United States,"New York, United States",Information Technology and Health Care Provider,Full-time,IT Services and IT Consulting and Hospitals and Health Care,"Company/Role Summary:

Alldus are working with a technology and software company that focuses on providing personalized healthcare insights and recommendations to their customers based on analytics, improving their quality of life.

The company is seeking an AWS Cloud Data Engineer to join a high-performing team that guides clients through each doctor's appointment, pharmacy visit, and bill payment, guaranteeing the best possible treatment at the cheapest possible price. This company is headquartered in New York City, but the position is to work remotely and prefers a candidate on the East Coast.




Responsibilities:

Maintain current ETL pipelines as well as build batch and streaming data pipelines with a variety of tools
Work with the AWS ecosystem and AWS tools to create new systems for data
Create new architectures for data transfer as well as maintain API’s for exposure
Design database schemas to optimize data performance




Requirements:

Experience working with Python, AWS, SQL, Postgres, Apache Spark, and scaling infrastructure
Experience planning, coding, testing, and documenting ETL pipelines as well as managing AWS production environments
Experience building and running applications/services with serverless architectures and containers
Familiarity with pharmacy and medical claims

Why:

This is a full-time opportunity that would allow you to work closely with clients, guiding them through the complexities of healthcare. You’d be working for a company that focuses on valuing the customer by making the healthcare experience more human, while also striving to make impactful advances through strategic and scalable marketing processes.

Show more Show less"
2756109149,Data Engineer,Cognite,2021-11-26,United States,"Austin, TX",Information Technology,Full-time,IT Services and IT Consulting,"Do you see how data can be used, modeled and visualized in new ways to improve decisions in industrial engineering, but you experience that the tools and data availability is insufficient to create impact? If you want to change that, and take part in forming what the future of the industry will look like you should join our Cognite and become a part of the team responsible for delivering Cognite’s cutting edge industry solutions to our customers!

As a Data Engineer, located in Austin, TX, you will design, develop and implement data infrastructure and best-in-class pipelines that collect, connect, centralize and curate data from various internal and external data sources. You will ensure that architectures support the needs of the business, and recommend ways to improve data reliability, efficiency. You are an experienced engineer with a passion for software development, hands-on in designing, implementing, and delivering features for flagship products.

What You'll Do

Partner with Solution Architects to understand client requirements and define queries with subject matter experts
Develop custom extractors using backend technologies and languages i.e Python, Spark, Rest APIs
Customize existing extractors i.e. database extractor using SQL, event streaming using Kafka and deploy using Docker
Create custom data models for data discovery, mapping, and cleansing
Collaborate with product development to turn customer needs into potential product offerings
Prototype data visualization and dashboards

Who You Are

3+ years of experience in a Data intense role
Experience in O&G, Power & Utilities and/or Manufacturing is required
BS or MS degree in computer science or related field
Loves to code, passion for coding, and enjoys sharing that knowledge with others
Strong understanding of data analysis or data science
Experience working with data technologies, such as: ETL, SQL, Python
Ability to work on both internal and external client-facing projects and communicate with key stakeholders
Ability to travel onsite to meet with and engage with clients -- we don’t build solutions in isolation.
Role based in Houston, TX or (Austin, TX w/ travel to Houston)

What Makes Us Great

An opportunity to make an impact on the industrial future and be part of disruptive and groundbreaking global projects
High level of autonomy, ability to influence decisions and to learn from mistakes
Work along side a driven, engaging team with in-depth software expertise and industry experience
Opportunity to join Together@Cognite for social, community, and diversity initiatives
Focus on agility and speed, openness, togetherness, impact, and obligation to speak up
Join a team that truly lives their values and brings their whole selves to Cognite --> watch some of our Cognite Voices Katrine Tjølsen , Petter Reistad .

Perks & Benefits

Competitive Compensation + 401(k) with employer matching
Health, Dental, Vision & Disability Coverages with premiums fully covered for employees and all dependents
Unlimited PTO + flexibility to enjoy it
Paid Parental Leave Program
Learning & Development Stipends
Global Mobility & Exchange Program
Company Paid Friday Lunch via DoorDash + Fully Stocked Fridges

Cognite is a global industrial SaaS company that was established with one clear vision: to rapidly empower industrial companies with contextualized, trustworthy, and accessible data to help drive the full-scale digital transformation of asset-heavy industries around the world. Our core Industrial DataOps platform, Cognite Data Fusion™, enables industrial data and domain users to collaborate quickly and safely to develop, operationalize, and scale industrial AI solutions and applications to deliver both profitability and sustainability. Visit us at www.cognite.com and follow us on Twitter @CogniteData or LinkedIn: https://www.linkedin.com/company/cognitedata

Equal Opportunity

Cognite is committed to creating a diverse and inclusive environment at work and is proud to be an equal opportunity employer. All qualified applicants will receive the same level of consideration for employment; everyone we hire will receive the same level of consideration for training, compensation, and promotion.

We ask for gender as part of our application because we want to ensure equal assessment in the recruitment process. Your answer will help us reach this commitment! However, the question about gender is optional and your choice not to answer will not affect the assessment of your application in any way.
Show more Show less"
2815443983,Data Engineer,23andMe,2021-11-06,United States,"Sunnyvale, CA",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Biotechnology Research","This company is built on science. We make evidence-based decisions. In a world where health is poorly understood, we use data to better understand wellness and disease.We are looking for a Data Engineer who could be a technical powerhouse when scaling data infrastructure, dashboards, tools, and reporting forecasts. As a Data Engineer, you will be working cross-functionally with business domain experts, analytics partners, and engineering teams to design and implement our Data Warehouse model. This is a great role for problem solvers, who can anticipate problems and can also look beyond immediate issues. They will be a self-starter, detail and quality oriented, and passionate about having a huge impact at 23andMe.

We look for people who are curious, inventive, and work to be a little better every single day. In our work together we aim to be smart, humble, hardworking and, above all, collaborative. An ideal candidate brings curiosity, a passion for data, and a deep understanding of the technologies behind data pipelines, warehousing, big data and analytics.

Who We Are

Since 2006, 23andMe’s mission has been to help people access, understand, and benefit from the human genome. We are a group of passionate individuals pushing the boundaries of what’s possible to help turn genetic insight into better health and personal understanding

What You'll Do

We are looking for a Data Engineer with passion for data analytics and product. As a part of the team you will:

Acquire deep business understanding on several domains and build scalable and optimized data solutions that impact many stakeholders.
Be an advocate for data quality and excellence of our platform.
Build close relationships with our partners to understand the value our platform can bring and how we can make it better.
Build tools that help streamline the management and operation of our data ecosystem.
Ensure best practices and standards in our data ecosystem are shared across teams.
Improve data discovery by creating data exploration processes and promoting adoption of data sources across the company.
Has a desire to write tools and applications to automate work rather than do everything by hand.
Comfortable with weekly on-call rotation
Passionate about CI/CD process.
Design, develop and establish KPIs to monitor analysis and provide strategic insights to drive growth and performance.

What You'll Bring

Bachelor's Degree in a quantitative discipline: computer science, statistics, operations research, informatics, engineering, applied mathematics, economics, etc.
5+ years of relevant work experience in analytics, data engineering, business intelligence, research or related fields.
Experience with SQL/Relational databases
Experience with Amazon Web Services: Redshift, S3, Glue,EMR, or Athena
Experience developing low latency data processing solutions like AWS Kinesis, Kafka, Spark Stream processing.
Experience in at least one programming languages (e.g. Python, Java,)
Strong experience with data scheduling tools like Stonebranch(Opswise) or Airflow.
Experience with data visualization using Microstrategy, Tableau, Quicksight, or similar tools.

Strongly Preferred

Master's degree or equivalent in Computer Science, Engineering, Mathematics, Statistics, Economics, or a related field.
Experience using analytics & reporting tools like Microstrategy, Tableau, Quicksight etc.
Experience with Airflow and Kinesis is a plus.
Advanced knowledge and experience building on AWS QuickSight.

About Us

23andMe, headquartered in Sunnyvale, CA, is a leading consumer genetics and research company. Founded in 2006, the company’s mission is to help people access, understand, and benefit from the human genome. 23andMe has pioneered direct access to genetic information as the only company with multiple FDA authorizations for genetic health risk reports. The company has created the world’s largest crowdsourced platform for genetic research, with 80 percent of its customers electing to participate. The platform also powers the 23andMe Therapeutics group, currently pursuing drug discovery programs rooted in human genetics across a spectrum of disease areas, including oncology, respiratory, and cardiovascular diseases, in addition to other therapeutic areas. More information is available at www.23andMe.com.

At 23andMe, we value a diverse, inclusive workforce and we provide equal employment opportunity for all applicants and employees. All qualified applicants for employment will be considered without regard to an individual’s race, color, sex, gender identity, gender expression, religion, age, national origin or ancestry, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, genetic information, military or veteran status, or any other basis protected by federal, state or local laws. If you are unable to submit your application because of incompatible assistive technology or a disability, please contact us at accommodations-ext@23andme.com. 23andMe will reasonably accommodate qualified individuals with disabilities to the extent required by applicable law.

Please note: 23andMe does not accept agency resumes and we are not responsible for any fees related to unsolicited resumes. Thank you.
Show more Show less"
2794023794,Data Engineer,Spring,2021-10-17,United States,"San Francisco, CA",Analyst,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","Spring believes the future of commerce is social, and each day is working towards becoming the world’s leading creator commerce platform. Allowing Creators to build businesses and create products that their fans will love. Spring is a verticalized commerce platform that spans from ideation of a new product idea through delivery to the end customer (including design, customer service and fulfillment). Spring has powered its creators to sell over 40 million products across 120 countries, generating over $1 billion in revenue along the way.

What We’re Looking For...

Data Engineering is critical in realizing our mission by fueling actionable data insights to drive impact across all areas of our business from product direction, marketing strategy and operational excellence. We are looking for a talented Data Engineer to join our team to optimize our technology stack which consists of Snowflake, Fivetran, and Databricks while also working directly with product managers and commercial leads to leverage existing data sources and new data sources to impact our strategy and decision making. This role will focus on data engineering work such as optimizing the existing database/pipelines, bringing in new sources of data, and working internally with the data team.

What You’ll Do...

Manage the data warehouse and pipelines to optimize for cost, speed, and end user access
Own the process behind connecting to new data sources and integrating them into the data warehouse
Work with business teams to create sandboxes that allow for increased data access and empowerment
Inspire new changes to the product or business initiatives through exploration of data
Build intuitive dashboards and visualizations and decks to communicate insights


Requirements

What we need...

5+ years’ experience in a data engineering role managing and improving the data warehouse.
Experience interfacing with API’s to access new data sources to enrich the warehouse
Expert in SQL and can quickly pick up on new schema as database evolves
Expert developer within data visualization tools (e.g. Tableau)
Highly impact driven with insatiable curiosity for how we could be better


Bonus Points:

Experience within a similar stack
Ecommerce experience


Benefits

Happiness is just as important to us as hard work. Here are the benefits you will receive:

Working with talented, collaborative, and entrepreneurial teams
Medical, dental and vision insurance
Company contributions toward Health Savings Accounts (HSA)
Company-paid life insurance and long-term disability
Flex time and paid holidays
401k
Generous stock options
Show more Show less"
2809579682,Data Engineer,Ace Technologies,2021-11-23,United States,"New York, United States",,Contract,,"
Responsibilities:

Gather and document current state data platform
Review and provide updates to envisioned target state data platform
Assist in revising the current development practices
Support BAU tasks/activities
Assist with new development/Enhancements
Assist in effort estimating data projects and develop IFS proposals
Goal here is for us to run a full POD to help expedite the implementation with existing team.


Skills Required:

DBT flow
BI environment (nice to have Looker hands on experience)
Good analysis skills with Python and Panda data framework experience
Excellent SQL knowledge (SNOWFLAKE and relational DB such as MS SQL-Server)
Experience with SQL and job performance tuning must have skills
Show more Show less"
2797255776,Data Engineer,Amazon,2021-11-18,United States,"Sunnyvale, CA","Information Technology, Consulting, and Engineering",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Amazon Fashion Tech is a growing multi-disciplinary team addressing everyday customer needs in online shopping of apparel and shoes (""softlines""). In softlines, the convenience, selection, and price benefits of shopping online have yet to be fully realized. Today the online shopper's largest friction is evaluating size and fit.

Our team’s ultimate goal is for customers to easily discover items they will like and to get the right size and fit on the first try: across the globe, on laptops and mobile, etc. Our technical challenges involve applied science, back-end software engineering, big data engineering and user interface development. We strive to build beautiful, intuitive, responsive user interfaces that our customers will use to discover items, evaluate fit and refine our understanding of their tastes.

We are looking for strong data engineers who can design and scale complex end-to-end data pipelines and develop new engineering patterns that leverage cloud architectures. You will work with scientists and engineers to build scalable data pipelines for machine learning use cases (deep learning, recommendation systems, natural language processing, etc.).

As a Data Engineer In Our Team, You Will

Design and build infrastructure required for data extraction and transformation leveraging AWS ‘big data’ technologies.
Work closely with machine learning and data scientists to scale model training and explore new data sources and model features, recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.
Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency
Work with complex structured and unstructured data (batch and streaming).
Implementing best practices for software development and documentation, making sure designs meet requirements, and delivering high quality work on tight schedules.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc
Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers.
This position is available in Seattle, SF Bay Area, NYC, San Diego and Austin (Texas).


Basic Qualifications

Bachelor’s degree in Computer Science or related field.
3+ years of experience working in Software Engineering / Data Engineering / Data Warehousing roles working in high traffic, fault tolerant, and highly available environments
3+ years of experience with SQL skills and with Big Data Technologies
3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.
Amazon.com is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age

Preferred Qualifications

Master’s degree in computer science, engineering, mathematics or a related technical discipline
5+ years of experience with and detailed knowledge of data warehouse technical architectures, data modeling, infrastructure components, ETL/ ELT, reporting/analytic tools and extracting value from large datasets.
Experience working with AWS services such as Hadoop, Spark, Kinesis, Lambda, SQS/SNS, S3, RDS, Redshift, Glue, DynamoDB, Athena, etc.
Experience with relational database systems (PostgreSQL, MS SQL Server, Oracle, DB2, etc.)
Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
Ability to take loosely defined business questions and translate them into clearly defined technical/data specifications for implementation.
Ability to deal with ambiguity and work with rapidly changing business data
Strong business acumen, proven ability to influence others, strong attention to detail, excellent organization skills, and ability to manage multiple projects.


Company - Amazon.com Services LLC

Job ID: A1683103
Show more Show less"
2797264355,Data Engineer,Amazon,2021-11-18,United States,"Dallas, TX","Information Technology, Consulting, and Engineering",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Are you a high-energy, highly skilled Data Engineer who wants to build and deliver using cutting edge technology that protects millions of people every day? Do you want to invent new technologies while collaborating with the very best software engineers, machine learning scientists and economists in the world? Do you want to push yourself and technology as far as they'll go with a group of smart and fun people?

We are looking for Data Engineers who want to solve some of most complex technical challenges and build solutions for measuring DSI (Downstream impact) to support Amazon's business decision making process which is driven by long term value for our customers . You will work closely with machine learning scientists, software engineers & economists building cutting edge models and predictive analytic solutions at a large scale to build solutions for DSI.

If this sounds like you and you have a history of working on high performance systems then we want you to join our Perfect Order Experience team!

You will be an integral part of an exceptionally talented team. As a DE, you will be responsible for designing and implementing scalable extract, transform, and load (ETL) processes. You will be creating and updating dashboards to provide business Intelligence reports. . You will be processing large data sets to support engineering efforts for DSI.


Basic Qualifications

Bachelor’s Degree in Computer Science/Engineering, Informatics, Mathematics, or a related technical discipline
4+ years of experience in data engineering, data science, business Intelligence or related field.
Extensive experience with demonstrated strength in ETL development, data modeling and data warehousing.
Expert level skills in writing and optimizing SQL queries.
Experience building data products incrementally, integrating and managing large data sets from multiple sources.
Knowledge of data management fundamentals and data storage principles.
Database design and administration experience with various RDBMS, such as MS SQL Server, PostgreSQL, MySQL, etc.
2+ years of experience in any of modern programming or scripting languages( Python, Scala or Java) etc.
Worked in collaborative environment and coached peer and junior engineers.

Preferred Qualifications

Master’s Degree in Data Engineering, Applied Data Science, Data and Web Science, or related certification
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.
Experience using business intelligence reporting tools (AWS QuickSight, Power BI, Tableau, etc.).
Experience architecting data solutions with AWS products including Big Data Technologies (Redshift, RDS, S3, Glue, Athena, EMR, Spark, Hive, etc.) and/or Microsoft Database Software Stack (SQL Server/SSIS/SSAS).
Worked on creating machine learning models and algorithms.


Company - Amazon.com Services LLC

Job ID: A1757886
Show more Show less"
2812938150,Data Engineer,CVS Health,2021-11-25,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Financial Services, and Hospitals and Health Care","Job Description

Looking for opportunities to use cutting edge technologies to construct data pipelines to analyze petabytes of data? Interested in working with data scientists to generate analytical insights that help members make the best decisions for the individual care needs?

As a Data Engineer you will work with our data scientists’ side by side to optimize our ability to engage with members to help them make better healthcare decisions via campaigns. A common campaign for us would include several predictive models that identify specific members to message at specific moments, a suite of creative tactics with varying behavioral economics principles to deliver content, and the use of a large number of channels and apps in a highly coordinated and journey-based fashion - all deployed by our own team through the experimentation platform that we’ve developed.

By joining our organization, you’ll learn about cutting edge machine learning techniques, develop the experiment platform to expand the ability to engage, and launch campaigns at large scale and high velocity.

Some of the responsibilities you will have as a Data Engineer include:

Participating in the design, build and management of large-scale data ETL (Extract / Transform / Load) workflows for real-time and offline analytic processing.
Integrating data from a variety of sources, assuring that they adhere to data quality and accessibility standards.
Collaborating with data scientists to integrate algorithms and models into automated processes.
Designing and implementing scalable, configurable and self-learning marketing campaign platforms.
Applying expertise, judgment and precedents to contribute to the resolution of moderately complex problems.
Leading portions of initiatives of limited scope, with guidance and direction.


Required Qualifications


2+ years of relevant Data Engineering experience.
Applied experience with Python, Java, Scala, or C++.
Experience with Shell Scripts.
Applied experience with SQL and experience in one of the relational databases.
Good software engineering fundamental.
Strong problem-solving skills and critical thinking ability.
Strong collaboration and communication skills within and across teams.


COVID Requirements

COVID-19 Vaccination Requirement

CVS Health requires its Colleagues in certain positions to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, pregnancy, or religious belief that prevents them from being vaccinated.

If you are vaccinated, you are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status within the first 10 days of your employment. For the two COVID-19 shot regimen, you will be required to provide proof of your second COVID-19 shot within the first 45 days of your employment. Failure to provide timely proof of your COVID-19 vaccination status will result in the termination of your employment with CVS Health.
If you are unable to be fully vaccinated due to disability, medical condition, pregnancy, or religious belief, you will be required to apply for a reasonable accommodation within the first 10 days of your employment in order to remain employed with CVS Health. As a part of this process, you will be required to provide information or documentation about the reason you cannot be vaccinated. If your request for an accommodation is not approved, then your employment may be terminated.

Preferred Qualifications


Experience with Spark, Hadoop and or Hive.
Experience within the Healthcare Industry.
Development Experience within Cloud (GCP, AWS and or Azure).

Education

Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline.

Master’s degree or PhD preferred

Business Overview

At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.
Show more Show less"
2787885016,Data Engineer,Hinge,2021-10-16,United States,"New York, NY",Engineering,Full-time,"Computer Software, Internet Publishing, and Consumer Services","As a Data Engineer at Hinge, you will create essential data processes and contribute to components of a modern data pipeline that will be the foundation of Hinge’s decision-making ability. The systems you help create, the problems you help solve, and the support of our analytical minds, will be pivotal to the success of Hinge.

This role is key to Hinge’s success. Not only will you help power the love lives of tons of people, but will play a critical part in the functioning of every team at Hinge, with stakeholders ranging from customer experience to marketing to leadership.

The Data Engineer will be implementing critical ETL pipelines, building fascinating data sets, and improving core functionality that will not only aid the data engineering team, but the rest of the organization. They will be working on an actual big data architecture while concentrating on real-world problems such as building core business reporting.

Responsibilities

Work with our Engineering teams to ensure data is flowing accurately through data creation to our presentation layers.
Write new and innovative ETL processes.
Improve our Data Engineering stack through containerization, data modeling, developing our ETL pipelines, and more.
Use your expertise in data modeling to design, build and maintain our analytics data warehouse that provides clean, accurate, and robust data sets to be leveraged for reporting and analytics.
Work with stakeholders and our Business Intelligence and Data Science subject matter experts in order to translate their needs and expectations into action items and deliverables.
Continue to learn more about the Data Engineering discipline, utilize that knowledge in your deliverables, and identify opportunities to enhance our pipelines.
Contribute meaningful insights and feedback to our team processes.


Requirements

Proficient in Python, SQL, shell scripting, and databases.
3+ years of professional/industry experience.
Experience delivering data products from conception to delivery and with the infrastructure that supports their underlying processes.
Good communication skills (written/verbal).
Experience modeling data sets for different types of sources and business processes.
Passionate about designing elegant ETL processes.
Familiarity with our stack (Kubernetes, Docker, Kafka, Redshift, Airflow, Hive, Looker) and with different modeling techniques such as data vault.


Our Company:

Hinge is the dating app for people who want to get off dating apps. In today’s digital world, singles are so busy matching that they’re not actually connecting, in person, where it counts. Hinge is on a mission to change that. So we built an app that’s designed to be deleted. On Hinge, there are no rules, timers, or games. Instead, you’ll meet your most compatible matches and you’ll have unique conversations over what you’ve shared on your detailed profile. It’s a natural way to find a great first date. Currently, 3 out of 4 first dates lead to second dates, we’re the #1 mobile-first dating app mentioned in the New York Times wedding section, and we’re the fastest growing dating app in the US, UK, Canada, and Australia.

Our Culture:

Authenticity: Share your genuine thoughts and opinions directly.
Courage: Invite and deeply consider challenges and criticism.
Empathy: Be empathetic, communitarian and trustworthy.


We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Show more Show less"
2779848253,Data Engineer,The Wonderful Company,2021-11-26,United States,"Los Angeles, CA",Information Technology,Full-time,Consumer Services,"Company Description

You may know us as FIJI Water, POM Wonderful, Justin Wine, Teleflora and Halos Citrus, but we're all Wonderful – and we have a great opportunity for a Data Engineer. The ideal candidate should have extensive experience working with modern data movement tools such as Azure Data Factory (ADF), Informatica and should have at-least two BI Analytics implementation experience.

Job Description

A Day In The Life at Wonderful:


Participate in design, implementation, and support of a data warehouse and analytics platform
Design and develop robust ETL / ELT processes, primarily using tools like Azure Data Factory (ADF) and Informatica Cloud (IICS).
Perform proof of concepts for innovation and to continuously improve and enhance the capabilities of the data analytics platform.
Develop and maintain strong effective working relationships with team members and internal customers.
Train and educate internal team members as well as partner consultants about best practices in data engineering and governance.


The Wonderful You:


Datawarehouse Design Skills: Focus area includes exceptional skills with data design and management
Strong Experience with data warehousing ETL process design/development/support (Azure Data Factory, Informatica, ODI).
Solid understanding of database design and best practices.
ETL Process Skills : Strong Knowledge of ETL Processes and SQL Query expertise.
Proven experience working with REST APIs and bringing data from REST APIs from multiple sources.
Extensive experience in SQL/PLSQL, Logical SQL Queries and Performance Tuning
Excellent understanding of star/snow-flake schema, SCDs and de-normalized operations
Hands-on experience on BI concepts, architecture and industry best practices
Design, model, document, and guide the logical and conceptual relationship of data and database changes for BI applications.
Experience in leading requirements gathering, gap analysis and create user requirements documentation.
Experience with Microsoft Analytics stack and solid exposure to varied databases such as Snowflake, RedShift, Oracle DW etc.
Experience working with ERP systems data such as Oracle EBS/Fusion (Purchasing, Order Management, Manufacturing and/or Financials modules).
Experience working with agile methodologies using CI/CD techniques in a DevOps environment using Azure DevOps and Git.
Experience with machine learning (Python, R, Azure ML, etc.) is a plus.


Qualifications

Your Contribution to Wonderful:


BS/MS in Computer Science or equivalent with at-least 3 years of experience in designing and building data pipelines and integrations using tools such as Informatica and Azure Data Factory.
In-depth knowledge on Azure components and know-how to integrate various products.
Depth and breadth of experience in ETL and other data analytics related technologies as well as broader integration solutions.
Proven versatility across multiple technologies, applications, and industries with the ability to design, estimate, propose, build, and document enterprise class architecture solutions and systems in complex environments
Excellent written, verbal communication skills, including experience in technical documentation and ability to communicate with senior business managers and executives
Ability to work independently, solve problems, and handle multiple project administration responsibilities.
COVID vaccination will be required for this position unless candidate has a legally valid exemption.


Additional Information

Wonderful's dedication to you:


Competitive benefits package including Medical (including 24/7 online access to a physician), Vision, Dental and 401k with match eligibility
Opportunities for development and internal mobility
Manager and leadership training, biweekly L&OD webinars, and eLearning offerings
Companywide problem solving and continuous improvement training
Wonderful Giving (com) - allowing you to donate company money to a cause of your choice
Company focus on wellness and health including virtual yoga and mindful meditation classes


Headquartered in Los Angeles, The Wonderful Company is a privately held $5 billion company dedicated to harvesting health around the world through its iconic consumer brands. The company's 10,000 employees worldwide are committed to bringing consumers everywhere the freshest, most wholesome pistachios, citrus and pomegranates; bottling the finest water and wines; and creating colorful bouquets that are sure to touch the heart. This commitment is reflected in the company's market share: Wonderful Pistachios® is America's No. 1 tree nut and America's fastest-growing snack; Wonderful® Halos® is the No. 1 mandarin orange in America; POM Wonderful® is the No. 1 100% pomegranate brand in America; FIJI® Water is America's No. 1 premium imported bottled water brand; JUSTIN® Wine has the No. 1 Cabernet Sauvignon in California; and Teleflora® is the world's leading floral delivery service.

The Wonderful Company's connection to consumers has health at its heart and giving back at its core. The company has a long-standing commitment to corporate social responsibility, including more than $1 billion invested in environmental sustainability; $65 million in charitable giving, education initiatives, and innovative health and wellness programs each year; and $143 million toward the construction of two charter school campuses in California's Central Valley.

To learn more about The Wonderful Company, its products and its core values, visit www.wonderful.com, or follow us on Facebook, Twitter and Instagram. To view the current Corporate Social Responsibility report, visit www.wonderful.com/csr.

The Wonderful Company is proud to be an Equal Opportunity employer. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.

EEO is the law
Show more Show less"
2822651176,Data Engineer,Nomi Health,2021-12-01,United States,"Austin, Texas Metropolitan Area",Information Technology and Engineering,Full-time,IT Services and IT Consulting and Computer Software,"WHAT IS A DAY IN THE LIFE?




As a Data Engineer, you will provide technical and domain subject knowledge to the company and future customers. You should be comfortable working in a fast-paced, startup environment. You should be able to know how to examine new data systems requirements and implement migration models. You will also spend a good deal of time problem solving, analyzing architecture, and assessing architect models, reviewing data migrations, selecting platforms, and onboarding of data management solutions that meet the technical and operational needs of the business. You must be hands-on with tools and code.




OK, HOW ABOUT A FEW SPECIFIC RESPONSIBILITIES?







Contribute to the development of the AI & ML capabilities for the Nomi Health
Develop and implement data models to guide business decisions
Work in a fast paced, startup environment
Mapping data sources, including descriptions of the business meaning of the data, its uses, its quality, the applications that maintain it and the database technology in which it is stored. Documentation of a data source must describe the semantics of the data so that the occasional subtle differences in meaning are understood.
Documenting interfaces and data movement by recording how mapped data is moved around the virtual enterprise. This includes the frequency of movement, the source and destination of each step, how the data is transformed as it moves, and any aggregation or calculations.
Designing the movement of data through the enterprise, including sources of data and how the data is moved around in order to be improved.
Defining integrative views of data to draw together data from across the enterprise. Some views will use a database of extracted data and others will bring together data in near real time, considering data currency, availability, response times and data volumes. Designing canonical data views to limit technical debt as data flows from point-to-point transformation.
Defining technical standards and guidelines. Assess and document when and how to use the architected producers and consumers, the technologies to be used for various purposes, and models of selected entities, objects, and processes. The guidelines should encourage reuse of existing data stores, as well as address issues of security, timeliness, and quality.
Investigate and participate in emerging technologies and new release Proofs of Concept (PoCs).
Leveraging existing [core] data assets.
Managing related metadata to include business descriptions of the data, details of any calculations or summaries, descriptions of the sources of the data, and indications of data quality and currency.
Communicating the data architecture across the enterprise.
Ensuring a focus on data quality by working effectively with data stewards so they can understand data semantics and identify opportunities for improving data quality.

DATA ENGINEER REQUIREMENTS




Bachelor's degree in Computer Science, Computer Engineering, or relevant field.
A minimum of 2-3 years’ experience in a similar role (production environment preferred)
Must have AWS experience. (Snowflake, Databricks, S3, Glue, RDS, Lambda desirable)
Must have big data experience
Must have coding experience (python preferred)
Experience with building APIs (REST or SOAP)
Familiarity of system concepts and tools within an enterprise architecture framework.
Knowledge of various modern data formats, tools, and methodologies. (Informatics desirable)
Knowledge of Clojure or Go (bonus)
Ability to work in a fast paced, startup environment
Excellent organizational and analytical abilities.
Outstanding problem solver.
Good written and verbal communication skills.

Benefits

Health, Dental, Vision, 401k with match, Commuter benefits with Great Pay, plus Equity.




WHO ARE WE?




The way healthcare is paid for and delivered in America today is fundamentally flawed, making it cost too much and take too long for most Americans. We pay more for our health care than any other developed country, and yet our healthcare outcomes lag far behind. COVID is a wake up call.




Nomi Health was founded in 2019 as a direct healthcare company with a simple yet bold mission: rewire how we pay for healthcare and how it is delivered in order to create the cost-effective -- and simply effective -- experiences we all deserve as employers, patients and providers.




Our COVID-19 public health programs are a perfect example of a more direct, digital-first health care model at work. Since the start of the pandemic, we have delivered several of the very few “burden-free” testing and vaccination programs in America -- not requiring insurance, a doctor’s note or cost. Our programs have supported millions of Americans with digital scheduling and result delivery and 24-48 hour test result turnaround times, as well as mobile-based programs to take COVID tests and vaccines directly where they are needed most. Our operational know-how means we can deliver these programs to local governments, organizations and employers at among the lowest per unit costs in the country. Today, we are focused on locking arms with governments and organizations on effective COVID response programs that help Americans return to school, work and life.




Having delivered millions of COVID tests and hundreds of thousands of vaccinations to date, Nomi’s journey is just starting in delivering integrated care the way it should be. Our mission won’t rest until we rewire health care infrastructure and deliver the kind of health care experience we all deserve in America.




The system must change, and we’re the ones to do it. Join us on the journey.

Show more Show less"
2817840448,Data Engineer- Public,IBM,2021-12-02,United States,"Raleigh, NC",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $75,000 to $145,000 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment
Prior experience working with clients in the public space
Experience with data integration and data management


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2822651176,Data Engineer,Nomi Health,2021-12-01,United States,"Austin, Texas Metropolitan Area",Information Technology and Engineering,Full-time,IT Services and IT Consulting and Computer Software,"WHAT IS A DAY IN THE LIFE?




As a Data Engineer, you will provide technical and domain subject knowledge to the company and future customers. You should be comfortable working in a fast-paced, startup environment. You should be able to know how to examine new data systems requirements and implement migration models. You will also spend a good deal of time problem solving, analyzing architecture, and assessing architect models, reviewing data migrations, selecting platforms, and onboarding of data management solutions that meet the technical and operational needs of the business. You must be hands-on with tools and code.




OK, HOW ABOUT A FEW SPECIFIC RESPONSIBILITIES?







Contribute to the development of the AI & ML capabilities for the Nomi Health
Develop and implement data models to guide business decisions
Work in a fast paced, startup environment
Mapping data sources, including descriptions of the business meaning of the data, its uses, its quality, the applications that maintain it and the database technology in which it is stored. Documentation of a data source must describe the semantics of the data so that the occasional subtle differences in meaning are understood.
Documenting interfaces and data movement by recording how mapped data is moved around the virtual enterprise. This includes the frequency of movement, the source and destination of each step, how the data is transformed as it moves, and any aggregation or calculations.
Designing the movement of data through the enterprise, including sources of data and how the data is moved around in order to be improved.
Defining integrative views of data to draw together data from across the enterprise. Some views will use a database of extracted data and others will bring together data in near real time, considering data currency, availability, response times and data volumes. Designing canonical data views to limit technical debt as data flows from point-to-point transformation.
Defining technical standards and guidelines. Assess and document when and how to use the architected producers and consumers, the technologies to be used for various purposes, and models of selected entities, objects, and processes. The guidelines should encourage reuse of existing data stores, as well as address issues of security, timeliness, and quality.
Investigate and participate in emerging technologies and new release Proofs of Concept (PoCs).
Leveraging existing [core] data assets.
Managing related metadata to include business descriptions of the data, details of any calculations or summaries, descriptions of the sources of the data, and indications of data quality and currency.
Communicating the data architecture across the enterprise.
Ensuring a focus on data quality by working effectively with data stewards so they can understand data semantics and identify opportunities for improving data quality.

DATA ENGINEER REQUIREMENTS




Bachelor's degree in Computer Science, Computer Engineering, or relevant field.
A minimum of 2-3 years’ experience in a similar role (production environment preferred)
Must have AWS experience. (Snowflake, Databricks, S3, Glue, RDS, Lambda desirable)
Must have big data experience
Must have coding experience (python preferred)
Experience with building APIs (REST or SOAP)
Familiarity of system concepts and tools within an enterprise architecture framework.
Knowledge of various modern data formats, tools, and methodologies. (Informatics desirable)
Knowledge of Clojure or Go (bonus)
Ability to work in a fast paced, startup environment
Excellent organizational and analytical abilities.
Outstanding problem solver.
Good written and verbal communication skills.

Benefits

Health, Dental, Vision, 401k with match, Commuter benefits with Great Pay, plus Equity.




WHO ARE WE?




The way healthcare is paid for and delivered in America today is fundamentally flawed, making it cost too much and take too long for most Americans. We pay more for our health care than any other developed country, and yet our healthcare outcomes lag far behind. COVID is a wake up call.




Nomi Health was founded in 2019 as a direct healthcare company with a simple yet bold mission: rewire how we pay for healthcare and how it is delivered in order to create the cost-effective -- and simply effective -- experiences we all deserve as employers, patients and providers.




Our COVID-19 public health programs are a perfect example of a more direct, digital-first health care model at work. Since the start of the pandemic, we have delivered several of the very few “burden-free” testing and vaccination programs in America -- not requiring insurance, a doctor’s note or cost. Our programs have supported millions of Americans with digital scheduling and result delivery and 24-48 hour test result turnaround times, as well as mobile-based programs to take COVID tests and vaccines directly where they are needed most. Our operational know-how means we can deliver these programs to local governments, organizations and employers at among the lowest per unit costs in the country. Today, we are focused on locking arms with governments and organizations on effective COVID response programs that help Americans return to school, work and life.




Having delivered millions of COVID tests and hundreds of thousands of vaccinations to date, Nomi’s journey is just starting in delivering integrated care the way it should be. Our mission won’t rest until we rewire health care infrastructure and deliver the kind of health care experience we all deserve in America.




The system must change, and we’re the ones to do it. Join us on the journey.

Show more Show less"
2817840448,Data Engineer- Public,IBM,2021-12-02,United States,"Raleigh, NC",Other,Full-time,Computer Hardware Manufacturing,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As an IBM Data Engineer, you will directly help clients transform their business and solve complex problems. You will be involved in the transformation by doing the critical work of getting the data in a state where and it be effectively used by the client for its business, analytics and AI. You will do this at scale with understanding of the needs of the various stakeholders. You will be responsible for implementing solutions that are cutting edge and utilizing best practices with solid documentation, unit testing, performance testing, capacity planning, monitoring, alerting and governing.

If you are hired into a Colorado work location, the anticipated compensation range for the position $75,000 to $145,000 is based on a full-time schedule. Your ultimate compensation may vary depending on your job-related skills and experience. For part time roles, the compensation will be adjusted appropriately.

POST COVID you are expected to travel up to 75% (4 days a week) of the time to meet our client needs across the US.

Benefits

Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.

http://www-01.ibm.com/employment/us/benefits/

CAREER GROWTH

At Our Core, We Are Committed To Believing And Investing In Our Workforce Through

Our goal is to be essential to the world, which starts with our people. Company-wide we kicked off an internal talent strategy program called Go Organic.

Skill Development: Helping our employees grow their foundational skills

Finding the Dream Career at IBM: Navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations

Diversity of People: Diversity of thought driving collective innovation

In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.

CORPORATE CITIZENSHIP

With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!

http://www.ibm.com/ibm/responsibility/initiatives.html

http://www.ibm.com/ibm/responsibility/corporateservicecorps

Required Technical and Professional Expertise


BS in Data Science, Machine Learning, Statistics, or AI
3+ years of proficiency in Python
3+ years of experience with applying deep learning and machine learning techniques to solve problems
3+ years of Experience with common Python libraries used by data scientists (e.g., NumPy, Pandas, SciPy, scikit-learn, matplotlib, Seaborn, etc.) and deep learning libraries (pytorch or Tesnorflow)
Experience working with structured and unstructured data
Experience building end-to-end data pipelines and deploying in the Cloud (AWS or Azure or GCP)
Demonstrated ability to think strategically about business, product, and technical challenges in an enterprise environment
Experience in Agile development
Excellent oral and written communication skills
Ability to collaborate in a team environment
Prior experience working with clients in the public space
Experience with data integration and data management


Preferred Technical And Professional Expertise


Master’s degree in quantitative Field
Demonstrated leadership abilities, with team leader or managerial experience preferred
Proficiency with dealing with big data (Spark)
Hands-on experience deploying analytical models to solve business problems
Experience working in a consulting or services environment


About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

This job requires you to be fully COVID-19 vaccinated prior to your start date, where legally permissible. Proof of vaccination status will be required. If you are unable to be vaccinated due to medical, pregnancy or religious reasons, we offer accommodations in accordance with applicable law.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

Benefits

In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to

IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work.


12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19.
World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals.
Well-being programs to support mental and physical health.
Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.).
Select educational reimbursement opportunities.
Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe.
Giving and volunteer programs to benefit charitable organizations and local communities.
Discounts on retail products, services, and experiences.


We consider qualified applicants with criminal histories, consistent with applicable law.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
Show more Show less"
2799404051,Data Engineer,Amazon,2021-11-18,United States,"Seattle, WA","Information Technology, Consulting, and Engineering",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Are you ready to change Prime? Join our team of data professionals!

Are you somebody that likes to use big data to drive business decisions? Do you enjoy building data applications used worldwide by business leaders? Do you want to be part of the data team which measures the pulse of Prime and drives change? If your answer is yes, join our team. We are the analytical arm of Prime globally. We work with country leaders, product managers, marketing and finance to ensure Prime remains one of the most loved membership programs.

What is Prime? It’s a membership program including over 150 million members in more than 18 countries. Prime offers some of the best shopping and entertainment experiences with Amazon. Prime members enjoy Prime FREE One-Day Shipping and Prime FREE Same-Day Delivery in more than 8,000 cities and towns, two-hour delivery with Prime Now in more than 30 major cities and unlimited Free Two-Day Shipping on more than 100 million items. In addition, in the U.S., members enjoy unlimited access to award-winning movies and TV entertainment with Prime Video; unlimited access to Prime Music, Prime Reading, Amazon Photos, Twitch Prime; early access to select Lightning Deals, Whole Foods Market discounts and more.

As part of the global Prime Analytics team, we build scalable data solutions to enable insight generation in addition to providing analytical support for flagship initiatives within Amazon. Example data solutions include 1) campaign analyzer, a tool which allows business leaders to A/B test product launches and marketing campaigns and 2) variance analyzer, a tool which enables country leaders to examine the movement of any business KPI along multiple dimensions and determine rate/mix effects. Recent analytical projects include impact measurement of 1 day shipping introduction, analysis of nation-wide brand campaigns and investigation of usage patterns to recommend products and campaigns to increase customer satisfaction.

As a Data Engineer in this team, you will collaborate closely with business leads and product managers working on improving Prime member satisfaction. You will work on creating analytical solutions, which help pinpoint, predict and surface customer pain points. Your analytical solutions will be used across the globe to ensure customer satisfaction with Prime continuously improves. As a successful candidate, you will be able to ingest and analyze complex data sets to help drive actionable insight, enable automation of insight where possible and ensure scalability, reliability, accuracy and performance of Prime analytical solutions.


Basic Qualifications

Bachelor’s degree in a technical field
Proficiency in at least one modern programming language such as Scala, Java, C# or Python.
Proficiency in manipulating big data and building analytical solutions
SQL/ETL expertise
3+ years of relevant work experience

Preferred Qualifications

MS in a technical or business field
5+ years of progressively responsible work experience
Experience building interactive, scalable data solutions
Experience in building large scale distributed data processing pipelines
Ability to take a project from scoping requirements through actual launch of the project
Experience with AWS technologies including Cradle, EMR, Spark, S3 etc.
Ability to deal well with ambiguity
Strong sense of ownership, urgency, and drive
Demonstrated ability to drive operational excellence and best practices.
Excellence in technical communication with peers, partners, and non-technical cohorts
“ Ability to work on a diverse team or with a diverse range of coworkers”

“Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us

We believe passionately that employing a diverse workforce is central to our success and we make recruiting decisions based on your experience and skills. We welcome applications from all members of society irrespective of age, gender, disability, sexual orientation, race, religion or belief.”


Company - Amazon.com Services LLC

Job ID: A1413009
Show more Show less"
2798045833,Data Engineer,Amazon,2021-11-18,United States,"Austin, TX","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

WW Consumer Fin Tech (WWCFT) team is looking for an outstanding Data Engineer who is data-driven, uncompromisingly detail oriented, smart, efficient, and driven to help our business succeed. You have passion for technology. You are keen to leverage existing skills while trying new approaches. You are not tool-centric; you determine what technology works best for the problem at hand and apply it accordingly. You can explain complex concepts to your non-technical customers in simple terms.

As a Data Engineer, you will be working in one of the world's largest and most complex data warehouse environments. You will design, implement and support scalable data infrastructure solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests. You will be exposed to cutting edge AWS big data technologies. You should have excellent business and communication skills to be able to work with business owners and Tech leaders to gather infrastructure requirements, design data infrastructure, build up data pipelines and data-sets to meet business needs. You stay abreast of emerging technologies, investigating and implementing where appropriate.

Your major responsibilities will include

Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies.
Explore and learn the latest AWS technologies to provide new capabilities and increase efficiencies.
Designing and implementing complex pipelines and other BI solutions.
Work closely with business owners, developers, Business Intelligence Engineer to explore new data sources and deliver the data.


Basic Qualifications

Bachelor's degree in Engineering, Mathematics, or a related technical discipline
1+ years of industry experience in Data Engineering, BI Engineer, or related field with a track record of and extracting value from bigdata
Hands-on experience and advanced knowledge of Python etc.
Strong experience in distributed data Data and Data Warehousing

Preferred Qualifications

Masters in mathematics, statistics, economics, or other quantitative fields.
5+ years of experience as a Data Engineer, BI Engineer or related field in a company with large, complex data sources.
Experience working with AWS big data technologies ( )
Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.
Familiarity with solving data quality issues and auto detection algorithms

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon.com Services LLC

Job ID: A1618337
Show more Show less"
2826976247,Data Engineer,RavenTek,2021-12-04,United States,"Tysons Corner, VA",Information Technology,Full-time,Internet Publishing,"Description:


RavenTek is seeking a Data Engineer to work with our engineering team to identify and implement the most optimal solutions for our customer. The Data Engineer be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company's data architecture to support our next generation of products and data initiatives.



.

Requirements:







Required Security Clearance: TS/SCI with FSP








Primary Responsibilities:



Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data' technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Qualification Requirements:



Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing big data' data pipelines, architectures, and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing, and extracting value from large, disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable big data' data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Required Education and Experience:



Bachelor's degree in mathematics, statistics, computer science, or a business-related field, experience can be substituted in lieu of degree
At least 8 years of professional experience
5+ years of experience in a Data Engineer role

Other Requirements:



This position may require that you be vaccinated against Covid-19 unless you need a reasonable accommodation for religion or a health-related need.








Employment Type: Full Time / Permanent








Working Conditions:



Business work hours are on site and set from Monday through Friday, 40 hours a week.








Physical Requirements:



Employee needs to be able to sit at a workstation for extended periods; use hand(s) to handle or feel objects, tools, or controls; reach with hands and arms; talk and hear. Most positions require ability to work on desktop or laptop computer for extended periods of time reading, reviewing/analyzing information, and providing recommendations, summaries and/or reports in written format. Must be able to effectively communicate with others verbally and in writing. Employee may be required to occasionally lift and/or move moderate amounts of weight, typically less than 20 pounds. Regular and predictable attendance is essential.








Background Screening/Check/Investigation:



Successful Completion of a Background Screening/Check/Investigation will/may be required as a condition of hire.








ADA: RavenTek will make reasonable accommodations in compliance with the Americans with Disabilities Act of 1990.








EEO/AA: RavenTek does not discriminate on the basis of race, color, national origin, sex, religion, age, disability, sexual orientation, gender identity, veteran status, height, weight, or marital status in employment or the provision of services and is an equal access/equal opportunity/affirmative action employer.








PM20



Show more Show less"
2748657885,Data Engineer,Zoom,2021-11-25,United States,United States,Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2824759967,Data Engineer,GovernmentCIO,2021-12-02,United States,United States,Information Technology,Full-time,Management Consulting,"As a Data Engineer, you will help with the development of data stores and the integration of data feeds, and pipelines used to support machine learning models and advanced statistics to improve OIT’s response posture to system events impacting end users and Veterans. You will explore new technologies and devise strategy for upgrading data storage infrastructure and will collaborate with other technical leads in designing data solutions. In this role you will directly support a chief data scientist team lead, working alongside analytics and data science professionals.

Areas of support include:

Deliver strategic direction for data architecture and data storage

Develop Entity Relationship Diagram to manage change to the logical schema and generate physical tablespaces to effectively manage data storage and capacity.

Primary directive will be to create data interfaces (ETL, API) to import essential data from ServiceNow and similarly with other disparate near-real time data sources.

Help improve and automate existing data processes and pipelines to create greater efficiency in production of analytic products

Provide high quality data to be used in cross-functional analytics models and interactive dashboards

Leverage methods to extract difficult or unstructured data from systems

Uses modern data science tools (ex: Python, R, SQL) to support creation of predictive models that identify impactful trends or insight related to Major Incident Management (MIM), Problem Management (PM), High Priority Incident (HPI), Critical Priority Incident (CPI), and Root Cause Analysis (RCA)

Qualifications

Education and Experience:

Bachelor’s degree in Computer Science, Engineering, Statistics, Information Technology, Business, or related field.

Knowledge of Python, R, SQL

Entity relationship modeling using tools to manage schema changes and physical storage (e.g. ERWin or other modeling tool).

Database Administration experience (SQL Server)

Data engineering in data integrations in relational (SQL Server) and insight into big data environments (Hadoop, HDInsight, Spark, Hive, etc.)

5+ years of related experience

8 to 10 years of relevant experience may be substituted for education (13-15 years total)

Skills:

Ability to communicate with multiple audiences to present findings, material, or other pertinent information with contract leadership, client and business stakeholders, and team members.
Experience working with cross-functional teams to accept and provide guidance and feedback
Ability to work independently and proactively.

Show more Show less"
2789628260,Data Engineer,Zoom,2021-12-03,United States,"Joliet, IL",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Job Summary

We’re looking for a Data Engineer who can find out the solution to support the requirement on service operation and product development. As a Big Data Engineer, you’ll understand and manage our data, work with the engineering team and operation team to figure out the tough problem about service operation and product design.

Job Responsibilities

Gather and process raw data at scale.
Process unstructured data into structured data, manage schema of new data.
Manage data access to protect data in a safe way.
Read, extract, transform, stage and load data to selected tools and frameworks as required.
Perform tasks such as writing scripts, write SQL queries, etc.
Work closely with the operation team to advise the solution about service scalability, health monitoring and refining optimization by data analysis.
Work closely with the engineering team to monitor product performance and track product quality.
Analyze processed data.
Monitoring data performance and modifying infrastructure as needed.
Define data retention policies.

Job Requirements

5+ years of recent experience in data engineering.
Bachelor’s Degree or more in Computer Science or a related field.
Experiences on Cloudera CDH platform or AWS Cloud Services, Spark programing, Impala SQL Language, Analyze data via Hive, etc.
A solid track record of data management showing your flawless execution and attention to details.
Programming experience, ideally in Python, Java or Scala, and willingness to learn new programming languages to meet goals and objectives.
Experience in Shell scripting, JavaScript or other programming languages is a plus.
Knowledge of ETL, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks.
Experience processing large amount of structured and unstructured data, including integrating data from multiple sources.
Experience in production support and troubleshooting.
You find satisfaction in a job well done and thrive on solving head-scratching problems.

Language requirement: English, Mandarin is plus

Minimum

Colorado Salary Range or On Target Earnings:

$97,920.00 USD

Maximum

$181,170.00 USD

In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here. Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram
Show more Show less"
2798583623,Data Engineer,VisitPay,2021-11-18,United States,United States,,Full-time,,"VisitPay, an R1 company, is looking for multiple Data Engineers to help us disrupt and revolutionize the patient payment and billing experience in health care.  As a Data Engineer, you will be responsible for the development of data integration processes, which will be used to move, cleanse, and transform large amounts of data between multiple systems. The work you do will directly contribute to the success and growth of VisitPay.




Key Activities:

 Design, build, deploy and support complex data pipelines that drive both internal and client-facing products
 Identify, design, and implement internal process improvements through automation, optimizing data delivery, redesigning infrastructure for greater scalability, etc.
 Develop fully automated data pipelines (CICD)
 Collaborate across multiple cross-functional teams including product, software development, QA, and end users.
 Work effectively on a product-driven agile team and collaborate with other data teams to drive organization wide efficiencies. 

Competencies for success:

 Thrives on challenges and loves learning
 Is self-driven, diligent, and enjoys solving problems
 Wants to be part of a high-growth, high-innovation company that will revolutionize a market
 Prefers a collaborative environment and is comfortable working with others and giving and receiving feedback 

Qualifications:

1+ years of significant SQL development experience
1+ years of recent object-oriented programming experience in Python, C# or .Net
 Hands-on experience developing ETL/data integration solutions
 Experience working with large, complex data sets
 Excellent analytical, conceptual, troubleshooting, and problem-solving skills
 Experience with PowerShell programming
 Experience with version control (GIT)
 BS in Computer Science, Information Systems, or related field 

Desired Experience:

 Experience working with Azure Databricks
 Experience working in a secure HIPAA/PHI environment
 Experience with hospital and/or financial systems

Location:

 Boise, ID or remote.
 We will only consider applicants who reside within the U.S. 




Why VisitPay?

VisitPay is an R1 company that works closely with some of the nation’s largest and most well-respected health systems to provide innovative and compelling SaaS-based products. We are poised to capture significant share in the massive and growing self-pay market. Our solutions help healthcare systems optimize their revenue while providing patients with a much improved and friendly billing experience.

With R1, VisitPay offers a competitive and comprehensive benefits package, inclusive culture and commitment to a work-life balance with a team that strives to deliver outstanding results.




Equal Employment Opportunity Employer

R1 RCM Inc. (“the Company”) is dedicated to the fundamentals of equal employment opportunity. The Company’s employment practices , including those regarding recruitment, hiring, assignment, promotion, compensation, benefits, training, discipline, and termination shall not be based on any person’s age, color, national origin, citizenship status, physical or mental disability, medical condition, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status or any other characteristic protected by federal, state or local law. Furthermore, the Company is dedicated to providing a workplace free from harassment based on any of the foregoing protected categories.




If you have a disability and require a reasonable accommodation to complete any part of the job application process, please contact us at 312-496-7709 for assistance.  

To learn more, visit: R1RCM.com

Show more Show less"
2805259162,Big Data Operations Engineer - Automation,Zoom,2021-11-23,United States,United States,Engineering and Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","About The Team

We are looking for a Big Data Operation Engineer with strong automation skills to ensure smooth function of data pipeline, self-motivated to continuously find optimization and deliver excellent results leveraging various tools.

About The Role

Understand Big Data architecture and implement large-scale data processing environment
Design then implement highly effective automated methods to build and update big data infrastructure
Manage and operate Big Data application system stack on daily basis
Determine operation metrics to measure operation and service quality
Setup goals to effectively increase service quality to meet business and operation's requirements
Work with the Big Data engineers to ensure data ingestion, transformation and data at rest smoothly
Drive issue resolutions and root cause analysis with on-call duty
Monitor data performance and modify infrastructure

About You

3+ years of recent experience in data operation engineering
Bachelor's Degree or more in Computer Science or a related field
You will report to your hiring manager and work with different teams in the Zoom Meeting Vertical
You developer with python, shell scripting, and Java to automate infrastructure buildup and changes
You have experience with manageability and automation interface of AWS services
You are experienced in Cloudera CDH/CDP platform or AWS Cloud Services, e.g., EC2, EMR will be a big plus
You hold operation, production support, and troubleshooting experience
You have knowledge of system design and implementation towards infrastructure management and operations
You have programming experience in Ansible, Terraform, Chef (or any infrastructure as code), and will learn new programming languages to meet goals
You find satisfaction in a job well done, feel happy to help team members and solve complex issues together

Benefits

At Zoom, we care about our employees, their families, and their well-being. As part of our award-winning workplace culture and commitment to delivering happiness, our benefits program offers a variety of perks, benefits, and options to help employees maintain their physical, mental, emotional, and financial health; support work-life balance; and contribute to their community in meaningful ways.

Ensuring a diverse and inclusive workplace where we learn from each other is core to Zoom’s values. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records as well as any qualified applicants requiring reasonable accommodations in accordance with the law.

We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.

Given Zoom’s status as a federal contractor, we are subject to President Biden’s Executive Order requiring COVID-19 vaccinations for all US employees. As such, Zoom requires all US employees, including remote employees, to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law.

Explore Zoom

Hear from our leadership team
Browse Awards and Employee Reviews on Comparably
Visit our Blog
Zoom with us!
Find us on social at the links below and on Instagram

Show more Show less"
2811358368,Data Engineer,CVS Health,2021-11-24,United States,"New York, NY",Information Technology,Full-time,"IT Services and IT Consulting, Financial Services, and Hospitals and Health Care","Job Description

Looking for opportunities to use cutting edge technologies to construct data pipelines to analyze petabytes of data? Interested in working with data scientists to generate analytical insights that help members make the best decisions for the individual care needs?

As a Data Engineer you will work with our data scientists’ side by side to optimize our ability to engage with members to help them make better healthcare decisions via campaigns. A common campaign for us would include several predictive models that identify specific members to message at specific moments, a suite of creative tactics with varying behavioral economics principles to deliver content, and the use of a large number of channels and apps in a highly coordinated and journey-based fashion - all deployed by our own team through the experimentation platform that we’ve developed.

By joining our organization, you’ll learn about cutting edge machine learning techniques, develop the experiment platform to expand the ability to engage, and launch campaigns at large scale and high velocity.

Some of the responsibilities you will have as a Data Engineer include:

Participating in the design, build and management of large-scale data ETL (Extract / Transform / Load) workflows for real-time and offline analytic processing.
Integrating data from a variety of sources, assuring that they adhere to data quality and accessibility standards.
Collaborating with data scientists to integrate algorithms and models into automated processes.
Designing and implementing scalable, configurable and self-learning marketing campaign platforms.
Applying expertise, judgment and precedents to contribute to the resolution of moderately complex problems.
Leading portions of initiatives of limited scope, with guidance and direction.


Required Qualifications


2+ years of relevant Data Engineering experience.
Applied experience with Python, Java, Scala, or C++.
Experience with Shell Scripts.
Applied experience with SQL and experience in one of the relational databases.
Good software engineering fundamental.
Strong problem-solving skills and critical thinking ability.
Strong collaboration and communication skills within and across teams.


COVID Requirements

COVID-19 Vaccination Requirement

CVS Health requires its Colleagues in certain positions to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, pregnancy, or religious belief that prevents them from being vaccinated.

If you are vaccinated, you are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status within the first 10 days of your employment. For the two COVID-19 shot regimen, you will be required to provide proof of your second COVID-19 shot within the first 45 days of your employment. Failure to provide timely proof of your COVID-19 vaccination status will result in the termination of your employment with CVS Health.
If you are unable to be fully vaccinated due to disability, medical condition, pregnancy, or religious belief, you will be required to apply for a reasonable accommodation within the first 10 days of your employment in order to remain employed with CVS Health. As a part of this process, you will be required to provide information or documentation about the reason you cannot be vaccinated. If your request for an accommodation is not approved, then your employment may be terminated.

Preferred Qualifications


Experience with Spark, Hadoop and or Hive.
Experience within the Healthcare Industry.
Development Experience within Cloud (GCP, AWS and or Azure).

Education

Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline

Master’s degree or PhD preferred

Business Overview

At CVS Health, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.

We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.
Show more Show less"
2798090611,Data Engineer,Amazon,2021-11-18,United States,"Seattle, WA","Strategy/Planning, Analyst, and Information Technology",Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Description

Love data as much as we do? Want to influence at Amazon? We have the career for you.

Amazon's Employee Services Technology (ES Tech) team is seeking an outstanding Data Engineer to join our BI team to build out the data platform with all of the data ingestion mechanisms required for the initiative. Our platform delivers business intelligence to a diverse, global community of internal customers from one of the world’s largest and most complex data sets. Amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable.

You will be responsible for designing and implementing data solutions using Amazon cloud technologies. A successful candidate knows and loves working with business intelligence ETL tools, is comfortable accessing and working with big data from multiple sources, and passionately partners with the business to identify strategic opportunities and deliver results. You should have an internal drive to answer “why?” questions, excellent analytical abilities, strong technical skills, as well as superior written and verbal communication skills. S/he would be a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoy working in a fast-paced dynamic environment.

Responsibilities Include

Build robust and scalable data integration (ETL) pipelines using SQL, Python and Mulesoft.
Build and deliver high quality data architecture to support business analyst, data scientists, and customer reporting needs.
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources.
Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers.
Design and development ETL mappings within data integration tool primarily for Salesforce applications.
Drive the collection of new data and the refinement of existing data sources to continually improve data quality and implement business logic using efficient transformations.


Basic Qualifications

1+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL
Build robust and scalable data integration (ETL) pipelines using SQL and Python.
Experience with Big Data Technologies.
2+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.
2+ years of experience in scripting languages like Python etc.
3+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.
Experience building ETL on Mulesoft.

Preferred Qualifications

Experience with AWS services including S3, Redshift, EMR and Kinesis.
Ability to work independently and problem solve with little to no direction.
Impeccable customer service focus with a demonstrated desire to exceed expectations.
Attention to detail; you prioritize multiple tasks simultaneously without sacrificing the ability to dive deep.
Mulesoft certification a plus.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.


Company - Amazon.com Services LLC

Job ID: A1530057
Show more Show less"
2766254874,Data Engineer,American Express,2021-12-01,United States,"Phoenix, AZ",Information Technology,Full-time,Financial Services,"“You Lead the Way. We’ve Got Your Back.

At American Express, we know that with the right backing, people and businesses have the power to progress in incredible ways. Whether we’re supporting our customers’ financial confidence to move ahead, taking commerce to new heights, or encouraging people to explore the world, our colleagues are constantly redefining what’s possible - and we’re proud to back each other every step of the way. When you join #TeamAmex, you become part of a diverse community of over 60,000 colleagues, all with a common goal to deliver an exceptional customer experience every day.”

There’s a difference between having a job and making a difference. American Express has been making a difference in people’s lives for over 160 years, backing them in moments big and small, granting access, tools, and resources to take on their biggest challenges and reap the greatest rewards. We’ve also made a difference in the lives of our people, providing a culture of learning and collaboration, and helping them with what they need to succeed and thrive. We have their backs as they grow their skills, conquer new challenges, or even take time to spend with their family or community. And when they’re ready to take on a new career path, we’re right there with them, giving them the guidance and momentum into the best future they envision. Because we believe that the best way to back our customers is to back our people.

At American Express the Enterprise Platforms team was created in 2018 as a fundamental part of the company’s Framework for Winning. Core to our purpose is reimagining the platform solution-delivery model to dramatically improve our business outcomes, strategic agility, speed to market, and delivery effectiveness. Our Enterprise Salesforce team of over 400 colleagues power this mission by developing Sales & Marketing solutions which harness the power of Data, Machine Learning, and Artificial Intelligence to offer powerful selling and re-selling engines to grow our business. Our platforms support nearly 30k users across the company to manage our customer relationships and grow our business using the full suite of Salesforce capabilities.

We’re always looking to grow our Salesforce team with the best talent and have a full spectrum of positions available for all experience levels and disciplines. Working at Amex will provide an opportunity to apply and extend your skills to Service Cloud, Marketing Cloud, Einstein, Tableau, Big data technologies and an extensive list of App Exchange capabilities. In return we expect a passionate and positive “can do” attitude, clear and logical communication skills, a team player, and someone willing to bring in new ideas and challenge the status quo to accelerate our transformation journey.

The Engineer plays a critical role in helping us transform our technology and architecture and delighting our customers with best in class technology platforms. Our Engineers not only understand how technology works, but how that technology intersects with the people who count on it every single day. Innovative ideas and new perspectives are at the core of how we create a more powerful, personal and fulfilling experience for all our customers. So, if you’re passionate about crafting breakthrough applications and making an impact on an audience of millions, look no further.

Job Responsibilities

Build ETL pipelines to analyze, combine and organize raw data from different sources.
Sometimes be involved in conducting complex data analysis and transform the result into visual report using data visualization tools.
Prepare data pipelines to create features for prescriptive and predictive modeling.
Collaborate with data scientists and architects to build end to end AI powered products.
Perform hands on coding and configuration to deliver solutions that impact multiple platforms and products.
Debug complex issues spanning multiple systems.
Harness the opportunities to build Intellectual Property within the team and for the enterprise.
Develop and improve our CI/CD workflow tools and processes
Promote inner sourcing.
Evangelize industry best practices.
Seek to understand your customer's needs and problems
Learn new technologies and drive opportunities for adoption.
Manage risks and issues as well as cross dependencies with other teams. Communicate effectively with internal teams and client to address technical design and functional gaps.
Partner with stakeholders to continuously upgrade Enterprise platforms as per industry standards and Technology stack latest offerings.


Employment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions.

BS degree or higher in computer science or related discipline.
4+ years of demonstrated experience in Agile development, application design, software development, and testing.
Good knowledge of Algorithms and Data structures, Software Design patterns and enterprise integration patterns.
Strong Hands-on Big data technologies like Apache Spark Data frame and Datasets, Hive Query Language, HDFS.
Experience in Java, Python, Scala languages.
Good understanding of CI/CD processes leveraging Jenkins, SBT, XLR and Maven.
Knowledge/ experience in Elastic Cache, RDBMS and NoSQL databases.
Hands-on experience on implementing RESTful APIs using Java and Python frameworks is a plus.
Experience in building ETL pipelines using tools like NIFI, Informatica, Ab Initio.
Ability to implement scalable, high performing, secure, highly available solutions.
Self-Starter, Problem solver, Highly collaborative and adaptive.
Excellent communication skills, enthusiasm and ability ask questions, understand business value.
Any knowledge of Salesforce ecosystem is a plus.


American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, age, or any other status protected by law.
Show more Show less"
2825117198,Data Engineer,Fearless,2021-11-08,United States,"Baltimore, MD",Information Technology,Full-time,"IT Services and IT Consulting, Computer Software, and Internet Publishing","Fearless is looking for a Mid level Data Engineer too add to our diverse team of 170+ employees (and counting!).

What you'll be doing:

We're looking to change the world by building software with a soul, and we want your help. The Data Engineer architects, builds, and maintains scalable tooling and infrastructure for managing data in a system. This includes building automated data pipelines, managing data storage, and creating systems to make data available to users. The data engineer also supports the team by performing tasks like data analysis, interpretation, extraction, formatting, labeling, cleaning, transformation, reduction, discretization, annotation, loading and processing.

What you should know:

This position is located in Baltimore.
The position is operating remotely during COVID-19. We value our culture and connection, plus flexibility to work from home. We are currently designing hybrid options.
To protect our Fearless community, and in consideration of the Executive Order on Ensuring Adequate COVID Safety Protocols for Federal Contractors, the U.S. Centers for Disease Control and Prevention (CDC), the Department of Labor, Occupational Safety and Health Administration (OSHA), and a variety of public health authorities, Fearless is implementing a mandatory COVID-19 vaccination policy for our full workforce. This vaccine mandate will help keep our people and our community safe through this ongoing health crisis.
All new employees must have received or be willing to receive the COVID-19 vaccine by date of hire to be considered for the position. Reasonable accommodations for qualified exemption requests will be considered.


Why we're excited about you:

We need your Data Engineering skills!

What other skills will help you succeed at Fearless? Glad you asked! We're excited about candidates who:

Take initiative for their own growth through personal leadership
Design and implement internal processes for automating data delivery and optimization
Build and maintain secure tooling and infrastructure for scalable automated data pipelines and machine learning models that align with the business objectives
Collaborate with data science engineers and business analysts to improve data models that solve challenges and support data-driven decision making
Support regular ad-hoc data and analysis needs to better understand customer behaviors.
Implement processes and systems to monitor data quality and volume, ensuring data is accurate and available
Perform data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Evaluate data and machine learning tools for efficacy


As well as:

Strong communication skills-both writing and orally what the data is communicating so that the customer can understand it
Strong analytical and problem-solving skills with attention to detail
Experience with Machine Learning and Deep Learning Tools and Software
Experience in statistics, data processing, or data annotation
Understanding of quality assurance with respect to data and models
Proficiency with programming languages including Python, R, SAS, and/or Java
Experience working with at least one data analysis tool like Hadoop, Apache Spark, or cloud-provider equivalents
Effective organizational and time management skills with the ability to work independently, as well as with remote teams, under strict project deadlines
Ability and willingness to work virtually and with online collaboration tools
Ability to operate and manage work, strategically reason, and build relationships and influence others
Empathy-recognizing that data has humans behind it


At Fearless, we believe in sharing knowledge, fresh perspectives, and unique interests as individuals and as a company, so we're also interested to know what makes you tick. We want to know where your interests and passions lie so we can all grow together.

Compensation:

We believe in paying people fairly, so we've established a compensation model that ensures everyone at Fearless — regardless of race, ethnicity, gender, sexual orientation, disability, religion, age, nationality, or negotiation skills — is given equal pay for equal work.

So, what's next?

Over the years, we've honed a 3-step interview process that helps ensure that every employee we hire is the right fit for us and that we're the right fit for them. If we think you're a good fit, we'll get in touch and start scheduling your interviews!

Cultural Interview - We're a people-first company, so we always start off by getting to know more about you, how you work, what your career goals are, and what you're passionate about. This is your opportunity to ask questions and get a feel for Fearless, so don't be shy!
Technical Interview - This is where we get into the nitty gritty of the project. During the Technical Interview, you'll be interviewed by our Passion Coaches and/or the team's Project Lead to make sure your skills align with the project requirements.
Business Interview - At this point, you've made it to the final frontier! The Business Interview is when you'll meet with Fearless leadership to dot the i's, cross the t's, and determine whether or not we'll be moving forward with the hiring process.


Why Fearless?

Our people make us who we are. We believe that every member of the Fearless team has something to share, and we value the unique viewpoint you'll bring to our community. But we value your community, too, so we offer fulfilling work that stays in balance with the rest of life. Because everyone has different needs, desires, and goals, our benefits offer the choices and flexibility that our team members need to live well and succeed. Here are a few highlights of our benefits package:

Flexible schedule
Family-friendly workplace
3 weeks accrued PTO + 1 week sick leave + 10 federal holidays + your birthday off
100% coverage of the employee-only premium for HSA, HMO, or PPO plan and Employee Wellness Plan
Tech, education / training, and snack allowances
Free parking in downtown Baltimore / public transit coverage
Safe Harbor 401(k) plan with employer contributions


About Fearless:

Fearless is a full-stack digital services firm in Baltimore that delivers sleek, modern, and user-friendly software designed to push the boundaries of possibility. It's our mission to build software with a soul — tools that empower communities and make a difference — so we can create a world where good software powers the things that matter.

That's not our only goal, though. We also strive to create a purple culture that makes our employees excited to come to work every day. That's why we encourage our employees to pursue their passions, both in and out of the office. With built-in company mentoring, continuing education support, flexible schedules, and a family-friendly work environment, we've created a culture that allows our team to thrive professionally and personally.

Fearless believes in equal opportunity employment. We won't discriminate against any employee or applicant on the basis of race, gender, nationality, age, religion, disability, military status, or sexual orientation. As a company and as individuals, we're committed to providing an inclusive and welcoming environment for our team, our family members, our clients, our subcontractors, and our vendors.
Show more Show less"
2790057047,"Data Engineer (Cloud), USA Remote",Dell Technologies,2021-11-10,United States,"Round Rock, TX",Information Technology,Full-time,"IT Services and IT Consulting, Computer Hardware Manufacturing, and Computer Software","Join us to do the best work of your career and make a profound social impact as a Data Engineer with our Data Engineering team based USA Remote with our global Services organization at Dell Technologies.

Data Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods and models. What’s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.

Our stack includes Azure, S3(Object Store), Databricks, Apache Airflow, and Apache Kafka, Teradata, Greenplum.

In this role you will use Open Source technologies like Spark, Scala/Python/Java in Azure/Dell cloud environment to design and develop data processing applications to provide our business stake holders with faster insights into their business; including assisting in creating and supporting data processing solutions in on-prem/cloud environments for our business units, at scale.

You will develop, test and deploy the solutions for warehousing systems. In addition, you will participate and contribute in resolving any issues with the systems as well as creating technical documentation outlining the design, troubleshooting and repair steps.

Take the first step towards your dream career

Essential Requirements

Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role:

Expertise in data munging/wrangling methods on large datasets
ETL processes, data integration, data quality framework
Strong SQL Skills along with an understanding of data warehouse methodologies
Hands on experience with building data or machine learning pipelines, familiar with machine learning concepts
Experience in Azure ADLS, Databricks, DataFactory and experience with one or more relevant tools (Spark, Sqoop, Flume, Kafka, Amazon Kinesis); Programming languages: Python (Intermediate)
Collaboration experience and success, including excellent communication skills verbally, in writing and in presentations

Desired Requirements

Familiarity with Postgres, Greenplum, or Teradata is an asset
Experience building large-scale machine-learning infrastructure that have been successfully delivered to customers
Knowledge of Advanced SQL; also programming languages such as Java, Scala

Here’s our story; now tell us yours.

Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress.

What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life -- while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more.

We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today.

You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here.

Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Equal Employment Opportunity Policy here.

Job Id: R139173
Show more Show less"
2813063290,Data Engineer,Tech Mahindra,2021-11-29,United States,"Cincinnati, OH",Information Technology,Contract,IT Services and IT Consulting,"3+ Years of IT Experience




Skills (Must Have):

Python – Ingestion/manipulation of large datasets to S3 using pandas
Python – Consumption of data from REST APIs using requests
Any language (Most preferably Python) – Small automation tasks within AWS S3, Glue, Athena
Experience developing in AWS. Key services: S3, Lambda, Athena, Step Functions, Glue
General familiarity with a variety of other systems such as Oracle/Postgres, REST APIs, Splunk
Deployment of resources to AWS using Serverless
General understand of Infrastructure as Code




Skills (Nice to have):

AI/ML experience in Sagemaker
General knowledge of cyber security practices and frameworks
Experience writing complex queries in Presto/Hadoop







Please send your Resume to ss00662625@techmahindra.com

Show more Show less"
2809708917,Data Engineer,Prudential Financial,2021-10-29,United States,"Newark, NJ",Information Technology,Full-time,Financial Services,"Job Classification

Technology - Software Development/Quality Engineering

Prudential’s Global Technology team is the spark that ignites the power of Prudential for our customers and employees worldwide. Our organization plays a critical and highly visible role in delivering customer-driven solutions across every area of the company. The Global Technology team is made up of diverse, agile-thinking, and highly-skilled professionals; we use our combined capabilities to enable the organization with innovation, speed, agility, scalability and efficiency.

The Global Technology team takes great pride in our culture where digital transformation is built into our DNA. When you join the Global Technology organization at Prudential, you’ll unlock a challenging and impactful career – all while growing your skills and advancing your profession at one of the world’s leading financial services institutions.

Data Tech team at Prudential Financials is looking for a Data Engineer to join a diverse team dedicated to providing best in class data services to our customers, stakeholders and partners.

As a part of our CDO organization, you will work with our ML Engineers, Data Scientist and various BUs to define solutions for operationalizing data-driven decision making in a cost effective and scalable manner.

Qualifications

Bachelor's degree in Computer Science, Software Engineering, MIS or equivalent combination of education and experience
Experience implementing, supporting data lakes, data warehouses and data applications on AWS for large enterprises
AWS Solutions Architect or AWS Big Data Certification preferred
Programming experience with Java, Python/Scala, Shell scripting
Solid experience of AWS services such as CloudFormation, S3, Glue, EMR/Spark, RDS, Redshift, DynamoDB, Lambda, Step Functions, IAM, KMS, SM etc.
Solid experience implementing solutions on AWS based data lakes.
Experience implementing metadata solutions leveraging AWS non-relational data solutions such as ElastiCache and DynamoDB.
Experience in AWS data lake/data warehouse/business analytics
Experience in system analysis, design, development, and implementation of data ingestion pipeline in AWS
Knowledge of ETL/ELT
Working experience with Hadoop, HDFS, SQOOP, Hive, Python, and Spark is desired Experience working on Agile projects

Requirements

3+ years of experience as Data developer
Experience developing business applications using NoSQL/SQL databases.
Experience working with Object stores(S3) and JSON is must have
Should have good experience with AWS Services - API Gateway, Lambda, Step Functions, SQS, DynamoDB, S3, ElasticSearch.
Serverless application development using AWS Lambda.

Responsibilities

Designing, building and maintaining efficient, reusable, and reliable architecture and code.
Ensure the best possible performance and quality of high scale web applications and services.
Participate in the architecture and system design discussions
Independently perform hands on development and unit testing of the applications;
Collaborate with the development team and build individual components into complex enterprise web systems;
Work in a team environment with product, frontend design, production operation, QE/QA and cross functional teams to deliver a project throughout the whole software development cycle;
Responsible to identify and resolve any performance issues
Keep up to date with new technology development and implementation
Participate in code review to make sure standards and best practices are met

Plus

Experience with business intelligence tools such as Tableau, Power BI or equivalent
Aware of Machine learning algorithms (supervised/unsupervised)
Working experience in Informatica toolset (Power Center, TDM)
-

Prudential Financial, Inc. of the United States is not affiliated with Prudential plc. which is headquartered in the United Kingdom.

Prudential is a multinational financial services leader with operations in the United States, Asia, Europe, and Latin America. Leveraging its heritage of life insurance and asset management expertise, Prudential is focused on helping individual and institutional customers grow and protect their wealth. The company's well-known Rock symbol is an icon of strength, stability, expertise and innovation that has stood the test of time. Prudential's businesses offer a variety of products and services, including life insurance, annuities, retirement-related services, mutual funds, asset management, and real estate services.

We recognize that our strength and success are directly linked to the quality and skills of our diverse associates. We are proud to be a place where talented people who want to make a difference can grow as professionals, leaders, and as individuals. Visit www.prudential.com to learn more about our values, our history and our brand.

Prudential is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, ancestry, sex, sexual orientation, gender identity, national origin, genetics, disability, marital status, age, veteran status, domestic partner status , medical condition or any other characteristic protected by law.

The Prudential Insurance Company of America, Newark, NJ and its affiliates.

Note that this posting is intended for individual applicants. Search firms or agencies should email Staffing at staffingagencies@prudential.com for more information about doing business with Prudential.

People With Disabilities

If you need an accommodation to complete the application process, which may include an assessment, please call (800) 433-8960, prompt 4 or email accommodation.h&w@prudential.com.

Please note that the above number and email are solely for individuals with disabilities requesting an accommodation. If you are experiencing a technical issue with your application or an assessment, please email careers@prudential.com to request assistance.
Show more Show less"
2817120245,Data Engineer,RE/MAX,2021-12-02,United States,United States,Information Technology,Full-time,Leasing Real Estate,"Typical Day:

A Data Engineer at RE/MAX works on our data ingestion platform which collects data from 500+ sources in near real time. A typical day for this role would be working with stake holders, designing, creating or troubleshooting data pipelines, analyzing data trends, and optimizing data retrieval. We manage the backend platform that powers remax.com, mobile apps, machine learning apps, BI tools and more. Our day to day tasks and projects support our staff and business needs from top to bottom.




Scope:

RE/MAX, LLC is looking for a Data Expert and software developer to support our microservices and database backend. This Data Engineer role will ensure the solutions are optimized for delivering critical data in a highly availability, real time environment. The Data Engineer will create, maintain and enhance data pipelines and APIs with an enterprise micro-services lens. Success in this role is bridging the demand for integration with the best fit solution for all stakeholders.  




This role will also work with the data aggregation team to map data from MLS boards to a common schema.




Essential Duties:

Develop data ingestion and pipeline solutions from business and technical data requirements
Support existing integrations and API solutions that power our Elasticsearch database
Map and maintain MLS board data feeds
Build and foster strong relationships with all levels of technical and non-technical audiences
Work effectively and collaboratively with internal and external stakeholders to ensure timely delivery of implementation
Enhance data integration services for the overall benefit of sustainability and usability
Address problems, change, and/or challenges quickly and enthusiastically




Qualifications & Skills:

Experience with data ingestion and data warehousing at scale
Experience building and maintaining distributed microservice architecture
Fluent in Go programming language
Experience with AWS
Preferred Real Estate background, managing IDX, IDX plus and VOW data feeds
Experience with async NodeJS a plus
Experience with Elasticsearch or other NoSQL datastore
Demonstrate work ethic based on a strong desire to exceed
Highly self-motivated and directed, with keen attention to detail
Proven analytical and creative problem-solving abilities
Experience working in an Agile environment




Hiring Range: $90k-105k




Now is your chance to become part of a world-class, industry leading organization that touts the #1 real estate brand in the world! RE/MAX is a business that builds businesses. We, alongside booj, our award-winning technology company, specialize in providing the tools, training and tech to our real estate network, which includes RE/MAX and Motto Mortgage franchises, agents, brokers and consumers. Join us and build a career where your contribution is heard, your innovative ideas are valued, and hard work and collaboration truly makes a difference. 




RE/MAX LLC, Motto Mortgage and booj are an equal opportunity employer committed to diversity and inclusion, as well as non-discrimination in employment. All qualified applicants receive consideration without regard to race, color, religion, gender, sexual orientation, national origin, age, veteran status, disability unrelated to performing the essential task of the job or other legally protected categories. All persons shall be afforded equal employment opportunity.

Show more Show less"
2820739153,Data Conversion Engineer,Daxko,2021-12-02,United States,"Birmingham, AL",Production,Full-time,Staffing and Recruiting,"Company Description

Daxko powers health & wellness throughout the world. Every day our team members focus their passion and expertise in helping health & wellness facilities operate efficiently and engage their members.

Whether a neighborhood yoga studio, a national franchise with locations in every city, a YMCA or JCC--and every type of organization in between--we build solutions that make every aspect of running and being a member of a health and wellness organization easier and delightful.

Job Description

As a Data Conversion Engineer, you are responsible for executing data conversions between client systems and Daxko's products including ETL processing and maintenance of internal tools designed for process automation.

The Data Conversion Engineer reports to the Data Conversion Technical Team Lead.

You Will Also

Execute high-level custom scripting from SQL/PHP/C# to manipulate and move data from legacy to Daxko systems
Provide scoping and project timeline analysis
Be responsible for critical analysis and building automation
Perform site creation with minimal issues/some help
Work closely with Daxko's Implementation team and communicate risks and/or roadblocks regarding assigned projects appropriately

Qualifications

One (1) to three (3) years of experience reporting and/or ETL Scripting using SQL
Moderate to advanced knowledge of SQL, T-SQL, and table structures - Writing needed statements, with some guidance on structure and best practices.
Ability to work well with other implementation teams and provide help/feedback on internal implementation processes
Demonstrated ability to determine table structure and build statements
Demonstrated ability to put complex ideas into layman's terms
Display consistent professional demeanor and make positive contributions to the team
Self-starter with a demonstrated ability to both work well on a team and work independently. High competency in attention to detail and prioritization
Excellent organizational skills and attention to detail
Excellent time management skills with a proven ability to meet deadlines
Strong analytical and problem-solving skillsÂ

Bonus Points For

Bachelor's Degree in Computer Science, Engineering, or related field
Microsoft SQL Certification
MySQL or SQL Server preferred
Higher-level database training
PL/SQL, T-SQL, and building routines for repeatability
Coding with PHP and/or C#

Additional Information

Daxko is dedicated to pursuing and hiring a diverse workforce. We are committed to diversity in the broadest sense, including thought and perspective, age, ability, nationality, ethnicity, orientation, and gender. The skills, perspectives, ideas, and experiences of all of our team members contribute to the vitality and success of our purpose and values.

Some Of Our Favorites Include

We truly care for our team members, and this is reflected through our offices, benefits, and great perks.

Flexible paid time off
Affordable health, dental, and vision insurance options
Monthly fitness reimbursement
401(k) matching
New-Parent Paid Leave
1-month paid sabbatical every 5 years
Casual work environments

All your information will be kept confidential according to EEO guidelines.

Daxko is dedicated to pursuing and hiring a diverse workforce. We are committed to diversity in the broadest sense, including thought and perspective, age, ability, nationality, ethnicity, orientation, and gender. The skills, perspectives, ideas, and experiences of all of our team members contribute to the vitality and success of our purpose and values.

Some Of Our Favorites Include

We truly care for our team members, and this is reflected through our offices, benefits, and great perks.

Flexible paid time off
Affordable health, dental, and vision insurance options
Monthly fitness reimbursement
401(k) matching
New-Parent Paid Leave
1-month paid sabbatical every 5 years
Casual work environments
Show more Show less"
2793123942,Big Data Engineer,LGZ New Media,2021-11-10,United States,"Philadelphia, PA",Information Technology,Contract,IT Services and IT Consulting,"Experience And Requirements

A successful Data Engineer will have the following:

"" Must be from Data warehouse/Big data background.

"" Experience in advanced Apache Spark processing framework, spark programming languages such as Scala/Python/Advanced Java with sound knowledge in shell scripting.

"" Experience in working with Core Spark, Spark Streaming, Data Frame API, Data set API, RDD APIs & Spark SQL programming dealing with processing terabytes of data. Specifically, this experience must be in writing """"Big Data"""" data engineering jobs for large scale data integration in AWS.

"" Advanced SQL experience using Hive/Impala framework including SQL performance tuning

"" Experience in writing spark streaming jobs integrating with streaming frameworks such as Apache Kafka or AWS Kinesis.

"" Create and maintain automated ETL processes with special focus on data flow, error recovery, and exception handling and reporting

"" Gather and understand data requirements, work in the team to achieve high quality data ingestion and build systems that can process the data, transform the data

"" Knowledge of using, setting up and tuning resource management framework such as standalone spark, Yarn or Mesos.

"" Experience in physical table design in Bigdata environment

"" Experience working with external job schedulers such as autosys, aws data pipeline, airflow etc.

"" Experience working in Key/Value data store such as Hbase

"" Experience in AWS services such as EMR, Glue (server less architecture), S3, Athena, IAM, Lambda and Cloud watch is required.""

Job Duties And Responsibilities

"" Evangelist for data engineering function leveraging big data processing framework.

"" Creation and optimization of data engineering pipelines for analytics projects.

"" Support data and cloud transformation initiatives

"" Support our software engineers and data scientists

"" Contribute to our cloud strategy based on prior experience

"" Understand the latest technologies in a rapidly innovative marketplace

"" Independently work with all stakeholders across the organization to deliver enhanced functionality""
Show more Show less"
2777350308,Big Data Engineer/PySpark Developer,Synechron,2021-11-15,United States,"Jersey City, NJ","Information Technology, Consulting, and Engineering",Full-time,"IT Services and IT Consulting, Information Services, and Computer Software","Synechron is seeking for PySparkDeveloper/Big Data Engineer. This role can be served from either Jersey City, NJ.




About Synechron:-

Synechron is one of the fastest-growing digital, business consulting & technology firms in the world. Specialized in financial services, the business’ focus on embracing the most cutting-edge innovations combined with expert knowledge and technical expertise has allowed Synechron to reach $650+ million in annual revenue, 10,000 employees and 20 offices worldwide. Synechron is agile enough to invest R&D into the latest technologies to help financial services firms stand at the cutting-edge of innovation; yet, also large enough to scale any global project. Learn more at: www.synechron.com




Synechron draws on over 15 years of financial services IT consulting experience to provide expert systems integration expertise and technical development work in highly-complex areas within financial services. This includes: Enterprise Architecture & Strategy, Application Development & Maintenance, Quality Assurance, Infrastructure Management, Data & Analytics and Cloud Computing. Synechron is one of the world’s leading systems integrators for specialist technology solutions including: Murex, Calypso, Pega, and others and also provides traditional offshoring capabilities with off-shore development centers located in Pune, Bangalore, Hyderabad, and Chennai as well as near-shoring capabilities for European banks with development centers in Serbia. Synechron’s technology team works with traditional technologies and platforms like Java, C++, Python, and others as well as the most cutting-edge technologies from blockchain to artificial intelligence. Learn more at: http://synechron.com/technology




Requirement:

Sound understanding and experience with Hadoop ecosystem (Cloudera). Able to understand and explore the constantly evolving tools within Hadoop ecosystem and apply them appropriately to the relevant problems at hand.
Experience in working with a Big Data implementation in production environment
Must have experience with Big Data technologies like Hadoop, Spark, Kafka, Kudu etc.
Must have experience with Spark using Python/PySpark
Sound knowledge of relational databases (SQL) and experience with large SQL based systems.
Experience in query optimization, performance tuning of the complex SQL queries.
Benchmark and debug critical issues with algorithms and software as they arise.
Lead and assist with the technical design/architecture and implementation of the big data cluster in various environments.
Able to guide/mentor development team for example to create custom common utilities/libraries that can be reused in multiple big data development efforts.
Provide technical resources to assist in the design, testing and implementation of software code and infrastructure to support data infrastructure and governance activities.
Collaborate with cross-functional teams Practice and enforce Agile and Scrum development methodologies




Desired Skills

Previous experience in the financial services industry
Understanding of industry trends and relevant application technologies
Experience in designing and implementing analytical environments and business intelligence solutions




Synechron’s Diversity & Inclusion Statement

Diversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programmes.

All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.

Show more Show less"
2822658073,Data Engineer,"IDR, Inc.",2021-12-01,United States,United States ,Information Technology,Full-time,IT Services and IT Consulting and Computer Software,"Exciting and fully remote opening for a Data Engineer working on Audience Targeting Products. The Data Engineer will assist in the development of a long-term product roadmap alongside delivery team, stakeholders, and leadership.




Desired Experience:

Experience working with SQL and NoSQL Databases
Skilled in developing Apache Spark applications, Apache Spark Streaming is a Plus
Experience working with Big Data technologies
Knowledge of Scala or Java Programming language
Experience with Containerization software such as Docker is a Plus
Bachelor’s Degree is Preferred




Why IDR?

20+ Years of Proven Industry Experience in 4 major markets
Employee Stock Ownership Program (ESOP)
Dedicated Engagement Manager who is committed to you and your success
Medical, Dental, Vision, and Life Insurance
ClearlyRated’s Best of Staffing® Client and Talent Award winner 7 years in a row
Show more Show less"
2649186505,"Software Engineer, Data Infrastructure",Asana,2021-11-24,United States,"San Francisco, CA",Engineering and Information Technology,Full-time,"Marketing and Advertising, Computer Software, and Internet Publishing","The Data Infrastructure team builds the infrastructure responsible for consuming, exposing and creating product and product-derived datasets. Our team owns the pipelines that transport and process database data from all of Asana’s product surfaces. We build and operate the infrastructure and services that ensure data accuracy and data availability for stakeholders in Data Science, Business and feature teams.

We’re looking for a n Infrastructure Engineer to build and operate software to make Asana secure, scalable and fast. You will work with the team on deploying and operating existing systems, and build and support platforms and tools that provide high leverage to data consumers.You will guide users of Asana data to use these platforms effectively and champion adopting best practices and better technologies to improve the efficiency, scalability, and stability of our offerings.

What You'll Do

Design, build, and operate streaming and batch services used by all of Asana
Build infrastructure to enable evaluation and reporting on product experiments
Co-create secure patterns/practices for data systems
Collaborate with infrastructure and data science to scale up data processing to meet the rapid data growth at Asana
Design and implement tooling and automation for clustering, scaling, monitoring, data access and alerting
Participate in the on-call rotation, investigate and resolve production problems

About You

A strong interest in building scalable and performant distributed systems with a focus on eliminating risks
Can think intuitively about systems and services and write high quality code; we care much more about your general engineering skills than knowledge of a particular language or framework.
Take pride in working on projects to successful completion involving a wide variety of technologies and systems.
You are comfortable helping the team build cohesion and team processes
Experience working in large, high-quality codebases
Experience with our tech stack - Scala, Python, Spark, Airflow, Kubernetes, AWS-based infrastructure

Does the above sound like it might be you? Then we’d love to hear from you. Our goal is to provide a hiring and working experience in which all people know they are equally respected and valued. So whatever it is that makes you unique—your gender identity or expression, sexual orientation, religion, ethnicity, age, citizenship, educational background, socioeconomic status—we value it, and we’d love to see what you might add to our team.

About Us

Asana helps teams orchestrate their work, from small projects to strategic initiatives. Millions of teams around the world rely on Asana to achieve their most important goals, faster. Asana has been named a Top 10 Best Workplace for 5 years in a row, is Fortune's #1 Best Workplace in the Bay Area, and one of Glassdoor’s and Inc.’s Best Places to Work. After spending more than a year physically distanced, Team Asana is safely and mindfully returning to in-person collaboration, incorporating flexibility that adds hybrid elements to our office-centric culture . With 11+ offices all over the world, we are always looking for individuals who care about building technology that drives positive change in the world and a culture where everyone feels that they belong.

We believe in supporting people to do their best work and thrive, and building a diverse, equitable, and inclusive company is core to our mission. Our goal is to ensure that Asana upholds an inclusive environment where all people feel that they are equally respected and valued, whether they are applying for an open position or working at the company. We welcome applicants of any educational background, gender identity and expression, sexual orientation, religion, ethnicity, age, citizenship, socioeconomic status, disability, and veteran status.


Show more Show less"
